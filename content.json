{"pages":[{"title":"About","text":"1.任何一件事，其过程往往比结果更加动人，勿要辜负生命对你的恩赐！ 2.生命的乐趣正在于此,只要坚持不懈,在逆境中不气馁,时来运到下或会出现令人惊喜,有似柳暗花明的转机。 Live @ChongQing, China MailBox :","link":"/about/index.html"},{"title":"404 Not Found","text":"Oooops, the page you&#39;re looking for is missing!This page may be deleted or does not existHome Page &gt;","link":"/404.html"}],"posts":[{"title":"10g rac管理命令","text":"10g RAC管理命令简介《大话Oracle RAC》 1.olsnode olsnode显示集群节点信息列表。 12345678910111213[oracle@oel1:/home/oracle]$ olsnodes -hUsage: olsnodes [-n] [-p] [-i] [&lt;node&gt; | -l] [-g] [-v] where -n print node number with the node name -p print private interconnect name with the node name -i print virtual IP name with the node name &lt;node&gt; print information for the specified node -l print information for the local node -g turn on logging -v run in verbose mode[oracle@oel1:/home/oracle]$ olsnodes -n -i -poel1 1 orcl1-prv orcl1-vip.oraclema.comoel2 2 orcl2-prv orcl2-vip.oraclema.com 2.oifcfg oifcfg用来管理网络组件，包括两张物理网卡和三个IP地址。 123456[oracle@oel1:/home/oracle]$ oifcfg iflisteth0 192.168.56.0eth1 10.10.56.0[oracle@oel1:/home/oracle]$ oifcfg getifeth0 192.168.56.0 global publiceth1 10.10.56.0 global cluster_interconnect 以上输出表面eth0网段为192.168.56.0，属于Public类型IP，及VIP及Public IP，eth1为心跳网卡。 添加新网卡，setif不会去检查是否存在物理网卡，以下命令表示为集群添加网段为10.0.0.0，类型为Public的网卡test0 123456789101112131415161718192021222324[oracle@oel1:/home/oracle]$ oifcfg setif -global test0/10.0.0.0:public#查看主机网络配置，明显没有test0这张网卡[root@oel1:/]# ip ad sh1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 16436 qdisc noqueue link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000 link/ether 08:00:27:63:8f:74 brd ff:ff:ff:ff:ff:ff inet 192.168.56.123/24 brd 192.168.56.255 scope global eth0 inet 192.168.56.125/24 brd 192.168.56.255 scope global secondary eth0:1 inet 192.168.56.126/24 brd 192.168.56.255 scope global secondary eth0:23: eth1: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast qlen 1000 link/ether 08:00:27:55:44:e5 brd ff:ff:ff:ff:ff:ffinet 10.10.56.123/24 brd 10.10.56.255 scope global eth1#但在Cluster配置中已经有了这个网卡[oracle@oel1:/home/oracle]$ oifcfg getifeth0 192.168.56.0 global publiceth1 10.10.56.0 global cluster_interconnecttest0 10.0.0.0 global public#删除网卡配置[oracle@oel1:/home/oracle]$ oifcfg delif -global test0[oracle@oel1:/home/oracle]$ oifcfg getifeth0 192.168.56.0 global publiceth1 10.10.56.0 global cluster_interconnect 3.crsctl/ocrcheck/ocrdump/ocrconfig crsctl在10g中功能较少，但在11g中已经取代了crs_stat，功能大大增强了。10g常用的几个如下： 1234567891011121314151617#检测crs运行状况[oracle@oel1:/home/oracle]$ crsctl check crsCSS appears healthyCRS appears healthyEVM appears healthy#检查votedisk磁盘设置[oracle@oel1:/home/oracle]$ crsctl query css votedisk 0. 0 /dev/raw/raw3 1. 0 /dev/raw/raw4 2. 0 /dev/raw/raw5located 3 votedisk(s).#设置crs随机启动，这个需要以root权限运行[root@oel1:/root]# /u01/app/oracle/product/crs/bin/crsctl enable crs#其实是修改了下面这个文档属性：[root@oel1:/root]# cat /etc/oracle/scls_scr/oel1/root/crsstartenable OCR是存放集群配置信息的地方，是Oracle RAC防止集群健忘症关键机制。在整个集群中，只能有一个主节点(Master Node)对OCR进行读写，其他节点在内存中保留一个OCR拷贝。当集群配置修改时候，主节点会自动同步修改到其他节点。 ocrdump以ASCII方式打印出OCR内容，因此dump出的内容是不能够作为备份恢复的。 ocrcheck用于检查OCR内容的一致性，这个命令不需要参数。 12345678910111213141516171819[oracle@oel1:/home/oracle]$ ocrcheckStatus of Oracle Cluster Registry is as follows : Version : 2 Total space (kbytes) : 200560 Used space (kbytes) : 4592 Available space (kbytes) : 195968 ID : 841952053 Device/File Name : /dev/raw/raw1 Device/File integrity check succeeded Device/File Name : /dev/raw/raw2 Device/File integrity check succeeded Cluster registry integrity check succeeded#上述输出结果是OCR一致，但如果不一致，会在某个OCR盘上出现#”Device/File needs to be synchronized with the other device”[oracle@oel1:/home/oracle]$ cat /etc/oracle/ocr.lococrconfig_loc=/dev/raw/raw1ocrmirrorconfig_loc=/dev/raw/raw2local_only=FALSE ocrconfig命令用于维护OCR磁盘。 1234567891011121314151617181920212223242526272829303132333435[oracle@oel1:/home/oracle]$ ocrconfig -hName: ocrconfig - Configuration tool for Oracle Cluster Registry. Synopsis: ocrconfig [option] option: -export &lt;filename&gt; [-s online] - Export cluster register contents to a file -import &lt;filename&gt; - Import cluster registry contents from a file -upgrade [&lt;user&gt; [&lt;group&gt;]] - Upgrade cluster registry from previous version -downgrade [-version &lt;version string&gt;] - Downgrade cluster registry to the specified version -backuploc &lt;dirname&gt; - Configure periodic backup location -showbackup - Show backup information -restore &lt;filename&gt; - Restore from physical backup -replace ocr|ocrmirror [&lt;filename&gt;] - Add/replace/remove a OCR device/file -overwrite - Overwrite OCR configuration on disk -repair ocr|ocrmirror &lt;filename&gt; - Repair local OCR configuration -help - Print out this help information Note: A log file will be created in $ORACLE_HOME/log/&lt;hostname&gt;/client/ocrconfig_&lt;pid&gt;.log. Please ensure you have file creation privileges in the above directory before running this tool.#查看自动备份[oracle@oel1:/home/oracle]$ ocrconfig -showbackup#导出ocr备份，需要以root用户执行[root@oel1:/root]# /u01/app/oracle/product/crs/bin/ocrconfig -export /tmp/ocr2.dmp -s online#恢复ocr，同样要用root执行，恢复前建议先停止crs[root@oel1:/root]# /u01/app/oracle/product/crs/bin/ocrconfig -import /tmp/ocr2.dmp#添加ocr mirror disk[root@oel1:/root]# /u01/app/oracle/product/crs/bin/ocrconfig -replace ocrmirror /dev/raw/raw21 4.srvctl/crs_stat crs_stat用于查看CRS维护的所有资源的运行状态，最常用的莫过于crs_stat -t。此命令比较简单。 srvctl是集群中维护最常见也是最复杂的命令， 1234567891011121314151617181920212223242526#查看数据库配置[oracle@oel1:/home/oracle]$ srvctl config database -d orcl -aoel1 orcl1 /u01/app/oracle/product/10.2.0/db_1oel2 orcl2 /u01/app/oracle/product/10.2.0/db_1DB_NAME: orclORACLE_HOME: /u01/app/oracle/product/10.2.0/db_1SPFILE: +DATA/orcl/spfileorcl.oraDOMAIN: nullDB_ROLE: nullSTART_OPTIONS: nullPOLICY: AUTOMATICENABLE FLAG: DB ENABLED#删除/添加数据库/实例到Clusterware中--删除$srvctl remove instance -d orcldb -i orcldb1$srvctl remove instance -d orcldb -i orcldb2$srvctl remove database -d orcldb--添加$ srvctl add database -d orcldb -o /u01/app/oracle/products/10.2.0/db$srvctl remove instance -d orcldb -i orcldb1$srvctl remove instance -d orcldb -i orcldb2#添加service$srvctl add service -d orcl -s orcl_taf -r orcl1,orcl2 -P BASIC--启动$srvctl start service -d orcl -s orcl_taf其他的详细用法可参照srvctl -h。 5.附录 OCR及Votedisk全部丢失且无备份情况下恢复Cluster。Clusterware是一种集群管理软件，在DBA的世界中，Oracle的Clusterware就是专门管理RAC的，虽然Oracle说可以用它管理其他集群，但是我还没见过其他集群底层跑Oracle的Clusterware管理的。RAC是多实例共享一个数据库的集群。因此，RAC可以说既可以托管于Clusterware，又独立于Clusterware。OCR及Votedisk只是保留集群配置及投票信息的。因此，在数据库没损坏的情况下，是可以重新构建Clusterware底层，以达到恢复目的的。在10g升级11g的过程中，同样可以用这个道理先装好11g的GI，用GI管理10g的集群，最后再升级DB。 以下为重构过程： 1234567891011121314151617181920212223242526#停止所有节点CRScrsctl stop crs#以root用户执行CRS_HOME下脚本，删除集群节点信息[root@oel1:/root]# /u01/app/oracle/product/crs/install/rootdelete.sh#在节点1执行以下脚本[root@oel1:/root]# /u01/app/oracle/product/crs/install/rootdeinstall.sh#继续在上述同一个节点执行脚本[root@oel1:/root]# /u01/app/oracle/product/crs/root.sh#其他节点执行上述脚本，注意最后的输出[root@oel2:/root]# /u01/app/oracle/product/crs/root.sh#netca配置监听，确认注册到了Clusterware#添加ASM、数据库，实例到新的Clusterwaresrvctl add asm -n oel1,-i +ASM1 -o $ORACLE_HOMEsrvctl add asm -n oel2,-i +ASM2 -o $ORACLE_HOME#手工添加Private IP到ASM实例的pfile中，启动ASM实例+ASM1.cluster_interconnects=&apos;10.10.56.123&apos;+ASM2.cluster_interconnects=&apos;10.10.56.124&apos;srvctl start asm -n oel1srvctl start asm -n oel2#添加数据库，实例到集群中srvctl add database -d orcl -o /u01/app/oracle/product/10.2.0/db_1srvctl add instance -d orcl -i orcl1 -n oel1srvctl add instance -d orcl -I orcl2 -n oel2#修改实例和ASM的依赖关系srvctl modify instance -d orcl -i orcl1 -s +ASM1srvctl modify instance -d orcl -i orcl2 -s +ASM2 1234#启动数据库前修改Private IP地址SQL&gt; alter system set cluster_interconnects=&apos;10.10.56.123&apos; scope=spfile sid=&apos;orcl1&apos;;SQL&gt; alter system set cluster_interconnects=&apos;10.10.56.124&apos; scope=spfile sid=&apos;orcl2&apos;;srvctl start database -d orcl","link":"/10g-rac-command.html"},{"title":"installing 10gr2 rac on linux","text":"实验环境：Oracle Enterprises Linux 5.8 x64 + Oracle 10gr2 RAC OCR:/dev/raw/raw1,/dev/raw/raw2 Votedisk:/dev/raw/raw3,/dev/raw/raw4,/dev/raw/raw5 Datafile:ASM with OMF #IP规划如下： #public 192.168.192.188 oel1.oraclema.com oel1 192.168.192.189 oel2.oraclema.com oel2 #VIP 192.168.192.178 oel1-vip.oraclema.com oel1-vip 192.168.192.179 oel2-vip.oraclema.com oel2-vip #heartbeat 10.10.10.188 oel1-prv 10.10.10.189 oel2-prv 1.安装所需的包 12[root@oel1 ~]# yum install oracle-validated [root@oel1 ~]# yum install oracleasm 2.配置时间同步 以节点1为时间服务器，使用rdate进行时间同步 12345678[root@oel1 ~]# vi /etc/xinetd.d/time-stream 修改disable=yes为disable=no 启动xinetd [root@oel1 ~]# service xinetd start 节点2同步： [root@oel2 yum.repos.d]# rdate -s oel1 [root@oel2 yum.repos.d]# crontab -l * * * * * rdate -s oel1 3.裸设备设置 首先要对共享磁盘mapping过来的盘进行分区。确保一点节点分区完后，其他节点fdisk -l能正常扫描到。 修改裸设备配置文件： 1234567891011121314[root@oel1 ~]# cat /etc/udev/rules.d/60-raw.rules # Enter raw device bindings here. ## An example would be: # ACTION==&quot;add&quot;, KERNEL==&quot;sda&quot;, RUN+=&quot;/bin/raw /dev/raw/raw1 %N&quot; # to bind /dev/raw/raw1 to /dev/sda, or # ACTION==&quot;add&quot;, ENV&#123;MAJOR&#125;==&quot;8&quot;, ENV&#123;MINOR&#125;==&quot;1&quot;, RUN+=&quot;/bin/raw /dev/raw/raw2 %M %m&quot; # to bind /dev/raw/raw2 to the device with major 8, minor 1. ACTION==&quot;add&quot;, KERNEL==&quot;sdb1&quot;,RUN+=&quot;/bin/raw /dev/raw/raw1 %N&quot; ACTION==&quot;add&quot;, KERNEL==&quot;sdc1&quot;,RUN+=&quot;/bin/raw /dev/raw/raw2 %N&quot; ACTION==&quot;add&quot;, KERNEL==&quot;sdd1&quot;,RUN+=&quot;/bin/raw /dev/raw/raw3 %N&quot; ACTION==&quot;add&quot;, KERNEL==&quot;sde1&quot;,RUN+=&quot;/bin/raw /dev/raw/raw4 %N&quot; ACTION==&quot;add&quot;, KERNEL==&quot;sdf1&quot;,RUN+=&quot;/bin/raw /dev/raw/raw5 %N&quot; ACTION==&quot;add&quot;, KERNEL==&quot;raw[1-5]&quot;, OWNER=&quot;oracle&quot;, GROUP=&quot;oinstall&quot;, MODE=&quot;660&quot; 启动udev服务，确保两个节点都能识别。 12345678[root@oel1 ~]# start_udev Starting udev: [ OK ] [root@oel1 ~]# ll /dev/raw/raw* crw-rw---- 1 oracle oinstall 162, 1 Mar 27 16:57 /dev/raw/raw1 crw-rw---- 1 oracle oinstall 162, 2 Mar 27 16:57 /dev/raw/raw2 crw-rw---- 1 oracle oinstall 162, 3 Mar 27 16:57 /dev/raw/raw3 crw-rw---- 1 oracle oinstall 162, 4 Mar 27 16:57 /dev/raw/raw4 crw-rw---- 1 oracle oinstall 162, 5 Mar 27 16:57 /dev/raw/raw5 4.配置节点ssh信任 12345678910111213[oracle@oel1 ~]$ mkdir ~/.ssh [oracle@oel2 ~]$ chmod 700 ~/.ssh [oracle@oel2 ~]$ ssh-keygen -t rsa [oracle@oel2 ~]$ ssh-keygen -t dsa [oracle@oel1 ~]$ cat ~/.ssh/*.pub &gt;&gt; ~/.ssh/authorized_keys #以上动作两个节点都需要做。 #节点1： [oracle@oel1 ~]$ cat ~/.ssh/*.pub &gt;&gt; ~/.ssh/authorized_keys [oracle@oel1 ~]$ scp ~/.ssh/authorized_keys oel2:~/.ssh/authorized_keys #节点2： [oracle@oel2 ~]$ cat ~/.ssh/*.pub &gt;&gt; ~/.ssh/authorized_keys [oracle@oel2 ~]$ scp ~/.ssh/authorized_keys oel1:~/.ssh/authorized_keys [oracle@oel2 ~]$ ssh oel1 date 5.创建所需目录 1234[root@oel1 ~]# mkdir -p /u01/app/oracle [root@oel1 ~]# mkdir -p /u01/app/oracle/product/crs [root@oel1 ~]# mkdir -p /u01/app/oracle/product/10.2.0/db_1 [root@oel1 ~]# chown -R oracle:oinstall /u01 6.修改内核参数 本实验采用oracle-validated，安装过程中会自动修改内核参数，只需要将11g的屏蔽，修改为10g的即可。修改完成后，使用以下命令使设置生效： 12345678910111213141516171819202122[root@oel1 ~]# sysctl -p net.ipv4.ip_forward = 0 net.ipv4.conf.default.rp_filter = 2 net.ipv4.conf.default.accept_source_route = 0 kernel.core_uses_pid = 1 net.ipv4.tcp_syncookies = 1 fs.file-max = 6815744 kernel.msgmni = 2878 kernel.msgmax = 8192 kernel.msgmnb = 65536 kernel.sem = 250 32000 100 142 kernel.shmmni = 4096 kernel.shmall = 1073741824 kernel.shmmax = 4398046511104 kernel.sysrq = 1 net.core.rmem_default = 262144 net.core.rmem_max = 2097152 net.core.wmem_default = 262144 net.core.wmem_max = 262144 fs.aio-max-nr = 3145728 net.ipv4.ip_local_port_range = 1024 65000 vm.min_free_kbytes = 51200 7.配置IO Fencing 有关IO Fencing请看文章结尾说明。 123456789101112#查找模块位置： [root@oel1 ~]# find /lib/modules -name &quot;hangcheck-timer.ko&quot; /lib/modules/2.6.32-300.10.1.el5uek/kernel/drivers/char/hangcheck-timer.ko /lib/modules/2.6.18-308.el5/kernel/drivers/char/hangcheck-timer.ko /lib/modules/2.6.32-300.10.1.el5uek.debug/kernel/drivers/char/hangcheck-timer.ko [root@oel1 ~]# modprobe hangcheck-timer #添加随机启动： vi /etc/rc.d/rc.local modprobe hangcheck-timer #配置模块参数： [root@rac1db ~]# vi /etc/modprobe.conf options hangcheck-timer hangcheck_tick=30 hangcheck_margin=180 8.ASMLib设置 12345678[root@oel1 ~]# /etc/init.d/oracleasm configure [root@oel1 ~]# /etc/init.d/oracleasm createdisk DATA1 /dev/sdg1 Marking disk &quot;DATA1&quot; as an ASM disk: [ OK ] #节点2扫描： [root@oel2 rules.d]# /etc/init.d/oracleasm scandisks Scanning the system for Oracle ASMLib disks: [ OK ] [root@oel2 rules.d]# /etc/init.d/oracleasm listdisks DATA1 9.oracle用户环境变量 123456789101112131415161718192021222324252627export EDITOR=vi # User specific environment and startup programs PATH=$PATH:$HOME/bin export ORACLE_BASE=/u01/app/oracle export ORA_CRS_HOME=$ORACLE_BASE/product/crs export ORACLE_HOME=$ORACLE_BASE/product/10.2.0/db_1 #export ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1 export ORACLE_SID=orcl1 export PATH=.:$&#123;PATH&#125;:$HOME/bin:$ORACLE_HOME/bin export PATH=$&#123;PATH&#125;:/usr/bin:/bin:/usr/bin/X11:/usr/local/bin export PATH=$&#123;PATH&#125;:$ORACLE_BASE/common/oracle/bin:$ORACLE_BASE/product/crs/bin export ORACLE_TERM=xterm export TNS_ADMIN=$ORACLE_HOME/network/admin export ORA_NLS10=$ORACLE_HOME/nls/data export LD_LIBRARY_PATH=$ORACLE_HOME/lib export LD_LIBRARY_PATH=$&#123;LD_LIBRARY_PATH&#125;:$ORACLE_HOME/oracm/lib export LD_LIBRARY_PATH=$&#123;LD_LIBRARY_PATH&#125;:/lib:/usr/lib:/usr/local/lib export CLASSPATH=$ORACLE_HOME/JRE export CLASSPATH=$&#123;CLASSPATH&#125;:$ORACLE_HOME/jlib export CLASSPATH=$&#123;CLASSPATH&#125;:$ORACLE_HOME/rdbms/jlib export CLASSPATH=$&#123;CLASSPATH&#125;:$ORACLE_HOME/network/jlib export THREADS_FLAG=native export TEMP=/tmp export TMPDIR=/tmp export DISPLAY=192.168.56.1:0.0 export PS1=&apos;[$LOGNAME@$HOSTNAME:$PWD]$ &apos; umask 022 10.安装Clusterware软件 实验OS为OEL 5，因此需要修改Linux release： 12[root@oel1 ~]# cat /etc/redhat-release redhat-4 安装步骤： 12345678910111213141516171819[oracle@oel1:/worktmp/clusterware]$ ./runInstaller Specify Inventory directory and credentials： Inventory:/u01/app/oracle/oraInventory OS Group:oinstall Specify Home Detail: Name:OraCrs10g_home Path:/u01/app/oracle/product/crs Specify Cluster Configuration: Cluster Name:orcl Cluster Nodes:add all nodes information, you may need modify something Specify Network Interface Usage: By default,there is no need modify. Please confirm with you network setting. Specify Oracle Cluster Registry Location: Normal Redundancy,/dev/raw/raw1,/dev/raw/raw2 Specify Vote Disk Location: Normal Redundancy,/dev/raw/raw3,/dev/raw/raw4,/dev/raw/raw5 #最后以root用户分别在两个节点执行以下脚本： /u01/app/oracle/oraInventory/orainstRoot.sh /u01/app/oracle/product/crs/root.sh 最后一个节点执行root.sh时候，最后执行vipca遇到 error while loading shared libraries: libpthread.so.0: cannot open shared object file: No such file or directory.此错误为Redhat的bug。可以先不理会，打Patch至10.2.0.4，然后手工执行vipca。最后因为vip的原因会导致安装最后一步检查的过程报错： The \"/u01/app/oracle/product/crs/cfgtoollogs/configToolFailedCommands\" script contains all commands that failed, were skipped or were cancelled. This file may be used to run these configuration assistants outside of OUI. Note that you may have to update this script with passwords (if any) before executing the same. 可以手动执行/u01/app/oracle/product/crs/cfgtoollogs/configToolFailedCommands看看是什么错，一般就是VIP无法确认： 1234Checking existence of VIP node application (required) Check failed. Check failed on nodes: oel2,oel1 11.Patch Clusterware 1234[oracle@oel1:/u01/worktmp/10gr2/Disk1]$ ./runInstaller Specify Home Detail: Name:OraCrs10g_home Path:/u01/app/oracle/product/crs 其他的一切照默认安装。安装完后同样执行脚本： [root@oel1:/u01/app/oracle]# /u01/app/oracle/product/crs/bin/crsctl stop crs Stopping resources. Successfully stopped CRS resources Stopping CSSD. Shutting down CSS daemon. Shutdown request successfully issued. [root@oel2:/u01/app/oracle]# /u01/app/oracle/product/crs/bin/crsctl stop crs Stopping resources. Successfully stopped CRS resources Stopping CSSD. Shutting down CSS daemon. Shutdown request successfully issued. [root@oel1:/u01/app/oracle]# /u01/app/oracle/product/crs/install/root102.sh [root@oel2:/u01/app/oracle]# /u01/app/oracle/product/crs/install/root102.sh #查看集群信息： [root@oel1:/u01/app/oracle/product/crs]# bin/crsctl check crs CSS appears healthy CRS appears healthy EVM appears healthy [root@oel1:/u01/app/oracle/product/crs]# bin/crsctl query css votedisk 0. 0 /dev/raw/raw3 1. 0 /dev/raw/raw4 2. 0 /dev/raw/raw5 located 3 votedisk(s). [root@oel1:/u01/app/oracle/product/crs]# bin/ocrcheck Status of Oracle Cluster Registry is as follows : Version : 2 Total space (kbytes) : 200560 Used space (kbytes) : 544 Available space (kbytes) : 200016 ID : 841952053 Device/File Name : /dev/raw/raw1 Device/File integrity check succeeded Device/File Name : /dev/raw/raw2 Device/File integrity check succeeded Cluster registry integrity check succeeded 12.配置VIP资源 以root用户执行vipca，配置VIP信息: 123456789101112131415[oracle@oel1:/u01/worktmp/10gr2/Disk1]$ which vipca /u01/app/oracle/product/crs/bin/vipca [root@oel1:/u01/app/oracle/product/crs]# export DISPLAY=192.168.56.1:0.0 [root@oel1:/u01/app/oracle/product/crs]# /u01/app/oracle/product/crs/bin/vipca #根据图形界面提示填入vip名称及ip地址。 #完成后可查看资源状态： [root@oel1:/u01/app/oracle/product/crs]# bin/crs_stat -t Name Type Target State Host ------------------------------------------------------------ ora.oel1.gsd application ONLINE ONLINE oel1 ora.oel1.ons application ONLINE ONLINE oel1 ora.oel1.vip application ONLINE ONLINE oel1 ora.oel2.gsd application ONLINE ONLINE oel2 ora.oel2.ons application ONLINE ONLINE oel2 ora.oel2.vip application ONLINE ONLINE oel2 13.安装数据库软件 12345678910111213141516171819202122232425262728[oracle@oel1:/u01/worktmp/10gr2/database]$ ./runInstaller Specify Installation Type： Enterprise Edtion Specify Home Detail: Name:OraDb10g_home Path:/u01/app/oracle/product/10.2.0/db_1 Specify Hardware Cluster Installation Mode: Cluster Installation:Select all nodes Select Configuration Option: Install database Software Only #安装完成执行脚本： [root@oel1:/u01/app/oracle]#/u01/app/oracle/product/10.2.0/db_1/root.sh Running Oracle10 root.sh script... The following environment variables are set as: ORACLE_OWNER= oracle ORACLE_HOME= /u01/app/oracle/product/10.2.0/db_1 Enter the full pathname of the local bin directory: [/usr/local/bin]: Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ... Creating /etc/oratab file... Entries will be added to the /etc/oratab file as needed by Database Configuration Assistant when a database is created Finished running generic part of root.sh script. Now product-specific root actions will be performed. 14.Patch数据库软件 [oracle@oel1:/u01/worktmp/10gr2/Disk1]$ ./runInstaller Specify Home Detail: Name:OraDb10g_home Path: /u01/app/oracle/product/10.2.0/db_1 #其他的一切照默认安装。安装完后同样执行脚本： [root@oel1:/u01/app/oracle]# /u01/app/oracle/product/10.2.0/db_1/root.sh #Netca配置监听 #完成后查看状态： [root@oel2:/u01/app/oracle/product/crs]# bin/crs_stat -t Name Type Target State Host ------------------------------------------------------------ ora....L1.lsnr application ONLINE ONLINE oel1 ora.oel1.gsd application ONLINE ONLINE oel1 ora.oel1.ons application ONLINE ONLINE oel1 ora.oel1.vip application ONLINE ONLINE oel1 ora....L2.lsnr application ONLINE ONLINE oel2 ora.oel2.gsd application ONLINE ONLINE oel2 ora.oel2.ons application ONLINE ONLINE oel2 ora.oel2.vip application ONLINE ONLINE oel2 15.dbca创建ASM实例 配置步骤如下： 1234Configure Automatic Storage Management Select All Nodes Enter SYS Password Initialization parameter file choose init file 创建完实例后，创建DATA磁盘组： 123DiskGroup Name：DATA Redundancy：External Change Disk Discovery Path：/dev/oracleasm/disks/* 完成后查看DG状态： 1234567891011121314151617[oracle@oel2:/home/oracle]$ export ORACLE_SID=+ASM2 [oracle@oel2:/home/oracle]$ sqlplus &quot;/as sysdba&quot; SQL&gt; select group_number,path,state,total_mb,free_mb from gv$asm_disk; GROUP_NUMBER PATH STATE TOTAL_MB FREE_MB ------------ -------------------------------------------------- -------- ---------- ---------- 1 /dev/oracleasm/disks/DATA1 NORMAL 8189 8096 1 /dev/oracleasm/disks/DATA1 NORMAL 8189 8096 SQL&gt; select name,state,type,total_mb,free_mb from gv$asm_diskgroup; NAME STATE TYPE TOTAL_MB FREE_MB ------------------------------ ----------- ------ ---------- ---------- DATA MOUNTED EXTERN 8189 8096 DATA MOUNTED EXTERN 8189 8096 查看集群资源状态： 1234567891011121314151617181920212223[root@oel1:/u01/app/oracle/product/crs]# bin/crs_stat -t -v Name Type R/RA F/FT Target State Host ---------------------------------------------------------------------- ora....SM1.asm application 0/5 0/0 ONLINE ONLINE oel1 ora....L1.lsnr application 0/5 0/0 ONLINE ONLINE oel1 ora.oel1.gsd application 0/5 0/0 ONLINE ONLINE oel1 ora.oel1.ons application 0/3 0/0 ONLINE ONLINE oel1 ora.oel1.vip application 0/0 0/0 ONLINE ONLINE oel1 ora....SM2.asm application 0/5 0/0 ONLINE ONLINE oel2 ora....L2.lsnr application 0/5 0/0 ONLINE ONLINE oel2 ora.oel2.gsd application 0/5 0/0 ONLINE ONLINE oel2 ora.oel2.ons application 0/3 0/0 ONLINE ONLINE oel2 ora.oel2.vip application 0/0 0/0 ONLINE ONLINE oel2 #为归档添加目录 export ORACLE_SID=+ASM1 asmcmd -p [oracle@oel2:/u01/app/oracle/admin/+ASM/bdump]$ asmcmd ASMCMD&gt; ls DATA/ ASMCMD&gt; cd data ASMCMD&gt; ls ORCL/ ASMCMD&gt; mkdir arch 16.dbca建库 12345678910111213141516171819202122232425262728293031323334353637383940414243444546[oracle@oel1:/home/oracle]$ dbca Create Database Select All Nodes Custom Database Global Name：orcl 取消EM Enter Password Storage mechanism：Choose ASM Select DATA Group Use Oracle-Managed Files Enable Archiving: +DATA/arch Database Services: Add service name:orcl_taf Two nodes choose Preferred TAF Policy:Basic #查看资源状态： [root@oel2:/u01/app/oracle/product/crs]# bin/crs_stat -t -v Name Type R/RA F/FT Target State Host ---------------------------------------------------------------------- ora....SM1.asm application 0/5 0/0 ONLINE ONLINE oel1 ora....L1.lsnr application 0/5 0/0 ONLINE ONLINE oel1 ora.oel1.gsd application 0/5 0/0 ONLINE ONLINE oel1 ora.oel1.ons application 0/3 0/0 ONLINE ONLINE oel1 ora.oel1.vip application 0/0 0/0 ONLINE ONLINE oel1 ora....SM2.asm application 0/5 0/0 ONLINE ONLINE oel2 ora....L2.lsnr application 0/5 0/0 ONLINE ONLINE oel2 ora.oel2.gsd application 0/5 0/0 ONLINE ONLINE oel2 ora.oel2.ons application 0/3 0/0 ONLINE ONLINE oel2 ora.oel2.vip application 0/0 0/0 ONLINE ONLINE oel2 ora.orcl.db application 0/0 0/1 ONLINE ONLINE oel1 ora....l1.inst application 0/5 0/0 ONLINE ONLINE oel1 ora....l2.inst application 0/5 0/0 ONLINE ONLINE oel2 ora...._taf.cs application 0/0 0/1 ONLINE ONLINE oel2 ora....cl1.srv application 0/0 0/0 ONLINE ONLINE oel1 ora....cl2.srv application 0/0 0/0 ONLINE ONLINE oel2 [root@oel1:/u01/app/oracle/product/crs]# bin/srvctl config database -d orcl -a oel1 orcl1 /u01/app/oracle/product/10.2.0/db_1 oel2 orcl2 /u01/app/oracle/product/10.2.0/db_1 DB_NAME: orcl ORACLE_HOME: /u01/app/oracle/product/10.2.0/db_1 SPFILE: +DATA/orcl/spfileorcl.ora DOMAIN: null DB_ROLE: null START_OPTIONS: null POLICY: AUTOMATIC ENABLE FLAG: DB ENABLED 17.集群的一些概念 摘自《大话Oracle RAC》 10g中的hangcheck-timer模块，是Linux提供的一个内核级的IO-Fencing模块，这个模块会监控Linux内核运行状态，如果长时间挂起，此模块会自动重启系统。配置这个模块需要两个参数，hangcheck_tick和hangcheck_margin。前一个参数用于定义多长时间检查一下，缺省值是30秒。第二个参数定义一个延时上限，缺省值为180秒。 CRS本身还有一个MissCount的参数，可以通过crsctl get css miscount命令查看。Hangcheck-timer根据hangcheck_tick的设置，定时检查内核，只要两次检查的时间间隔小于hangcheck_tick+hangcheck_margin，都会认为内核运行正常，否则，就意味着运行异常，这个模块会重启系统。 这3个参数会影响RAC重构，假设节点间Heartbeat丢失，Clusterware必须确保在重构时，故障节点确实是Dead状态。如果仅仅因为节点负载过高导致心跳丢失，它是不会重启的。因此，MissCount必须大于两个参数的和，这样，节点重构时，其他节点已经被hangcheck-timer模块重启。 这种机制涉及到集群原理，在大多数集群设计中，都要考虑到几个问题：1.健忘症(Amnesia)，2.脑裂(Split Brain)，3.IO Fencing。 1的现象表现为集群配置文件存放在各个节点的本地，当集群正常运行时，用户可以在任意节点更改集群配置，同时自动同步到其他节点。但当某个节点正常关闭，在运行的某个节点修改配置文件，所做的修改是会丢失的。 2的现象更简单，但却涉及更复杂的原理。在集群中，节点是通过Heartbeat了解彼此健康状况的。如果心跳出现问题，节点间无法正常通讯，每个节点都会认为自己是正常节点，从而导致资源的争抢，同时意味这数据灾难，这就是脑裂。为了防止脑裂现象，任何的集群都会配置一个仲裁投票机制，即配置一个集群锁盘(仲裁盘)。在三个节点的集群中，如果A节点故障，那么B和C作为一个整体得到BC两票，A得到一票，因此A被剔除集群，BC构成一个新的集群。如果在两个节点的集群上，这种情况就无法实现，因此，又引进一个Quorum Disk，这个共享磁盘也代表一票，集群节点发生故障时候，两个节点会同时去抢qdisk的投票，最先达到的请求先被满足，剩下的节点被剔除。 当脑裂发生时候，仅仅通过投票算法解决谁获取集群控制权是不够的，还要保证被剔除的节点无法对共享磁盘数据进行操作才行。这就是IO Fencing要解决的问题。 Fence设备有软件和硬件两种。 硬件Fence：Power Fencing，如果Power loss，该节点就无法IO，此功能需要整合power management功能来完成，例如iLO，IPMI，DRAC，RSA等。 软件Fence：fibre channel zoning，一般由fibre channel switches来切断host到SAN的路径；SCSI-3 reservations：正常节点使用SCSI Reserve命令锁住存储设备，故障节点发现存储被锁后，知道自己被踢出集群，就要自己进行重启，以恢复到正常状态。 在Oracle RAC中，使用OCR磁盘来解决健忘症的问题，使用Votedisk来解决脑裂问题。10g RAC中，Linux平台使用hangcheck-timer解决IO Fencing问题(由css服务保证)，UNIX平台则由进程Process Monitor Daemon(oprocd)负责。而在10.2.0.4中，已经在Linux中引进oprocd来取代hangcheck-timer。11gr2中，使用cssdagent来解决IO Fencing的问题。","link":"/10gr2-rac-installation.html"},{"title":"11gr2 RAC Voting Disk及OCR管理","text":"1.关闭ntp，使用ctss同步两个节点 要使用Oracle提供的ctss(Cluster Time Synchronize Service)服务，必须停止使用NTP服务，并且移除NTP配置文件。在Linux中，使用以下操作可达成此目的： 12#chkconfig ntpd off #mv /etc/ntp.conf /etc/ntp.conf_bak 查询CTSS服务是否为Active： 1234[grid@ora11g:/home/grid]$ crsctl stat res ora.ctssd -t -init[grid@ora11g:/home/grid]$ crsctl check ctss CRS-4701: The Cluster Time Synchronization Service is in Active mode. CRS-4702: Offset (in msec): 0 2.管理Voting文件 I．查询Voting文件的编号状态及所在磁盘名： 1234567[grid@ora11g:/home/grid]$ crsctl query css votedisk## STATE File Universal Id File Name Disk group -- ----- ----------------- --------- --------- 1. ONLINE 565fecb6ed384fc0bfa5a6d8901e9296 (/dev/oracleasm/disks/CRS1) [OCR] 2. ONLINE 523c79b027b44fbebfee7eaf0f429f54 (/dev/oracleasm/disks/CRS2) [OCR] 3. ONLINE 31590f50dea54f07bf1b4e429bd733f5 (/dev/oracleasm/disks/CRS3) [OCR] Located 3 voting disk(s). II．删除损坏的Voting文件： $crsctl delete css votedisk 31590f50dea54f07bf1b4e429bd733f5 然后在原来的存储位置重新添加一个Voting文件： $crsctl add css votedisk +OCR III．Voting文件迁移 希望将Voting文件从OCR磁盘组迁移至+DATA磁盘组，使用以下操作： $crsctl replace votedisk +DATA IV．所有Voting文件损坏的情况 首先需要以root用户将Clusterware启动到exclusive模式： #crsctl start crs –excl 再查询Voting文件状态，显示结果为空或者在STATE字段显示为OFF [grid@ora11g:/home/grid]$ crsctl query css votedisk 因为Voting Disk存储在ASM磁盘中，通过以下命令可以恢复Voting文件，恢复的Voting文件可以被恢复到以前的磁盘组中，或者其他组： $crsctl replace votedisk +OCR 替换完再次查询Voting文件的状态，然后用root用户重新启动Clusterware： #crsctl stop crs #crsctl start crs 3.管理OCR文件 OCR记录Clusterware及数据库的配置信息。对OCR的管理主要包括备份、恢复、添加、删除及迁移等。 I．备份 123[root@ora11g:/root]# /u01/app/grid/product/11.2.0.4/bin/ocrconfig -manualbackup ora11g 2013/09/04 10:43:57 /u01/app/grid/product/11.2.0.4/cdata/fung/backup_20130904_104357.ocr ora11g 2013/09/04 10:29:22 /u01/app/grid/product/11.2.0.4/cdata/fung/backup_20130904_102922.ocr 查看备份结果： 123[root@ora11g:/root]# /u01/app/grid/product/11.2.0.4/bin/ocrconfig -showbackupPROT-24: Auto backups for the Oracle Cluster Registry are not available ora11g 2013/09/04 10:29:22 /u01/app/grid/product/11.2.0.4/cdata/fung/backup_20130904_102922.ocr OCR文件的备份是一个二进制文件，但是通过ocrdump命令可以查看它的内存： 语法： 123456789#ocrdump -backupfile backup_file_name[root@ora11g:/root]# /u01/app/grid/product/11.2.0.4/bin/ocrdump -backupfile /u01/app/grid/product/11.2.0.4/cdata/fung/backup_20130904_102922.ocr [root@ora11g:/root]# ll total 288 -rw------- 1 root root 1840 Aug 30 20:55 anaconda-ks.cfg drwxr-xr-x 2 root root 4096 Aug 30 14:14 Desktop -rw-r--r-- 1 root root 56109 Aug 30 20:54 install.log -rw-r--r-- 1 root root 0 Aug 30 19:45 install.log.syslog -rw------- 1 root root 205176 Sep 4 10:46 OCRDUMPFILE 上面OCRDUMPFILE即为此命令产生的文本文件，可以直接vi打开。 II．检查OCR文件是否损坏 1234567891011121314[root@ora11g:/root]# /u01/app/grid/product/11.2.0.4/bin/ocrcheck -configOracle Cluster Registry configuration is : Device/File Name : +OCR [root@ora11g:/root]# /u01/app/grid/product/11.2.0.4/bin/ocrcheck -local Status of Oracle Local Registry is as follows : Version : 3 Total space (kbytes) : 262120 Used space (kbytes) : 2532 Available space (kbytes) : 259588 ID : 180513404 Device/File Name : /u01/app/grid/product/11.2.0.4/cdata/ora11g.olr Device/File integrity check succeeded Local registry integrity check succeeded Logical corruption check succeeded III．恢复OCR文件 以root用户强制停止CRS： #crsctl stop crs -f 以root用户启动crs至exclusive状态： #crsctl start crs -excl 停止crsd进程： #crsctl stop resource ora.crsd -init 利用OCR备份文件进行恢复，使用ocrconfig -showbackup命令查找OCR备份文件路径，使用以下命令进行恢复： #ocrconfig –restore file_name 在此及节点上停止Clusterware运行： #crsctl stop crs -f 重新在所有节点启动CRS #crsctl start crs 最后，再次通过ocrcheck验证OCR文件完整性。 IV．OCR文件多份存储 查找OCR文件存储位置： 123[root@ora11g:/root]# cat /etc/oracle/ocr.lococrconfig_loc=+OCR local_only=FALSE 在磁盘组+DATA中再创建一个OCR文件： 12345678#ocrconfig -add +DATA[root@ora11g:/root]# /u01/app/grid/product/11.2.0.4/bin/ocrconfig -add +DATA [root@ora11g:/root]# cat /etc/oracle/ocr.loc #Device/file getting replaced by device +DATA ocrconfig_loc=+OCR ocrmirrorconfig_loc=+DATA local_only=false [root@ora11g:/root]# 删除命令如下： 123456[root@ora11g:/root]# /u01/app/grid/product/11.2.0.4/bin/ocrconfig -delete +DATA[root@ora11g:/root]# cat /etc/oracle/ocr.loc #Device/file +DATA being deleted ocrconfig_loc=+OCR local_only=false [root@ora11g:/root]# V．迁移OCR 以下命令把OCR文件从磁盘组DATA迁移到磁盘组DATABASE： #ocrconfig -replace +data -replacement +database EOF","link":"/11gr2-rac-voting-ocr-manage.html"},{"title":"11gr2 RAC SCAN DNS Configuration","text":"11gr2中RAC SCAN DNS简单配置，环境： 11.2.0.4+OEL5.8 x64 简单描述一下11gr2中引进的SCAN概念。SCAN全称为Single Client Access Name，顾名思义，客户端可以通过一个SCAN NAME就可以访问RAC。在此之前，客户端访问RAC都是通过VIP，如果RAC节点很多，那么在客户端TNS配置中就要写很多IP地址，最重要的是，如果增加或者减少RAC节点，相应的客户端TNS配置也要修改，为了增加可扩展性及灵活性，Oracle在11gr2推出了SCAN这个概念。 SCAN是以虚拟主机名形式出现，可以通过DNS，Oracle本身自带的GNS(Grid Name Serveice)或者hosts文件解析，最大支持3个IP解析，而hosts文件解析则只能解析一个IP。同时SCAN IP地址需和公网、VIP网段一致。Oracle强烈建议不使用hosts文件解析SCAN，但其实在现实生产环境中，大部分都是使用hosts解析的。但如果使用hosts解析的话，在安装的结尾会接到Cluster Verification Utility Failed的错误，详情请查询MOS：Note: 887471.1。为了高可用性及可扩展性，Oracle推荐DNS中解析方式为轮询模式(Round Robin)。 Grid Infrastructure在各个节点启用本地监听LISTENER去监听本地VIP，同时启用SCAN监听(最少一个，最多三个)去监听SCAN VIPs，11gr2默认设置local_listner为本地监听，remote_listener为SCAN监听。 SCAN IP与原有的VIP是紧密连接在一起的，当客户端请求访问时，SCAN监听根据LBA算法转发给对应实例的local LISTENER，最终还是由VIP对客户端提供服务。因此，在一个多节点的RAC中，同一个SCAN VIP有可能分布在多个节点，或者同一节点。在sqlnet.ora配置中，同时也要保证一点要有easy connect naming method存在,即添加参数NAMES.DIRECTORY_PATH=(tnsnames,ezconnect)。 以下DNS Server为节点1，纯粹为了测试，生产环境不建议这样操作，因为如果节点1宕机了，SCAN就无法解析了。 1234567891011121314151617181920[root@node1:/root]# cat /etc/hosts # Do not remove the following line, or various programs # that require network functionality will fail. 127.0.0.1 localhost.localdomain localhost #public IP 192.168.56.101 node1.kkdba.com node1 192.168.56.102 node2.kkdba.com node2 #priv 10.10.10.101 node1-prv 10.10.10.102 node2-prv #Virtual IP 192.168.56.103 node1-vip.kkdba.com node1-vip 192.168.56.104 node2-vip.kkdba.com node2-vip #SCAN #192.168.56.110 racdb-scan.kkdba.com racdb-scan #192.168.56.111 racdb-scan.kkdba.com racdb-scan #192.168.56.112 racdb-scan.kkdba.com racdb-scan 以上node1为DNS服务器。 12345678910[root@node1:/root]# yum install -y bind bind-chroot bind-utils caching-nameserver [root@node1:/root]# cd /var/named/chroot/etc/ [root@node1:/var/named/chroot/etc]# ll total 16 -rw-r--r-- 1 root root 405 Jan 22 12:25 localtime -rw-r----- 1 root named 1230 Dec 20 2011 named.caching-nameserver.conf -rw-r----- 1 root named 955 Dec 20 2011 named.rfc1912.zones -rw-r----- 1 root named 113 Mar 24 16:57 rndc.key [root@node1:/var/named/chroot/etc]# cp -p named.caching-nameserver.conf named.conf [root@node1:/var/named/chroot/etc]# cp -p named.rfc1912.zones named.zones 修改配置文件，修改完后如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104[root@node1:/var/named/chroot/etc]# cat named.conf // // named.caching-nameserver.conf // // Provided by Red Hat caching-nameserver package to configure the // ISC BIND named(8) DNS server as a caching only nameserver // (as a localhost DNS resolver only). // // See /usr/share/doc/bind*/sample/ for example named configuration files. // // DO NOT EDIT THIS FILE - use system-config-bind or an editor // to create named.conf - edits to this file will be lost on // caching-nameserver package upgrade. // options &#123; listen-on port 53 &#123; any; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory &quot;/var/named&quot;; dump-file &quot;/var/named/data/cache_dump.db&quot;; statistics-file &quot;/var/named/data/named_stats.txt&quot;; memstatistics-file &quot;/var/named/data/named_mem_stats.txt&quot;; // Those options should be used carefully because they disable port // randomization // query-source port 53; // query-source-v6 port 53; allow-query &#123; any; &#125;; allow-query-cache &#123; any; &#125;; &#125;; logging &#123; channel default_debug &#123; file &quot;data/named.run&quot;; severity dynamic; &#125;; &#125;; view localhost_resolver &#123; match-clients &#123; any; &#125;; match-destinations &#123; any; &#125;; recursion yes; include &quot;/etc/named.zones&quot;; &#125;; [root@node1:/var/named/chroot/etc]# cat named.zones // named.rfc1912.zones: // // Provided by Red Hat caching-nameserver package // // ISC BIND named zone configuration for zones recommended by // RFC 1912 section 4.1 : localhost TLDs and address zones // // See /usr/share/doc/bind*/sample/ for example named configuration files. // zone &quot;.&quot; IN &#123; type hint; file &quot;named.ca&quot;; &#125;; zone &quot;localdomain&quot; IN &#123; type master; file &quot;localdomain.zone&quot;; allow-update &#123; none; &#125;; &#125;; zone &quot;localhost&quot; IN &#123; type master; file &quot;localhost.zone&quot;; allow-update &#123; none; &#125;; &#125;; zone &quot;0.0.127.in-addr.arpa&quot; IN &#123; type master; file &quot;named.local&quot;; allow-update &#123; none; &#125;; &#125;; zone &quot;0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.ip6.arpa&quot; IN &#123; type master; file &quot;named.ip6.local&quot;; allow-update &#123; none; &#125;; &#125;; zone &quot;255.in-addr.arpa&quot; IN &#123; type master; file &quot;named.broadcast&quot;; allow-update &#123; none; &#125;; &#125;; zone &quot;0.in-addr.arpa&quot; IN &#123; type master; file &quot;named.zero&quot;; allow-update &#123; none; &#125;; &#125;; #Add new zone zone &quot;kkdba.com&quot; IN &#123; type master; file &quot;node1.kkdba.zero&quot;; allow-update &#123; none; &#125;; &#125;; zone &quot;56.168.192.in-addr.arpa&quot; IN &#123; type master; file &quot;56.168.192.local&quot;; allow-update &#123; none; &#125;; &#125;; 配置正向和反向解析文件： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@node1:/var/named/chroot/etc]# cd ../var/named/ [root@node1:/var/named/chroot/var/named]# cp -p named.local 56.168.192.local [root@node1:/var/named/chroot/var/named]# cp -p named.zero node1.kkdba.zero [root@node1:/var/named/chroot/var/named]# cat node1.kkdba.zero $TTL 86400 @ IN SOA node1.kkdba.com. root.kkdba.com. ( 42 ; serial (d. adams) 3H ; refresh 15M ; retry 1W ; expiry 1D ) ; minimum IN NS node1.kkdba.com. racdb-scan IN A 192.168.56.110 racdb-scan IN A 192.168.56.111 racdb-scan IN A 192.168.56.112 racdb-scan.kkdba.com IN A 192.168.56.110 racdb-scan.kkdba.com IN A 192.168.56.111 racdb-scan.kkdba.com IN A 192.168.56.112 node1-vip IN A 192.168.56.103 node2-vip IN A 192.168.56.104 node1-vip.kkdba.com IN A 192.168.56.103 node2-vip.kkdba.com IN A 192.168.56.104 node1 IN A 192.168.56.101 node2 IN A 192.168.56.102 node1.kkdba.com IN A 192.168.56.101 node2.kkdba.com IN A 192.168.56.102 [root@node1:/var/named/chroot/var/named]# cat 56.168.192.local $TTL 86400 @ IN SOA node1.kkdba.com. root.kkdba.com. ( 1997022700 ; Serial 28800 ; Refresh 14400 ; Retry 3600000 ; Expire 86400 ) ; Minimum IN NS node1.kkdba.com. 1 IN PTR node1.kkdba.com. 101 IN PTR node1.kkdba.com. 102 IN PTR node2.kkdba.com. 101 IN PTR node1. 102 IN PTR node2. 110 IN PTR racdb-scan.kkdba.com. 111 IN PTR racdb-scan.kkdba.com. 112 IN PTR racdb-scan.kkdba.com. 110 IN PTR racdb-scan. 111 IN PTR racdb-scan. 112 IN PTR racdb-scan. 102 IN PTR node1-vip. 103 IN PTR node2-vip. 102 IN PTR node1-vip.kkdba.com. 103 IN PTR node2-vip.kkdba.com. 添加/etc/resolv.conf，重启named服务，并且在当前节点测试： 12345678910111213141516171819202122232425262728293031323334[root@node1:/root]# cat /etc/resolv.conf search kkdba.com nameserver 192.168.56.101 [root@node1:/root]# /etc/init.d/named restart Stopping named: .[ OK ] Starting named: [ OK ] [root@node1:/root]# nslookup racdb-scan Server: 192.168.56.101 Address: 192.168.56.101#53 Name: racdb-scan.kkdba.com Address: 192.168.56.110 Name: racdb-scan.kkdba.com Address: 192.168.56.111 Name: racdb-scan.kkdba.com Address: 192.168.56.112 [root@node1:/root]# nslookup racdb-scan.kkdba.com Server: 192.168.56.101 Address: 192.168.56.101#53 Name: racdb-scan.kkdba.com Address: 192.168.56.112 Name: racdb-scan.kkdba.com Address: 192.168.56.110 Name: racdb-scan.kkdba.com Address: 192.168.56.111 [root@node1:/root]# nslookup 192.168.56.111 Server: 192.168.56.101 Address: 192.168.56.101#53 111.56.168.192.in-addr.arpa name = racdb-scan. 111.56.168.192.in-addr.arpa name = racdb-scan.kkdba.com. Another question: 测试环境原来为hosts解析，scan ip只有一个IP，现在增加了两个，但目前集群仍旧只识别出一个IP，需要对CRS做更新，具体如下，请参考MOS： How to update the IP address of the SCAN VIP resources (ora.scan{n}.vip) (文档 ID 952903.1) 1234[root@node1:/root]# cd /u01/app/11gr2/grid/bin/ [root@node1:/u01/app/11gr2/grid/bin]# ./srvctl config scan SCAN name: racdb-scan, Network: 1/192.168.56.0/255.255.255.0/eth0 SCAN VIP name: scan1, IP: /racdb-scan/192.168.56.110 确实只有一个IP在被使用，客户端修改TNS，改用其他SCAN IP无法连通。 停止SCAN及SCAN监听： 12[root@node1:/u01/app/11gr2/grid/bin]# ./srvctl stop scan_listener [root@node1:/u01/app/11gr2/grid/bin]# ./srvctl stop scan 刷新SCAN的IP地址： 1[root@node1:/u01/app/11gr2/grid/bin]# ./srvctl modify scan -n racdb-scan 更新SCAN监听： 1[root@node1:/u01/app/11gr2/grid/bin]# ./srvctl modify scan_listener –u 查看修改结果状态： 123456789101112131415161718192021[grid@node1:/home/grid]$ srvctl config scan SCAN name: racdb-scan, Network: 1/192.168.56.0/255.255.255.0/eth0 SCAN VIP name: scan1, IP: /racdb-scan/192.168.56.110 SCAN VIP name: scan2, IP: /racdb-scan/192.168.56.111 SCAN VIP name: scan3, IP: /racdb-scan/192.168.56.112 [grid@node1:/home/grid]$ srvctl start scan [grid@node1:/home/grid]$ srvctl start scan_listener [grid@node1:/home/grid]$ srvctl status scan SCAN VIP scan1 is enabled SCAN VIP scan1 is running on node node1 SCAN VIP scan2 is enabled SCAN VIP scan2 is running on node node1 SCAN VIP scan3 is enabled SCAN VIP scan3 is running on node node1 [grid@node1:/home/grid]$ srvctl status scan_listener SCAN Listener LISTENER_SCAN1 is enabled SCAN listener LISTENER_SCAN1 is running on node node1 SCAN Listener LISTENER_SCAN2 is enabled SCAN listener LISTENER_SCAN2 is running on node node1 SCAN Listener LISTENER_SCAN3 is enabled SCAN listener LISTENER_SCAN3 is running on node node1 Important：因为转成DNS解析，因此需要将原有/etc/hosts文件中关于SCAN的信息要MARK掉，默认的解析设置中，是先查找/etc/hosts文件，因此，所作的DNS解析三个IP也就相当于失效了，还是只能解析一个IP。一定要先注释掉/etc/hosts中有关SCAN的相关信息。","link":"/11gr2-scan-dns.html"},{"title":"12C静默安装CDB","text":"1. Oracle OFA结构体系Oracle OFA全称Optimal Flexible Architecture，中文一般翻译为Oracle最优体系架构。OFA是在安装Oracle软件或者创建数据库的时候，文件夹及文件命名方式的一种标准。 1.1 Oracle Inventory目录此目录存储了在此服务器上安装了的Oracle软件清单，此目录必不可少，共享于多个Oracle软件版本。同时，在每个$ORACLE_HOME目录下有个inventory目录，保存了local inventory的信息。当第一次安装，Oracle会自动检测OFA结构是否带有/u[01-09]目录，如果存在，则把Inventory目录创建为类似/u01/app/oraInventory。如果Oracle安装用户环境存在ORACLE_BASE，则创建为$ORACLE_BASE同级目录下，如ORACLE_BASE为/oracle/app/oracle，则Inventory目录为/oracle/app/oraInventory。如果以上两点都不存在，那么，Inventory目录会创建在Oracle用户的$HOME目录下，如/home/oracle/oraInventory。 1.2 Oracle Base目录Oracle Base是Oracle软件安装最顶层目录，在此目录下可以安装多个版本软件，一般命名规范为/mount_point/app/software_owner。 1.3 Oracle Home目录Oracle Home目录定义指定的产品路径，如Oracle database 12c或者Oracle database 11g，每个版本的软件应该有不同的ORACLE_HOME。一般命名规范为$ORACLE_BASE/product/version/install_name。 1.4 Automatic Diagnostic Repository从11g开始，Oracle开始启用ADR，此目录包括了Oracle相关的诊断信息，包括alert log，trace文件等，一般定义为ORACLE_BASE/diag/rdbms/lower(db_unique_name)/instance_name。在10g以前，为$ORACLE_BASE/admin/db_unique_name/{a,b,c,u}ump。11g的ADR可参照前文11g新特性—FDI简介。 2. 安装Oracle软件oracle 12c在OS用户组上增加了几个权限，包括备份恢复组，DataGuard管理组等，具体如下所示。在一般用途上，如果数据库管理员只有一个，为减低复杂度，建议按照10g前，只创建一个dba组即可。 2.1 创建OS用户12#group add -g 500#useradd -u 500 -g oinstall -G dba ora12c 系统参数设定略。 2.2 创建oraInst.loc文件oraInst.loc文件内容记录了Oracle Inventory目录，Oracle软件安装和升级的OS用户组。如：123[root@linora u02]# cat /etc/oraInst.loc inventory_loc=/u01/app/oraInventoryinst_group=oinstall 创建完后同时赋予权限：12# chown ora12c:oinstall oraInst.loc# chmod 664 oraInst.loc 2.3 静默安装进入安装软件所在文件夹，查找响应文件：1234[ora12c@linora:/worktmp]$ find . -name &quot;*.rsp&quot;./database/response/dbca.rsp./database/response/db_install.rsp./database/response/netca.rsp 编辑db_install.rsp12[ora12c@linora:/worktmp]$ cd ./database/response/[ora12c@linora:/worktmp/database/response]$ cat db_install.rsp | grep -v ^# | grep -v ^$ &gt; ~/dbinst.rsp 对于只安装软件，修改后的配置文件如下：1234567891011121314151617[ora12c@linora:/home/ora12c]$ cat dbinst.rsp oracle.install.responseFileVersion=/oracle/install/rspfmt_dbinstall_response_schema_v12.1.0oracle.install.option=INSTALL_DB_SWONLYORACLE_HOSTNAME=linoraUNIX_GROUP_NAME=oinstallINVENTORY_LOCATION=/u01/app/oraInventorySELECTED_LANGUAGES=en,zh_CNORACLE_HOME=/u02/app/ora12c/product/12.1.0/db_1ORACLE_BASE=/u02/app/ora12coracle.install.db.InstallEdition=EEoracle.install.db.DBA_GROUP=dbaoracle.install.db.OPER_GROUP=oracle.install.db.BACKUPDBA_GROUP=dbaoracle.install.db.DGDBA_GROUP=dbaoracle.install.db.KMDBA_GROUP=dbaSECURITY_UPDATES_VIA_MYORACLESUPPORT=falseDECLINE_SECURITY_UPDATES=true 开始静默安装：123456789[ora12c@linora:/worktmp/database]$ ./runInstaller -ignoreSysPrereqs -force -silent \\-responseFile /home/ora12c/dbinst.rspStarting Oracle Universal Installer...Checking Temp space: must be greater than 500 MB. Actual 4381 MB PassedChecking swap space: must be greater than 150 MB. Actual 3047 MB PassedPreparing to launch Oracle Universal Installer from /tmp/OraInstall2014-08-09_05-42-55PM. Please wait ... You can find the log of this install session at: /u01/app/oraInventory/logs/installActions2014-08-09_05-42-55PM.log 在安装过程中，查看日志是否有报错。在安装完成后，按照日志提示以root用户执行脚本.12345The installation of Oracle Database 12c was successful.Please check &apos;/u01/app/oraInventory/logs/silentInstall2014-08-09_05-42-55PM.log&apos; for more details.As a root user, execute the following script(s): 1. /u02/app/ora12c/product/12.1.0/db_1/root.sh 安装过程中相关文件及路径信息。 3. 复制现有数据库软件到新机器上这种方法能快速部署Oracle软件，从原有软件复制到新机器，或者在同一台机器复制到不同路径。由于是复制，许多目录，如dump目录，inventory目录可能需要手动创建。且因为没有全局inventory，需要重新创建。 3.1 复制数据库软件123[ora12c@linora:/home/ora12c]$ cd $ORACLE_HOME[ora12c@linora:/u02/app/ora12c/product/12.1.0/db_1]$ cd ../[ora12c@linora:/u02/app/ora12c/product/12.1.0]$ tar -czvf /u02/orahome.tgz db_1/ 通过ftp或者其他远程传输工具将文件传输至目的机器，并解压。也可以通过一条强大的命令直接完成以上两个需求，如：1$tar -cvf - db_1 | ssh ora12c &quot;cd /u01/app/oracle/product/12c; tar -xvf -&quot; 3.2 重新创建全局inventory解压后需要执行attach Oracle home：123456789101112131415161718192021222324252627[oracle@ora12c:/home/oracle]$ cd $ORACLE_HOME/oui/bin[oracle@ora12c:/u01/app/oracle/product/12c/db_1/oui/bin]$ [oracle@ora12c:/u01/app/oracle/product/12c/db_1/oui/bin]$ ./runInstaller -silent \\-attachHome -invPtrLoc /etc/oraInst.loc \\ORACLE_HOME=&quot;/u01/app/oracle/product/12c/db_1&quot; ORACLE_HOME_NAME=&quot;ONEW&quot;Starting Oracle Universal Installer...Checking swap space: must be greater than 500 MB. Actual 4095 MB PassedThe inventory pointer is located at /etc/oraInst.loc&apos;AttachHome&apos; was successful.#查看Inventory，看看是否添加成功[oracle@ora12c:/home/oracle]$ cat /u01/app/oraInventory/ContentsXML/inventory.xml &lt;?xml version=&quot;1.0&quot; standalone=&quot;yes&quot; ?&gt;&lt;!-- Copyright (c) 1999, 2014, Oracle and/or its affiliates.All rights reserved. --&gt;&lt;!-- Do not modify the contents of this file by hand. --&gt;&lt;INVENTORY&gt;&lt;VERSION_INFO&gt; &lt;SAVED_WITH&gt;12.1.0.2.0&lt;/SAVED_WITH&gt; &lt;MINIMUM_VER&gt;2.1.0.6.0&lt;/MINIMUM_VER&gt;&lt;/VERSION_INFO&gt;&lt;HOME_LIST&gt;&lt;HOME NAME=&quot;ONEW&quot; LOC=&quot;/u01/app/oracle/product/12c/db_1&quot; TYPE=&quot;O&quot; IDX=&quot;1&quot;/&gt;&lt;/HOME_LIST&gt;&lt;COMPOSITEHOME_LIST&gt;&lt;/COMPOSITEHOME_LIST&gt;&lt;/INVENTORY&gt; 上述命令是10g的方式创建的，11gr2以后可以省略ORACLE_HOME_NAME参数了，对于RAC而言，至少需要修复两个ORACLE_HOME，一个是RDBMS，一个是CRS(10g)或者Gird_HOME(11g)：123456./runInstaller -silent -ignoreSysPrereqs -attachHome ORACLE_HOME=&quot;&lt;Ora_Crs_HomePath&gt;&quot; ORACLE_HOME_NAME=&quot;&lt;Name of oracleCRSHome&gt;&quot; LOCAL_NODE=&apos;node1&apos;CLUSTER_NODES=node1,node2 CRS=true./runInstaller -silent -ignoreSysPrereqs -attachHome ORACLE_HOME=&quot;&lt;Oracle_HomePath&gt;&quot; ORACLE_HOME_NAME=&quot;&lt;Name of oracleHome&gt;&quot; LOCAL_NODE=&apos;node1&apos;CLUSTER_NODES=node1,node2 4. 创建数据库数据库的创建，可以通过DBCA模版或者在sqlplus手工创建。首先添加/etc/oratab1234# Entries are of the form:# $ORACLE_SID:$ORACLE_HOME:&lt;N|Y&gt;:linora:/u01/app/oracle/product/11gr2:Nora12c:/u02/app/ora12c/product/12.1.0/db_1:N 4.1 手工创建实例[推荐]首先创建pfile，然后创建spfile，从spfile启动.pfile内容如下：1234567891011121314db_name=ora12cdb_block_size=8192memory_target=800Mmemory_max_target=800Mprocesses=300control_files=(/u02/oradata/ora12c/control01.ctl,/u02/oradata/ora12c/control02.ctl)job_queue_processes=10open_cursors=500undo_management=AUTOundo_tablespace=UNDOTBS1remote_login_passwordfile=EXCLUSIVEenable_pluggable_database=truecompatible =&apos;12.0.0&apos;diagnostic_dest=/u02/app/ora12c 在nomount状态下执行创建CDB数据库命令：12345678910111213141516171819202122232425262728[ora12c@linora:/home/ora12c]$ cat dbcreate.sql CREATE DATABASE ora12cMAXLOGFILES 16MAXLOGMEMBERS 4MAXDATAFILES 1024MAXINSTANCES 1MAXLOGHISTORY 680CHARACTER SET AL32UTF8DATAFILE &apos;/u02/oradata/ora12c/system01.dbf&apos; SIZE 100M autoextend on next 64M maxsize unlimitedEXTENT MANAGEMENT LOCALUNDO TABLESPACE undotbs1 DATAFILE &apos;/u02/oradata/ora12c/undotbs01.dbf&apos; SIZE 100M autoextend on next 64M maxsize unlimitedSYSAUX DATAFILE &apos;/u02/oradata/ora12c/sysaux01.dbf&apos; SIZE 100M autoextend on next 64M maxsize unlimitedDEFAULT TEMPORARY TABLESPACE TEMP TEMPFILE &apos;/u02/oradata/ora12c/temp01.dbf&apos; SIZE 10M autoextend on next 64M maxsize unlimitedDEFAULT TABLESPACE USERS DATAFILE &apos;/u02/oradata/ora12c/users01.dbf&apos; SIZE 20M autoextend on next 64M maxsize unlimitedLOGFILE GROUP 1 (&apos;/u02/oradata/ora12c/redo01a.rdo&apos;) SIZE 50M,GROUP 2 (&apos;/u02/oradata/ora12c/redo02a.rdo&apos;) SIZE 50M,GROUP 3 (&apos;/u02/oradata/ora12c/redo03a.rdo&apos;) SIZE 50MUSER sys IDENTIFIED BY oracleUSER system IDENTIFIED BY oracle ENABLE PLUGGABLE DATABASE SEED FILE_NAME_CONVERT = (&apos;/u02/oradata/ora12c/&apos;, &apos;/u02/oradata/ora12c/pdbseed/&apos;) SYSTEM DATAFILES SIZE 125M AUTOEXTEND ON NEXT 10M MAXSIZE UNLIMITED SYSAUX DATAFILES SIZE 100M USER_DATA TABLESPACE usertbs DATAFILE &apos;/u02/oradata/ora12c/pdbseed/usertbs01.dbf&apos; SIZE 200M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED; 对以上语句部分解析： ENABLE PLUGGABLE DATABASE表示使用多租户环境，允许建立可插拔数据库，Oracle建立CDB$ROOT后，会自动建立一个只读的PDB seed(PDB$SEED)。如果创建non-CDB，则不需要添加Enable PDB子句。 SEED开始指定PDB$SEED相关设定，Oracle使用OMF或者使用&#39;FILE_NAME_CONVERT&#39;决定system、sysaux及default temp tablespace文件名称，在将来新建每一个PDB，可以透过复制PDB$SEED快速建立PDB。 FILE_NAME_CONVERT指定SEED数据文件与root数据文件转换，如上例中，Oracle会将CDB$ROOT system表空间数据文件&#39;/u02/oradata/ora12c/system01.dbf&#39;复制为PDB$SEED system表空间数据文件&#39;/u02/oradata/ora12c/pdbseed/system01.dbf&#39;，如果使用OMF，将会忽略这一语句。上述的例子中，Oracle会创建如下的表空间及数据文件：123456789101112#root(CDB$ROOT)SYSTEMSYSAUXUSERS (Default permanent tablespace)UNDOTBS1 (undo tablespace ，整個CDB共用)TEMP (Default temporary tablespace)#seed(PDB$SEED)SYSTEMSYSAUXDEFTBS(Default permanent tablespace)USERTBSTEMP(Default temporary tablespace) 创建Database后可查看如下信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354#CDB和PDB信息SYS@ora12c&gt; col name for a10SYS@ora12c&gt; col open_mode for a10SYS@ora12c&gt; select con_id,dbid,name,open_mode,total_size from v$containers; CON_ID DBID NAME OPEN_MODE TOTAL_SIZE---------- ---------- ---------- ---------- ---------- 1 233213762 CDB$ROOT READ WRITE 0 2 104991688 PDB$SEED READ ONLY 466616320#CDB和PDB表空间信息SYS@ora12c&gt; select con_id,ts#,name from v$tablespace order by 1,2; CON_ID TS# NAME---------- ---------- ---------- 1 0 SYSTEM 1 1 SYSAUX 1 2 UNDOTBS1 1 3 TEMP 1 4 USERS 2 0 SYSTEM 2 1 SYSAUX 2 2 TEMP 2 3 USERS 2 4 USERTBS#数据库文件信息SYS@ora12c&gt; set linesize 110SYS@ora12c&gt; col name for a85SYS@ora12c&gt; col con_id for 99999SYS@ora12c&gt; select con_id,name from v$datafile order by 1;CON_ID NAME------ ----------------------------------------------------- 1 /u02/oradata/ora12c/sysaux01.dbf 1 /u02/oradata/ora12c/users01.dbf 1 /u02/oradata/ora12c/undotbs01.dbf 1 /u02/oradata/ora12c/system01.dbf 2 /u02/oradata/ora12c/pdbseed/users01.dbf 2 /u02/oradata/ora12c/pdbseed/usertbs01.dbf 2 /u02/oradata/ora12c/pdbseed/system01.dbf 2 /u02/oradata/ora12c/pdbseed/sysaux01.dbfSYS@ora12c&gt; select con_id,name from v$tempfile order by 1;CON_ID NAME------ ----------------------------------------------------- 1 /u02/oradata/ora12c/temp01.dbf 2 /u02/oradata/ora12c/pdbseed/temp01.dbfSYS@ora12c&gt; col member for a80SYS@ora12c&gt; select con_id,member from v$logfile;CON_ID MEMBER------ ------------------------------------------------------ 0 /u02/oradata/ora12c/redo01a.rdo 0 /u02/oradata/ora12c/redo02a.rdo 0 /u02/oradata/ora12c/redo03a.rdoSYS@ora12c&gt; select con_id,name from v$controlfile;CON_ID NAME------ ------------------------------------------------------ 0 /u02/oradata/ora12c/control01.ctl 0 /u02/oradata/ora12c/control02.ctl 实例创建完后，创建数据字典：1SQL&gt; @?/rdbms/admin/catcdb.sql 按照官方文档执行完之后，发现数据字典依旧没有生成。使用以下方式创建(以oracle用户执行)：1234567[ora12c@linora:/home/ora12c]$ cd $ORACLE_HOME/rdbms/admin[ora12c@linora:/home/ora12c]$ $ORACLE_HOME/perl/bin/perl catcon.pl -u sys/oracle -s -e -d \\$ORACLE_HOME/rdbms/admin -b catalog1 catalog.sql &gt; ~/.catcon-catalog.log[ora12c@linora:/home/ora12c]$ $ORACLE_HOME/perl/bin/perl catcon.pl -u sys/oracle -s -e -d \\$ORACLE_HOME/rdbms/admin -b catproc1 catproc.sql &gt; ~/.catcon-catproc.log[ora12c@linora:/home/ora12c]$ $ORACLE_HOME/perl/bin/perl catcon.pl -u system/oracle -s -e -d \\$ORACLE_HOME/sqlplus/admin -b pupbld1 pupbld.sql &gt; ~/.catcon-pupbld.log 4.2 dbca静默建库修改默认dbca.rsp文件1234567891011121314[ora12c@linora:/home/ora12c]$ cat dbca.rsp [GENERAL]RESPONSEFILE_VERSION = &quot;12.1.0&quot;OPERATION_TYPE = &quot;createDatabase&quot;[CREATEDATABASE]GDBNAME = &quot;ora12c&quot;SID = &quot;ora12c&quot;CREATEASCONTAINERDATABASE =trueTEMPLATENAME = &quot;General_Purpose.dbc&quot;SYSPASSWORD = &quot;oracle&quot;SYSTEMPASSWORD = &quot;oracle&quot;DATAFILEDESTINATION =/u02/oradata/CHARACTERSET = &quot;AL32UTF8&quot;NATIONALCHARACTERSET= &quot;AL16UTF16&quot; 执行创建时候报错，因为本例中的/etc/oratab已经存在SID为ora12c的条目，删除后重新执行命令:12345678910111213141516171819202122232425262728293031323334353637[ora12c@linora:/home/ora12c]$ dbca -silent -createDatabase -responseFile ./dbca.rsp Look at the log file &quot;/u02/app/ora12c/cfgtoollogs/dbca/ora12c0.log&quot; for further details.[ora12c@linora:/home/ora12c]$ cat /u02/app/ora12c/cfgtoollogs/dbca/ora12c0.logThe Oracle system identifier(SID) &quot;ora12c&quot; already exists. Specify another SID./u02/ has enough space. Required space is 6900 MB , available space is 13407 MB.File Validations Successful.[ora12c@linora:/home/ora12c]$ vi /etc/oratab linora:/u01/app/oracle/product/11gr2:N#ora12c:/u02/app/ora12c/product/12.1.0/db_1:N[ora12c@linora:/home/ora12c]$ dbca -silent -createDatabase -responseFile ./dbca.rsp Copying database files1% complete3% complete11% complete18% complete26% complete37% completeCreating and starting Oracle instance40% complete45% complete46% complete47% complete52% complete57% complete58% complete59% complete62% completeCompleting Database Creation66% complete70% complete74% complete85% complete96% complete100% completeLook at the log file &quot;/u02/app/ora12c/cfgtoollogs/dbca/ora12c/ora12c.log&quot; for further details. 4.3 创建密码文件使用dbca创建会自动生成密码文件12orapwd file=$ORACLE_HOME/dbs/orapw$ORACLE_SID \\password=oracle entries=5 force=y ignorecase=y 4.4 配置监听12345678910111213141516171819202122[ora12c@linora:/home/ora12c]$ cat $ORACLE_HOME/network/admin/sqlnet.oraNAMES.DIRECTORY_PATH= (TNSNAMES)ADR_BASE = /u02/app/ora12c[ora12c@linora:/home/ora12c]$ cat $ORACLE_HOME/network/admin/listener.oraLISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = linora)(PORT = 1522)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1522)) ) )ADR_BASE_LISTENER = /u02/app/ora12cSID_LIST_LISTENER = (SID_DESC = (GLOBAL_DBNAME = ora12c) (ORACLE_HOME = /u02/app/ora12c/product/12.1.0/db_1) (SID_NAME = ora12c) ) 4.5 配置EM Express1234567891011121314151617181920212223[ora12c@linora:/home/ora12c]$ cat $ORACLE_HOME/network/admin/tnsnames.oraora12c = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.56.188)(PORT = 1522)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = ora12c) ) )SYS@ora12c&gt; show parameter serviceNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------service_names string ora12cSYS@ora12c&gt; show parameter local_listenerNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------local_listener stringSYS@ora12c&gt; alter system set local_listener=ora12c scope=both;--此处选择的是tns连接名，而不是Service nameSystem altered.SYS@ora12c&gt; alter system set dispatchers=&quot;(PROTOCOL=TCP)&quot; scope=both;System altered.SYS@ora12c&gt; exec DBMS_XDB_CONFIG.SETHTTPSPORT(5500);PL/SQL procedure successfully completed. 4.6 修改归档模式1234567891011SYS@ora12c&gt; alter system set LOG_ARCHIVE_DEST_1 = &apos;LOCATION=/u02/arch&apos; scope=both;SYS@ora12c&gt; shutdown immediateSYS@ora12c&gt; startup mountSYS@ora12c&gt; alter database archivelog;SYS@ora12c&gt; archive log list;Database log mode Archive ModeAutomatic archival EnabledArchive destination /u02/archOldest online log sequence 28Next log sequence to archive 30Current log sequence 30 最后根据需求，调整对应参数，PDB的管理在下一篇文章会提及。Reference:Oracle® Database Administrator&#39;s Guide 12c Release 1 (12.1)Pro Oracle Database 12c Administration, 2nd Edition","link":"/12c-silent-installation.html"},{"title":"A Brief Introduction of Oracle Role and Privilege","text":"This brief introduction will cover with the fundamentals of Oracle privilege as well as roles, including how to retrieve all privilege for a user, and how to grant necessary roles or privilege to a user. 1. Basic Views of privileges and roles DBA_SYS_PRIVS DBA_TAB_PRIVS DBA_ROLE_PRIVS ROLE_SYS_PRIVS SESSION_PRIVS When granting a privilege to user, the PRIVILEGE will infect immediate; but when granting a role to a user, already connected session have to reconnect or use set role all to refresh the new granted role privileges 2. Script to find all privileges12345678select privilege from dba_sys_privs where grantee = upper('&amp;1')unionselect privilege from dba_sys_privs where grantee in (select granted_role from dba_role_privs where grantee = upper('&amp;1')); 3. Analysis of specific rolesRoles privileges can be retrieved from role_sys_privs view: Resource role does not have create view privilege, but have unlimited tablespace 1234567891011121314151617181920212223242526272829303132333435363738394041sys@LINORA&gt; select PRIVILEGE, role from role_sys_privs where role = upper('&amp;1');Enter value for 1: connectold 1: select PRIVILEGE, role from role_sys_privs where role = upper('&amp;1')new 1: select PRIVILEGE, role from role_sys_privs where role = upper('connect')PRIVILEGE ROLE--------------------- ----------------------SET CONTAINER CONNECTCREATE SESSION CONNECT-- resource roleEnter value for 1: resourceold 1: select PRIVILEGE, role from role_sys_privs where role = upper('&amp;1')new 1: select PRIVILEGE, role from role_sys_privs where role = upper('resource')PRIVILEGE ROLE------------------ --------------------------------------------------CREATE TRIGGER RESOURCECREATE SEQUENCE RESOURCECREATE TYPE RESOURCECREATE PROCEDURE RESOURCECREATE CLUSTER RESOURCECREATE OPERATOR RESOURCECREATE INDEXTYPE RESOURCECREATE TABLE RESOURCE-- olap user roleEnter value for 1: olap_userold 1: select PRIVILEGE, role from role_sys_privs where role = upper('&amp;1')new 1: select PRIVILEGE, role from role_sys_privs where role = upper('olap_user')PRIVILEGE ROLE------------------------ --------------------------------------------------CREATE CUBE BUILD PROCESS OLAP_USERCREATE CUBE DIMENSION OLAP_USERCREATE MEASURE FOLDER OLAP_USERCREATE JOB OLAP_USERCREATE CUBE OLAP_USERCREATE SEQUENCE OLAP_USERCREATE VIEW OLAP_USERCREATE TABLE OLAP_USER Based on above information, we can grant application user OLAP_USER, CONNECT and RESOURCE roles. 4. Identify users with DBA role123set line 200col grantee for a30select * from dba_role_privs where granted_role='DBA'; EOF","link":"/A-Brief-Introduction-of-Oracle-Role-and-Privilege.html"},{"title":"Correct way to monitor tablespace usages via SQLs","text":"There are many ways to monitor Oracle tablespace usages. OEM, SQL Developer, ect,. But in some cases, we have no handy GUI tools, which require us to use SQLs for monitoring tablespace usages.Some v$ views and dictionaries are useful while monitoring tablespace. 1. Permanent tablespace DBA_TABLESPACE_USAGE_METRICS Describes tablespace usage metrics for all types of tablespaces, including permanent, temporary, and undo tablespaces. Not suitable for autoextend data files. TABLESPACE_SIZE is the maximum possible size if AUTO extended on, not the current size. The same applies to USED_PERCENT.USED_SPACE and TABLESPACE_SIZE are in blocks. see MOS: Difference in Tablespace Size Values From dba_data_files and dba_tablespace_usage_metrics/V$filespace_usage (Doc ID 455715.1) For the usage of tablespace(must exclude autoextensible data files):123456789101112131415set line 200col tablespace_name for a30SELECT a.tablespace_name, ROUND((a.used_space * b.block_size)/1024/1024, 2) AS \"USED_SPACE(MB)\", ROUND((a.tablespace_size * b.block_size)/1024/1024, 2) AS \"TABLESPACE_SIZE(MB)\", ROUND(a.used_percent, 2) AS \"USED_PERCENT\" FROM DBA_TABLESPACE_USAGE_METRICS a JOIN DBA_TABLESPACES b ON a.tablespace_name = b.tablespace_name;ABLESPACE_NAME USED_SPACE(MB) TABLESPACE_SIZE(MB) USED_PERCENT------------------------------ -------------- ------------------- ------------SYSTEM 828.13 4741.98 17.46 --autoextend on, not realSYSAUX 645.94 4741.98 13.62 --autoextend on, not realTEMP 3 4741.98 .06USERS 7920.25 8322.5 95.17 --auto extend off, real usages v$filespace_usage Summarizes space allocation information of each datafile and tempfile. This view is the basic view of DBA_TABLESPACE_USAGE_METRICS. DBA_HIST_TBSPC_SPACE_USAGE Displays historical tablespace usage statistics, deponds on AWR retention Below shows the examples: 1.1 Monitoring real tablespace usageNon-CDB:123456789101112131415161718192021col dbname for a10col tbs_name for a30col sum_size for a30col free_size for a30col usage_pct for a30SELECT * FROM ( SELECT substr (d.NAME || ' ', 1, 15) AS DBNAME, SUBSTR (a.tablespace_name || ' ', 1, 30) AS TBS_NAME, SUBSTR (a.BYTES ||' ', 1, 8) AS SUM_SIZE, SUBSTR (TO_CHAR(decode(ROUND(c.BYTES,1),null,0,ROUND(c.bytes,1)))||' ', 1, 8) AS FREE_SIZE, substr (ROUND (100 * (1 - (NVL (c.BYTES, 0) / NVL (a.BYTES, 0))), 2)||' ',1,5) AS USAGE_PCT FROM (SELECT tablespace_name,SUM (BYTES) / 1024 / 1024 AS BYTES FROM dba_data_files GROUP BY tablespace_name) a, (SELECT f.tablespace_name,SUM (f.BYTES) / 1024 / 1024 AS BYTES FROM dba_free_space f GROUP BY f.tablespace_name) c, v$database d WHERE a.tablespace_name = c.tablespace_name(+)); CDB:12345678910111213141516171819202122232425262728SET LINES 132 PAGES 100COL con_name FORM A15 HEAD \"Container|Name\"COL tablespace_name FORM A15COL fsm FORM 999,999,999,999 HEAD \"Free|Space Meg.\"COL apm FORM 999,999,999,999 HEAD \"Alloc|Space Meg.\"COL usage_pct form a10 head \"Used|Percent%\"--COMPUTE SUM OF fsm apm ON REPORTBREAK ON REPORT ON con_id ON con_name ON tablespace_name--WITH x AS (SELECT c1.con_id, cf1.tablespace_name, SUM(cf1.bytes)/1024/1024 fsm FROM cdb_free_space cf1 ,v$containers c1 WHERE cf1.con_id = c1.con_id GROUP BY c1.con_id, cf1.tablespace_name), y AS (SELECT c2.con_id, cd.tablespace_name, SUM(cd.bytes)/1024/1024 apm FROM cdb_data_files cd ,v$containers c2 WHERE cd.con_id = c2.con_id GROUP BY c2.con_id ,cd.tablespace_name)SELECT x.con_id, v.name con_name, x.tablespace_name, x.fsm, y.apmLPAD(ROUND((1 - x.fsm / y.apm ) * 100, 2)||'%', 10, ' ') as usage_pctFROM x, y, v$containers vWHERE x.con_id = y.con_idAND x.tablespace_name = y.tablespace_nameAND v.con_id = y.con_idORDER BY 1, 3; 1.2 Monitoring tablespace growth rate123456789101112131415161718192021222324SELECT A.NAME, B.TABLESPACE_ID,B.DATETIME,B.USED_SIZE_MB,B.INC_MB, CASE WHEN SUBSTR(INC_RATE,1,1)='.' THEN '0'||INC_RATE WHEN SUBSTR(INC_RATE,1,2)='-.' THEN '-0'||SUBSTR(INC_RATE,2,LENGTH(INC_RATE)) ELSE INC_RATE END AS INC_RATEX FROM V$TABLESPACE A, ( SELECT TABLESPACE_ID,DATETIME, USED_SIZE_MB, (DECODE(PREV_USE_MB,0,0,USED_SIZE_MB)-PREV_USE_MB) AS INC_MB, TO_CHAR(ROUND((DECODE(PREV_USE_MB,0,0,USED_SIZE_MB)-PREV_USE_MB)/DECODE(PREV_USE_MB,0,1,PREV_USE_MB)*100,2))||'%' AS INC_RATE FROM ( SELECT TABLESPACE_ID, TRUNC(TO_DATE(RTIME, 'mm/dd/yyyy hh24:mi:ss')) DATETIME, MAX(TABLESPACE_USEDSIZE * 8 / 1024) USED_SIZE_MB, LAG(MAX(TABLESPACE_USEDSIZE * 8 / 1024),1,0) OVER(PARTITION BY TABLESPACE_ID ORDER BY TRUNC(TO_DATE(RTIME, 'mm/dd/yyyy hh24:mi:ss')) ) AS PREV_USE_MB FROM DBA_HIST_TBSPC_SPACE_USAGE WHERE TRUNC(TO_DATE(RTIME, 'mm/dd/yyyy hh24:mi:ss')) &gt; TRUNC(SYSDATE - 30) GROUP BY TABLESPACE_ID, TRUNC(TO_DATE(RTIME, 'mm/dd/yyyy hh24:mi:ss')) ) ) B WHERE A.TS# = B.TABLESPACE_ID ORDER BY B.TABLESPACE_ID,DATETIME; 2. Temporary tablespace GV_$TEMP_SPACE_HEADER The views v$sort_usage or v$tempseg_usage ( and v$sort_segment) give the correct information regarding the allocation of sort segments. The view v$temp_space_header shows that these many blocks were touched in each temp file at some point when temp usage was at its highest,in essence, it shows the number of initialized blocks for each tempfile, not the actual allocated blocks. See MOS: Mismatch Between V$TEMP_SPACE_HEADER and V$TEMPSEG_USAGE/V$SORT_USAGE (Doc ID 2095211.1). Correct way to show TEMP tablespace usage 12345678910111213141516171819202122232425select tablespace_name,tablespace_size/1024/1024 \"Total Space\",allocated_space/1024/1024 \"Alloc Space\",free_space/1024/1024 \"Free Space\"from dba_temp_free_space;select tablespace_name, total_blocks*8/1024 total_mb, used_blocks*8/1024 used_mb, free_blocks*8/1024 free_mbfrom v$sort_segment;SELECT D.tablespace_name, SPACE \"SUM_SPACE(M)\", blocks \"SUM_BLOCKS\", used_space \"USED_SPACE(M)\", Round(Nvl(used_space, 0) / SPACE * 100, 2) \"USED_RATE(%)\", SPACE - used_space \"FREE_SPACE(M)\" FROM (SELECT tablespace_name, Round(SUM(bytes) / (1024 * 1024), 2) SPACE, SUM(blocks) BLOCKS FROM dba_temp_files GROUP BY tablespace_name) D, (SELECT tablespace, Round(SUM(blocks * 8192) / (1024 * 1024), 2) USED_SPACE FROM v$sort_usage GROUP BY tablespace) F WHERE D.tablespace_name = F.tablespace(+) 3. Get table/segment growth historyMOS: How To Get Table Growth History Information? (Doc ID 1395195.1) DBA_HIST_SEG_STAT DBA_HIST_SEG_STAT displays historical information about segment-level statistics. This view captures the top segments based on a set of criteria and captures information from V$SEGSTAT. View the object (segment) growth in blocks:1234567891011121314151617181920column owner format a16column object_name format a36column start_day format a11column block_increase format 9999999999select obj.owner, obj.object_name, to_char(sn.BEGIN_INTERVAL_TIME,'RRRR-MON-DD') start_day, sum(a.SPACE_USED_DELTA) block_increase_bytesfrom dba_hist_seg_stat a, dba_hist_snapshot sn, dba_objects objwhere sn.snap_id = a.snap_idand obj.object_id = a.obj#and obj.owner not in ('SYS','SYSTEM')and end_interval_time between to_timestamp('01-JAN-2012','DD-MON-RRRR') and to_timestamp('02-FEB-2012','DD-MON-RRRR')group by obj.owner, obj.object_name, to_char(sn.BEGIN_INTERVAL_TIME,'RRRR-MON-DD')order by obj.owner, obj.object_name/ Segments with highest growth (Top n):123456789101112131415161718SELECT o.OWNER , o.OBJECT_NAME , o.SUBOBJECT_NAME , o.OBJECT_TYPE , t.NAME \"Tablespace Name\", s.growth/(1024*1024) \"Growth in MB\", (SELECT sum(bytes)/(1024*1024) FROM dba_segments WHERE segment_name=o.object_name) \"Total Size(MB)\"FROM DBA_OBJECTS o, ( SELECT TS#,OBJ#, SUM(SPACE_USED_DELTA) growth FROM DBA_HIST_SEG_STAT GROUP BY TS#,OBJ# HAVING SUM(SPACE_USED_DELTA) &gt; 0 ORDER BY 2 DESC ) s, v$tablespace tWHERE s.OBJ# = o.OBJECT_IDAND s.TS#=t.TS#AND rownum &lt; 51ORDER BY 6 DESC/ Script to display table size changes between two periods:1234567891011121314151617181920212223column \"Percent of Total Disk Usage\" justify right format 999.99column \"Space Used (MB)\" justify right format 9,999,999.99column \"Total Object Size (MB)\" justify right format 9,999,999.99set linesize 150set pages 80set feedback offselect * from (select to_char(end_interval_time, 'MM/DD/YY') mydate,sum(space_used_delta) / 1024 / 1024 \"Space used (MB)\",avg(c.bytes) / 1024 / 1024 \"Total Object Size (MB)\",round(sum(space_used_delta) / sum(c.bytes) * 100, 2) \"Percent of Total Disk Usage\"from dba_hist_snapshot sn, dba_hist_seg_stat a, dba_objects b, dba_segments cwhere begin_interval_time &gt; trunc(sysdate) - &amp;days_backand sn.snap_id = a.snap_idand b.object_id = a.obj#and b.owner = c.ownerand b.object_name = c.segment_nameand c.segment_name = '&amp;segment_name'group by to_char(end_interval_time, 'MM/DD/YY'))order by to_date(mydate, 'MM/DD/YY'); With above information, it&#39;s easier to ask application owner if the growth is normal or not. EOF","link":"/Correct-way-to-monitor-tablespace-usages.html"},{"title":"RAC DG Broker ora-16843 ora-16839错误","text":"新搭的一套ADG，在启用配置后，查询状态报以下错误：12345678910111213141516171819202122232425262728DGMGRL&gt; show configurationConfiguration - ADG_ZT Protection Mode: MaxAvailability Members: cdb01 - Primary database cdb02 - Physical standby database ztdb - Physical standby database Error: ORA-16843: errors discovered in diagnostic repositoryDGMGRL&gt; show database ztdbDatabase - ztdb Role: PHYSICAL STANDBY Intended State: APPLY-ON Transport Lag: 0 seconds (computed 0 seconds ago) Apply Lag: 0 seconds (computed 0 seconds ago) Average Apply Rate: 29.00 KByte/s Real Time Query: ON Instance(s): ztdb1 Database Error(s): ORA-16839: one or more user data files are missingDatabase Status:ERROR 一度怀疑restore的时候部分文件丢失了，对比主备库两边的数据文件，并没有异常，备库查询恢复/还原错误，也是正常的。1234RMAN&gt; report schema;RMAN&gt; list failure;Database Role: PHYSICAL STANDBYno failures found that match specification MOS上有一个bug，怀疑是这个bug引起的：Bug 21495155 - data guard broker configuration shows ORA-16843 in RAC (Doc ID 21495155.8) Workaround:删除ADR下面的HM_FINDING.ams文件：12345678910111213141516171819202122[oracle@ztdb diag]$ find ./ -name \"metadata\"./rdbms/ztdb01/ztdb011/metadata[oracle@ztdb diag]$ cd ./rdbms/ztdb01/ztdb011/metadata[oracle@ztdb metadata]$ mv HM_FINDING.ams HM_FINDING.ams.oldDGMGRL&gt; show configurationConfiguration - ADG_ZT Protection Mode: MaxAvailability Members: cdb01 - Primary database cdb02 - Physical standby database ztdb01 - Physical standby databaseFast-Start Failover: DISABLEDConfiguration Status:SUCCESS (status updated 56 seconds ago)[oracle@ztdb metadata]$ ls -ltr HM_FIND*-rw-r----- 1 oracle oinstall 475136 9月 7 16:26 HM_FINDING.ams.old-rw-r----- 1 oracle oinstall 65536 9月 7 17:15 HM_FINDING.ams EOF","link":"/DG-Broker-ora-16843-ora-16839.html"},{"title":"Error for Oracle 12c in AIX rtld: 0712-001","text":"During HA testing, I shutdown one of node of RAC in AIX, after rebooting, the node couldn&#39;t join the cluster. I tried to start it manually, but failed with below issue: 12345exec(): 0509-036 Cannot load program crsctl because of the following errors:rtld: 0712-001 Symbol CreateIoCompletionPort wasreferenced from module /opt/oracle/product/12.1.0/lib/libttsh12.so(),but a runtime definition of the symbol was not found. This is due to incorrect setting of AIX IOCP. Check if the IOCP installed: 12345678[root@finmdb01a /]# lslpp -l bos.iocp.rte Fileset Level State Description ----------------------------------------------------------------------------Path: /usr/lib/objrepos bos.iocp.rte 7.2.3.0 COMMITTED I/O Completion Ports APIPath: /etc/objreposbos.iocp.rte 7.2.3.0 COMMITTED I/O Completion Ports API Change IOCP setting from smitty 123# smitty iocpSelect Change / Show Characteristics of I/O Completion Ports.Change configured state at system restart from Defined to Available Check the status of IOCP after rebooting Should be Available status.12[root@finmdb01a /]# lsdev -Cc iocpiocp0 Available I/O Completion Ports This is a prerequisite to change IOCP parameter before installing database 12c in IBM AIX environment. EOF","link":"/Error-for-Oracle-12c-in-AIX-rtld-0712-001.html"},{"title":"12c使用dataguard broker配置带farsync的active dataguard","text":"Active DataGuard far sync是12c引进的新功能。在以前的版本中，如果要做到sync同步，日志传输服务需要等待主库及远程备库均写入日志文件，然后向应用程序返回提交成功的通知。 如果备库与主库物理距离增加，例如跨广域网实施零数据丢失的实时保护，这个返回确认的时间也会随之增加，数据库性能因此会受到极大影响，在距离较远的ADG同步上，sync模式也就变得有点不切实际。 1. Far sync instance Far sync instance(下文称Farsync实例)可以在跨广域网部署一个远程同步实例，这个实例只包含控制文件，spfile，密码文件和standby redo log，而不包含数据文件和联机重做日志。其在两地三中心建设中有很大的实用价值。 Farsync实例通过sync传输从主库接收redo，并立即以async方式传输该redo到最多29个远程standby。 Farsync实例可以为主库减轻以下负担： 解析远程standby接收的归档日志的差异 主库仅需向远程同步实例传输一次redo，远程同步实例负责传输redo到多个目标 Farsync实例可以执行网络压缩，从而提高异地机房的传输效率 1.1 部署架构解析 上图中，Farsync实例1及实例2部署在同城灾备中心，standby备库部署在异地机房，主库与farsync1通过sync实时同步，当farsync1失效时，farsync2接管farsync1进行实时同步redo；异地灾备机房同时部署一个farsync实例，在进行角色切换时，异地灾备机房同时拥有farsync实例进行实时同步。 创建步骤大概如下： 通过rman duplicate创建standby 启用dataguard broker 通过broker启用farsync实例 下面的例子中，采用OMF管理，如果非OMF管理需添加db_file_name_convert和log_file_name_convert参数. 2. rman duplicate前准备2.1 所有节点主机名配置1234192.168.129.7 sdcdb01 # primary192.168.129.8 stcdb01 # standby192.168.129.9 sdfsdb01 # primary site farsync192.168.129.10 stfsdb01 # standby site farsync 2.2 主库启用force logging12ALTER DATABASE FORCE LOGGING;ALTER SYSTEM SWITCH LOGFILE; 2.3 主库添加standby redo log1234ALTER DATABASE ADD STANDBY LOGFILE SIZE 2048M;ALTER DATABASE ADD STANDBY LOGFILE SIZE 2048M;ALTER DATABASE ADD STANDBY LOGFILE SIZE 2048M;ALTER DATABASE ADD STANDBY LOGFILE SIZE 2048M; 2.4 主库调整参数1234567891011sqlplus / as sysdba &lt;&lt;EOFALTER SYSTEM SET STANDBY_FILE_MANAGEMENT=AUTO;alter system set archive_lag_target=1800 scope=both;ALTER SYSTEM SET db_create_file_dest='/u01/oradata';ALTER SYSTEM SET db_create_online_log_dest_1='/u01/oradata';ALTER PLUGGABLE DATABASE sdpdb1 SAVE STATE;ALTER SYSTEM SET local_listener='LISTENER';ALTER SYSTEM SET db_recovery_file_dest_size=20G;ALTER SYSTEM SET db_recovery_file_dest='/u01/app/oracle';exit;EOF&gt;&gt; 2.5 主备库监听设置 主备库及farsync tns设置 1234567891011121314151617181920212223242526272829303132333435363738SDCDB = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = sdcdb01)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = sdcdb) ) )STCDB = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = stcdb01)(PORT = 1521)) ) (CONNECT_DATA = (SID = sdcdb) ) )SDFS01 = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = sdfsdb01)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = sdfs01) ) )STFS01 = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = stfsdb01)(PORT = 1521)) ) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = stfs01) ) ) 主备库监听设置 123456789101112131415161718192021222324252627282930313233343536373839--primaryLISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = sdcdb01)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) )SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = sdcdb_DGMGRL) (ORACLE_HOME = /u01/app/oracle/product/12.1.0) (SID_NAME = sdcdb) ) )ADR_BASE_LISTENER = /u01/app/oracle--standbyLISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = stcdb01)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) )SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = stcdb_DGMGRL) (ORACLE_HOME = /u01/app/oracle/product/12.1.0) (SID_NAME = sdcdb) ) )ADR_BASE_LISTENER = /u01/app/oracle 启动监听12lsnrctl stoplsnrctl start 2.6 主库生成密码文件并传送到备库1orapwd file=$ORACLE_HOME/dbs/orapw$ORACLE_SID password=manager entries=5 force=y ignorecase=y 2.7 备库创建相关目录12345mkdir -p /u01/oradata/sdcdb/pdbseedmkdir -p /u01/oradata/sdcdb/sdpdb1mkdir -p /u01/app/oracle/sdcdbmkdir -p /u01/app/oracle/fast_recovery_area/sdcdbmkdir -p /u01/app/oracle/admin/sdcdb/adump 2.8 备库添加pfile内容如下:1*.db_name=sdcdb 3. 通过rman duplicate创建standby3.1 在备库启动辅助数据库1STARTUP NOMOUNT PFILE='/home/oracle/stdby_pfile.ora' 3.2 备库启动rman duplicate1234567891011121314rman target sys/manager@sdcdb auxiliary sys/manager@STCDB &lt;&lt;EOFrun&#123;allocate channel c1 type disk;allocate auxiliary channel ch1 TYPE disk;DUPLICATE TARGET DATABASE FOR STANDBY FROM ACTIVE DATABASE DORECOVERspfileset compatible='12.1.0.2.0'set db_unique_name='stcdb'## 如果是非OMF管理## SET db_file_name_convert='/oradata','/oradata_new','/data','/data_new'## SET log_file_name_convert='/oradata','/oradata_new','/data','/data_new'nofilenamecheck;&#125;EOF 4. 启用dgbroker等待rman duplicate完成后，启用dataguard broker进行配置,从12c开始，如果是broker管理，已经不需要单独设置log_archive_dest_2了，如果主备库没有清除这个参数，broker会报以下错误:1Error: ORA-16698: LOG_ARCHIVE_DEST_n parameter set for object to be added 4.1 主备库同时修改参数不存在则需要修改，如果参数已经存在，则可以不修改。如果是在RAC环境中，建议修改为ASM共享磁盘中。123--RACALTER SYSTEM SET DG_BROKER_CONFIG_FILE1 = '+DATA/BROKER/dr1sdcdb.dat' scope=both SID='*';ALTER SYSTEM SET DG_BROKER_CONFIG_FILE2 = '+DATA/BROKER/dr2sdcdb.dat' scope=both SID='*'; 4.2 主备库启用broker deamon1ALTER SYSTEM SET DG_BROKER_START=TRUE SCOPE=BOTH sid='*'; 4.3 broker中注册主备库1234567dgmgrl sys/manager@sdcdbDGMGRL&gt; CREATE CONFIGURATION sd_adg AS PRIMARY DATABASE IS sdcdb CONNECT IDENTIFIER IS sdcdb;--添加备库ADD DATABASE stcdb AS CONNECT IDENTIFIER IS stcdb MAINTAINED AS PHYSICAL;--启用配置ENABLE CONFIGURATION; 验证配置情况:1234567891011121314151617181920212223242526272829GMGRL&gt; show configurationConfiguration - sd_adg Protection Mode: MaxPerformance Members: sdcdb - Primary database stcdb - Physical standby databaseFast-Start Failover: DISABLEDConfiguration Status:SUCCESS (status updated 17 seconds ago)DGMGRL&gt; show database stcdbDatabase - stcdb Role: PHYSICAL STANDBY Intended State: APPLY-ON Transport Lag: 0 seconds (computed 1 second ago) Apply Lag: 0 seconds (computed 1 second ago) Average Apply Rate: 4.00 KByte/s Real Time Query: OFF # 实时查询状态为关闭 Instance(s): sdcdbDatabase Status:SUCCESS 主备库添加archive_lag参数 12345DGMGRL&gt;edit database sdcdb set property 'ArchiveLagTarget' = '1800';edit database stcdb set property 'ArchiveLagTarget' = '1800';--数据库中添加相应参数SQL&gt; alter system set archive_lag_target=1800 scope=both; 4.4 备库启用实时应用123SHUTDOWN IMMEDIATE;STARTUP MOUNT;ALTER DATABASE OPEN READ ONLY; 查询实时应用状态:123456789101112131415DGMGRL&gt; show database stcdbDatabase - stcdb Role: PHYSICAL STANDBY Intended State: APPLY-ON Transport Lag: 0 seconds (computed 0 seconds ago) Apply Lag: 0 seconds (computed 0 seconds ago) Average Apply Rate: 4.00 KByte/s Real Time Query: ON # 实时查询为on Instance(s): sdcdbDatabase Status:SUCCESS 5. 添加farsync5.1 添加farsync监听 主库farsync监听 12345678910111213141516171819202122232425262728LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = sdfsdb01 )(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) )SID_LIST_LISTENER= (SID_LIST= (SID_DESC= (SID_NAME=sdfs01) (ORACLE_HOME=/u01/app/oracle/product/12.1.0) (GLOBAL_DBNAME=sdfs01) ) (SID_DESC= (SID_NAME=sdfs01) (ORACLE_HOME=/u01/app/oracle/product/12.1.0) (GLOBAL_DBNAME=sdfs01_DGMGRL) ) (SID_DESC= (SID_NAME=sdfs01) (ORACLE_HOME=/u01/app/oracle/product/12.1.0) (GLOBAL_DBNAME=sdfs01_DGB) ) )ADR_BASE_LISTENER = /u01/app/oracleENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ONVALID_NODE_CHECKING_REGISTRATION_LISTENER=SUBNET 备库farsync监听 12345678910111213141516171819202122232425262728LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = stfsdb01 )(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) )SID_LIST_LISTENER= (SID_LIST= (SID_DESC= (SID_NAME=stfs01) (ORACLE_HOME=/u01/app/oracle/product/12.1.0) (GLOBAL_DBNAME=stfs01) ) (SID_DESC= (SID_NAME=stfs01) (ORACLE_HOME=/u01/app/oracle/product/12.1.0) (GLOBAL_DBNAME=stfs01_DGMGRL) ) (SID_DESC= (SID_NAME=stfs01) (ORACLE_HOME=/u01/app/oracle/product/12.1.0) (GLOBAL_DBNAME=stfs01_DGB) ) )ADR_BASE_LISTENER = /u01/app/oracleENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ONVALID_NODE_CHECKING_REGISTRATION_LISTENER=SUBNET 5.2 主库创建farsync所需文件两个farsync同时执行以下操作 主库创建farsync控制文件，传输到两个farsync节点，并且修改成相应的名字 1ALTER DATABASE CREATE FAR SYNC INSTANCE CONTROLFILE AS '/home/oracle/controlsdfs01.ctl'; 主库创建farsync实例所需pfile，且修改相关参数 以主库farsync实例为例, broker管理farsync仍然不需要log_archive_dest_2/3参数:123456789101112131415161718192021222324252627*.archive_lag_target=1800*.audit_file_dest='/u01/app/oracle/admin/sdcdb/adump'*.audit_trail='db'*.compatible='12.1.0.2.0'*.control_files='/u01/oradata/sdcdb/control01.ctl','/u01/app/oracle/fast_recovery_area/sdcdb/control02.ctl'*.db_block_size=8192*.db_create_file_dest='/u01/oradata'*.db_create_online_log_dest_1='/u01/oradata'*.db_domain=''*.db_name='sdcdb'*.db_unique_name='sdfs01' #新增加参数*.db_recovery_file_dest_size=21474836480*.db_recovery_file_dest='/u01/app/oracle'*.dg_broker_start=TRUE*.diagnostic_dest='/u01/app/oracle'*.dispatchers='(PROTOCOL=TCP) (SERVICE=sdcdbXDB)'*.enable_pluggable_database=true*.log_archive_format='%t_%s_%r.dbf'*.log_archive_max_processes=4*.log_archive_min_succeed_dest=1*.open_cursors=300*.pga_aggregate_target=4096m*.processes=300*.remote_login_passwordfile='EXCLUSIVE'*.sga_target=12288m*.standby_file_management='AUTO'*.undo_tablespace='UNDOTBS1' 两个farsync实例创建spfile:1create spfile from pfile='/home/oracle/pfile_farsync.ora'; 主库传输密码文件到两个farsync节点 Farsync节点创建相关目录 123456mkdir -p /u01/oradata/sdcdb/pdbseedmkdir -p /u01/oradata/sdcdb/sdpdb1mkdir -p /u01/oradata/SDCDBmkdir -p /u01/app/oracle/sdcdbmkdir -p /u01/app/oracle/fast_recovery_area/sdcdbmkdir -p /u01/app/oracle/admin/sdcdb/adump mount farsync实例 1SQL&gt; startup mount pfile='/home/oracle/pfile_farsync.ora'; 5.3 Broker添加farsync实例主库执行:1234567891011dgmgrl sys/manageradd FAR_SYNC sdfs01 as connect identifier is sdfs01;add FAR_SYNC stfs01 as connect identifier is stfs01;--主库指定redo路由edit database sdcdb set property redoroutes='(LOCAL : sdfs01 SYNC)';--主库farsyn指定redo路由edit far_sync sdfs01 set property redoroutes='(sdcdb : stcdb ASYNC)';--备库指定redo路由edit database stcdb set property redoroutes='(LOCAL : stfs01 SYNC)';--备库farsync指定redo路由edit far_sync stfs01 set property redoroutes='(stcdb : sdcdb ASYNC)'; 按照本文图中的架构，如果主库有两个farsync，其中一个为备用fasync，可参照以下设定：1234--optional,如果主库有两个farsync(12.1.0.2)EDIT DATABASE sdcdb SET PROPERTY RedoRoutes = '(LOCAL : sdfs01 SYNC ALT=(sdfs02 ASYNC FALLBACK))';--12.2设定priorityEDIT DATABASE sdcdb SET PROPERTY RedoRoutes = '(LOCAL : ( sdfs01 SYNC PRIORITY=1, sdfs02 ASYNC PRIORITY=2 ) )'; 5.4 修改同步模式及保护级别12345EDIT far_sync sdfs01 SET PROPERTY LogXptMode='SYNC';EDIT far_sync stfs01 SET PROPERTY LogXptMode='SYNC';edit database sdcdb set property LogXptMode='SYNC';edit database stcdb set property LogXptMode='SYNC';EDIT CONFIGURATION SET PROTECTION MODE AS MAXAVAILABILITY; 5.5 启用配置并且检查结果1234567891011121314151617181920212223enable configurationshow database verbose sdcdb statusreportshow configuration [verbose]show far_sync verbose sdfs01 [statusreport]DGMGRL&gt; show configurationConfiguration - sd_adg Protection Mode: MaxAvailability Members: sdcdb - Primary database sdfs01 - Far sync instance stcdb - Physical standby database Members Not Receiving Redo: stfs01 - Far sync instanceFast-Start Failover: DISABLEDConfiguration Status:SUCCESS (status updated 28 seconds ago) 同时也可以查看备库切换后的配置信息:1234567891011DGMGRL&gt; show configuration when primary is stcdbConfiguration when stcdb is primary - sd_adg Members: stcdb - Primary database stfs01 - Far sync instance sdcdb - Physical standby database Members Not Receiving Redo: sdfs01 - Far sync instance 查询主备库归档情况:12345678910111213141516171819202122--主库SQL&gt; col DESTINATION for a30col DEST_NAME for a50set line 200 pagesize 200SELECT DEST_NAME,STATUS,DESTINATION,TRANSMIT_MODE FROM V$ARCHIVE_DEST WHERE DESTINATION IS NOT NULL;DEST_NAME STATUS DESTINATION TRANSMIT_MODE-------------------------------------------------- ------------------ ------------------------------ ------------------------LOG_ARCHIVE_DEST_1 VALID USE_DB_RECOVERY_FILE_DEST SYNCHRONOUSLOG_ARCHIVE_DEST_2 VALID sdfs01 PARALLELSYNC--far syncSQL&gt; col DESTINATION for a30col DEST_NAME for a50set line 200 pagesize 200SELECT DEST_NAME,STATUS,DESTINATION,TRANSMIT_MODE FROM V$ARCHIVE_DEST WHERE DESTINATION IS NOT NULL;SQL&gt; SQL&gt; SQL&gt;DEST_NAME STATUS DESTINATION TRANSMIT_MODE-------------------------------------------------- ------------------ ------------------------------ ------------------------LOG_ARCHIVE_DEST_1 VALID USE_DB_RECOVERY_FILE_DEST SYNCHRONOUSLOG_ARCHIVE_DEST_2 VALID stcdb ASYNCHRONOUSSTANDBY_ARCHIVE_DEST VALID USE_DB_RECOVERY_FILE_DEST SYNCHRONOUS 6. 主备库角色切换6.1 validate database1234validate database sdcdbvalidate database stcdbvalidate far_sync sdfs01validate far_sync stfs01 6.2 switchover to standby123456789101112DGMGRL&gt; switchover to stcdbPerforming switchover NOW, please wait...Operation requires a connection to instance \"sdcdb\" on database \"stcdb\"Connecting to instance \"sdcdb\"...Connected as SYSDBA.New primary database \"stcdb\" is opening...Operation requires start up of instance \"sdcdb\" on database \"sdcdb\"Starting instance \"sdcdb\"...ORACLE instance started.Database mounted.Database opened.Switchover succeeded, new primary is \"stcdb\" 切换完成后查看状态:1234567891011121314151617DGMGRL&gt; show configurationConfiguration - sd_adg Protection Mode: MaxAvailability Members: stcdb - Primary database stfs01 - Far sync instance sdcdb - Physical standby database Members Not Receiving Redo: sdfs01 - Far sync instanceFast-Start Failover: DISABLEDConfiguration Status:SUCCESS (status updated 9 seconds ago) 7. Failover测试7.1 故障切换当前主库为stcdb,切换到sdcdb123DGMGRL&gt; failover to sdcdbPerforming failover NOW, please wait...Failover succeeded, new primary is \"sdcdb\" 切换后的状态:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950DGMGRL&gt; show configurationConfiguration - sd_adg Protection Mode: MaxAvailability Members: sdcdb - Primary database sdfs01 - Far sync instance stcdb - Physical standby database (disabled) ORA-16661: the standby database needs to be reinstated Members Not Receiving Redo: stfs01 - Far sync instanceFast-Start Failover: DISABLEDConfiguration Status:SUCCESS (status updated 89 seconds ago)DGMGRL&gt; show database stcdbDatabase - stcdb Role: PHYSICAL STANDBY Intended State: APPLY-ON Transport Lag: (unknown) Apply Lag: (unknown) Average Apply Rate: (unknown) Real Time Query: OFF Instance(s): sdcdbDatabase Status:ORA-16661: the standby database needs to be reinstatedDGMGRL&gt; show database sdcdbDatabase - sdcdb Role: PRIMARY Intended State: TRANSPORT-ON Instance(s): sdcdb Database Warning(s): ORA-16629: database reports a different protection level from the protection modeDatabase Status:WARNING 7.2 故障切换后的ADG还原 重启旧primary(stcdb)到mount状态 123startup mountdgmgrl sys/managerreinstate database stcdb 如果原来数据库没有开启flashback功能，则failover之后需要重建standby:12345DGMGRL&gt; reinstate database stcdbORA-16795: the standby database needs to be re-createdConfiguration details cannot be determined by DGMGRLDGMGRL&gt; 7.3 重建standbyFailover后broker中重新保存着主备库信息，因此需要先移除再重建。由于数据库当前保护模式及redorouter的关系，移除standby过程出现以下错误:12DGMGRL&gt; REMOVE DATABASE stcdbError: ORA-16691: cannot remove a configuration member that is specified in a RedoRoutes property 解决方式：12345edit database sdcdb set property redoroutes='';edit far_sync sdfs01 set property redoroutes='';edit database stcdb set property redoroutes='';edit far_sync stfs01 set property redoroutes='';EDIT CONFIGURATION SET PROTECTION MODE AS 'MaxPerformance'; 之后再重建. 8. 错误排查8.1 Far sync standby redo log issueshow far_sync出现以下错误 123Far Sync Instance Warnings(s): ORA-16857: standby disconnected from redo source for longer than specified threshold ORA-16789: standby redo logs configured incorrectly 检查farsync实例日志：123456Errors in file /u01/app/oracle/diag/rdbms/sdfs01/sdcdb/trace/sdcdb_rsm0_22604.trc:ORA-00313: open failed for members of log group 4 of thread 0ORA-00312: online log 4 thread 0: '/u01/oradata/SDCDB/onlinelog/o1_mf_4_gp9tllq3_.log'ORA-27037: unable to obtain file statusLinux-x86_64 Error: 2: No such file or directoryAdditional information: 3 解决方法：Farsync实例重新添加standby log:1234567891011121314151617181920212223SQL&gt; select group# from v$standby_log; GROUP#---------- 4 5 6 7alter database clear logfile group 4;alter database clear logfile group 5;alter database clear logfile group 6;alter database clear logfile group 7;alter database drop logfile group 4;alter database drop logfile group 5;alter database drop logfile group 6;alter database drop logfile group 7;ALTER DATABASE ADD STANDBY LOGFILE SIZE 2048M;ALTER DATABASE ADD STANDBY LOGFILE SIZE 2048M;ALTER DATABASE ADD STANDBY LOGFILE SIZE 2048M;ALTER DATABASE ADD STANDBY LOGFILE SIZE 2048M; 8.2 ORA-166291Warning: ORA-16629: database reports a different protection level from the protection mode 主备库切换完成后提示以上错误，一般这种原因是由于配置中的保护模式与数据库中的保护模式不一致导致的. 如果不介意保护模式降低，可以修改为最大性能模式 1EDIT CONFIGURATION SET PROTECTION MODE AS 'MaxPerformance'; 或者，修改切换后的主库的日志模式 1edit database stcdb set property LogXptMode='SYNC'; 或者，重新re-enable configuration 在数据库配置正确下，出现这种错误，极可能是切换后日志传输进程被deffer掉了.重新re-enable下： 1234--查询状态, 如果protection_level为`RESYNCHRONIZATION`,则重新re-enableselect database_role,protection_mode,protection_level from v$database;disable configurationenable configuration Reference:Oracle Active Data Guard 远程同步任意距离的零数据丢失保护Data Guard 12C 新特性：Far Sync Standby (Doc ID 2179719.1)12c 的 Cascaded Standby 数据库 (Doc ID 2179701.1)使用DGMGRL(Dataguard Broker 命令行)执行12c Dataguard Swithover的最佳实践 (Doc ID 2440140.1)Scenarios Using the DGMGRL Command-Line Interface EOF","link":"/How-to-create-active-dataguard-with-farsync-by-using-dataguard-broker.html"},{"title":"12c PDB级别可修改参数","text":"12C中，PDB级别可修改的参数有上百个，通过v$system_parameter可查询，但PDB级别没有单独SPFILE的。当前数据库含有1个PDB： 123456SQL&gt; show pdbs CON_ID CON_NAME OPEN MODE RESTRICTED---------- ------------------------------ ---------- ---------- 2 PDB$SEED READ ONLY NO 3 SDPDB1 READ WRITE NO 尝试修改PDB级参数： 12SQL&gt; alter session set container = sdpdb1;SQL&gt; alter system set open_cursors=5000; 查看修改后的状态：1234567891011121314SQL&gt; show parameter open_cursorNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------open_cursors integer 5000SQL&gt; alter session set container = cdb$root;Session altered.SQL&gt; show parameter open_cursorNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------open_cursors integer 300 修改完后的PDB参数实际上存储在pdb_spfile$中： 12345678col db_uniq_name for a10col pdb_name for a10col params for a20col \"VALUE$\" for a20set line 200 pagesize 200select db_uniq_name,b.name pdb_name, sid, a.name params, value$from pdb_spfile$ a, gv$pdbs bwhere a.pdb_uid=b.con_uid; 一般建议使用v$parameter或者v$system_parameter去查看。1select name, con_id, value from v$system_parameter where name='open_cursors'; 通过v$parameter或者v$system_parameter中的ispdb_modifiable栏位确定该参数是否在PDB级别修改。123select name, ispdb_modifiablefrom v$parameterwhere ispdb_modifiable='TRUE' EOF","link":"/How-to-find-parameters-modifiable-in-PDB-level.html"},{"title":"Hugepage setting on Linux/AIX","text":"Nowadays, with inexpensive hardware cost, large memory is more and more popular then before. In best practice, for the large memory, there are some recommendations. 1. What is HugepageHugePages is a method to have larger pages where it is useful for working with very large memory. It is both useful in 32- and 64-bit configurations. By default, Linux kernel manage memory by dividing 4K pages, with Hugepage, the pagesize is increased to 2MB, therefore, reduce total number of pages by Linux kernel, meanwhile, it reduce the amount of memory for managing the page table. Hugepages are not swappable, which avoiding performance issue by swapping.From the Oracle Database perspective, with HugePages, the Linux kernel will use less memory to create pagetables to maintain virtual to physical mappings for SGA address range, in comparison to regular size pages. This makes more memory to be available for process-private computations or PGA usage. The Hugapage concept is introduced in 2.6.23 kernel. 2. How to setBe aware, Hugepage is conflict with AMM, DO NOT use AMM while Hugepage is enabled. 2.1 Linux platformThere&#39;s a script to calculate the Hugepage size in MOS: Oracle Linux: Shell Script to Calculate Values Recommended Linux HugePages / HugeTLB Configuration (Doc ID 401749.1) The output should be like this:12...Recommended setting: vm.nr_hugepages = 67 Add above values to /etc/sysctl.conf, and execute sysctl -p to enable the configuration. MOS: HugePages on Oracle Linux 64-bit (Doc ID 361468.1) Setting memlock in /etc/security/limits.confSet the value (in KB) slightly smaller than installed RAM, example for 64G RAM: 12oracle soft memlock 60397977oracle hard memlock 60397977 Verify Hugepage is set 123456grep -i huge /proc/meminfoHugePages_Total: 133300 --total huge pagesHugePages_Free: 28031 --free huge pagesHugePages_Rsvd: 0HugePages_Surp: 0Hugepagesize: 2048 kB DO NOT forget to disable AMM if enabled. Remove memory_target and memory_max_size from spfile is recommended. 2.2 AIX platformHuge page on AIX is called largepages.MOS: How to enable Large Page Feature on AIX-Based Systems (Doc ID 372157.1) Verify current large pages setting 1234567891011121314root@db01:/# vmo -L lgpg_sizeNAME CUR DEF BOOT MIN MAX UNIT TYPE DEPENDENCIES--------------------------------------------------------------------------------lgpg_size 0 0 0 0 16M bytes D lgpg_regions--------------------------------------------------------------------------------root@db01:/# vmo -L lgpg_regionsNAME CUR DEF BOOT MIN MAX UNIT TYPE DEPENDENCIES--------------------------------------------------------------------------------lgpg_regions 0 0 0 0 8E-1 D lgpg_size-------------------------------------------------------------------------------- Setting large pagesGive the Oracle user ID the CAP_BYPASS_RAC_VMM and CAP_PROPAGATE capabilities by following these steps: 1234567--First check the current capabilities:lsuser -a capabilities rootlsuser -a capabilities gridlsuser -a capabilities oracle--dd the CAP_BYPASS_RAC_VMM and CAP_PROPAGATE capabilities to the list of capabilities already assigned to this user ID:chuser capabilities=CAP_NUMA_ATTACH,CAP_BYPASS_RAC_VMM,CAP_PROPAGATE oraclechuser capabilities=CAP_NUMA_ATTACH,CAP_BYPASS_RAC_VMM,CAP_PROPAGATE root Configure the number and size of large pages:1vmo -p -o lgpg_regions=3800 -o lgpg_size=16777216 num_of_large_pages = INT((total_SGA_size-1)/16MB)+1Allocate 16777216 bytes to provide large pages, with 3800 actual large pages. Change lru_file_repage, the default is 1:1vmo -o lru_file_repage=0 Load the configuration into the kernel and reboot the server12bosboot -areboot Setting parameters in instance level 1alter system set lock_sga=TRUE scope=spfile; On AIX databases, USE_LARGE_PAGES parameter has NO impact.These parameters are only valid for databases running on Linux, the value of this parameter even if set to FALSE will be ignored on AIX. After starting up instance, verify large pages is using:12svmon -P SMON_PIDvmstat -P all 3. Disable transparent Hugepages in LinuxMOS: ALERT: Disable Transparent HugePages on SLES11, RHEL6, RHEL7, OL6, OL7, and UEK2 and above (Doc ID 1557478.1) For Linux, Oracle strongly recommend to disable transparent Hugepages, especially in RAC, transparent Hugepages will occur node reboot. Verify current setting 123cat /sys/kernel/mm/transparent_hugepage/enabled #OELcat //sys/kernel/mm/redhat_transparent_hugepage/enabled #RHEL [always] madvise never If &quot;enabled&quot; is NOT set to &quot;[never]&quot;, the Transparent HugePages are being used. Or1grep AnonHugePages /proc/meminfo If the AnonHugePages is not equal 0, the kernel is using Transparent HugePages. RHEL6Add &quot;transparent_hugepage=never&quot; to the kernel boot line in the &quot;/boot/grub/grub.conf&quot; file. RHEL7RHEL7: edit the &quot;/boot/grub2/grub.cfg&quot; file using the grubby command. 1234grubby --default-kernel /boot/vmlinuz-4.1.12-61.1.6.el7uek.x86_64grubby --args=\"transparent_hugepage=never\" --update-kernel /boot/vmlinuz-4.1.12-61.1.6.el7uek.x86_64grubby --info /boot/vmlinuz-4.1.12-61.1.6.el7uek.x86_64 Server must be rebooted for this to take effect Alternatively, add the following lines into the &quot;/etc/rc.local&quot; file and reboot the server.123456if test -f /sys/kernel/mm/transparent_hugepage/enabled; then echo never &gt; /sys/kernel/mm/transparent_hugepage/enabledfiif test -f /sys/kernel/mm/transparent_hugepage/defrag; then echo never &gt; /sys/kernel/mm/transparent_hugepage/defragfi 4. Recommended setting for SGA &gt; 100G in RACFor RAC system which SGA is over 100G, Oracle provide a best practice: Best Practices and Recommendations for RAC databases with SGA size over 100GB (Doc ID 1619155.1) init.ora parameters: 12a. Set _lm_sync_timeout to 1200(this recommendation is valid only for databases that are12.2 and lower) Setting this will prevent some timeouts during reconfiguration and DRM. It&#39;s a static parameter and rolling restart is supported. 1b. Set shared_pool_size to 15% or larger of the total SGA size. For example, if SGA size is 1 TB, the shared pool size should be at least 150 GB. It&#39;s a dynamic parameter. 1c. Set _gc_policy_minimum to 15000 There is no need to set _gc_policy_minimum if DRM is disabled by setting _gc_policy_time = 0. _gc_policy_minimum is a dynamic parameter, _gc_policy_time is a static parameter and rolling restart is not supported. To disable DRM, instead of _gc_policy_time, _lm_drm_disable should be used as it&#39;s dynamic. 12d. Set _lm_tickets to 5000(this recommendation is valid only for databases that are12.2 and lower) Default is 1000. Allocating more tickets (used for sending messages) avoids issues where we ran out of tickets during the reconfiguration. It&#39;s a static parameter and rolling restart is supported. When increasing the parameter, rolling restart is fine but a cold restart can be necessary when decreasing. 12e. Set gcs_server_processes to the twice the default number of lms processes that are allocated.(this recommendation is valid only for databases that are12.2 and lower) The default number of lms processes depends on the number of CPUs/cores that the server has, so please refer to the gcs_server_processes init.ora parameter section in the Oracle Database Reference Guide for the default number of lms processes for your server. Please make sure that the total number of lms processes of all databases on the server is less than the total number of CPUs/cores on the server. Please refer to the Document 558185.1 It&#39;s a static parameter and rolling restart is supported. EOF","link":"/Hugepage-setting-on-Linux-AIX.html"},{"title":"Issues of building RAC ADG","text":"The background of this case is that our customer want to build a RAC to RAC ADG, we used duplicate database from backup set to restore the ADG, but because the source database is very huge, about 16TB, all the backup sets were stored in NFS file system which shared by primary and standby. Customer&#39;s network bandwidth is 1000Mb, but the transportation speed is under 30MB/s, it took a very long time to restore the whole database. 1. Missing directoryThe first problem we encountered is data file name non-normalization, because the ASM diskgroups are the same with both primary and standby database, we didn&#39;t specify the set new name command, almost all the datafiles in this backup piece were failed to be restored.But it didn&#39;t impact the whole restore progress, duplicate process would restore those missing datafiles from previous backupset, or recreate them with empty contents.123456789101112131415161718192021222324252627--error messages because of datafile name's non-normalizationchannel ORA_AUX_DISK_1: restoring datafile 00555 to +dgdata5channel ORA_AUX_DISK_1: reading from backup piece /nfs_file/fullbakcup_4htlbj6l_1_1channel ORA_AUX_DISK_1: ORA-19870: error while restoring backup piece /nfs_file/fullbakcup_4htlbj6l_1_1--we didn't have +DGDATA3/proddb directoryORA-19504: failed to create file \"+DGDATA3/proddb/datafile/tbscrj_data_1_647.dbf\"ORA-17502: ksfdcre:4 Failed to create file +DGDATA3/proddb/datafile/tbscrj_data_1_647.dbfORA-15173: entry 'proddb' does not exist in directory '/'...--duplicate process tring to restore from previous backupchannel ORA_AUX_DISK_1: reading from backup piece /nfs_file/fullbakcup_4ptlgovj_1_1channel ORA_AUX_DISK_1: piece handle=/nfs_file/fullbakcup_4ptlgovj_1_1 tag=TAG20181221T175217channel ORA_AUX_DISK_1: restored backup piece 1channel ORA_AUX_DISK_1: restore complete, elapsed time: 20:44:49failover to previous backup--re-creating missing datafilecreating datafile file number=331 name=+DGDATA3/proddb/datafile/tbscrj_data_1_647.dbfcreating datafile file number=340 name=+dgdata3--because previous backup recored in control files are years ago, the backup set can't be found nowchannel ORA_AUX_DISK_1: ORA-19870: error while restoring backup piece /backup/DB_PRODDB_s70_p1_t939760538ORA-19505: failed to identify file \"/backup/DB_PRODDB_s70_p1_t939760538\"ORA-27037: unable to obtain file statusIBM AIX RISC System/6000 Error: 2: No such file or directoryAdditional information: 3 After restore finished, duplicate process would try to recover the standby, but the archived logs which need to be applied by recover process are years ago, recover process was failed again. All we need to do is restore those impacted files and recover them. 1.1 resolutionOne of the resolution is restore the missing datafiles from backup set, or take data file copy from primary: restore from backup set Every time you issue a restore command, rman would read relevant backup piece once, it&#39;s recommended to use one restore command to restore multiple datafiles, especial your backup piece is very large:123456789rman target / &lt;&lt;EOFrun &#123;allocate channel c1 type disk;allocate channel c2 type disk;restore datafile 340, 331, 342;release channel c1;release channel c2;&#125;EOF restore from datafile copy Take the datafile copy from primary:12345678910RMAN&gt; backup as copy datafile 319 format '/arch2/data319.dbf';Starting backup at 2019-01-04 10:01:24using target database control file instead of recovery catalogallocated channel: ORA_DISK_1channel ORA_DISK_1: SID=387 instance=proddb2 device type=DISKchannel ORA_DISK_1: starting datafile copyinput datafile file number=00319 name=+DGDATA3/proddb/datafile/tbscrj_fq_dzd_2017.382.940007677output file name=/arch2/data319.dbf tag=TAG20190104T100125 RECID=4 STAMP=996660397channel ORA_DISK_1: datafile copy complete, elapsed time: 00:05:15Finished backup at 2019-01-04 10:06:40 scp to the standby and catalog with it:1234567891011121314151617RMAN&gt; catalog datafilecopy '/gglog/data319.dbf'; using target database control file instead of recovery catalog cataloged datafile copy datafile copy file name=/gglog/data319.dbf RECID=1085 STAMP=996663809RMAN&gt; list copy of datafile 319; List of Datafile Copies ======================= Key File S Completion Time Ckp SCN Ckp Time ------- ---- - ------------------- ---------- ------------------- 1085 319 A 2019-01-04 11:03:29 16326666095593 2019-01-04 10:01:25 Name: /gglog/data319.dbf Tag: TAG20190104T100125RMAN&gt; restore datafile 319; 2. Backup from standby sideIf you want to backup in standby side, you must resync catalog from primary, otherwise, it will get the below errors:1234567resyncing from database with DB_UNIQUE_NAME PRODDBRMAN-00571: ===========================================================RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============RMAN-00571: ===========================================================RMAN-03009: failure of resync command on default channel at 11/22/2016 10:49:00ORA-17629: Cannot connect to the remote database serverORA-17627: ORA-00942: table or view does not exist resync catalog from primary 1234RMAN&gt; connect catalog rman/&lt;rman password&gt;@RMAN_REMOTE_CATconnected to recovery catalog databaseRMAN&gt; show all for db_unique_name PRODDB; resync catalog from standby 1RMAN&gt; resync catalog; After that, run the usual backup script in the standby. EOF","link":"/Issues-of-building-RAC-ADG.html"},{"title":"Log file sync wait event","text":"While user commit/rollback, commit will trigger log file sync, that is lgwr writing log buffer(memory) to log file(disk), before the commit/rollback completing, user will see the log file sync wait event.Quote from MOS ID:1376916.1: At the time of commit, the user session will post LGWR to write the log buffer (containing the current unwritten redo, including this session's redo records) to the redo log file. Once LGWR knows that its write requests have completed, it will post the user session to notify it that this has completed. The user session waits on 'log file sync' while waiting for LGWR to post it back to confirm all redo it generated have made it safely onto disk. The time between the user session posting the LGWR and the LG's posting the user after the write has completed is the wait time for 'log file sync' that the user session will show. In RAC system, gc log flush sync is another manifestation of log file sync. For diagnosing log file sync issue, we can: Check the AWR report and dynamic views Check the alert log, alert log shows how frequently redo log file are switching, recommended time for redo log switching is 15 mins to 30 mins As of 10.2.0.4, Oracle will write the warning message(&quot;log write elapsed time xxms, xxKB&quot;) to LG&#39;s trace file when writing takes more then 500ms, if the size is very small, we can consider the I/O is poor Check the hidden parameter _use_adaptive_log_file_sync, see its value is true or false 1. What cause log file sync1.1 Slow Disk I/OIf log file sync and log file parallel write are approximate equal, we can consider the Disk I/O is poor.The average wait time on log file sync on HDD should be less then 20ms. Checking LGWR wait time:123select event, state, seq#, seconds_in_wait, p1,p2from gv$sessionwhere program like '%LGWR%'; In AWR report, check the statistics of Log file parallel write per second. Recommendation Identify any bottle neck of I/O subsystems, including bandwidth Avoid placing redo log in RAID 5/RAID 6 disk array Avoid placing redo log in SSD Identify any other processes are occupied too much IO operations Example Below example shows slow disk IO, we can see that, the avg wait ms is over 20ms.TOP 10 wait event: Log file parallel write: If log file sync are greater then log parallel write and log parallel write is within the normal time, it doesn&#39;t mean I/O subsystem works fine, peak IO may occur during the past snapshot time, if nmon or oswatcher is implemented, there should be some clues with peak IO statistics. 1.2 High commit activityIn the AWR or Statspack report, if the average user calls per commit/rollback calculated as &quot;user calls/(user commits+user rollbacks)&quot; is less than 30, then commits are happening too frequently:Excessive commit(5.2 user calls/user commit): 1.3 High CPUsIf the r column of vmstat output is higher than CPU numbers, we can consider excessive consuming. Sometimes the IO response time is slower because of high CPU usages. 1.4 Bugs2. Relevant factorsIn AWR report, some other wait events maybe company with log file sync. As shown previous top 10 event, log buffer space and log file switch also on the top 10 event. 2.1 _use_adaptive_log_file_syncFrom 11.2.0.3, underscore parameter _use_adaptive_log_file_sync will affect log write performance because it changes the default behavior of LGWR. See Hidden parameter &#39;_use_adaptive_log_file_sync&#39; 2.2 log file blocksizeBlocksize in v$log view shows how much size of the block size, the default size is 512 kb, on a busy oltp system, modify the size to 2M maybe is a better option. 2.3 log file sizeFirst, if log file size is too small, alert.log will show lots of log and AWR report may show log file switch (checkpoint incomplete) wait event it the top 10 wait events.Below AWR report shows excessive log switches, Oracle recommend that a log switch should occur at most once every 15 to 20 minutes. Under this circumstance, resize redo log file size is a better choice(current size is the default size:50M). Reference:High Waits for &#39;Log File Sync&#39;: Known Issue Checklist for 11.2 (Doc ID 1548261.1)Troubleshooting: &#39;Log file sync&#39; Waits (Doc ID 1376916.1)Script to Collect Log File Sync Diagnostic Information (lfsdiag.sql) EOF","link":"/Log-file-sync-wait-event.html"},{"title":"A brief introduction of MGMTDB","text":"From Oracle 12.1.0.2, MGMTDB is a mandatory database installed by Oracle itself.The MGMTDB is a built-in database to store Grid Infrastructure Management Repository (GIMR). This repository enables such features as Cluster Health Monitor(aka CHM/OS, ora.crf), Oracle Database QoS Management, and Rapid Home Provisioning, and provides a historical metric repository that simplifies viewing of past performance and diagnosis of issues.Management Repository is a single instance database that&#39;s managed by Oracle Clusterware in 12c. As it&#39;s a single instance database, it will be up and running on one node in the cluster; as it&#39;s managed by GI, in case the hosting node is down, the database will be automatically failed over to other node. In 12.2, MGMTLSNR also listens on public network, therefore ora.MGMTLSNR has dependency on VIP resource type, both MGMTLSNR and MGMTDB will failover when public network is down. In 12.1, by default, Management database uses the same shared storage as OCR/Voting File; in 12.2, fresh installation allows separate diskgroup for it. What&#39;s the implications of not configuring Management Database during installation/upgrade? In 12.1.0.1, GIMR is optional, if Management Database is not selected to be configured during installation/upgrade, all features (Cluster Health Monitor (CHM/OS) etc) that depend on it will be disabled. This changed in 12.1.0.2, it&#39;s mandatory to have GIMR and it&#39;s not supported to be turned off with the exception of Exadata. Starting with Oracle Grid Infrastructure 19c, the Grid Infrastructure Management Repository (GIMR) is optional for new installations of Oracle Standalone Cluster. Oracle Domain Services Clusters still requirethe installation of a GIMR as a service component. How to start Management Database if it&#39;s down? Management Database is managed by GI and should be up and running all the time automatically. In case it&#39;s down for some reason, the following srvctl command can be used to start it: 123export ORACLE_SID=-MGMTDBsrvctl start mgmtdbsrvctl start mgmtlsnr How to &quot;cd&quot; to Management Database subdirectory to review trace file etc? 1234567891011cd -MGMTDB-bash: cd: -M: invalid optioncd: usage: cd [-L|-P] [dir]cd ./-MGMTDB ==&gt;&gt; this will work as &quot;./&quot; is specifiedmore -MGMTDB_m000_9912.trcmore: unknown option &quot;-M&quot;usage: more [-dflpcsu] [+linenum | +/pattern] name1 name2 ...more ./-MGMTDB_m000_9912.trc How much (shared) disk space should be allocated for the Management Database? Minimum: At least 5.2 GB for the OCR volume that contains the Grid Infrastructure Management Repository (4.5 GB + 300 MB voting files + 400 MB OCR), plus 500 MB for each node for clusters greater than four nodes. For example, a six-node cluster allocation should be 6.2 GB. What is the default MGMT listener port in 12.2? MGMT listener default is 1525 in 12.2 version. Repost from:FAQ: 12c Grid Infrastructure Management Repository (GIMR) (Doc ID 1568402.1) EOF","link":"/MGMTDB-in-Oracle-12c-RAC.html"},{"title":"Migrating Oracle ASM storage","text":"This post is about how to migrate Oracle asm data to another storage, for my environment, is migrating from HHD storage to SSD storage, the redo blocksize also need to be modified to 4K for good performance. 1. Preparation for migration1.1 Backup whole database123RMAN&gt;backup database format '/backup/rman_full_%U' tag='db_full_bak'including archive log all; 1.2 Verify file types and numbers in the ASM12345678910111213141516171819202122232425262728-- grid usersqlplus \"/as sysasm\"select d.name group_name,f.type,count(*) cnt from v$asm_file f join v$asm_diskgroup d on f.group_number=d.group_number group by rollup (d.name,f.type);--output exampleGROUP_NAME TYPE CNT--------------------------- -------------------------- ----------CRS OCRFILE 1CRS DATAFILE 11CRS PASSWORD 1CRS TEMPFILE 3CRS ONLINELOG 3CRS CONTROLFILE 1CRS PARAMETERFILE 1CRS ASMPARAMETERFILE 1CRS 22FRA ONLINELOG 8FRA ARCHIVELOG 9FRA CONTROLFILE 1FRA 18DBDATA DATAFILE 25DBDATA PASSWORD 1DBDATA TEMPFILE 6DBDATA PARAMETERFILE 1DBDATA 33 73 1.3 Verify asm_diskstrings parameterMust include new storage path in the asm_diskstrings. 12--grid usershow parameter asm_diskstring 1.4 Verify current ASM disks and diskgroups mapping information12345678910111213141516171819--grid usersqlplus \"/as sysasm\"set line 200 pagesize 200col name for a10col path for a40select group_number,name,OS_MB ,TOTAL_MB,FREE_MB ,HOT_USED_MB,COLD_USED_MB,PATH ,SECTOR_SIZE from v$asm_disk order by 1;col PATH for a30col DG_NAME for a10col DG_STATE for a10col FAILGROUP for a15col name for a20set lines 200 pages 10000select dg.name dg_name, dg.state dg_state, dg.type, d.disk_number dsk_no,d.path, d.mount_status, d.FAILGROUP,d.name, d.statefrom v$asm_diskgroup dg, v$asm_disk dwhere dg.group_number=d.group_numberorder by dg_name, dsk_no; 1.5 Backup ASM diskgroup metadata and OCR/Voting disk information Query OCR and voting disk information 1234--root user/u01/app/12.1.0/grid/bin/crsctl query css votedisk/u01/app/12.1.0/grid/bin/ocrcheckcat /etc/oracle/ocr.loc Backup OLR and OCR Because voting disk is backed up by Oracle automatically, no need to backup again.1234567--root user--check the backup/u01/app/12.1.0/grid/bin/ocrconfig -showbackup--backup olr/u01/app/12.1.0/grid/bin/ocrconfig -local -manualbackup--backup ocr/u01/app/12.1.0/grid/bin/ocrconfig -manualbackup Backup asm diskgroup metadata 1234ASMCMD [+] &gt; md_backup /home/grid/ocrvote.bak -G OCRASMCMD [+] &gt; md_backup /home/grid/datadg.bak -G DBDATAASMCMD [+] &gt; md_backup /home/grid/fradg.bak -G FRAsrvctl config asm &gt; /home/grid/ocr_config.bak Backup ASM spfile 12345--grid user$ORACLE_HOME/bin/gpnptool get -o- | xmllint --format - | grep -i spfileasmcmd spgetsqlplus / as sysasmSQL&gt; create pfile = '/home/grid/pfile_asm.txt' from spfile; 2. Migrating ASM diskgroups2.1 Adding new disk to diskgroups12345678910111213--grid usersqlplus / as sysasmALTER DISKGROUP fra ADD DISK '/dev/mapper/fra_new_01', '/dev/mapper/fra_new_02';--Monitoring rebalance progressset line 3000select * from gv$asm_operation;--Speed up rebalancealter diskgroup fra rebalance power 48;--Put rebalance power back to 1 after rebalancingalter diskgroup fra rebalance power 1; 2.2 Dropping old disk123456--grid usersqlplus / as sysasm--It's better to drop disk one by oneALTER DISKGROUP fra drop DISK 'FRA_0000';ALTER DISKGROUP fra drop DISK 'FRA_0001'; Also, monitor and adjust rebalance power if needed. For all the diskgroups in ASM, repeat step 2.1 - 2.2 one diskgroup by one diskgroup. 2.3 Verify migration result1234567891011121314151617181920212223sqlplus \"/as sysasm\"set line 200 pagesize 200col name for a10col path for a40select group_number,name,OS_MB ,TOTAL_MB,FREE_MB ,HOT_USED_MB,COLD_USED_MB,PATH ,SECTOR_SIZE from v$asm_disk order by 1;col PATH for a30col DG_NAME for a10col DG_STATE for a10col FAILGROUP for a15col name for a20set lines 200 pages 10000select dg.name dg_name, dg.state dg_state, dg.type, d.disk_number dsk_no,d.path, d.mount_status, d.FAILGROUP,d.name, d.statefrom v$asm_diskgroup dg, v$asm_disk dwhere dg.group_number=d.group_numberorder by dg_name, dsk_no;select d.name group_name,f.type,count(*) cnt from v$asm_file f join v$asm_diskgroup d on f.group_number=d.group_number group by rollup (d.name,f.type); 3. Modify redo log file&#39;s blocksize12345678--oracle user--query current log infocol member for a80set line 200 pagesize 999select a.inst_id,thread#,a.status, a.bytes/1024/1024,a.group#,b.type,member, a.blocksizefrom gv$log a,gv$logfile bwhere a.group#=b.group#order by 5; We need to add hidden parameter _disk_sector_size_override for modifing redo blocksize, this parameter is dynamic, no instance recycle needed. 1alter system set \"_disk_sector_size_override\"=TRUE scope=both; Add new redo log 12345678alter database add logfile thread 1 group 9 ('+FRA') size 2048M blocksize 4096;alter database add logfile thread 1 group 10 ('+FRA') size 2048M blocksize 4096;alter database add logfile thread 1 group 11 ('+FRA') size 2048M blocksize 4096;alter database add logfile thread 1 group 12 ('+FRA') size 2048M blocksize 4096;alter database add logfile thread 2 group 13 ('+FRA') size 2048M blocksize 4096;alter database add logfile thread 2 group 14 ('+FRA') size 2048M blocksize 4096;alter database add logfile thread 2 group 15 ('+FRA') size 2048M blocksize 4096;alter database add logfile thread 2 group 16 ('+FRA') size 2048M blocksize 4096; Drop old redo groups Ensure the log groups need to be dropped are in inactive status, by switching log, and checkpoint, we can put target redo groups in inactive state 1234567891011121314151617181920212223242526SQL&gt;ALTER SYSTEM ARCHIVE LOG CURRENT;ALTER SYSTEM ARCHIVE LOG CURRENT;alter system checkpoint;alter system checkpoint;--Confirm target redo group is in inactive statuscol member for a80set line 200select a.inst_id,thread#,a.status, a.bytes/1024/1024,a.group#,b.type,member, a.blocksizefrom gv$log a,gv$logfile bwhere a.group#=b.group#order by 5;--Drop old groupalter database drop logfile group 1;alter database drop logfile group 2;alter database drop logfile group 3;alter database drop logfile group 4;alter database drop logfile group 5;alter database drop logfile group 6;alter database drop logfile group 7;alter database drop logfile group 8;--Backup controlfilealter database backup controlfile; 4. Risk assessment If ASM diskgroup is too large, rebalance maybe can&#39;t complete in the change window Setting rebalance power too high would cause bad performance It&#39;s recommended to schedule multiple change window if data amount is too large. 5. BackoutAdding disks is a low risk operation, except rebalance power set to high and impact the performance. Under such circumstance, lower down rebalance power speed: 1alter diskgroup DG_NAME rebalance power 1; If something wrong with dropping disks, stop dropping operation by below command, only available for status = dropping in v$asm_disk: 1ALTER DISKGROUP data1 UNDROP DISKS; If something wrong with OCR or voting disk during migrating or RAC can&#39;t be started after migrating, follow below steps to restore OCR: 1234567891011121314151617181920212223242526--root user, stop crs resource on all nodescrsctl stop crs -fcrsctl stop resource ora.crsd -init--root user, start crs in one node only in exclusive modecrsctl start crs -excl -nocrs--restore OCRocrconfig -restore OCR_BACKUP_FILENAME--check the statusocrcheck--restore voting diskcrsctl replace votedisk +asm_disk_group--check the statuscrsctl query css votedisk--restart RAC clustercrsctl stop crs -fcrsctl stop cluster -allcrsctl start cluster -all--check all nodes OCR with CVU toolcluvfy comp ocr -n all -verbosecrsctl check cluster -all 6. Alternative way of migratingPrevious steps are available for online migration, we also can use rman copy to migrate, which need to stop database. Assume we&#39;ve create a new diskgroup named DATA_NEW, our purpose is to restore the whole database to DATA_NEW diskgroup. Backup database as copy into new diskgroup 123456789run &#123;allocate channel c1 type disk;allocate channel c2 type disk;backup as copy database format '+data_new';release channel c1;release channel c2;&#125;RMAN&gt; list copy; After backing up, restart database to mount status 12srvctl stop database -d DB_NAMEsrvctl start database -d DB_NAME -startoptions mount Switch database to copy 1234RMAN&gt;switch database to copy;RMAN&gt;recover database; Restart database in normal mode 12srvctl stop database -d DB_NAMEsrvctl start database -d DB_NAME Reference:How To A Recreate Disk Group Used By CRSOCR / Vote disk Maintenance Operations: (ADD/REMOVE/REPLACE/MOVE) (Doc ID 428681.1)Software Patch Level and 12c Grid Infrastructure OCR Backup/Restore (Doc ID 1558920.1)Linux/Unix 平台，在CRS 磁盘组完全丢失后，如何恢复基于 ASM 的 OCR (Doc ID 2331776.1) EOF","link":"/Migrating-Oracle-ASM-storage-via-ASM-disk-rebalance.html"},{"title":"OCR Voting disk replacement or movement","text":"Essentially speaking, OCR disk is a two-way ASM disk, which can be replaced via ASM disk rebalance method.This post introduces another method by ocrconfig tool.Assume we&#39;ve created a new diskgroup name OCR_NEW to replace old diskgroup OCR. Pay attention to compatible.asm parameter of diskgroup. 1. Replace voting disk1234--root usercrsctl replace votedisk +OCR_NEW--check the resultcrsctl query css votedisk 2. Replace OCR1234567--root userocrconfig -add +OCR_NEW--check the result, the result should include +OCR_NEW and +OCRocrchek--delete old diskgroupocrconfig -delete +OCR 3. Recreate spfile for ASM Check current spfile location 123--grid user$ORACLE_HOME/bin/gpnptool get -o- | xmllint --format - | grep -i spfileasmcmd spget Recreate spfile to new diskgroup 123--grid usercreate pfile='/home/grid/asmpfile.ora' from spfile;create spfile='+OCR_NEW' from pfile='/home/grid/asmpfile.ora'; 4. Move password file to new diskgroup12--grid userasmcmd pwmove --asm +OCR/orapwASM +OCR_NEW/orapwASM 5. Migrate mgmtdb(as of 12c)MGMTDB is a built-in CDB database managed by Oracle GI, it stores Cluster Health Monitor information, by default, this database is localted on OCR disk. If we move OCR to another diskgroup, ensure this database also need to be moved. 5.1 Migrate by RMAN copy Check current status of mgmtdb 1234--grid usersrvctl status diskgroup -g ocrsrvctl config mgmtdbsrvctl status mgmtdb Restart mgmtdb to mount status 123--grid usersrvctl stop mgmtdbsrvctl stop mgmtlsnr Backup mgmtdb 1234--grid userexport ORACLE_SID=-MGMTDBRMAN&gt; startup mountRMAN&gt; backup database format '/home/grid/backup/rman_mgmtdb_%U' tag='bk_db_move_dg'; Restore spfile to new diskgroup 1RMAN&gt; restore spfile to \"+OCR_NEW\" from '/home/grid/backup'; Confirm the result:1234srvctl config mgmtdb |grep SpfileSQL&gt; shutdown immediateSQL&gt; startup nomountSQL&gt; show parameter spfile Restore controlfile to new diskgroup 12345RMAN&gt; shutdown immediateRMAN&gt; startup nomountSQL&gt; show parameter control_fileSQL&gt; alter system set control_files='+OCR_NEW' scope=spfile ;RMAN&gt; restore controlfile from '/home/grid/backup/xxxxx'; Migrate mgmtdb by rman copy 12345RMAN&gt; alter database mount;RMAN&gt; backup as copy DEVICE TYPE DISK DATABASE FORMAT '+OCR_NEW';RMAN&gt; SWITCH DATABASE TO COPY;--confirm the result, all tempfile should be resided in old diskgroupRMAN&gt; report schema; Recreate temp file 123456RMAN&gt; run &#123;SET NEWNAME FOR TEMPFILE 1 TO '+OCR';SET NEWNAME FOR TEMPFILE 2 TO '+OCR';SET NEWNAME FOR TEMPFILE 3 TO '+OCR';SWITCH TEMPFILE ALL;&#125; Verify migration result 1234RMAN&gt; startupRMAN&gt; report schema;--delete copyRMAN&gt; delete copy; Modify mgmtdb startup resource 123456--grid usercrsctl status res ora.mgmtdb -p |grep OCR--replacing new diskgroup for start/stop dependencycrsctl modify res ora.mgmtdb -attr \"START_DEPENDENCIES='hard(ora.MGMTLSNR,ora.OCR_NEW.dg) weak(uniform:ora.ons) pullup(ora.MGMTLSNR,ora.OCR_NEW.dg)'\" -unsupportedcrsctl modify res ora.mgmtdb -attr \"STOP_DEPENDENCIES='hard(intermediate:ora.MGMTLSNR,intermediate:ora.asm,shutdown:ora.OCR_NEW.dg)'\" -unsupported The unsupported key word is for fixing below issue, because as 12c, Oracle does not support to modify ora resource by crsctl, using srvctl to modify ora resource instead, but didn&#39;t find anything about how to modify ora* resource by srvctl. 1CRS-4995: The command ‘Modify resource’ is invalid in crsctl. Use srvctl for this command. Delete old diskgroup resource 12345--grid user, stop old diskgroupsrvctl stop diskgroup -g OCR--restart gi, if nothing wrong, old diskgroup can be droppedexport ORACLE_SID=+ASM1SQL&gt; DROP DISKGROUP CRS INCLUDING CONTENTS; 5.2 Migrate by recreating Backup current configuration 1[grid@racdb1:/home/grid]$ oclumon dumpnodeview -allnodes -v &gt; ./mgmtdb.bak Stop and disable ora.crf resource on all nodes 12345678910[root@racdb1 ~]# /u01/app/12.1.0/grid/bin/crsctl stop res ora.crf -initCRS-2673: Attempting to stop 'ora.crf' on 'racdb1'CRS-2677: Stop of 'ora.crf' on 'racdb1' succeeded[root@racdb2 ~]# /u01/app/12.1.0/grid/bin/crsctl stop res ora.crf -initCRS-2673: Attempting to stop 'ora.crf' on 'racdb2'CRS-2677: Stop of 'ora.crf' on 'racdb2' succeeded--Disable ora.crf[root@racdb1 ~]# /u01/app/12.1.0/grid/bin/crsctl modify res ora.crf -attr ENABLED=0 -init[root@racdb2 ~]# /u01/app/12.1.0/grid/bin/crsctl modify res ora.crf -attr ENABLED=0 -init Delete mgmtdb by dbca As grid user, locate the node mgmrdb is running:1srvctl status mgmtdb As grid user, delete mgmtdb by dbca: 12345678910111213141516[grid@racdb1:/home/grid]$ dbca -silent -deleteDatabase -sourceDB -MGMTDBConnecting to database4% complete9% complete14% complete19% complete23% complete28% complete47% completeUpdating network configuration files48% complete52% completeDeleting instance and datafiles76% complete100% completeLook at the log file \"/u01/app/grid/cfgtoollogs/dbca/_mgmtdb.log\" for further details. Recreate mgmtdb As grid user create container database: 123456789101112131415161718192021222324252627282930[grid@racdb1:/home/grid]$ dbca -silent -createDatabase -sid -MGMTDB -createAsContainerDatabase true \\-templateName MGMTSeed_Database.dbc -gdbName _mgmtdb -storageType ASM \\-diskGroupName +CRS -datafileJarLocation $ORACLE_HOME/assistants/dbca/templates \\-characterset AL32UTF8 -autoGeneratePasswords -skipUserTemplateCheckRegistering database with Oracle Grid Infrastructure5% completeCopying database files7% complete9% complete16% complete23% complete30% complete37% complete41% completeCreating and starting Oracle instance43% complete48% complete49% complete50% complete55% complete60% complete61% complete64% completeCompleting Database Creation68% complete79% complete89% complete100% completeLook at the log file \"/u01/app/grid/cfgtoollogs/dbca/_mgmtdb/_mgmtdb0.log\" for further details. As grid user, create PDB, be aware, -pdbname is the cluster name, any &#39;-&#39; of cluster should be replaced by &#39;_&#39;12345678910111213141516[grid@racdb1:/home/grid]$ dbca -silent -createPluggableDatabase -sourceDB -MGMTDB \\-pdbName racdb -createPDBFrom RMANBACKUP \\-PDBBackUpfile $ORACLE_HOME/assistants/dbca/templates/mgmtseed_pdb.dfb \\-PDBMetadataFile $ORACLE_HOME/assistants/dbca/templates/mgmtseed_pdb.xml \\-createAsClone trueCreating Pluggable Database4% complete12% complete21% complete38% complete55% complete85% completeCompleting Pluggable Database Creation100% completeLook at the log file \"/u01/app/grid/cfgtoollogs/dbca/_mgmtdb/racdb/_mgmtdb.log\" for further details. Post-creation 12345--check the status of mgmtdb with grid usersrvctl status MGMTDB--secure the mgmtdb credentialmgmtca Start ora.crf on all nodes 123456--with root user on each node[root@racdb1 ~]# /u01/app/12.1.0/grid/bin/crsctl modify res ora.crf -attr ENABLED=1 -init[root@racdb2 ~]# /u01/app/12.1.0/grid/bin/crsctl modify res ora.crf -attr ENABLED=1 -init[root@racdb1 ~]# /u01/app/12.1.0/grid/bin/crsctl start res ora.crf -initCRS-2672: Attempting to start 'ora.crf' on 'racdb2'CRS-2676: Start of 'ora.crf' on 'racdb2' succeeded 5.3 Migrate by MOS tool mdbutil.plBelow example is migrating mgmtdb from OCR to CRS. Check the status 123456789[grid@racdb1:/home/grid]$ ./mdbutil.pl --statusmdbutil.pl version : 1.982019-07-31 19:13:43: I Checking CHM status...2019-07-31 19:14:06: I Listener MGMTLSNR is configured and running on racdb12019-07-31 19:14:10: I Database MGMTDB is configured and running on racdb12019-07-31 19:14:11: I Cluster Health Monitor (CHM) is configured and running--------------------------------------------------------------------------------CHM Repository Path = +OCR/_MGMTDB/8ECBF2858125261EE053C938A8C0A78B/DATAFILE/sysmgmtdata.259.1014914317MGMTDB space used on DG +OCR = 4187 Mb Migrate mgmtdb files via mdbutil tool 12345678910111213141516171819202122232425262728293031[grid@racdb1:/home/grid]$ ./mdbutil.pl --mvmgmtdb --target=+CRSmdbutil.pl version : 1.98Moving MGMTDB, it will be stopped, are you sure (Y/N)? y2019-07-31 19:15:57: I Checking for the required paths under +CRS2019-07-31 19:16:06: I Creating new path +CRS/_MGMTDB/ONLINELOG2019-07-31 19:16:08: I Creating new path +CRS/_MGMTDB/DATAFILE2019-07-31 19:16:10: I Creating new path +CRS/_MGMTDB/DATAFILE/PDB$SEED2019-07-31 19:16:10: I Creating new path +CRS/_MGMTDB/DATAFILE/TEMPFILE/PDB$SEED2019-07-31 19:16:15: I Creating new path +CRS/_MGMTDB/DATAFILE/racdb_cluster2019-07-31 19:16:16: I Creating new path +CRS/_MGMTDB/TEMPFILE/racdb_cluster2019-07-31 19:16:17: I Getting MGMTDB Database files location2019-07-31 19:16:17: I Getting MGMTDB Temp files location2019-07-31 19:16:17: I Getting MGMTDB PDB PDB$SEED files location2019-07-31 19:16:18: I Getting MGMTDB PDB PDB$SEED Temp files location2019-07-31 19:16:18: I Getting MGMTDB PDB racdb_cluster files location2019-07-31 19:16:19: I Getting MGMTDB PDB racdb_cluster Temp files location2019-07-31 19:16:23: I Creating temporary PFILE2019-07-31 19:16:23: I Creating target SPFILE2019-07-31 19:16:28: I Stopping mgmtdb2019-07-31 19:16:51: I Copying MGMTDB DBFiles to +CRS2019-07-31 19:17:00: I Copying MGMTDB PDB$SEED DBFiles to +CRS2019-07-31 19:17:04: I Copying MGMTDB PDB DBFiles to +CRS2019-07-31 19:17:23: I Creating the CTRL File2019-07-31 19:19:03: I The CTRL File has been created and MGMTDB is now running from +CRS2019-07-31 19:19:03: I Setting MGMTDB SPFile location2019-07-31 19:19:07: I Modifing the init parameter2019-07-31 19:19:07: I Removing old MGMTDB2019-07-31 19:19:20: I Changing START_DEPENDENCIES2019-07-31 19:19:21: I Changing STOP_DEPENDENCIES2019-07-31 19:19:22: I Restarting MGMTDB using target SPFile2019-07-31 19:21:12: I MGMTDB Successfully moved to +CRS! Check the result 12345678910[grid@racdb1:/home/grid]$ ./mdbutil.pl --statusmdbutil.pl version : 1.982019-07-31 19:23:18: I Checking CHM status...2019-07-31 19:23:20: I Listener MGMTLSNR is configured and running on racdb12019-07-31 19:23:21: I Database MGMTDB is configured and running on racdb12019-07-31 19:23:21: I Cluster Health Monitor (CHM) is configured and running--------------------------------------------------------------------------------CHM Repository Path = +CRS/_MGMTDB/DATAFILE/racdb_cluster/sysmgmtdata.20190731191620.dbfMGMTDB space used on DG +CRS = 742 Mb-------------------------------------------------------------------------------- Reference:How to Move/Recreate GI Management Repository to Different Shared Storage (Diskgroup, CFS or NFS etc) (Doc ID 1589394.1)crsctl modify ora.* resource fails with CRS-4995 in 12.1.0.2 and above (Doc ID 1918102.1)MDBUtil: GI Management Repository configuration tool (Doc ID 2065175.1) EOF","link":"/OCR-Voting-disk-replace-or-move.html"},{"title":"优化expdp/impdp思路","text":"expdp RAC环境中，设置cluster=n参数 排除统计信息导出: exclude=statistics 并行导出: parallel=Number Of CPUs RAC环境中，设置PARALLEL_FORCE_LOCAL=TRUE 12c中，添加version=12.1以增强兼容性 示例：1234expdp system/manager@xxxx schemas=xxx \\cluster=n exclude=statistics parallel=4 \\PARALLEL_FORCE_LOCAL=true version=12.1 \\directory=xxx dumpfile=xxx.dmp impdp 导入数据后再建立索引、约束等, 以避免产生大量的undo和temp 123--生成DDl语句impdp system/manager@xxxx directory=xxx dumpfile=xxx.dmp \\sqlfile=xxx.sql include=constraint,index 根据sql语句保留约束、索引的创建语句再进行导入：1234impdp system/xxxxxxxx directory=datapump dumpfile=xxx.dump \\EXCLUDE=STATISTICS,constraint,index \\remap_tablespace=aaaa:bbbb parallel=4 \\remap_schema=xxx:xxx transform=disable_archive_logging:Y 尽量不要使用TABLE_EXISTS_ACTION=APPEND or TABLE_EXISTS_ACTION=TRUNCATE 导入时添加transform=disable_archive_logging:Y参数，12c新特性，可以在导入的时候减少redo的产生 Reference:Error ORA-30036 DataPump Import (IMPDP) Exhausts Undo Tablespace (Doc ID 727894.1)Import DataPump - How To Limit The Amount Of UNDO Generation of an IMPDP job ? (Doc ID 1670349.1) EOF","link":"/Optimize-expdp-impdp.html"},{"title":"Oracle 12c Proactive Bundle Patch","text":"As of Oracle 12.1.0.2, ORACLE provide a new way to patch PSU which called Proactive Bundle Patch(DBBP) and replace the previous PSU.With DBBP, applying patch is more easier. PSU is conflict with DBBP, if you want to apply DBBP in your database which PSUs are installed, you have to rollback all PSUs to make sure applying DBBP successfully.Because DBBP covers more bug fixes than PSU, it&#39;s recommended to use DBBP to apply latest patches. 1. Pre-installation taskFirst, it&#39;s always essential to check the opatch version, find the readme file in the patchset to meet the minimum version. In RAC environment, both GRID_HOME and ORACLE_HOME Opatch should be replaced with target version. Reserve historical information 12345678910111213141516&lt;ORACLE_HOME&gt;/OPatch/opatch lsinventory -detail -oh &lt;ORACLE_HOME&gt; &gt;/tmp/lsinv.info&lt;ORACLE_HOME&gt;/OPatch/opatch lspatches &gt;&gt; /tmp/lsinv.infoSQL&gt; SET LINESIZE 200COLUMN action_time FORMAT A20COLUMN action FORMAT A10COLUMN status FORMAT A10COLUMN description FORMAT A40COLUMN version FORMAT A10COLUMN bundle_series FORMAT A10spool /tmp/datapatch.infoSELECT TO_CHAR(action_time, 'DD-MON-YYYY HH24:MI:SS') AS action_time,action, status, description, version, patch_id, bundle_seriesFROM sys.dba_registry_sqlpatchORDER by action_time;spool off Run OPatch Conflict check 1$ORACLE_HOME/OPatch/opatch prereq CheckConflictAgainstOHWithDetail -phBaseDir &lt;UNZIPPED_PATCH_LOCATION&gt;/27968010/27547374 One-off patch conflict detection and resolution 1GRID_HOME/OPatch/opatchauto apply &lt;UNZIPPED_PATCH_LOCATION&gt;/27968010 -analyze 2. Installation2.1 Applying DBBP opatchautoRunning below commands on all nodes, this command require sequential execution, DO NOT run in both nodes parallel in RAC. 123--with root userexport PATH=$PATH:&lt;GI_HOME&gt;/OPatchopatchauto apply &lt;UNZIPPED_PATCH_LOCATION&gt;/27968010 After opatchauto installed, lspatches will show latest patch numbers, but they&#39;re not yet applied to database. 2.2 DatapatchExecute below commands in one of instance(RAC) with Oracle user id:1234567--for CDBalter pluggable database all open;$ORACLE_HOME/OPatch/datapatch -verboseSQL&gt; @?/rdbms/admin/utlrp.sql--If an OJVM PSU is installed or planned to be installed, no further actions are necessary. Otherwise, the workaround of using the OJVM Mitigation patch can be activated. As SYSDBA do the following from the admin directorySQL&gt; @?/rdbms/admin/dbmsjdev.sqlSQL&gt; exec dbms_java_dev.disable Upgrade rman catalog if any 12rman catalog username/password@aliasRMAN&gt; UPGRADE CATALOG; 2.3 Verifying patching result123456789101112131415161718ET LINESIZE 400COLUMN action_time FORMAT A20COLUMN action FORMAT A10COLUMN status FORMAT A10COLUMN description FORMAT A45COLUMN version FORMAT A10COLUMN bundle_series FORMAT A10SELECT TO_CHAR(action_time, 'DD-MON-YYYY HH24:MI:SS') AS action_time, action, status, description, version, patch_id, bundle_seriesFROM sys.dba_registry_sqlpatchORDER by action_time; 3. Backout Execute as root to uninstall patches 1234--RAC&lt;GI_HOME&gt;/OPatch/opatchauto rollback &lt;UNZIPPED_PATCH_LOCATION&gt;/27968010--Non RACopatch rollback -id 27547374 Update data dictionary with datapatch 1234SQL&gt; startup--CDB, not necessary if non-CDBSQL&gt; alter pluggable database all open;$ORACLE_HOME/OPatch/datapatch -verbose 4. Trouble shootingIn Linux platform, with error:1opatchauto/opatch apply failing with CLSRSC-46: Error: &apos;&lt;GRID_HOME&gt;/suptools/tfa/release/tfa_home/jlib/jewt4.jar&apos; does not exist According to MOS: opatchauto/opatch apply failing with CLSRSC-46: Error: &#39;&lt;GRID_HOME&gt;/suptools/tfa/release/tfa_home/jlib/jewt4.jar&#39; does not exist (Doc ID 2409411.1), following the instructions:12cp -p $GRID_HOME/crs/sbs/crsconfig_fileperms.sbs $GRID_HOME/crs/sbs/crsconfig_fileperms.sbs.bakcp -p $GRID_HOME/crs/utl/&lt;node&gt;/crsconfig_fileperms $GRID_HOME/crs/utl/&lt;node&gt;/crsconfig_fileperms.bak Remove below lines in above files:12unix %ORA_CRS_HOME%/suptools/tfa/release/tfa_home/jlib/jdev-rt.jar %HAS_USER% %ORA_DBA_GROUP% 0644unix %ORA_CRS_HOME%/suptools/tfa/release/tfa_home/jlib/jewt4.jar %HAS_USER% %ORA_DBA_GROUP% 0644 Run opatchauto resume again will proceed to apply patches. AIX dba_registry_sqlpatch shows nothing This is related with [BUG 20244108 - QOPIPREP.BAT MODIFIES XML INVENTORY WHILE READING], after applying one-off patch Patch 20244108 everything works fine. EOF","link":"/Oracle-12c-Proactive-Bundle-Patch.html"},{"title":"Prerequisite Check \"CheckActiveFilesAndExecutables\" Failed","text":"在对数据库进行打补丁的时候，遇到以下错误：12345678910111213141516171819202122232425itjkdb01l:/oracle&gt; opatch applyOracle Interim Patch Installer version 12.2.0.1.16Copyright (c) 2019, Oracle Corporation. All rights reserved.Oracle Home : /oracle/app/oracle/12.1.0Central Inventory : /grid/app/oraInventory from : /oracle/app/oracle/12.1.0/oraInst.locOPatch version : 12.2.0.1.16OUI version : 12.1.0.2.0Log file location : /oracle/app/oracle/12.1.0/cfgtoollogs/opatch/opatch2019-08-12_10-20-02AM_1.logVerifying environment and performing prerequisite checks...Prerequisite check \"CheckActiveFilesAndExecutables\" failed.The details are:Following active executables are not used by opatch process :/oracle/app/oracle/12.1.0/bin/oracleFollowing active executables are used by opatch process :UtilSession failed: Prerequisite check \"CheckActiveFilesAndExecutables\" failed.Log file location: /oracle/app/oracle/12.1.0/cfgtoollogs/opatch/opatch2019-08-12_10-20-02AM_1.logOPatch failed with error code 73 原因当使用opatch apply进行补丁应用时，在$ORACLE_HOME下的所有进程要被停止掉，如果有任何的进程在跑，就会报上述opatch 73的错误。 尝试用ps, lsof等命令查找出相关进程，如有必要，可以把它杀掉。之后重启apply，恢复正常。 建议在执行apply前，运行以下命令: 1$ORACLE_HOME/OPatch/opatch prereq CheckActiveFilesAndExecutables -ph ./ EOF","link":"/Prerequisite-Check-CheckActiveFilesAndExecutables-Failed.html"},{"title":"远程复制数据库到现有的CDB","text":"在12c中，针对PDB，Oracle提供了快捷便利的迁移方式。 以下分别示例了从传统数据库以及PDB下，迁移/复制数据库到目标CDB数据库。所有的操作都是在standalone模式下完成，文中有关于RAC的仅限于理论。数据库版本：12.1.0.2 1. 限制Oracle PDB的远程克隆有以下限制： 源库common user对应的表空间必须存在目标端中，否则复制过来的PDB会以受限模式开启(Bug 19174942) 如果源库是non-cdb，则源跟目标端版本必须在12.1.0.2以上 源库需处于read only模式; 如果是12.2，使用local undo, 启动归档，则可在正常模式下复制 目标端需建立到源库的DBLINK，这个dblink可以是到源库CDB或者PDB 对应的，目标端DBLINK的用户必须有create pluggable database的权限 两边需要有一致的字节顺序，字符集以及数据库的选件 在测试过程中，连小补丁版本都需一致，否则，目标端需要重新升级/降级到与源库相同的版本 2. 复制远程non-cdb复制前准备，查询两边数据库文件路径或者ASM磁盘名称，路径及名称不一致，需要添加FILE_NAME_CONVERT参数进行转换。 2.1 目标库创建DBLINK123456CREATE DATABASE LINK orcl_lnkCONNECT TO system IDENTIFIED BY manager USING 'orcl';--remote user must be having create pluggable database privelege-- test dblinkselect name, open_mode from v$database@orcl_lnk; 2.2 将源库处于read only模式 standalone 1234SHUTDOWN IMMEDIATE;STARTUP MOUNT;ALTER DATABASE OPEN READ ONLY;EXIT; RAC 12srvctl stop database -d $DBNAMEsrvctl start database -d $DBNAME -startoption \"read only\" 2.3 开始复制1234CREATE PLUGGABLE DATABASEtellerdb FROM orcl@orcl_lnk--first orcl: name of non-cdb in source; second orcl_lnk: name for dblink in targetFILE_NAME_CONVERT= ('/oracle/oradata/orcl/tablespace','/oradata/orcldb/tellerdb','/oracle/oradata/orcl','/oradata/orcldb/tellerdb'); 如果数据库文件是OMF命名，使用create_file_dest初始化参数去指定数据文件位置。12create pluggable database tellerdb from orcl@orcl_lnkcreate_file_dest = '/oradata/orcldb/tellerdb'; 2.4 开启源库到read write模式复制完成后, 将源库重新启动到read write模式, 同时，检查日志是否有报错。 standalone 1234SHUTDOWN IMMEDIATE;STARTUP MOUNT;ALTER DATABASE OPEN ;EXIT; RAC 12srvctl stop database -d $DBNAMEsrvctl start database -d $DBNAME 2.5 将non-cdb转换成pdb由于源库是non-cdb,因此，需要执行以下脚本对其进行清理: 12ALTER SESSION SET CONTAINER=tellerdb;@$ORACLE_HOME/rdbms/admin/noncdb_to_pdb.sql 2.6 检查目标数据库PDB状态123alter pluggable database all open;COLUMN name FORMAT A30SELECT name, open_mode FROM v$pdbs WHERE name = 'TELLERDB'; 检查补丁情况: 1234567col time for a20col name for a10col message for a40col action for a40set line 200 pagesize 9999select to_char(time) as time, name,message, status, action from pdb_plug_in_violationswhere status &lt;&gt;'RESOLVED'; 3. 远程复制PDB3.1 目标库创建到PDB的dblink1234567CREATE PLUGGABLE DATABASEsldb1 FROM ldb1@ldb1_zdb06--ldb1: name for pdb in source db; ldb1_zdb06: name or dblink in target dbFILE_NAME_CONVERT= ('/oradata/zdb06','/oradata/hdkcdb');--检查dblinkselect name, open_mode from v$database@ldb1_zdb06; 3.2 源库pdb置于read only模式1234alter pluggable database ldb1 close immediate instances=all;alter pluggable database ldb1 open read only instances=all;--alter pluggable database all except PDB1 close immediate instances=all;--alter pluggable database all except PDB1 open read only instances=all; 3.3 复制pdb123CREATE PLUGGABLE DATABASEldb1 FROM ldb1@ldb1_zdb06FILE_NAME_CONVERT= ('/oradata/zdb06','/oradata/hdkcdb'); 3.4 重启源库到read write状态克隆完成，将源数据库处于read write状态12alter pluggable database ldb1 close immediate instances=all;alter pluggable database ldb1 open read write instances=all; 3.5 检查目标PDB状态12345678910ALTER PLUGGABLE DATABASE ldb1 OPEN;SELECT name, open_mode FROM v$pdbs WHERE name = 'LDB1';col time for a20col name for a10col message for a40col action for a40set line 200 pagesize 9999select to_char(time) as time, name,message, status, action from pdb_plug_in_violationswhere status &lt;&gt;'RESOLVED'; 4. 总结 NON-CDB跟PDB步骤都差不多，只不过non-cdb需要执行一个清理转换脚本。 在复制过过程中，出现有补丁版本不一致导致还原后的PDB一直处于restricted模式从pdb_plug_in_violations，出现 12PSU bundle patch 170418 (DATABASE PATCHSET UPDATE 12.1.0.2.170418):Installed in the CDB but not in the PDB 原因 在我的环境里，non-cdb及pdb的源库均打了相关的补丁，但是呢，打补丁的同事最后并没有应用datapatch，因此，在数据字典中无法识别 解决 第一次复制non-cdb, 在目标库中，我尝试rollback之前的补丁，然后在打源库对应的补丁，问题能得到解决。 第二次复制pdb, 我尝试在目标库中apply对应的补丁,在源库应用datapatch，之后再复制,复制过后的pdb状态正常。 建议 利用远程复制来创建PDB，都是基于物理复制，建议数据库小版本都要一致。 如果需要单独对某个pdb进行datapatch的apply或者回滚，请参照以下命令： 12datapatch -rollback 28790654 -pdbs SLDB2 -force -verbose$ORACLE_HOME/OPatch/datapatch -apply 29251241 -pdbs SLDB2 -force -verbose 复制过程中出现ora-01031 123ERROR at line 2:ORA-17628: Oracle error 1031 returned by remote Oracle serverORA-01031: insufficient privileges 在源库给dblink用户赋予必须权限:1GRANT CREATE SESSION, SYSOPER, CREATE PLUGGABLE DATABASE TO system; 4.1 远程复制前的checklist 对比源跟目标库cdb/pdb下dba_registry_sqlpatch记录 对比源跟目标库DBBP/PSU版本 当存在OJVM补丁时候，考虑回滚目标端OJVM补丁，再进行复制 DBLINK用户需有sysoper或则create pluggable database的权限 Reference:How to clone PDB ( Remote Clone ) across CDB using Database Link (Doc ID 2297470.1)How to Clone a Pluggable Database (PDB) Without Closing the PDB (Doc ID 1958865.1)Example for Cloning PDB from NON-CDB via Dblink (Doc ID 1928653.1) EOF","link":"/Remote-Clone-Database-into-Existent-CDB.html"},{"title":"Security Hardening of Oracle Database","text":"This post introduces how to implement security hardening of Oracle database. 1. Verification function of password limitsBelow script contains a verification function name ora12c_verify_function:12[oracle@cdb01 ~]$ ls -l $ORACLE_HOME/rdbms/admin/utlpw*-rw-r--r--. 1 oracle oinstall 12543 11月 7 2013 /oracle/app/oracle/product/12c/db_1/rdbms/admin/utlpwdmg.sql 2. Resource limit of default profile after executing utlpwdmg.sqlutlpwdmg.sql script will modify default profile as below rules: 12345678ALTER PROFILE DEFAULT LIMITPASSWORD_LIFE_TIME 180PASSWORD_GRACE_TIME 7PASSWORD_REUSE_TIME UNLIMITEDPASSWORD_REUSE_MAX UNLIMITEDFAILED_LOGIN_ATTEMPTS 10PASSWORD_LOCK_TIME 1PASSWORD_VERIFY_FUNCTION ora12c_verify_function; Also create ORA_STIG_PROFILE as below rules: 12345678910111213141516171819202122232425262728293031323334353637383940SQL&gt; col profile for a30col resource for a30col limit for a50set line 200 pagesize 200select * from dba_profiles;SQL&gt; PROFILE RESOURCE_NAME RESOURCE LIMIT COM------------------------------ -------------------------------- -------- -------------------------------------------------- ---DEFAULT COMPOSITE_LIMIT KERNEL UNLIMITED NODEFAULT SESSIONS_PER_USER KERNEL UNLIMITED NODEFAULT CPU_PER_SESSION KERNEL UNLIMITED NODEFAULT CPU_PER_CALL KERNEL UNLIMITED NODEFAULT LOGICAL_READS_PER_SESSION KERNEL UNLIMITED NODEFAULT LOGICAL_READS_PER_CALL KERNEL UNLIMITED NODEFAULT IDLE_TIME KERNEL UNLIMITED NODEFAULT CONNECT_TIME KERNEL UNLIMITED NODEFAULT PRIVATE_SGA KERNEL UNLIMITED NODEFAULT FAILED_LOGIN_ATTEMPTS PASSWORD 10 NODEFAULT PASSWORD_LIFE_TIME PASSWORD 180 NODEFAULT PASSWORD_REUSE_TIME PASSWORD UNLIMITED NODEFAULT PASSWORD_REUSE_MAX PASSWORD UNLIMITED NODEFAULT PASSWORD_VERIFY_FUNCTION PASSWORD NULL NODEFAULT PASSWORD_LOCK_TIME PASSWORD 1 NODEFAULT PASSWORD_GRACE_TIME PASSWORD 7 NOORA_STIG_PROFILE COMPOSITE_LIMIT KERNEL DEFAULT NOORA_STIG_PROFILE SESSIONS_PER_USER KERNEL DEFAULT NOORA_STIG_PROFILE CPU_PER_SESSION KERNEL DEFAULT NOORA_STIG_PROFILE CPU_PER_CALL KERNEL DEFAULT NOORA_STIG_PROFILE LOGICAL_READS_PER_SESSION KERNEL DEFAULT NOORA_STIG_PROFILE LOGICAL_READS_PER_CALL KERNEL DEFAULT NOORA_STIG_PROFILE IDLE_TIME KERNEL 15 NOORA_STIG_PROFILE CONNECT_TIME KERNEL DEFAULT NOORA_STIG_PROFILE PRIVATE_SGA KERNEL DEFAULT NOORA_STIG_PROFILE FAILED_LOGIN_ATTEMPTS PASSWORD 3 NOORA_STIG_PROFILE PASSWORD_LIFE_TIME PASSWORD 60 NOORA_STIG_PROFILE PASSWORD_REUSE_TIME PASSWORD 365 NOORA_STIG_PROFILE PASSWORD_REUSE_MAX PASSWORD 10 NOORA_STIG_PROFILE PASSWORD_VERIFY_FUNCTION PASSWORD ORA12C_STRONG_VERIFY_FUNCTION NOORA_STIG_PROFILE PASSWORD_LOCK_TIME PASSWORD UNLIMITED NOORA_STIG_PROFILE PASSWORD_GRACE_TIME PASSWORD 5 NO 3. Difference between 11g and 12c3.1 verify_function_11G Function Password RequirementsThis function checks for the following requirements when users create or modify passwords: The password is not the same as the user name, nor is it the user name spelled backward or with the numbers 1–100 appended. The password is not the same as the server name or the server name with the numbers 1–100 appended. The password is not too simple (for example, oracle, oracle with the numbers 1–100 appended, welcome1, database1, account1, user1234, password1, oracle123, computer1, abcdefg1, or change_on_install). The password includes at least 1 numeric and 1 alphabetic character. The password differs from the previous password by at least 3 characters. The following internal checks are also applied: The password contains no fewer than 8 characters and does not exceed 30 characters. The password does not contain the double-quotation character (&quot;). It can be surrounded by double-quotation marks, however. 3.2 ora12c_verify_function Password RequirementsThe ora12c_verify_function function provides requirements that the Department of Defense Database Security Technical Implementation Guide recommends. This function checks for the following requirements when users create or modify passwords: The password contains no fewer than 8 characters and includes at least 1 numeric and 1 alphabetic character. The password is not the same as the user name or the user name reversed. The password is not the same as the database name. The password does not contain the word oracle (such as oracle123). The password is not too simple (for example, welcome1, database1, account1, user1234, password1, oracle123, computer1, abcdefg1, or change_on_install). The password differs from the previous password by at least 3 characters. The password contains at least one special character. The following internal checks are also applied: The password does not exceed 30 characters. The password does not contain the double-quotation character (&quot;). It can be surrounded by double-quotation marks, however. 3.3 ora12c_strong_verify_function Function Password RequirementsThe ora12c_strong_verify_function function fulfills the Department of Defense Database Security Technical Implementation Guide requirements. This function checks for the following requirements when users create or modify passwords: The password must contain at least 2 upper case characters, 2 lower case characters, 2 numeric characters, and 2 special characters. These special characters are as follows: 1‘ ~ ! @ # $ % ^ &amp; * ( ) _ - + = &#123; &#125; [ ] \\ / &lt; &gt; , . ; ? &apos; : | (space) The password must differ from the previous password by at least 4 characters. The following internal checks are also applied: The password contains no fewer than nine characters and does not exceed 30 characters. The password does not contain the double-quotation character (&quot;). It can be surrounded by double-quotation marks, however. 4. Example of modifying user profile12alter profile default limit PASSWORD_LIFE_TIME UNLIMITED;alter profile default limit PASSWORD_VERIFY_FUNCTION null; 5. SummaryEven with Oracle 12c, security hardening is not enabled by force, DBA need to execute utlpwdmg.sql manually to enable.By default, this script will update default profile, which is the default profile for all users. It&#39;s recommended to modify this script, not using default profile for all users. Reference:Database Security Guide-Configuring Authentication EOF","link":"/Security-Hardening-of-Oracle-Database.html"},{"title":"Security Hardening of VPS","text":"For the perspective of security, Linux VPS should do some action for security hardening. Some of rules are also applicable for Linux server. This post based on CentOS 7. 1. SSH configurationModify /etc/ssh/sshd_config, to: 1.1 Disable root ssh login Disabled root log from ssh, you must create a normal user before do that.1PermitRootLogin no 1.2 Modify default ssh port 1Port xxx # from 0 ~ 65535 But don&#39;t use any port from range 0 to 1024, most of them are known port for other important service, such as HTTP 80 port. 1.3 Enable two-factor authorization Using RSA public keys instead:12345# generate public rsa key from local serverssh-keygen -t rsa# copy public key to remote serverssh-copy-id -i ~/.ssh/id_rsa.pub &lt;Your Username for remote server&gt;@&lt;Your IP or Hostname&gt; -p &lt;Your SSH port&gt; Enable two factor authentication: 123456RSAAuthentication yesPubkeyAuthentication yesAuthorizedKeysFile .ssh/authorized_keysPasswordAuthentication yesAuthenticationMethods publickey,password 2. Firewall configurationAdd ssh port to firewall whitelist.12345678910111213141516# Install semanage first, for selinux policy managementyum provides /usr/sbin/semanage# Tell selinux the new portsemanage port -a -t ssh_port_t -p tcp &lt;PORT_NUM&gt;# Add whitelist to the firewallfirewall-cmd --permanent --zone=public --add-port=&lt;PORT_NUM&gt;/tcpfirewall-cmd --add-port &lt;PORT_NUM&gt;/tcp# Reload firewallfirewall-cmd --reload# Restart sevice and check the resultsystemctl restart sshd.servicesemanage port -l | grep sshss -tnlp | grep ssh 3. Other configuration Generate random strong password: 123openssl rand -base64 10# oropenssl rand -hex 10 Disable ping 1234vi /etc/sysctl.confnet.ipv4.icmp_echo_ignore_all=1sysctl -p EOF","link":"/Security-Hardening-of-VPS.html"},{"title":"Understand DB time","text":"When talking about Oracle performance tuning, DBAs always face some indices of time dimension, such as DB time, CPU time, etc,. Time Model is a critical metric of performance tuning measure. Because, performance is always about time--response time, we tune the system and try to make it run faster. Time Model Metric can be the starting point of tuning. About DB time Abstract As it name implies, DB time is database time total spend on handling user calls(that means db time not include background cpu time. In other words, DB Time = CPU Time + IO Time + NonIdle Wait Time. DB time is not only the time spend on handling active session calls but also on waiting for some resources. In an AWR report, some busy systems, the DB time is greater than Elapsed time, we know Elapsed time it&#39;s the time between to snapshots. But why DB time is greater than Elapsed time? Basically this means that multiple sessions were active for the investigated time period. Mention about DB time, it can&#39;t ignore the Average Active Session(AAS). AAS means, between a given time intervals, how many active sessions in average. For example, if time interval is 15mins, and DB time is 30mins, the AAS = DB time / Elapsed time = 2.0, that means, there are two active sessions during the 15 mins, and each session can use a whole Elapsed time. That&#39;s why in busy system, DB time is always greater then Elapsed time. So, Average Active Session is one of the manifestation of DB loading. And that&#39;s why in OEM performance home page, it shows both the Average Active Session and DB time.If average active sessions passes CPU Cores limit it means that some sessions will experience wait for CPU (CPU Wait). DB time and ASH v$active_session_history, samples all active background and foreground sessions in every second, only foreground sessions are calculated in DB time. This view&#39;s purpose is reserving 1 hours statistics data. DBA_HIST_ACTIVE_SESS_HISTORY, on the other hand, samples only 1 out of 10 seconds. This view stores duration is depending on snapshot duration setting. Based on above information, DB time in Seconds = : 12345678select count(*) from v$active_session_historywhere sample_time between xxx and xxx where session_type = 'FOREGROUND'select ..., sum(1) ash_secsfrom v$active_session_historywhere ...group by ... Equals: 123456789select count(*) * 10 from dba_hist_active_sess_historywhere session_type = 'FOREGROUND'and sample_time between xxx and xxx;select ..., sum(10) ash_secsfrom dba_hist_active_sess_historywhere ...group by ... The &quot;DB Time&quot; in AWR is generated using the following query 123456789SELECT Round(NVL((e.value - s.value),-1)/60/1000000,2)||' minutes' \"DB Time\"FROM DBA_HIST_SYS_TIME_MODEL s, DBA_HIST_SYS_TIME_MODEL eWHERE s.snap_id = &amp;AWRStartSnapID AND e.snap_id = &amp;AWREndSnapID anD e.dbid = s.dbid AND e.instance_number = s.instance_number AND s.stat_name = 'DB time' AND e.stat_id = s.stat_id; Other tips 123Inactive session = totol waits in second(SQL*Net message from client)/elasped time * 60.DB CPU is time running in CPU(waiting in runqueue not included, which is CPU in WAITs in OEM).DB CPU load = DB CPU wait time(s) /elasped time * 60 About CPU timeIn AWR report, three different names indicate CPU usage for database: CPU time Represents foreground and background processes spend on CPU, does not include time waiting on CPU. DB CPU Represents only foreground process spend on CPU. CPU used by this session Amount of CPU time (in 10s of milliseconds) used by a session from the time a user call starts until it ends. If a user call completes within 10 milliseconds, the start and end user-call time are the same for purposes of this statistics, and 0 milliseconds are added. For calculating CPU usage in ARR, in the section Operating System Statistics, CPU usage%=BUSY_TIME/(BUSY_TIME+IDLE_TIME), which derived from v$osstat. High CPU usage diagnosing High Parse consumption Excessive Logical reads Looking at SQL ordered by CPU time section of AWR report to see if any excessive logical IO can be tuned or sorts can be avoided. Also check the segments by logical reads to see which segments are causing excessive logical IO. Logon storms Looking at logons cumulative statistics at AWR report to find out. Every time a new logon requires, OS need to start up a process, allocate memory for shared pool and PGA, all these activities take CPU. Resource manager events For example: resmgr: cpu quantum Latch/Mutex wait events Latch/Mutex contention burns cpu in a high rate. In this case, SQL ordered by CPU time is useless, looking at ASH report to find more out. Relevant dynamic performance viewsBased on cumulative statistics, some performance views provided different metric, such as CPU time, user call, etc,. v$sysmetric Displays the system metric values captured for the most current time interval for both the long duration (60-second) and short duration (15-second) system metrics. The column group_id represents different interval: group_id=2: 60 second intervalgroup_id=3: 15 second interval For a single session metric, view the v$sessmetric instead. v$sysmetric_summary Displays the system metric average, maximum, minimum values for the last hour. Only for the long duration data. v$sysmetric_history For the last hour Oracle stores the 60 second intervals and for the 15 second intervals in this view. v$metricname Displays the mapping of the name of metrics to their metric ID. DBA_HIST_SYSMETRIC_HISTORY This view contains snapshots of V$SYSMETRIC_HISTORY. One of the source of AWR report. Summary of metric v$ views: v$sysmetric - last 15 seconds and 60 seconds v$sysmetric_summary - values last hour (last snapshot) like avg, max, min etc v$sysmetric_history - last hour for 1 minute, last 3 mintes for 15 second deltas v$sess_time_model Displays the session-wide accumulated times for various operations. v$sys_time_model Displays the system-wide accumulated times for various operations. The time reported is the total elapsed or CPU time (in microseconds). Any timed operation will buffer at most 5 seconds of time data. Specifically, this means that if a timed operation (such as SQL execution) takes a long period of time to perform, the data published to this view is at most missing 5 seconds of the time accumulated for the operation. Example of time model distribution: 1234--time model tracks time in microseconds (one millionth of a second)select stat_name, trunc(value/1000000,2) secondsfrom v$sys_time_modelorder by 2 desc; v$sysstat Displays system statistics. To find the name of the statistic associated with each statistic number (STATISTIC#), query the V$STATNAME view. v$sesstat Displays user session statistics &quot;CPU used by this session&quot; from v$sesstat changes only at the end of transaction. The corresponding value can be checked here Statistics Descriptions. v$sysstat and v$sys_time_model report CPU usage of current INSTANCE only, and v$osstat report CPU usage for whole OS. Reference:How Does Oracle Calculate the &quot;DB time&quot; &amp; &quot;Elapsed&quot; Time Presented in AWR Report (Doc ID 1934757.1)&quot;DB CPU&quot; / &quot;CPU + Wait for CPU&quot; / &quot;CPU time&quot; Reference Note (Doc ID 1965757.1)How to Use AWR Reports to Diagnose Database Performance Issues (Doc ID 1359094.1) EOF","link":"/Understand-DB-time.html"},{"title":"Tablespace in backup pending after DB2 load","text":"After enabling archive log mode, customer complaint their database cannot DML any more.After examining db2diag.log and tablespace status, one of tablespaces used by db2 load are in backup pending status. From the inforcenter of load command, load have three options which would impact database status in different log circulate mode. COPY NO Specifies that the table space in which the table resides will be placed in backup pending state if forward recovery is enabled (that is, logretain or userexit is on). The COPY NO option will also put the table space state into the Load in Progress table space state. This is a transient state that will disappear when the load completes or aborts. The data in any table in the table space cannot be updated or deleted until a table space backup or a full database backup is made. However, it is possible to access the data in any table by using the SELECT statement. LOAD with COPY NO on a recoverable database leaves the table spaces in a backup pending state. For example, performing a LOAD with COPY NO and INDEXING MODE DEFERRED will leave indexes needing a refresh. Certain queries on the table might require an index scan and will not succeed until the indexes are refreshed. The index cannot be refreshed if it resides in a table space which is in the backup pending state. In that case, access to the table will not be allowed until a backup is taken. Index refresh is done automatically by the database when the index is accessed by a query. If one of COPY NO, COPY YES, or NONRECOVERABLE is not specified, and the database is recoverable (logretain or logarchmeth1 is enabled), then COPY NO is the default. COPY YES Specifies that a copy of the loaded data will be saved. This option is invalid if forward recovery is disabled. USE TSM Specifies that the copy will be stored using Tivoli® Storage Manager (TSM). OPEN num-sess SESSIONS The number of I/O sessions to be used with TSM or the vendor product. The default value is 1. TO device/directory Specifies the device or directory on which the copy image will be created. LOAD lib-name The name of the shared library (DLL on Windows operating systems) containing the vendor backup and restore I/O functions to be used. It can contain the full path. If the full path is not given, it will default to the path where the user exit programs reside. NONRECOVERABLE Specifies that the load transaction is to be marked as nonrecoverable and that it will not be possible to recover it by a subsequent roll forward action. The roll forward utility will skip the transaction and will mark the table into which data was being loaded as &quot;invalid&quot;. The utility will also ignore any subsequent transactions against that table. After the roll forward operation is completed, such a table can only be dropped or restored from a backup (full or table space) taken after a commit point following the completion of the non-recoverable load operation. With this option, table spaces are not put in backup pending state following the load operation, and a copy of the loaded data does not have to be made during the load operation. If one of COPY NO, COPY YES, or NONRECOVERABLE is not specified, and the database is not recoverable (logretain or logarchmeth1 is not enabled), then NONRECOVERABLE is the default. From the explanation, impacted database because in non-archive log mode, therefore default is nonrecoverable option, after enabling archive log, the default behavior is change to copy no, which would put database/tablespace in backup pending mode. With customer&#39;s environment, they don&#39;t want to change the load command. But no worries, there&#39;s a db2set registry DB2_LOAD_COPY_NO_OVERRIDE can achive this. This registry also have three options that identical to load command: copy no, copy yes and nonrecoverable, after setting this registry to nonrecoverable(no instance recycle will be needed), issue is gone.This registry will be ignored in HADR standby database. Only applicable for primary database. But because nonrecvoerable will not recover loaded table from redo log, it&#39;s highly recommended to take a full backup after load. EOF Reference: LOAD command DB2 registry and environment variables","link":"/Tablespace-in-backup-pending-after-DB2-load.html"},{"title":"Updating Global Indexes Automatically","text":"By default, partition table maintenance such as drop/truncate partitions invalidate corresponding global index which mark them as UNUSABLE. User must rebuild the corresponding indexes. Database lets user override the default behavior by specifying update indexes clause. With this option, database will update the indexes at the same time it executes the maintenance DDL statements, and not mark them as UNUSABLE. Prior to 12c, update indexes is a time consuming operation, DBA must wait for the index rebuild complete. As of 12c, a new feature is supported by Oracle database — Asynchronous Global Index Maintenance. The partition maintenance operations DROP PARTITION and TRUNCATE PARTITION are optimized by making the index maintenance for metadata only. Asynchronous global index maintenance for DROP and TRUNCATE is performed by default; however, the UPDATE INDEXES clause is still required for backward compatibility. 1. Limitations of asynchronous global index maintenance Only performed on the heap tables No support for tables with object types No support for tables with domain indexes Not performed for the user SYS 2. Scheduler JobsThere&#39;s an automatically maintenance scheduler job SYS.PMO_DEFERRED_GIDX_MAINT_JOB to clean up all global indexes. This job is schedule at 2:00AM by defaul. You can run this job at any time by calling DBMS_SCHEDULER.RUN_JOB,also, DBA can modify scheduler window for running this job. 123456789101112131415-- query the maintenance windowselect job_name , start_date,enabled,state,commentsfrom dba_scheduler_jobswhere job_name ='PMO_DEFERRED_GIDX_MAINT_JOB';-- execute the job manuallyexec dbms_scheduler.run_job('SYS.PMO_DEFERRED_GIDX_MAINT_JOB')-- query jobs running statusselect job_name, start_date, enabled, state, comments from dba_scheduler_jobs where job_name ='PMO_DEFERRED_GIDX_MAINT_JOB'; select * from dba_scheduler_job_run_details where job_name ='PMO_DEFERRED_GIDX_MAINT_JOB'; 3. Summary If we truncate/drop a partition tables with update indexes, we can maintenance index manually: Check the index status 1234SELECT table_name, index_name, orphaned_entries,statusFROM user_indexesORDER BY 1; Execute one of the following SQLs 1234567891011121314/* This PL/SQL package procedure gathers the list of global indexes in the system thatmay require cleanup and runs the operations necessaryto restore the indexes to a clean state.*/exec DBMS_PART.CLEANUP_GIDX('USERNAME','INDEX_NAME'); -- specific index--database levelexec dbms_part.cleanup_gidx--schema levelexec dbms_part.cleanup_gidx(&lt;schema_name&gt;);--table levelexec dbms_part.cleanup_gidx(&lt;schema_name&gt;, &lt;table_name&gt;); 123456-- this SQL statement rebuilds the entire index-- or index partition as was done prior to Oracle Database 12.1 releasesALTER INDEX INDEX_NAME REBUILD;--This SQL statement cleans up any orphaned entries in index blocksALTER INDEX INDEX_NAME COALESCE CLEANUP; Check the index status again Reference:ORA-01555 Caused By Auto Execute Of Job &quot;SYS&quot;.&quot;PMO_DEFERRED_GIDX_MAINT_JOB&quot; (Doc ID 2523018.1) EOF","link":"/Updating-Global-Indexes-Automatically.html"},{"title":"等待事件enq:TM contention","text":"开发人员反应在进行大量insert操作时，速度很慢，平时只要几分钟，但目前跑了几个小时仍旧没结束。 诊断步骤： 从活动会话查找相关信息 1234567891011121314151617181920212223242526set linesize 200set pagesize 100clear columnscol inst for 99999999col sid for 9990col serial# for 999990col username for a12col osuser for a16col program for a10 trunccol Locked for a6col status for a1 trunc printcol \"hh:mm:ss\" for a8col SQL_ID for a15col seq# for 99990col event heading 'Current/LastEvent' for a25 trunc col state head 'State (sec)' for a14select inst_id inst, sid , serial# , username, ltrim(substr(osuser, greatest(instr(osuser, '\\', -1, 1)+1,length(osuser)-14))) osuser , substr(program,instr(program,'/',-1)+1,decode(instr(program,'@'),0,decode(instr(program,'.'),0,length(program),instr(program,'.')- 1),instr(program,'@')-1)) program, decode(lockwait,NULL,' ','L') locked, status, to_char(to_date(mod(last_call_et,86400), 'sssss'), 'hh24:mi:ss') \"hh:mm:ss\", SQL_ID, seq# , event,decode(state,'WAITING','WAITING '||lpad(to_char(mod(SECONDS_IN_WAIT,86400),'99990'),6),'WAITED SHORT TIME','ON CPU','WAITED KNOWN TIME','ON CPU',state) state , substr(module,1,25) module, substr(action,1,20) actionfrom GV$SESSIONwhere type = 'USER'and audsid != 0 -- to exclude internal processessorder by inst_id, status, last_call_et desc, sid/ 从等待事件查看相关信息 123456SELECT NVL(a.event, 'ON CPU') AS event, COUNT(*) AS total_wait_timeFROM gv$active_session_history aWHERE a.sample_time &gt; SYSDATE - 5/(24*60) -- 5 minsGROUP BY a.eventORDER BY total_wait_time DESC; 通过以上sql定位到用户SQL相关信息，其等待事件为enq: TM-contention。对于这个等待事件有以下几种可能： 有外键约束的子表缺少索引 并行直接路径插入 Analyze Index Validate Structure 使用insert append导致 通过SQL ID获取的SQL TEXT发现，该SQL使用了insert append，修改SQL取消append，顺利插入。 附，其他思路: 123456789101112--通过gv$active_history_session/dba_active_sess_history查找相关SQLset line 300 pagesize 300col event for a30col machine for a20col program for a20select sql_id,event,machine,program,p1,p2,p3,blocking_session--from DBA_HIST_ACTIVE_SESS_HISTORYfrom gv$active_session_historywhere lower(event) like '%enq%tm%'and sample_time &gt;= to_date('2019-09-16 08:26','yyyy-mm-dd hh24:mi')and sample_time &lt; to_date('2019-09-16 09:26','yyyy-mm-dd hh24:mi'); 123456--查找对应排名第一的sql idselect sql_id,count(1)from v$active_session_historywhere lower(event) like '%enq%tm%'and sample_time &gt;= to_date('2019-09-16 08:26','yyyy-mm-dd hh24:mi')and sample_time &lt; to_date('2019-09-16 09:26','yyyy-mm-dd hh24:mi')group by sql_id; 如果是缺失外键索引，则添加对应的外键索引即可。123456789101112--查找缺失索引的外键SELECT * FROM (SELECT c.table_name, cc.column_name, cc.position column_positionFROM user_constraints c, user_cons_columns ccWHERE c.constraint_name = cc.constraint_nameAND c.constraint_type = 'R'MINUSSELECT i.table_name, ic.column_name, ic.column_positionFROM user_indexes i, user_ind_columns icWHERE i.index_name = ic.index_name)ORDER BY table_name, column_position; Reference:WAITEVENT: &quot;enq: TM - contention&quot; Reference Note (Doc ID 1980175.1)High Enq: TM - Contention Wait Events When Using Insert APPEND (Doc ID 2247733.1) Resolving Issues Where &#39;enq: TM - contention&#39; Waits are Occurring (Doc ID 1905174.1)EOF","link":"/Wait-Event-enq-TM-contention.html"},{"title":"Adaptive log file sync","text":"From Oracle 11.2.0.3, hidden parameter _use_adaptive_log_file_sync is changed default value from FALSE to TRUE.Quote from Oracle community:_use_adaptive_log_file_syncWhen _use_adaptive_log_file_sync is set to true, Oracle switches between two methods of communication between the LGWR and foreground processes to acknowledge that a commit has completed: Post/wait - conventional method available in previous Oracle releases. LGWR explicitly posts all processes waiting for the commit to complete. Polling Foreground processes sleep and poll to see if the commit is complete. The advantage of this new method is to free LGWR from having to inform many processes waiting on commit to complete thereby freeing high CPU usage by the LGWR. Initially the LGWR uses post/wait and according to an internal algorithm evaluates whether polling is better. Under high system load polling may perform better because the post/wait implementation typically does not scale well.If the system load is low, then post/wait performs well and provides better response times than polling.Oracle relies on internal statistics to determine which method should be used.Because switching between post/wait and polling incurs an overhead, safe guards are in place in order to ensure that switches do not occur too frequently.Switch is logged in LGWR tracefileBelow DB version is 12.2, should be different from 11g, the first parameter freq_threshold limits the mode switch frequency.1234567891011121314select a.ksppinm name, b.ksppstvl value, a.ksppdesc descriptionfrom sys.x$ksppi a, sys.x$ksppcv bwhere a.indx = b.indx and a.ksppinm like '_%adaptive_log%';NAME VALUE DESCRIPTION------------------------------------------------------- ---------- ----------------------------------------------------------------------------_adaptive_log_file_sync_high_switch_freq_threshold 3 Threshold for frequent log file sync mode switches (per minute)_adaptive_log_file_sync_poll_aggressiveness 0 Polling interval selection bias (conservative=0, aggressive=100)_adaptive_log_file_sync_sampling_count 128 Evaluate post/wait versus polling every N writes_adaptive_log_file_sync_sampling_time 3 Evaluate post/wait versus polling every N seconds_adaptive_log_file_sync_sched_delay_window 60 Window (in seconds) for measuring average scheduling delay_adaptive_log_file_sync_use_polling_threshold 110 Ratio of redo synch time to expected poll time as a percentage_adaptive_log_file_sync_use_postwait_threshold 50 Percentage of foreground load from when post/wait was last used_adaptive_log_file_sync_use_postwait_threshold_aging 1001 Permille of foreground load from when post/wait was last used_use_adaptive_log_file_sync FALSE Adaptively switch between post/wait and polling From v$sysstat view, polling status can be checked by below sql:12345sys@LINORA&gt; select name,value from v$sysstat where name in ('redo synch poll writes','redo synch polls');NAME VALUE-------------------------------------------------- ----------redo synch poll writes 0redo synch polls 0 From AWR, other instance activity stats also shows the redo synch poll writes and redo synch polls activities information. Enabling adaptive log file sync may occur LGWR relative performance issue, from best practise, disable this feature is recommended:12alter system set \"_use_adaptive_log_file_sync\" = false scope=spfile sid='*';--and recycle the instance In summary, conventional way will reduce the wait time of log file sync, but LGWR background process will cost more overhead.And polling way, it reduce LGWR&#39;s overhead, because the COMMIT foreground process will sleep after it inform LGWR to write the changed data into log, hence the COMMIT process will wait more time for event log file sync. For large OLTP system, this mechanism is not suitable. Reference:Adaptive Switching Between Log Write Methods can Cause &#39;log file sync&#39; Waits (Doc ID 1462942.1)Adaptive Log File Sync Optimization (Doc ID 1541136.1)EOF","link":"/adaptive-log-file-sync.html"},{"title":"11gr2 RAC增加节点","text":"RAC的扩展分两个层次：Clusterware及Oracle数据库。在对RAC进行增加节点时候，需要分别对Clusterware及数据库进行扩展，其实就跟安装步骤差不多。也需要分grid及oracle用户完成。 在安装RAC的时候，可以现在一个节点上安装GI及Oracle软件，并且创建数据库，由这个节点构成单一节点的RAC集群，然后再根据对集群进行扩展，本文将以此种方式演示11gr2 RAC添加节点。 1. 扩展前准备 操作系统设置 OS版本必须相同，检查内核参数，系统内存、CPU、文件系统大小、swap空间等。 创建必要的用户及组 用户及用户组UID及GID必须跟其他节点相同，同时对这些用户环境变量进行设置。 网络配置 网络规划，Public及private网络名称必须相同。 共享存储配置 对于共享存储，必须保证在新的节点上是可以访问的，而且对软件安装者必须有读写权限。 创建相关目录 这些目录用户存放GI及Oracle数据库软件，同时要保证用户组及用户对这些目录的权限。 配置RAC等效性 时间同步设置(CTSS ) 2. 扩展Clusterware 首先在正常运行的节点对新增加的节点进行验证，包括ssh等效性、rpm包等。 以grid用户进入GI软件安装目录，执行以下命令： 12[grid@orcl1:/home/grid/.ssh]$ cd /u01/app/11.2.0/grid/bin/ [grid@orcl1:/u01/app/11.2.0/grid/bin]$ ./cluvfy stage -pre nodeadd -n orcl2 -fixup –verbose 接着进入GI安装目录的oui/bin子目录，执行以下命令将新节点node2加入集群中： 12[grid@orcl1:/u01/app/11.2.0/grid/bin]$ cd ../oui/bin/ [grid@orcl1:/u01/app/11.2.0/grid/oui/bin]$ export IGNORE_PREADDNODE_CHECKS=Y 以上变量是因为在之前已经检测过节点2，因此忽略执行addNode.sh时候忽略检测。 123[grid@orcl1:/u01/app/11.2.0/grid/oui/bin]$ ./addNode.sh -silent \\ &quot;CLUSTER_NEW_NODES=&#123;orcl2&#125;&quot; &quot;CLUSTER_NEW_VIRTUAL_HOSTNAMES=&#123;racdb2-vip&#125;&quot; \\ &quot;CLUSTER_NEW_PRIVATE_NODE_NAMES=&#123;racdb2-priv&#125;&quot; &amp;&gt;~/add_node.log 执行完之后需要以root用户在新加节点上执行两个脚本。请勿无视结果输出。 输出结果如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@orcl1:/worktmp]# cat /home/grid/add_node.log Starting Oracle Universal Installer... Checking swap space: must be greater than 500 MB. Actual 3694 MB Passed Oracle Universal Installer, Version 11.2.0.4.0 Production Copyright (C) 1999, 2013, Oracle. All rights reserved. Performing tests to see whether nodes orcl2 are available ............................................................... 100% Done. .----------------------------------------------------------------------------- Cluster Node Addition Summary Global Settings Source: /u01/app/11.2.0/grid New Nodes Space Requirements New Nodes orcl2 /: Required 4.43GB : Available 17.14GB Installed Products Product Names Oracle Grid Infrastructure 11g 11.2.0.4.0 ……………….. Oracle Database 11g 11.2.0.4.0 ----------------------------------------------------------------------------- Instantiating scripts for add node (Friday, September 6, 2013 2:19:09 PM CST) . 1% Done. Instantiation of add node scripts complete Copying to remote nodes (Friday, September 6, 2013 2:19:12 PM CST) ............................................................................................... 96% Done. Home copied to new nodes Saving inventory on nodes (Friday, September 6, 2013 2:37:27 PM CST) . 100% Done. Save inventory complete WARNING:A new inventory has been created on one or more nodes in this session. However, it has not yet been registered as the central inventory of this system. To register the new inventory please run the script at &apos;/u01/app/oraInventory/orainstRoot.sh&apos; with root privileges on nodes &apos;orcl2&apos;. If you do not register the inventory, you may not be able to update or patch the products you installed. The following configuration scripts need to be executed as the &quot;root&quot; user in each new cluster node. Each script in the list below is followed by a list of nodes. /u01/app/oraInventory/orainstRoot.sh #On nodes orcl2 /u01/app/11.2.0/grid/root.sh #On nodes orcl2 To execute the configuration scripts: 1. Open a terminal window 2. Log in as &quot;root&quot; 3. Run the scripts in each cluster node The Cluster Node Addition of /u01/app/11.2.0/grid was successful. Please check &apos;/tmp/silentInstall.log&apos; for more details. 执行结果： 1234567891011121314151617181920212223242526272829303132333435363738[root@orcl2:/root]# /u01/app/oraInventory/orainstRoot.sh Creating the Oracle inventory pointer file (/etc/oraInst.loc) Changing permissions of /u01/app/oraInventory. Adding read,write permissions for group. Removing read,write,execute permissions for world. Changing groupname of /u01/app/oraInventory to oinstall. The execution of the script is complete. [root@orcl2:/root]# /u01/app/11.2.0/grid/root.sh Performing root user operation for Oracle 11g The following environment variables are set as: ORACLE_OWNER= grid ORACLE_HOME= /u01/app/11.2.0/grid Enter the full pathname of the local bin directory: [/usr/local/bin]: Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ... Creating /etc/oratab file... Entries will be added to the /etc/oratab file as needed by Database Configuration Assistant when a database is created Finished running generic part of root script. Now product-specific root actions will be performed. Using configuration parameter file: /u01/app/11.2.0/grid/crs/install/crsconfig_params Creating trace directory User ignored Prerequisites during installation Installing Trace File Analyzer OLR initialization - successful Adding Clusterware entries to inittab CRS-4402: The CSS daemon was started in exclusive mode but found an active CSS daemon on node orcl1, number 1, and is terminating An active cluster was found during exclusive startup, restarting to join the cluster clscfg: EXISTING configuration version 5 detected. clscfg: version 5 is 11g Release 2. Successfully accumulated necessary OCR keys. Creating OCR keys for user &apos;root&apos;, privgrp &apos;root&apos;.. Operation successful. Preparing packages for installation... cvuqdisk-1.0.9-1 Configure Oracle Grid Infrastructure for a Cluster ... succeeded 如果root.sh执行失败，执行以下脚本，fixup完再重新实现root.sh: [root@orcl2:/u01/app/11.2.0/grid/crs/install]# ./rootcrs.pl -deconfig -force 在此节点重启CRS： 12[root@orcl2:/root]# /u01/app/11.2.0/grid/bin/crsctl stop crs [root@orcl2:/root]# /u01/app/11.2.0/grid/bin/crsctl start crs 最后，在新加节点上用grid用户通过以下命令对RAC扩展结果进行验证： [grid@orcl2:/u01/app/11.2.0/grid]$ cluvfy stage -post nodeadd -n orcl1,orcl2 3. 扩展Oracle数据库服务器 Oracle数据库服务器的扩展包括两部：第一步复制Oracle数据库软件；第二步在新节点上创建数据库实例及数据库监听。 3.1复制软件 以Oracle用户登录node1,执行以下命令将数据库软件复制到新添加节点上。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[root@orcl1:/root]# su - oracle [oracle@orcl1:/home/oracle]$ cd $ORACLE_HOME/oui/bin [oracle@orcl1:/u01/app/oracle/product/11gr2/oui/bin]$ [oracle@orcl1:/u01/app/oracle/product/11gr2/oui/bin]$ ./addNode.sh -silent &quot;CLUSTER_NEW_NODES=&#123;orcl2&#125;&quot; Performing pre-checks for node addition Checking node reachability... Node reachability check passed from node &quot;orcl1&quot; Checking user equivalence... User equivalence check passed for user &quot;oracle&quot; WARNING: Node &quot;orcl2&quot; already appears to be part of cluster Pre-check for node addition was successful. Starting Oracle Universal Installer... Checking swap space: must be greater than 500 MB. Actual 3739 MB Passed Oracle Universal Installer, Version 11.2.0.4.0 Production Copyright (C) 1999, 2013, Oracle. All rights reserved. Performing tests to see whether nodes orcl2 are available ............................................................... 100% Done. .. ----------------------------------------------------------------------------- Cluster Node Addition Summary Global Settings Source: /u01/app/oracle/product/11gr2 New Nodes Space Requirements New Nodes orcl2 /: Required 4.29GB : Available 13.18GB Installed Products Product Names Oracle Database 11g 11.2.0.4.0 ……… Oracle Partitioning 11.2.0.4.0 Enterprise Edition Options 11.2.0.4.0 ----------------------------------------------------------------------------- Instantiating scripts for add node (Friday, September 6, 2013 3:12:01 PM CST) . 1% Done. Instantiation of add node scripts complete Copying to remote nodes (Friday, September 6, 2013 3:12:07 PM CST) ............................................................................................... 96% Done. Home copied to new nodes Saving inventory on nodes (Friday, September 6, 2013 3:36:48 PM CST) . 100% Done. Save inventory complete WARNING: The following configuration scripts need to be executed as the &quot;root&quot; user in each new cluster node. Each script in the list below is followed by a list of nodes. /u01/app/oracle/product/11gr2/root.sh #On nodes orcl2 To execute the configuration scripts: 1. Open a terminal window 2. Log in as &quot;root&quot; 3. Run the scripts in each cluster node The Cluster Node Addition of /u01/app/oracle/product/11gr2 was successful. Please check &apos;/tmp/silentInstall.log&apos; for more details. 在节点2以root用户执行以上脚本： [root@orcl2:/worktmp]# /u01/app/oracle/product/11gr2/root.sh 3.2创建数据库实例 在node1上以Oracle用户登录，使用dbca silent模式创建数据库实例： 12345678910111213141516171819[oracle@orcl1:/u01]$ dbca -silent -addInstance -nodeList orcl2 -gdbName racdb \\ -instanceName racdb2 -sysDBAUserName sys -sysDBAPassword oracle Adding instance 1% complete 2% complete 6% complete 13% complete 20% complete 26% complete 33% complete 40% complete 46% complete 53% complete 66% complete Completing instance management. 76% complete 100% complete Look at the log file &quot;/u01/app/oracle/cfgtoollogs/dbca/racdb/racdb.log&quot; for further details. 节点添加完毕，验证下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@orcl2:/root]# /u01/app/11.2.0/grid/bin/crsctl stat res -t -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.CRS.dg ONLINE ONLINE orcl1 ONLINE ONLINE orcl2 ora.DATA.dg ONLINE ONLINE orcl1 ONLINE ONLINE orcl2 ora.LISTENER.lsnr ONLINE ONLINE orcl1 ONLINE ONLINE orcl2 ora.asm ONLINE ONLINE orcl1 Started ONLINE ONLINE orcl2 Started ora.gsd OFFLINE OFFLINE orcl1 OFFLINE OFFLINE orcl2 ora.net1.network ONLINE ONLINE orcl1 ONLINE ONLINE orcl2 ora.ons ONLINE ONLINE orcl1 ONLINE ONLINE orcl2 ora.registry.acfs ONLINE ONLINE orcl1 ONLINE ONLINE orcl2 -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE orcl1 ora.cvu 1 ONLINE ONLINE orcl2 ora.oc4j 1 ONLINE ONLINE orcl1 ora.orcl1.vip 1 ONLINE ONLINE orcl1 ora.orcl2.vip 1 ONLINE ONLINE orcl2 ora.racdb.db 1 ONLINE ONLINE orcl1 Open 2 ONLINE ONLINE orcl2 Open ora.scan1.vip 1 ONLINE ONLINE orcl1 查看inventory，节点2已经能被识别： 1234567891011121314151617181920212223242526272829[grid@orcl2:/home/grid]$ /u01/app/11.2.0/grid/OPatch/opatch lsinventory Oracle Interim Patch Installer version 11.2.0.3.4 Copyright (c) 2012, Oracle Corporation. All rights reserved. Oracle Home : /u01/app/11.2.0/grid Central Inventory : /u01/app/oraInventory from : /u01/app/11.2.0/grid/oraInst.loc OPatch version : 11.2.0.3.4 OUI version : 11.2.0.4.0 Log file location : /u01/app/11.2.0/grid/cfgtoollogs/opatch/opatch2013-09-06_22-01-23PM_1.log Lsinventory Output file location : /u01/app/11.2.0/grid/cfgtoollogs/opatch/lsinv/lsinventory2013-09-06_22-01-23PM.txt -------------------------------------------------------------------------------- Installed Top-level Products (1): Oracle Grid Infrastructure 11g 11.2.0.4.0 There are 1 products installed in this Oracle Home. There are no Interim patches installed in this Oracle Home. Rac system comprising of multiple nodes Local node = orcl2 Remote node = orcl1 -------------------------------------------------------------------------------- OPatch succeeded. [grid@orcl2:/home/grid]$ EOF","link":"/addnodes-in-11g-rac.html"},{"title":"AIX基本操作","text":"1.change swap size12345678910111213141516171819202122232425262728293031323334--check current swap size# lsps -aPage Space Physical Volume Volume Group Size %Used Active Auto Type Chksumhd6 hdisk0 rootvg 512MB 2 yes yes lv 0--check the memory size in the mechine# lsattr -Elmem0ent_mem_cap I/O memory entitlement in Kbytes Falsegoodsize 7648 Amount of usable physical memory in Mbytes Falsemem_exp_factor Memory expansion factor Falsesize 7648 Total amount of physical memory in Mbytes Falsevar_mem_weight Variable memory capacity weight False--check rootvg PP size# lsvg rootvgVOLUME GROUP: rootvg VG IDENTIFIER: 00c868bf00004c000000000000848812VG STATE: active PP SIZE: 128 megabyte(s)VG PERMISSION: read/write TOTAL PPs: 1345 (172160 megabytes)MAX LVs: 256 FREE PPs: 1147 (146816 megabytes)LVs: 12 USED PPs: 198 (25344 megabytes)OPEN LVs: 11 QUORUM: 2 (Enabled)TOTAL PVs: 2 VG DESCRIPTORS: 3STALE PVs: 0 STALE PPs: 0ACTIVE PVs: 1 AUTO ON: yesMAX PPs per VG: 32512MAX PPs per PV: 1016 MAX PVs: 32LTG size (Dynamic): 128 kilobyte(s) AUTO SYNC: noHOT SPARE: no BB POLICY: relocatablePV RESTRICTION: none--increase swap to 8GB# chps -s 64 hd6lquerypv: Warning, physical volume hdisk2 is excluded since it may be either missing or removed.# lsps -aPage Space Physical Volume Volume Group Size %Used Active Auto Type Chksumhd6 hdisk0 rootvg 8704MB 1 yes yes lv 0 2.create file system12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152--check vg# lsvgrootvg# lsvg -p rootvgrootvg:PV_NAME PV STATE TOTAL PPs FREE PPs FREE DISTRIBUTIONhdisk0 active 546 136 108..18..00..00..10#--check pv# lspvhdisk0 00c868bfc7fd26e6 rootvg active# lsdev -Cc diskhdisk0 Available 04-08-00-8,0 16 Bit LVD SCSI Disk Drivehdisk1 Defined 02-08-01 MPIO Other DS4K Array Diskhdisk2 Defined 02-08-01 MPIO Other DS4K Array Diskhdisk3 Defined 02-08-01 MPIO Other DS4K Array Disk# lspv hdisk0PHYSICAL VOLUME: hdisk0 VOLUME GROUP: rootvgPV IDENTIFIER: 00c868bfc7fd26e6 VG IDENTIFIER 00c868bf00004c000000000000848812PV STATE: activeSTALE PARTITIONS: 0 ALLOCATABLE: yesPP SIZE: 128 megabyte(s) LOGICAL VOLUMES: 12TOTAL PPs: 546 (69888 megabytes) VG DESCRIPTORS: 2FREE PPs: 348 (44544 megabytes) HOT SPARE: noUSED PPs: 198 (25344 megabytes) MAX REQUEST: 256 kilobytesFREE DISTRIBUTION: 109..21..00..109..109USED DISTRIBUTION: 01..88..109..00..00MIRROR POOL: None--create vg# mkvg -y oravg -s 128M hdisk1--create lv# mklv -t jfs2 -y oralv rootvg 24 hdisk0oralv--create file system# mkdir /oracle# crfs -v jfs2 -d oralv -A yes -m /oracleFile system created successfully.3145428 kilobytes total disk space.New File System size is 6291456# mount /oracle# df -gFilesystem GB blocks Free %Used Iused %Iused Mounted on/dev/hd4 0.25 0.07 74% 10612 40% //dev/hd2 2.25 0.04 99% 49260 80% /usr/dev/hd9var 0.50 0.19 63% 8223 16% /var/dev/hd3 10.00 9.53 5% 748 1% /tmp/dev/hd1 0.12 0.12 1% 5 1% /home/dev/hd11admin 0.12 0.12 1% 5 1% /admin/proc - - - - - /proc/dev/hd10opt 0.50 0.26 48% 8748 13% /opt/dev/livedump 0.25 0.25 1% 4 1% /var/adm/ras/livedump/dev/oralv 3.00 3.00 1% 4 1% /oracle 3.online extend file system123456789101112131415161718192021222324252627282930313233# extendlv oralv 240lquerypv: Warning, physical volume hdisk2 is excluded since it may be either missing or removed.# lsvg -l rootvgrootvg:LV NAME TYPE LPs PPs PVs LV STATE MOUNT POINThd5 boot 1 1 1 closed/syncd N/Ahd6 paging 68 68 1 open/syncd N/Ahd8 jfs2log 1 1 1 open/syncd N/Ahd4 jfs2 2 2 1 open/syncd /hd2 jfs2 18 18 1 open/syncd /usrhd9var jfs2 4 4 1 open/syncd /varhd3 jfs2 80 80 1 open/syncd /tmphd1 jfs2 1 1 1 open/syncd /homehd10opt jfs2 4 4 1 open/syncd /opthd11admin jfs2 1 1 1 open/syncd /adminlg_dumplv sysdump 16 16 1 open/syncd N/Alivedump jfs2 2 2 1 open/syncd /var/adm/ras/livedumporalv jfs2 264 264 1 open/syncd /oracle# chfs -a size=+30G /oracleFilesystem size changed to 69206016# df -gFilesystem GB blocks Free %Used Iused %Iused Mounted on/dev/hd4 0.25 0.07 74% 10612 40% //dev/hd2 2.25 0.04 99% 49260 80% /usr/dev/hd9var 0.50 0.19 63% 8223 16% /var/dev/hd3 10.00 9.53 5% 748 1% /tmp/dev/hd1 0.12 0.12 1% 5 1% /home/dev/hd11admin 0.12 0.12 1% 5 1% /admin/proc - - - - - /proc/dev/hd10opt 0.50 0.26 48% 8748 13% /opt/dev/livedump 0.25 0.25 1% 4 1% /var/adm/ras/livedump/dev/oralv 33.00 32.99 1% 4 1% /oracle 4.create user &amp; group12345# mkgroup id=501 oinstall# mkgroup id=502 dba# mkuser id=501 pgrp=&apos;oinstall&apos; groups=dba oracle# id oracleuid=501(oracle) gid=501(oinstall) groups=502(dba) 5.disk driver info &amp; lun info123456789101112131415# lsattr -El hdisk0PCM PCM/friend/scsiscsd Path Control Module Falsealgorithm fail_over Algorithm Truedist_err_pcnt 0 Distributed Error Percentage Truedist_tw_width 50 Distributed Error Sample Time Truehcheck_interval 0 Health Check Interval Truehcheck_mode nonactive Health Check Mode Truemax_coalesce 0x10000 Maximum Coalesce Size Truemax_transfer 0x100000 Maximum TRANSFER Size Truepvid 00f8c13b65847a820000000000000000 Physical volume identifier Falsequeue_depth 16 Queue DEPTH Truereserve_policy no_reserve Reserve Policy Truesize_in_mb 146800 Size in Megabytes Falseunique_id 2A1135000C5005EA9607B0BST9146853SS03IBMsas Unique device identifier Falseww_id 5000c5005ea9607b World Wide Identifier False 上述命令不能看到emc多路径LUN的大小：12345678910111213141516171819#lsattr -El hdiskpower3PR_key_value none Reserve Key. Trueclr_q no Clear Queue (RS/6000) Truelocation Location Truelun_id 0x3000000000000 LUN ID Falselun_reset_spt yes FC Forced Open LUN Truemax_coalesce 0x100000 Maximum coalesce size Truemax_transfer 0x100000 Maximum transfer size Truepvid 00f8c13b3303bc100000000000000000 Physical volume identifier Falsepvid_takeover yes Takeover PVIDs from hdisks Trueq_err yes Use QERR bit Trueq_type simple Queue TYPE Falsequeue_depth 32 Queue DEPTH Truereassign_to 120 REASSIGN time out value Truereserve_policy single_path Reserve Policy used to reserve device on open. Truerw_timeout 30 READ/WRITE time out Truescsi_id 0x11600 SCSI ID Falsestart_timeout 60 START unit time out Trueww_name 0x500601693ee02689 World Wide Name False 查看存储mapping过来的LUN大小，该LUN的VG必须要激活：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647#lsvg -odatavgrootvg#lspvhdisk0 00f8c13c29b5f01d rootvg activehdisk2 00f8c13c55eba068 rootvg activehdisk3 none Nonehdisk4 none Nonehdisk5 none Nonehdisk6 none Nonehdisk7 none Nonehdisk8 none Nonehdisk9 none Nonehdisk10 none Nonehdisk11 none Nonehdisk12 none Nonehdisk13 none Nonehdisk14 none Nonehdisk15 none Nonehdisk16 none Nonehdisk17 none Nonehdisk18 none Nonehdisk19 none Nonehdisk20 none Nonehdisk21 none Nonehdisk22 none Nonehdisk23 none Nonehdisk24 none Nonehdisk25 none Nonehdisk26 none Nonehdisk27 none Nonehdiskpower0 00f8c13b330bcfbd hbvghdiskpower1 00f8c13b3301701a datavg activehdiskpower2 00f8c13b330502dd datavg activehdiskpower3 00f8c13b3303bc10 datavg active#lspv hdiskpower1PHYSICAL VOLUME: hdiskpower1 VOLUME GROUP: datavgPV IDENTIFIER: 00f8c13b3301701a VG IDENTIFIER 00f8c13b00004c00000001446a0ea7e3PV STATE: activeSTALE PARTITIONS: 0 ALLOCATABLE: yesPP SIZE: 512 megabyte(s) LOGICAL VOLUMES: 1TOTAL PPs: 399 (204288 megabytes) VG DESCRIPTORS: 1FREE PPs: 0 (0 megabytes) HOT SPARE: noUSED PPs: 399 (204288 megabytes) MAX REQUEST: 1 megabyteFREE DISTRIBUTION: 00..00..00..00..00USED DISTRIBUTION: 80..80..79..80..80MIRROR POOL: None 对于EMC使用powerpath mapping的LUN，可用如下命令查询：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384#powermt display dev=allPseudo name=hdiskpower0CLARiiON ID=CKM00130902402 [HACMP]Logical device ID=600601605C80340006DBA9929B9DE311 [LUN 0]state=alive; policy=CLAROpt; priority=0; queued-IOs=0;Owner: default=SP A, current=SP A Array failover mode: 4==============================================================================--------------- Host --------------- - Stor - -- I/O Path -- -- Stats ---### HW Path I/O Paths Interf. Mode State Q-IOs Errors============================================================================== 0 fscsi0 hdisk10 SP B0 active alive 0 0 1 fscsi2 hdisk16 SP A1 active alive 0 0 1 fscsi2 hdisk22 SP B1 active alive 0 0 0 fscsi0 hdisk4 SP A0 active alive 0 0Pseudo name=hdiskpower4CLARiiON ID=CKM00130902402 [HACMP]Logical device ID=600601605C80340024AE82E69B9DE311 [LUN 4]state=alive; policy=CLAROpt; priority=0; queued-IOs=0;Owner: default=SP B, current=SP B Array failover mode: 4==============================================================================--------------- Host --------------- - Stor - -- I/O Path -- -- Stats ---### HW Path I/O Paths Interf. Mode State Q-IOs Errors============================================================================== 0 fscsi0 hdisk14 SP B0 active alive 0 0 1 fscsi2 hdisk20 SP A1 active alive 0 0 1 fscsi2 hdisk26 SP B1 active alive 0 0 0 fscsi0 hdisk8 SP A0 active alive 0 0Pseudo name=hdiskpower5CLARiiON ID=CKM00130902402 [HACMP]Logical device ID=600601605C803400705107F09B9DE311 [LUN 5]state=alive; policy=CLAROpt; priority=0; queued-IOs=0;Owner: default=SP A, current=SP A Array failover mode: 4==============================================================================--------------- Host --------------- - Stor - -- I/O Path -- -- Stats ---### HW Path I/O Paths Interf. Mode State Q-IOs Errors============================================================================== 0 fscsi0 hdisk15 SP B0 active alive 0 0 1 fscsi2 hdisk21 SP A1 active alive 0 0 1 fscsi2 hdisk27 SP B1 active alive 0 0 0 fscsi0 hdisk9 SP A0 active alive 0 0Pseudo name=hdiskpower1CLARiiON ID=CKM00130902402 [HACMP]Logical device ID=600601605C8034008A0968A99B9DE311 [LUN 1]state=alive; policy=CLAROpt; priority=0; queued-IOs=0;Owner: default=SP A, current=SP A Array failover mode: 4==============================================================================--------------- Host --------------- - Stor - -- I/O Path -- -- Stats ---### HW Path I/O Paths Interf. Mode State Q-IOs Errors============================================================================== 0 fscsi0 hdisk11 SP B0 active alive 0 0 1 fscsi2 hdisk17 SP A1 active alive 0 0 1 fscsi2 hdisk23 SP B1 active alive 0 0 0 fscsi0 hdisk5 SP A0 active alive 0 0Pseudo name=hdiskpower3CLARiiON ID=CKM00130902402 [HACMP]Logical device ID=600601605C803400963FDACC9B9DE311 [LUN 3]state=alive; policy=CLAROpt; priority=0; queued-IOs=0;Owner: default=SP A, current=SP A Array failover mode: 4==============================================================================--------------- Host --------------- - Stor - -- I/O Path -- -- Stats ---### HW Path I/O Paths Interf. Mode State Q-IOs Errors============================================================================== 0 fscsi0 hdisk13 SP B0 active alive 0 0 1 fscsi2 hdisk19 SP A1 active alive 0 0 1 fscsi2 hdisk25 SP B1 active alive 0 0 0 fscsi0 hdisk7 SP A0 active alive 0 0Pseudo name=hdiskpower2CLARiiON ID=CKM00130902402 [HACMP]Logical device ID=600601605C803400DA36EBC19B9DE311 [LUN 2]state=alive; policy=CLAROpt; priority=0; queued-IOs=0;Owner: default=SP B, current=SP B Array failover mode: 4==============================================================================--------------- Host --------------- - Stor - -- I/O Path -- -- Stats ---### HW Path I/O Paths Interf. Mode State Q-IOs Errors============================================================================== 0 fscsi0 hdisk12 SP B0 active alive 0 0 1 fscsi2 hdisk18 SP A1 active alive 0 0 1 fscsi2 hdisk24 SP B1 active alive 0 0 0 fscsi0 hdisk6 SP A0 active alive 0 0 To be continued","link":"/aix-basic-operations.html"},{"title":"Archiving and Compressing Files","text":"一、在linux或者unix环境，DBA或者SA经常要对文档归档压缩以保存至远程机器。在linux/unix环境用的比较多的命令是tar、cpio和zip。以下是几个命令的几个简单用法。1.tar命令1$tar –cvf tarfilename.tar source_file(or source diretory) c表示创建一个tar文件，f表示tar包名称，f后面必须紧接tar包名称，否则会出现错误。如需压缩，则用z(gzip)或者j(bzip2)参数：1$tar -cvzf orahome.tar.gz /oracle/product/10.2 如果使用的是非GNU的tar，则可能无-j或者-z参数(HP-UX 11.23遇到过),这时候想要压缩，则须通过pipe结合其他压缩命令达到此目的:1$ tar -cvf - /oracle/product/10.2 | gzip &gt; orahome.tar.gz 同时，tar还可以cp某个目录至另外一个目录而不需要借助中间介质：1$ tar -cvf - scripts | (cd /ora01/backup; tar -xvf -) 上面给出的例子表示将当前目录下scripts目录cp至/ora01/bakcup下。Tar包的解压命令只需要该c为x(extrate),如$ tar -xvf mytar.tar2.cpio命令cpio通常用参数-ov表示创建cpio文件，通常扩展名为.cpio。以下命令表示ls出来的结果pipe给cpio，创建文件名为backup.cpio的文档。1$ ls | cpio -ov &gt; backup.cpio 如果需要打包整个目录怎么办？可以用find结合，如：1$ find . -depth | cpio -ov &gt; orahome.cpio 如果需要压缩，则可与gzip结合：1$ find . -depth | cpio -ov | gzip &gt; orahome.cpio.gz 以下是cpio打包的语法：1$ [find or ls command] | cpio -o[other options] &gt; filename cpio解包一般指定idmv参数(AIX中，还需要c参数)，i表示从cpio包重定向，d和m参数则表示在解包中会自动创建目录和保留文件修改时间。123456789101112131415161718$ cpio -idvm &lt; linux10g_disk1.cpio$ cat linux10g_disk1.cpio | cpio -idvm$ cat linux10g_disk1.cpio.gz | gunzip | cpio –idvm# cpio -idmv &lt; 10gr2_aix5l64_database.cpio cpio: 0511-903 Out of phase! cpio attempting to continue... cpio: 0511-904 skipping 732944 bytes to get back in phase! One or more files lost and the previous file is possibly corrupt!cpio: 0511-027 The file name length does not match the expected value.#FOR AIX c Reads and writes header information in ASCII character form. If a cpio archive was created using the c flag, it must be extracted with c flag.cpio -idcmv &lt; 10gr2_aix5l64_database.cpio 当然，从cpio包中也可以只释放其中的一个文件，以下例子表示从dbascripts.cpio中释放出rman.bsh这个脚本：1$ cpio -idvm rman.bsh &lt; dbascripts.cpio 二、在打包好的文件中添加文件1.tar往tar包中添加文件，加上参数-r(append)：1$ tar -rvf backup.tar newscript.sql 或添加目录：1$ tar -rvf backup.tar scripts 2.cpiocpio添加-A(append),同时也会指定F参数指定添加文件到指定的cpio包中：1$ ls *.sql | cpio -ovAF my.cpio 目录：1$ find backup | cpio -ovAF my.cpio 3.zipzip包添加-g参数：123$ zip -g my.zip script.sql目录：$ zip -gr my.zip backup 注意：在HP-UX或者AIX下，并不会自动安装unzip工具，此时，需要用到jar去解压：1234# man unzipManual entry for unzip not found or not installed.# jar -xvf p10404530_112030_AIX64-5L_2of7.zip# jar -cvf database.zip database/","link":"/archiving-and-compressing-files.html"},{"title":"ASM utilities","text":"Oracle自带的ASM类似OS级别的LVM，由于Oracle本身对其进行了封装，在一定程度上来讲，对维护人员就提高了要求。Oracle提供了一系列的工具能对ASM磁盘进行管理。 1. ASMCMDASM由Oracle进行封装，在OS级别，我们无法访问ASM磁盘组，Oracle提供了asmcmd这个工具，它包含了部分类似OS级别的操作，如ls，du，cp(11g)等。在11g里面，这个工具比之前版本增强了很多。1234567891011121314151617181920212223--查找磁盘组信息，包括没有被mount的磁盘组[grid@orl6:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------NAME TARGET STATE SERVER STATE_DETAILS --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.DATA.dg OFFLINE OFFLINE orl6 ora.DATA1.dg ONLINE ONLINE orl6 [grid@orl6:/home/grid]$ asmcmd lsdg -g --discovery Inst_ID State Type Rebal Sector Block AU Total_MB Free_MB Req_mir_free_MB Usable_file_MB Offline_disks Voting_files Name 1 DISMOUNTED N 0 4096 0 0 0 0 0 0 N DATA/ 1 MOUNTED EXTERN N 512 4096 1048576 20480 16970 0 16970 0 N DATA1/--检测ASM磁盘状态,仅被mount的磁盘能被检测[grid@orl6:/home/grid]$ asmcmd lsdsk -k -gInst_ID Total_MB Free_MB OS_MB Name Failgroup Failgroup_Type Library Label UDID Product Redund Path 1 20480 16970 20480 DATA1_0000 DATA1_0000 REGULAR System UNKNOWN /dev/asmdisk1--检测候选磁盘状态[grid@orl6:/home/grid]$ asmcmd lsdsk -k -g --candidateInst_ID Total_MB Free_MB OS_MB Name Failgroup Failgroup_Type Library Label UDID Product Redund Path 1 0 0 12288 REGULAR System UNKNOWN /dev/asmdisk3 --连接到ASM实例的客户端信息12345678910111213141516171819202122232425[grid@orl6:/home/grid]$ asmcmd lsctDB_Name Status Software_Version Compatible_version Instance_Name Disk_Groupkyun CONNECTED 11.2.0.4.0 11.2.0.4.0 kyun DATA1 kyun CONNECTED 11.2.0.4.0 11.2.0.4.0 kyun DATA --ASM中被打开文件句柄的文件[grid@orl6:/home/grid]$ asmcmd lsofDB_Name Instance_Name Path kyun kyun +data/kyun/datafile/tt01.256.883261951 kyun kyun +data1/kyun/controlfile/current.256.858438947 kyun kyun +data1/kyun/datafile/data.274.859116297 kyun kyun +data1/kyun/datafile/demotsdata.270.858444769 kyun kyun +data1/kyun/datafile/demotsidx.271.858444795 kyun kyun +data1/kyun/datafile/example.264.858439059 kyun kyun +data1/kyun/datafile/fung.267.858444647 kyun kyun +data1/kyun/datafile/perf.268.858444681 kyun kyun +data1/kyun/datafile/sysaux.261.858438997 kyun kyun +data1/kyun/datafile/system.260.858438969 kyun kyun +data1/kyun/datafile/test.269.858444735 kyun kyun +data1/kyun/datafile/undotbs2.277.860582391 kyun kyun +data1/kyun/datafile/undotbs3.278.860582395 kyun kyun +data1/kyun/datafile/users.265.858439071 kyun kyun +data1/kyun/onlinelog/group_1.257.858438949 kyun kyun +data1/kyun/onlinelog/group_2.258.858438955 kyun kyun +data1/kyun/onlinelog/group_3.259.858438959 kyun kyun +data1/kyun/tempfile/temp.263.858439035 11G新增cp命令1234[grid@linora:/tmp]$ asmcmd find +data1/ *.dbf |xargs -i asmcmd cp &#123;&#125; /tmpcopying +data1/kyun/arch/1_56_858438943.dbf -&gt; /tmp/1_56_858438943.dbfcopying +data1/kyun/arch/1_57_858438943.dbf -&gt; /tmp/1_57_858438943.dbfcopying +data1/kyun/arch/1_58_858438943.dbf -&gt; /tmp/1_58_858438943.dbf 其他详细的用法请参照asmcmd help。 2. KFODKernal Files OSM Disk, OSM表示Order and Service Management。这个工具是在OS级别Discover Disk的。具体的用法参照kfod -h。123456789101112131415161718--Discover Disks[grid@orl6:/home/grid]$ kfod status=TRUE asm_diskstring=&apos;/dev/asmdisk*&apos; disk=all dscvgroup=TRUE-------------------------------------------------------------------------------- Disk Size Header Path Disk Group User Group ================================================================================ 1: 20480 Mb MEMBER /dev/asmdisk1 DATA1 grid oinstall 2: 15584 Mb MEMBER /dev/asmdisk2 DATA grid oinstall 3: 12288 Mb CANDIDATE /dev/asmdisk3 # grid oinstall--------------------------------------------------------------------------------ORACLE_SID ORACLE_HOME ================================================================================ +ASM /u01/app/11gr2/grid [grid@orl6:/home/grid]$ kfod op=groups--------------------------------------------------------------------------------Group Size Free Redundancy Name ================================================================================ 1: 20480 Mb 16970 Mb EXTERN DATA1 2: 15584 Mb 15431 Mb EXTERN DATA 3. KFEDKfed，全称为Kernal Files metadata EDitor。顾名思义，它是可以分析ASM磁盘头信息的，其最大的作用是能修正corrupt的ASM metadata。在11g中，这个工具随着GI的安装自动安装，但是在以前的版本中，kfed需要通过编译才能使用，如：123--Linux编译kfed工具before 11gcd $ORACLE_HOME/rdbms/libmake -f ins_rdbms.mk ikfed 这个工具的使用帮助可以直接在grid用户下执行kfed即可。 3.1 kfed readkfed read命令能读取单独一个ASM块。对于kfed read的语法如下：1kfed read [aun=ii aus=jj blkn=kk dev=]asm_disk_name 其中，aun表示从哪个AU(Allocation Unit)开始读取，默认为AU0，或者是ASM磁盘最开始的地方；aus表示AU大小，默认为1048576，即1M，如果ASM diskgroup使用的不是默认的AU size，请指定此大小；blkn读取第几个块，默认为0，即AU的第一个block。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778[grid@node1:/home/grid]$ kfed read aun=0 aus=1048576 blkn=0 dev=/dev/asm-diskc--以上命令等同于kfed read /dev/asm-diskc--kfbh=kernal file block header[grid@orl6:/home/grid]$ kfed read aun=0 aus=1048576 blkn=0 dev=/dev/asmdisk1kfbh.endian: 1 ; 0x000: 0x01 --系统endian，1为little，0为bigkfbh.hard: 130 ; 0x001: 0x82kfbh.type: 1 ; 0x002: KFBTYP_DISKHEAD --块类型，这里表示file header，文件头kfbh.datfmt: 1 ; 0x003: 0x01kfbh.block.blk: 0 ; 0x004: blk=0 --当前块位置kfbh.block.obj: 2147483648 ; 0x008: disk=0kfbh.check: 3459712326 ; 0x00c: 0xce370546kfbh.fcn.base: 7316 ; 0x010: 0x00001c94kfbh.fcn.wrap: 0 ; 0x014: 0x00000000kfbh.spare1: 0 ; 0x018: 0x00000000kfbh.spare2: 0 ; 0x01c: 0x00000000kfdhdb.driver.provstr: ORCLDISK ; 0x000: length=8 --ORCLDISK+[ASM Disk Name]表示使用ASMLIB，只有ORCLDISK表示没有使用ASMLIBkfdhdb.driver.reserved[0]: 0 ; 0x008: 0x00000000kfdhdb.driver.reserved[1]: 0 ; 0x00c: 0x00000000kfdhdb.driver.reserved[2]: 0 ; 0x010: 0x00000000kfdhdb.driver.reserved[3]: 0 ; 0x014: 0x00000000kfdhdb.driver.reserved[4]: 0 ; 0x018: 0x00000000kfdhdb.driver.reserved[5]: 0 ; 0x01c: 0x00000000kfdhdb.compat: 186646528 ; 0x020: 0x0b200000 --打开本磁盘组所需的ASM最小版本，b2=11.2kfdhdb.dsknum: 0 ; 0x024: 0x0000kfdhdb.grptyp: 1 ; 0x026: KFDGTP_EXTERNAL --group redundancy typekfdhdb.hdrsts: 3 ; 0x027: KFDHDR_MEMBER --ASM disk header status，v$asm_disk.header_statuskfdhdb.dskname: DATA1_0000 ; 0x028: length=10 --ASM disk namekfdhdb.grpname: DATA1 ; 0x048: length=5 --ASM disk group namekfdhdb.fgname: DATA1_0000 ; 0x068: length=10 --ASM failure group namekfdhdb.capname: ; 0x088: length=0kfdhdb.crestmp.hi: 33007118 ; 0x0a8: HOUR=0xe DAYS=0x10 MNTH=0x9 YEAR=0x7dekfdhdb.crestmp.lo: 2136205312 ; 0x0ac: USEC=0x0 MSEC=0xfa SECS=0x35 MINS=0x1fkfdhdb.mntstmp.hi: 33020693 ; 0x0b0: HOUR=0x15 DAYS=0x18 MNTH=0x6 YEAR=0x7dfkfdhdb.mntstmp.lo: 446956544 ; 0x0b4: USEC=0x0 MSEC=0x101 SECS=0x2a MINS=0x6 --以上为四个时间，asm磁盘加入磁盘组的日期时间和最后被mount日期的时间kfdhdb.secsize: 512 ; 0x0b8: 0x0200kfdhdb.blksize: 4096 ; 0x0ba: 0x1000 --ASM Metadata Block size，为4Kkfdhdb.ausize: 1048576 ; 0x0bc: 0x00100000 --ASM AU大小kfdhdb.mfact: 113792 ; 0x0c0: 0x0001bc80kfdhdb.dsksize: 20480 ; 0x0c4: 0x00005000 --ASM磁盘大小，此处为20Gkfdhdb.pmcnt: 2 ; 0x0c8: 0x00000002kfdhdb.fstlocn: 1 ; 0x0cc: 0x00000001kfdhdb.altlocn: 2 ; 0x0d0: 0x00000002kfdhdb.f1b1locn: 2 ; 0x0d4: 0x00000002kfdhdb.redomirrors[0]: 0 ; 0x0d8: 0x0000kfdhdb.redomirrors[1]: 0 ; 0x0da: 0x0000kfdhdb.redomirrors[2]: 0 ; 0x0dc: 0x0000kfdhdb.redomirrors[3]: 0 ; 0x0de: 0x0000kfdhdb.dbcompat: 168820736 ; 0x0e0: 0x0a100000 --打开磁盘组所需的数据库实例最小版本，a1=10.1kfdhdb.grpstmp.hi: 33007118 ; 0x0e4: HOUR=0xe DAYS=0x10 MNTH=0x9 YEAR=0x7dekfdhdb.grpstmp.lo: 2136086528 ; 0x0e8: USEC=0x0 MSEC=0x86 SECS=0x35 MINS=0x1f --以上两个items表示磁盘组创建时间kfdhdb.vfstart: 0 ; 0x0ec: 0x00000000kfdhdb.vfend: 0 ; 0x0f0: 0x00000000kfdhdb.spfile: 58 ; 0x0f4: 0x0000003a --ASM Spfile的AU Number，11.2以后支持，此处表示spfile存放在当前磁盘的第58AU上。kfdhdb.spfflg: 1 ; 0x0f8: 0x00000001kfdhdb.ub4spare[0]: 0 ; 0x0fc: 0x00000000kfdhdb.ub4spare[1]: 0 ; 0x100: 0x00000000...kfdhdb.acdb.aba.seq: 0 ; 0x1d4: 0x00000000kfdhdb.acdb.aba.blk: 0 ; 0x1d8: 0x00000000kfdhdb.acdb.ents: 0 ; 0x1dc: 0x0000kfdhdb.acdb.ub2spare: 0 ; 0x1de: 0x0000 如果需要将输出保存到一个文件中，则使用text关键字，屏幕则不会输出:12345678910[grid@orl6:/home/grid]$ kfed read aun=0 aus=1048576 blkn=0 dev=/dev/asmdisk1 text=/tmp/kfed.txt[grid@orl6:/home/grid]$ more /tmp/kfed.txt kfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 1 ; 0x002: KFBTYP_DISKHEADkfbh.datfmt: 1 ; 0x003: 0x01kfbh.block.blk: 0 ; 0x004: blk=0kfbh.block.obj: 2147483648 ; 0x008: disk=0kfbh.check: 3459712326 ; 0x00c: 0xce370546... 3.2 kfed备份修复ASM磁盘kred中可以看出部分基本信息，比如kfbh.type为KFBTYP_DISKHEAD表示这个块是file header，kfdhdb.secsize,kfdhdb.blksize,kfdhdb.ausize分别表示sector size，block size和AU size。本例中AU大小为1M，块大小为4096，即4K。因此，每个AU最多有1m/4k = 256个块。 #####备份磁盘信息手动备份磁盘头信息可采用kfed或者dd：12[grid@orl6:/home/grid]$ kfed read /dev/asmdisk1 aun=0 blkn=0 text=./au1.header[grid@orl6:/home/grid]$ dd if=/dev/asmdisk1 of=./au1_bak.header bs=4096 count=1 模拟破坏磁盘头1[grid@orl6:/home/grid]$ dd if=/dev/zero of=/dev/asmdisk1 bs=4096 count=1 用kfed read查看此块(au0 block 0)：123456789101112131415[grid@orl6:/home/grid]$ kfed read aun=0 blkn=0 dev=/dev/asmdisk1 |morekfbh.endian: 0 ; 0x000: 0x00kfbh.hard: 0 ; 0x001: 0x00kfbh.type: 0 ; 0x002: KFBTYP_INVALIDkfbh.datfmt: 0 ; 0x003: 0x00kfbh.block.blk: 0 ; 0x004: blk=0kfbh.block.obj: 0 ; 0x008: file=0kfbh.check: 0 ; 0x00c: 0x00000000kfbh.fcn.base: 0 ; 0x010: 0x00000000kfbh.fcn.wrap: 0 ; 0x014: 0x00000000kfbh.spare1: 0 ; 0x018: 0x00000000kfbh.spare2: 0 ; 0x01c: 0x000000007F5687C67400 00000000 00000000 00000000 00000000 [................] Repeat 255 timesKFED-00322: Invalid content encountered during block traversal: [kfbtTraverseBlock][Invalid OSM block type][][0] 已经报错了，同时，kfbh.type也变成了KFBTYP_INVALID。进行修复动作：1234567891011121314[grid@orl6:/home/grid]$ kfed repair /dev/asmdisk1[grid@orl6:/home/grid]$ kfed read aun=0 blkn=0 dev=/dev/asmdisk1 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 1 ; 0x002: KFBTYP_DISKHEADkfbh.datfmt: 1 ; 0x003: 0x01kfbh.block.blk: 0 ; 0x004: blk=0kfbh.block.obj: 2147483648 ; 0x008: disk=0kfbh.check: 3459712326 ; 0x00c: 0xce370546kfbh.fcn.base: 7316 ; 0x010: 0x00001c94kfbh.fcn.wrap: 0 ; 0x014: 0x00000000kfbh.spare1: 0 ; 0x018: 0x00000000kfbh.spare2: 0 ; 0x01c: 0x00000000kfdhdb.driver.provstr: ORCLDISK ; 0x000: length=8 通过kfed repair，kfbh.type已经变成KFBTYP_DISKHEAD,说明此block恢复正常了。采用kfed write进行修复：12345678910111213[grid@orl6:/home/grid]$ dd if=/dev/zero of=/dev/asmdisk1 bs=4096 count=11+0 records in1+0 records out4096 bytes (4.1 kB) copied, 0.00122345 s, 3.3 MB/s[grid@orl6:/home/grid]$ kfed read aun=0 blkn=0 dev=/dev/asmdisk1 |morekfbh.endian: 0 ; 0x000: 0x00kfbh.hard: 0 ; 0x001: 0x00kfbh.type: 0 ; 0x002: KFBTYP_INVALID[grid@orl6:/home/grid]$ kfed write aun=0 blkn=0 dev=/dev/asmdisk1 text=./au1.header chksum=yes[grid@orl6:/home/grid]$ kfed read aun=0 blkn=0 dev=/dev/asmdisk1 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 1 ; 0x002: KFBTYP_DISKHEAD 采用dd进行修复：12345678[grid@orl6:/home/grid]$ dd if=./au1_bak.header bs=4096 count=1 of=/dev/asmdisk1 bs=4096 count=11+0 records in1+0 records out4096 bytes (4.1 kB) copied, 0.00149188 s, 2.7 MB/s[grid@orl6:/home/grid]$ kfed read aun=0 blkn=0 dev=/dev/asmdisk1 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 1 ; 0x002: KFBTYP_DISKHEAD 需要注意的是，kfed repair仅能修复au0，后面的au，repair无效。请看下例：12345--以AU1为例，破坏前先备份此AU数据。[grid@orl6:/home/grid]$ dd if=/dev/asmdisk1 of=./au1_bak bs=4096 count=1 seek=510[grid@orl6:/home/grid]$ kfed read /dev/asmdisk1 aun=1 blkn=254 text=au1.bak--开始破坏[grid@orl6:/home/grid]$ dd if=/dev/zero of=/dev/asmdisk1 bs=4096 count=1 seek=510 确认此block状态1234[grid@orl6:/home/grid]$ kfed read /dev/asmdisk1 aun=1 blkn=254 |morekfbh.endian: 0 ; 0x000: 0x00kfbh.hard: 0 ; 0x001: 0x00kfbh.type: 0 ; 0x002: KFBTYP_INVALID 尝试使用repair修复：12[grid@orl6:/home/grid]$ kfed repair /dev/asmdisk1 KFED-00320: Invalid block num1 = [0], num2 = [1], error = [endian_kfbh] 尝试用dd修复：1[grid@orl6:/home/grid]$ dd if=./au1_bak of=/dev/asmdisk1 bs=4096 count=1 seek=510 查看修复结果：1234[grid@orl6:/home/grid]$ kfed read /dev/asmdisk1 aun=1 blkn=254 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 1 ; 0x002: KFBTYP_DISKHEAD 此外，还可以使用kfed write进行修复，和dd修复差不多，都要有之前的备份信息。123456--备份kfed read /dev/asmdisk1 aun=1 blkn=254 text=./au1.text--破坏dd if=/dev/zero of=/dev/asmdisk1 bs=4096 count=1 seek=510--修复kfed write aun=1 blkn=254 dev=/dev/asmdisk1 text=./au1.text chksum=yes 3.3 ASM磁盘头的自动备份对于ASM disk Header，在版本11.1.0.7以后，Oracle会自动备份一个相同的disk Header到AU1上倒数第二个块上，块的位置根据AU的大小不同而异，这个Block Number的计算可以参照以下脚本(由于ASM的默认块大小为4K，因此在1M的AU中，1024K/4K=256个block，从0开始计算，倒数第二个即为254)。在10.2.0.5版本中，ASM disk header的自动备份也已经开始存储，11gr2和10.2.0.5的备份有些许的区别，10.2.0.5中，block 0和block 254是完全一致的，包括block Number，而在11gr2中，block Number是不一致的，且Checksum值在11gr2中也是不相同的。在恢复的时候或许有点区别。12345678[grid@orl6:/home/grid]$ cat asm_dsk_hdr_bk.sh #!/bin/bashecho -n &quot;Enter the value of ASM Disk:&quot;read ASM_DISKausize=`kfed read $ASM_DISK | grep ausize | tr -s &apos; &apos; | cut -d&apos; &apos; -f2`blksize=`kfed read $ASM_DISK | grep blksize | tr -s &apos; &apos; | cut -d&apos; &apos; -f2`let n=$ausize/$blksize-2echo &quot;ASM Disk Header is in Block:$n&quot; 10.2.0.5 ASM Disk Header自动备份12345678910111213141516[oracle@ora10g:/home/oracle/asm]$ ./asm_hdr_blk.sh Enter the value of ASM Disk:/dev/oracleasm/disks/DATA1The NO. of ASM Header Block is:254[oracle@ora10g:/home/oracle/asm]$ kfed read aun=1 blkn=254 dev=/dev/oracleasm/disks/DATA1 \\text=./orig_block.txt[oracle@ora10g:/home/oracle/asm]$ kfed read aun=0 blkn=0 dev=/dev/oracleasm/disks/DATA1 \\text=./orig_block.txt[oracle@ora10g:/home/oracle/asm]$ diff orig_block.txt bak_block.txt [oracle@ora10g:/home/oracle/asm]$ more bak_block.txt kfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 1 ; 0x002: KFBTYP_DISKHEADkfbh.datfmt: 1 ; 0x003: 0x01kfbh.block.blk: 0 ; 0x004: T=0 NUMB=0x0--哪怕是备份的块，其块号和原始块号都是一样的kfbh.block.obj: 2147483648 ; 0x008: TYPE=0x8 NUMB=0x0kfbh.check: 880638603 ; 0x00c: 0x347d7a8b --用于块一致性检查的校验和也相同 11gr2 ASM Disk Header自动备份1234567891011[grid@orl6:/home/grid]$ kfed read aun=0 blkn=0 dev=/dev/asmdisk1 text=./orgi_blk[grid@orl6:/home/grid]$ kfed read aun=1 blkn=254 dev=/dev/asmdisk1 text=./bak_blk[grid@orl6:/home/grid]$ diff orgi_blk bak_blk 5c5&lt; kfbh.block.blk: 0 ; 0x004: blk=0---&gt; kfbh.block.blk: 254 ; 0x004: blk=2547c7&lt; kfbh.check: 1002445176 ; 0x00c: 0x3bc01978---&gt; kfbh.check: 1002445190 ; 0x00c: 0x3bc01986 可以看到，在11gr2中，上述两个地方都是不相同的。因此，在AU1上的第254个Block将会是Au0，Block 0的备份，两个块的内容基本是相同的。在ASM实例上，可用以下命令检测DG的disk header备份信息是否一致,检查结果会出现在alert.log里面：123456SQL&gt; alter diskgroup data1 check NOTE: starting check of diskgroup DATA1Thu Jun 25 12:22:08 2015GMON checking disk 0 for group 1 at 9 for pid 17, osid 22337SUCCESS: check of diskgroup DATA1 found no errorsSUCCESS: alter diskgroup data1 check 注意:AU1最后一个block是磁盘心跳：12345678910111213141516171819[grid@orl6:/home/grid]$ kfed read aun=1 blkn=255 dev=/dev/asmdisk1 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 19 ; 0x002: KFBTYP_HBEATkfbh.datfmt: 2 ; 0x003: 0x02kfbh.block.blk: 511 ; 0x004: blk=511kfbh.block.obj: 2147483648 ; 0x008: disk=0kfbh.check: 2462310944 ; 0x00c: 0x92c3e220kfbh.fcn.base: 0 ; 0x010: 0x00000000kfbh.fcn.wrap: 0 ; 0x014: 0x00000000kfbh.spare1: 0 ; 0x018: 0x00000000kfbh.spare2: 0 ; 0x01c: 0x00000000kfdpHbeatB.instance: 1 ; 0x000: 0x00000001kfdpHbeatB.ts.hi: 33020716 ; 0x004: HOUR=0xc DAYS=0x19 MNTH=0x6 YEAR=0x7dfkfdpHbeatB.ts.lo: 1435727872 ; 0x008: USEC=0x0 MSEC=0xde SECS=0x19 MINS=0x15kfdpHbeatB.rnd[0]: 148639519 ; 0x00c: 0x08dc0f1fkfdpHbeatB.rnd[1]: 4128301322 ; 0x010: 0xf610e10akfdpHbeatB.rnd[2]: 1569681180 ; 0x014: 0x5d8f6f1ckfdpHbeatB.rnd[3]: 3891741690 ; 0x018: 0xe7f743fa 4. AMDU--ASM Metadata Dump UtilityAMDU在磁盘组无法挂载的时候，是一个很好的抽取数据攻击。磁盘组是否mounted跟amdu并没有关系，amdu可以处理dismounted状态的磁盘组。其主要功能是从ASM disk中抽取metadata。这个工具是11g以后的，10g如果要用到可以到MOS上去下载。AMDU的用法帮助可以使用amdu help=y查看。amdu可以查看磁盘组详细的信息，如：1[grid@orl6:/home/grid]$ amdu -diskstring &apos;/dev/asm*&apos; -dump &apos;DATA1&apos; 下面模拟ASM磁盘组无法挂载的情况下抽取ASM里面相关的文件，如数据文件、控制文件，甚至参数文件。在上述的条件下，我们首先要确认各种文件的file number，这些文件的file number及alias都是存储ASM中，因此，首先要确认ASM Alias在哪个AU，而指向alias 所在的AU为file directory。而在ASM AU分布中，AU0和AU1为physical metadata，ASM的File directory在AU2，block 6上，首先通过file directory找出alias所在AU。1234567[grid@orl6:/home/grid]$ kfed read aun=2 blkn=6 dev=/dev/asmdisk1 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 4 ; 0x002: KFBTYP_FILEDIR...kfffde[0].xptr.au: 48 ; 0x4a0: 0x00000030.. xptr.au即alias directory所在的au,从blkn=0开始查找，本例中：12345678910111213141516171819202122232425262728293031323334353637383940#spfile的file number[grid@orl6:/home/grid]$ kfed read aun=48 blkn=3 dev=/dev/asmdisk1 |morekfade[5].name: spfilekyun.ora ; 0x1b0: length=14 kfade[5].fnum: 266 ; 0x1e0: 0x0000010a #controlfile的file number[grid@orl6:/home/grid]$ kfed read aun=48 blkn=4 dev=/dev/asmdisk1 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 11 ; 0x002: KFBTYP_ALIASDIR......kfade[0].name: Current ; 0x034: length=7kfade[0].fnum: 256 ; 0x064: 0x00000100 ...#online redo log的file number[grid@orl6:/home/grid]$ kfed read aun=48 blkn=5 dev=/dev/asmdisk1 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 11 ; 0x002: KFBTYP_ALIASDIR...kfade[0].name: group_1 ; 0x034: length=7kfade[0].fnum: 257 ; 0x064: 0x00000101...kfade[1].name: group_2 ; 0x080: length=7kfade[1].fnum: 258 ; 0x0b0: 0x00000102...kfade[2].name: group_3 ; 0x0cc: length=7kfade[2].fnum: 259 ; 0x0fc: 0x00000103 --online redo log的file number...#Tablespace的file number[grid@orl6:/home/grid]$ kfed read aun=48 blkn=6 dev=/dev/asmdisk1 |morekfbh.endian: 1 ; 0x000: 0x01kfbh.hard: 130 ; 0x001: 0x82kfbh.type: 11 ; 0x002: KFBTYP_ALIASDIR...kfade[0].name: SYSTEM ; 0x034: length=6kfade[0].fnum: 260 ; 0x064: 0x00000104...kfade[1].name: SYSAUX ; 0x080: length=6kfade[1].fnum: 261 ; 0x0b0: 0x00000105... 通过kfed得到file number，然后使用amdu进行抽取即可。在实际环境中，spfile和control file的file number其实是可以通过alert日志得到相关的信息的，有了control file，即可以读取datafile，从v$datafile中可以获取datafile的file number。12345678910111213141516171819202122232425262728#使用amdu抽取spfile[grid@orl6:/home/grid]$ amdu -diskstring=&apos;/dev/asmdisk1&apos; -extract DATA1.266 -nodir -noreport -output kyun.spfile.266[grid@orl6:/home/grid]$ strings kyun.spfile.266 kyun.__db_cache_size=364904448kyun.__java_pool_size=4194304kyun.__large_pool_size=8388608kyun.__oracle_base=&apos;/u01/app/oracle&apos;#ORACLE_BASE set from environmentkyun.__pga_aggregate_target=322961408kyun.__sga_target=515899392kyun.__shared_io_pool_size=0kyun.__shared_pool_size=130023424kyun.__streams_pool_size=0*.audit_file_dest=&apos;/u01/app/oracle/admin/kyun/adump&apos;*.audit_trail=&apos;db&apos;*.compatible=&apos;11.2.0.4.0&apos;*.control_files=&apos;+DATA1/kyun/controlfile/current.256.858438947&apos;*.db_block_size=8192*.db_create_file_dest=&apos;+DATA1&apos;*.db_domain=&apos;&apos;*.db_name=&apos;kyun&apos;*.diagnostic_dest=&apos;/u01/app/oracle&apos;*.dispatchers=&apos;(PROTOCOL=TCP) (SERVICE=kyunXDB)&apos;*.log_archive_dest_1=&apos;location=+DATA1/kyun/arch&apos;*.memory_target=838860800*.open_cursors=300*.processes=150*.remote_login_passwordfile=&apos;EXCLUSIVE&apos;*.undo_tablespace=&apos;UNDOTBS1&apos; 修改control_files路径，启动数据库至mount状态，查询数据文件，同样抽取出数据文件，通过rename或者重建控制文件即可把库拉起来。 123456789101112131415161718192021222324252627[grid@orl6:/home/grid]$ amdu -dis=&apos;/dev/asm*&apos; -extract DATA1.267 -nodir -noreport -output fung.267.dbf[grid@orl6:/home/grid]$ dbvdbv dbvO [grid@orl6:/home/grid]$ dbv file=fung.267.dbf DBVERIFY: Release 11.2.0.4.0 - Production on Thu Jun 25 13:14:43 2015Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.DBVERIFY - Verification starting : FILE = /home/grid/fung.267.dbfDBVERIFY - Verification completeTotal Pages Examined : 37376Total Pages Processed (Data) : 24705Total Pages Failing (Data) : 0Total Pages Processed (Index): 5545Total Pages Failing (Index): 0Total Pages Processed (Other): 771Total Pages Processed (Seg) : 0Total Pages Failing (Seg) : 0Total Pages Empty : 6355Total Pages Marked Corrupt : 0Total Pages Influx : 0Total Pages Encrypted : 0Highest block SCN : 748761 (0.748761) Reference:ID 1485597.1 EOF","link":"/asm-utilities.html"},{"title":"[shell学习笔记]awk基础1","text":"awk是一种用于处理数据和生成报告的UNIX编程语言。nawk是awk的新版本，gawk是基于Linux的GNU版本。 awk 以逐行方式扫描文件，从第一行到最后一行，以查找匹配某个特定模式的问本行，并对这些文本执行(括号在花括号中的)指定动作。如果只给出模式而未指定动作，则所有该匹配的模式的行都显示在屏幕上；如果只指定动作而未定义模式，会对所有输入行指定指定动作。 1.awk格式 以下面这个文本为例，简单说明awk的用法。 1234567[root@linora shell]# cat employee Tom Jones 4424 5/12/66 54335 Mary Adams 5346 11/4/63 28765 Sally Chang 1654 7/22/54 65000 Billy Black 1683 9/23/44 33650 [root@linora shell]# awk &apos;/Tom/&apos; employee Tom Jones 4424 5/12/66 54335 说明： 打印含有模式Tom的行。 12345[root@linora shell]# awk &apos;&#123;print $1&#125;&apos; employee Tom Mary Sally Billy 说明： 打印文件第一个字段，字段从行的左端开始，以空白符分隔。如果需要自定义分隔符，则需加上-F的参数。 12[root@linora shell]# awk &apos;/Tom/&#123;print $1,$2&#125;&apos; employee Tom Jones 说明： 打印含有模式Tom的第一个和第二个字段。注意，字段中间有逗号分隔，它在awk中映射为一个内部变量，称为输出字段分隔符(output field separator)，OFS默认为空格，逗号被OFS变量中存储的字符替换。 123[root@linora shell]# df |awk &apos;$4&gt;10240000&apos; Filesystem 1K-blocks Used Available Use% Mounted on /dev/sda3 28337624 14901832 11973076 56% / 说明： df为文件系统磁盘剩余空间报告。df命令的输出通过pipe发给awk，如果其中某行的第四个字段大于10G，则该行被打印。 12[root@linora shell]# w |awk &apos;/^oracle/&#123;print $3&#125;&apos; 192.168.56.1 说明： w命令是Linux下查看有哪些用户登录做了哪些事情的命令。通过pipe将w的输出命令传给awk，如果w结果含有以oracle开头的行，则打印其第三个字段，即查找以oracle用户登录的IP地址。 2.格式化输出 2.1.print函数 awk命令的操作部分被括在大括号重化工。print函数用于打印不需要特别编排格式简单输出。更为复杂的格式编排则要使用printf或sprintf函数。 在awk命令中，可以用{print}形式显式地调用print函数。其参数可以是变量、数值或字符串常量。字符串必须用双引号括起来。参数之间用逗号分隔，逗号等价于OFS中的值，默认情况下是空格。如果没有逗号分隔，那么所有参数将会被串在一起。 12345[root@linora shell]# date Thu Sep 26 23:41:52 CST 2013 [root@linora shell]# date |awk &apos;&#123;print &quot;Month:&quot;,$2 &quot;\\nYear:&quot;,$6&#125;&apos; Month: Sep Year: 2013 上例中的“\\n”为转义字符，见下表。 表2-1 print函数使用的转义序列 转义序列 含义 \\b 退格 \\f 换页 \\n 换行 \\r 回车 \\t 制表符，即tab键 \\047 八进制值47，即单引号 \\c c代表任一其他字符，如“\\” 12[root@linora shell]# awk &apos;/Tom/&#123;print &quot;\\t\\tHave a nice day,&quot; $1,$2 &quot;!!!&quot;&#125;&apos; employee Have a nice day,Tom Jones!!! 2.2.printf函数 打印输出时，可能需要指定字段间的空格数，从而把列排整齐。在print函数中使用制表符并不能保证得到想要的输出，因此可用printf来格式化特别输出。 printf函数返回一个带格式的字符串给标准输出，其语句包括一个加引号的控制串，控制串中可能嵌有若干格式说明和修饰符。控制串后面跟一个逗号，之后是一列由逗号分隔的表达式。printf函数根据控制串中的说明编排这些表达式的格式，但printf不会在行尾自动换行，需要在控制串中提供转义字符\\n。 表2-2 printf使用的转义字符 转义字符 定义 c 字符 s 字符串 d 十进制整数 ld 十进制长整数 u 十进制无符号整数 lu 十进制无符号长整数 x 十六进制整数 lx 十六进制长整数 o 八进制整数 lo 八进制长整数 e 用科学计数法表示的浮点数 f 浮点数 g 选用e或者f中较短的一种形式 表2-3 printf的修饰符 字符 定义 - 左对齐修饰符 # 显示8进制整数时在前面加个0显示16进制整数时在前面加0x + 显示使用d、e、f、和g转换的整数时，加上正负号 0 用0而不是空白符来填充所显示的值 表2-4 printf的格式说明符 格式说明符 功能 假定x=’A’、y=15、z=2.3且$1=Bob Smith %c printf(\"The character is %c\\n\",x)output:The character is A %d printf(\"The boy is %d years old!\\n\",y)output: The boy is 15 years old! %e [root@linora shell]# echo \"2.3\" |awk '{printf(\"z is %e\\n\",$1)}'z is 2.300000e+00 %f [root@linora shell]# echo \"2.3\" |awk '{printf(\"z is %f\\n\",$1)}'z is 2.300000 %o [root@linora shell]# echo \"15\" |awk '{printf(\"z is %o\\n\",$1)}'z is 17 %s printf(\"His name is %s\\n\",$1)打印字符串:His name is Bob smith %x [root@linora shell]# echo \"15\" |awk '{printf(\"y is %x\\n\",$1)}'y is f 下面这个例子中，printf控制串里的pipe字符是文本的一部分，用于指示格式的开始与结束。 1234[root@linora shell]# echo &quot;UNIX&quot;|awk &apos;&#123;printf &quot;|%-15s|\\n&quot;,$1&#125;&apos; |UNIX | [root@linora shell]# echo &quot;UNIX&quot;|awk &apos;&#123;printf &quot;|%15s|\\n&quot;,$1&#125;&apos; | UNIX| 通过以上输出控制，可以控制文本靠左靠右对齐，百分号让printf做好准备，它要打印一个占15格，向左对其的字符串，这个字符串夹在两个pipe符号间，并且以换行符结尾。百分号后的减号表示左对齐。无减号表示右对齐。 12345[root@linora shell]# awk &apos;&#123;printf &quot;The name is:%-15s ID is %8d\\n&quot;,$1,$3&#125;&apos; employee The name is:Tom ID is 4424 The name is:Mary ID is 5346 The name is:Sally ID is 1654 The name is:Billy ID is 1683 上例中，要打印的字符放置在两个引号之间。第一个格式说明符是%-15s，它对应的参数是$1。格式%8d表示在字符串的这个位置打印$3的十进制值。这个整数占8格，向右对齐。也可以将加引号的字符串和表达式放在圆括号内。 1awk &apos;&#123;printf (&quot;The name is:%-15s ID is %8d\\n&quot;,$1,$3)&#125;&apos; employee 2.3.记录与字段 awk在默认情况下，每一行称为一条记录，以换行符结束，输入和输出的分隔符都是换行符，分别保存在awk的内置变量ORS和RS中。同时awk用$0代表整条记录，变量NR保存每条记录的记录号，每处理完一条记录NR自动加1. 12345[root@linora shell]# awk &apos;&#123;print NR,$0&#125;&apos; employee 1 Tom Jones 4424 5/12/66 54335 2 Mary Adams 5346 11/4/63 28765 3 Sally Chang 1654 7/22/54 65000 4 Billy Black 1683 9/23/44 33650 每条记录都是由称为字段的词组成，字段由美元符号和字段编号做标记。默认情况下，字段间用空白符(空格或者制表符)分隔。每条记录的字段值保存在内置变量NF中，NF的值因行而异。 12345[root@linora shell]# awk &apos;&#123;print NR,$1,$2,$3,NF&#125;&apos; employee 1 Tom Jones 4424 5 2 Mary Adams 5346 5 3 Sally Chang 1654 5 4 Billy Black 1683 5 awk的内置变量FS中保存了输入字段分隔符的值。默认用空格或者制表符，并且删除各字段前多于的空格或制表符。同时，可以使用-F参数修改FS值。 1234[root@linora shell]# awk &apos;/oracle/&#123;print $1&#125;&apos; /etc/passwd oracle:x:500:500::/home/oracle:/bin/bash [root@linora shell]# awk -F: &apos;/oracle/&#123;print $1,$2,$3&#125;&apos; /etc/passwd oracle x 500 上例中，使用-F参数，后面紧跟冒号来取代默认的输入分隔符。 我们也可以指定多个输入字段分隔符，如果有多个字符被用于字段分隔符FS，则FS对应是一个正则表达式字符串，并且被括在方括号内。下面的例子中(注意冒号前有空格)，FS的值是空格，冒号或者制表符。 1234[root@linora shell]# sed -n &apos;/Tom/p&apos; employee2 Tom Jones:4424:5/12/66:54335 [root@linora shell]# awk -F&apos;[ :\\t]&apos; &apos;/Tom/&#123;print $1,$2,$3&#125;&apos; employee2 Tom Jones 4424 输出分隔符被保存在内置变量OFS中，默认都是单个空格。如果需要修改OFS值，可以参照以下例子。但无论OFS如何设置，print语句中用于分隔字段的逗号，在输出时候都被转换成OFS的值。 12[root@linora shell]# awk -F: &apos;BEGIN &#123;OFS=&quot;:&quot;&#125;/oracle/&#123;print $1,$2,$3&#125;&apos; /etc/passwd oracle:x:500 3.awk内置变量 表2-5 awk内置变量 变量 描述 变量 描述 $n 当前记录的第n个字段，字段间由FS分隔 FIELDWIDTHS 字段宽度列表 $0 完整的输入记录 ARGC 命令行参数的数目 ARGIND 命令行当前的文件的位置 ARGV 包含命令行参数的数组 CONVFMT 数字转换格式，默认为%.6g ENVIRON 环境变量关联数组 ERRNO 最后一个系统错误的描述 FILENAME 当前文件名 FNR 同NR，但相对于当前文件 FS 输入字段分隔符 NF 当前记录的字段数 IGNORECASE 如果为真，则忽略大小写 NR 当前记录数 OFMT 数字的输出格式，默认%.6g OFS 输出字段分隔符 ORS 输出记录分隔符 RLENGTH 由match函数所匹配的字符串长度 RSTART 由match函数所匹配的字符串的第一个位置 RS 输入记录分隔符 SUBSEP 数组下标分隔符 4.模式与操作 awk模式用来控制对输入的文本行执行什么操作。模式由正则表达式、判别条件真伪的表达式或者两者的组合构成。awk默认操作是打印所有表达式为真的文本行。如果模式表达式含有if的意思，就不必用花括号把它括起来。 12[root@linora shell]# awk &apos;/Tom/&apos; employee Tom Jones 4424 5/12/66 54335 操作(action)是花括号中以分号分隔的语句。如果操作前面有个模式，则该模式控制执行操作的时间。同一行的多条语句由分号分隔，独占一行的语句则以换行符分隔。 5.正则表达式 对awk而言，正则表达式是置于两个斜杠之间、由字符组组成的模式。Awk支持使用(与egrep相同的)正则表达式元字符对正则表达式进行某种方式的修改。如果输入行中的某个字符串与正则表达式相匹配，则最终条件为真，于是执行与该表达式关联的所有操作，如果没有指定操作，则打印与正则表达式匹配的记录。 表2-6 awk的正则表达式元字符 元字符 说明 ^ 在串首匹配 $ 在串尾匹配 . 匹配任意单个字符 * 匹配零个或者多个前导字符 + 匹配一个或者多个前导字符 ? 匹配零个或者一个前导字符 [ABC] 匹配指定字符组中任意一个字符 [^ABC] 匹配任何一个不在指定字符组内的字符 [A-Z] 匹配A-Z之间的任一字符 A|B 匹配A或者B (AB)+ 匹配一个或者多个AB组合，即AB、ABAB等 \\* 匹配星号本身 &amp; 用在替代串中，代表查找传中匹配到的内容 表2-7列出的元字符，大多数版本的grep和sed都支持，但是任何版本的awk都不支持。对于POSIX支持的括号类正则表达式，除了gawk支持外，awk及nawk均不支持。 表2-7 awk不支持的元字符 元字符 说明 \\&lt;\\&gt; 单词定位 \\(\\) 向前引用 \\{\\} 重复 匹配操作符(~)用于对记录或字段的表达式进行匹配。下例中，表示显示所有在第一个字段里匹配到Tom或者tom的行。 12[root@linora shell]# awk &apos;$1 ~ /[tT]om/&apos; employee Tom Jones 4424 5/12/66 54335 下面这个例子中，显示所有不是以ly结尾的行。 123[root@linora shell]# awk &apos;$1 !~ /ly$/&apos; employee Tom Jones 4424 5/12/66 54335 Mary Adams 5346 11/4/63 28765 6.awk脚本范例 在awk脚本中，如果同一行中有多条语句或操作，必须用分号将它们分隔开。如果每条语句都在不同的行上，就不需要分号分开。如果操作跟在某个模式后面，它的左花括号就必须与该模式位于同一行，注释以#开头。 123456789[root@linora shell]# cat awkfile #My first awk script /Tom/&#123;print &quot;Tom&apos;s birthday is &quot;$3&#125; /Mary/&#123;print NR, $0&#125; /^Sally/&#123;print &quot;Hi,Sally. &quot; $1 &quot; has a salary of $&quot; $4 &quot;.&quot;&#125; [root@linora shell]# awk -F: -f awkfile employee2 Tom&apos;s birthday is 5/12/66 2 Mary Adams:5346:11/4/63:28765 Hi,Sally. Sally Chang has a salary of $65000. 第一行以#开头，表示是注释。 第二行表示查找模式含有Tom的行，并且通过print函数打印”Tom’s birthday is”和该行的第三个字段的值。 第三行，查找含有模式Mary的行，打印整行，并且加上记录号。 第四行，查找以Sally开头的行，依次打印”Hi Sally.”、该行第一个字段值、字符串”has a salary of $”和该行第四个字段的值。 Write an awk script called facts that a.Prints full names and phone numbers for the Savages. b.Prints Chet's contributions. c.Prints all those who contributed $250 the first month. 答案(为了方便，作了个简单排序)： 12345678910111213141516[root@linora shell]# cat facts $2 ~ /Savage/&#123;print &quot;1st request: &quot; $1,$2,$3,$4&#125; /Chet/&#123;print &quot;2nd request: &quot; $5,$6,$7&#125; $5 ~ /^250$/&#123;print &quot;3rd request: &quot; $1,$2&#125; [root@linora shell]# awk -F&quot;[ :]&quot; -f facts lab3.data |sort -n 1st request: Dan Savage (406) 298-7744 1st request: Jody Savage (206) 548-1278 1st request: Tom Savage (408) 926-3456 2nd request: 50 95 135 3rd request: Archie McNichol 3rd request: Guy Quigley 3rd request: John Goldenrod 3rd request: Mike Harrington 3rd request: Nancy McNeil 3rd request: Susan Dalsass 3rd request: Tom Savage EOF","link":"/awk_fundamental1.html"},{"title":"BBED Demo","text":"BBED功能有限，对很多类型的数据块都不支持。BBED虽然支持在open状态下修改数据块，但建议先干净的关闭数据库在进行BBED修改。正常关闭数据库能避开检查点进程覆盖掉bbed修改的块缓存。 1. 修改数据12345FUNG@linora&gt; select * from test;ID NAME---------- --------------------002 Kong001 Fung 假设修改id=002的name为kyun。首先确定id=2所在的dba：12345678910SYS@linora&gt; SELECT DBMS_ROWID.ROWID_RELATIVE_FNO(rowid) &quot;FILE&quot;, 2 DBMS_ROWID.ROWID_BLOCK_NUMBER(rowid) &quot;BLOCK&quot;, 3 DBMS_ROWID.ROWID_ROW_NUMBER(rowid) &quot;ROW&quot;, 4 id,name 5 FROM fung.test; FILE BLOCK ROW ID NAME---------- ---------- ---------- ---------- -------------------- 5 212 0 002 Kyun 5 213 0 001 Fung 首先定位数据所在dba1234567891011121314151617BBED&gt; set dba 5,212 DBA 0x014000d4 (20971732 5,212)BBED&gt; find /c Kong File: /oradata/datafile/linora/fung01.dbf (5) Block: 212 Offsets: 8174 to 8191 Dba:0x014000d4------------------------------------------------------------------------ 4b6f6e67 2c000201 32044b6f 6e670106 7319 &lt;32 bytes per line&gt;BBED&gt; d /v dba 5,212 offset 8174 count 64 File: /oradata/datafile/linora/fung01.dbf (5) Block: 212 Offsets: 8174 to 8191 Dba:0x014000d4------------------------------------------------------- 4b6f6e67 2c000201 32044b6f 6e670106 l Kong,...2.Kong.. 7319 l s. &lt;16 bytes per line&gt; 开始修改数据:12345678910111213141516BBED&gt; m /c kyun dba 5,212 offset 8174Warning: contents of previous BIFILE will be lost. Proceed? (Y/N) y File: /oradata/datafile/linora/fung01.dbf (5) Block: 212 Offsets: 8173 to 8191 Dba:0x014000d4------------------------------------------------------------------------ 6b79756e 672c0002 0132044b 6f6e6701 067319 &lt;32 bytes per line&gt;BBED&gt; d /v File: /oradata/datafile/linora/fung01.dbf (5) Block: 212 Offsets: 8174 to 8191 Dba:0x014000d4------------------------------------------------------- 6b79756e 2c000201 32044b6f 6e670106 l kyun,...2.Kong.. 7119 l q. &lt;16 bytes per line&gt; 此时数据库级别是看不到的，需要sum验证一下，同时刷新库缓存：12345678910BBED&gt; sum applyCheck value for File 5, Block 212:current = 0x04bb, required = 0x04bbSYS@linora&gt; alter system flush buffer_cache;System altered.SYS@linora&gt; select * from fung.test;ID NAME---------- --------------------002 Kyun001 Fung 2. 找回删除的数据在Oracle中，delete操作并不是真正删除了该行数据，而是将被删除的行标记为删除状态，12345678SYS@linora&gt; alter system dump datafile 5 block 212;System altered.--dump trace内容block_row_dump:tab 0, row 0, @0x1f82tl: 12 fb: --H-FL-- lb: 0x0 cc: 2col 0: [ 3] 30 30 32col 1: [ 4] 4b 79 75 6e 删除表中数据：123456789101112SYS@linora&gt; delete from fung.test;2 rows deleted.SYS@linora&gt; commit;Commit complete.SYS@linora&gt; alter system flush buffer_cache;System altered.SYS@linora&gt; alter system dump datafile 5 block 212;System altered.--dump trace内容block_row_dump:tab 0, row 0, @0x1f82tl: 2 fb: --HDFL-- lb: 0x1 由两次的dump文件内容可以看到，被删除了的数据会在fb栏位添加一个D的标识符。如果一个row 没有被删除，那么它就具有上面的3个属性，即Flag 表示为：--H-FL--. 这里的字母分别代表属性的首字母。其对应的值：32 + 8 + 4 =44 or 0x2c。如果一个row 被delete了，那么row flag 就会更新，bitmask 里的deleted 被设置为16. 此时row flag 为： 32 + 16 + 8 + 4 = 60 or 0x3c。如果需要将被删除的数据找回来，只需要修改3c为2c即可：123456789101112131415161718192021BBED&gt; set dba 5,212 DBA 0x014000d4 (20971732 5,212)--查看此块包含几行记录BBED&gt; map File: /oradata/datafile/linora/fung01.dbf (5) Block: 212 Dba:0x014000d4------------------------------------------------------------ KTB Data Block (Table/Cluster) struct kcbh, 20 bytes @0 struct ktbbh, 72 bytes @20 struct kdbh, 14 bytes @100 struct kdbt[1], 4 bytes @114 --只有一行数据 sb2 kdbr[1] @118 ub1 freespace[8046] @120 ub1 rowdata[22] @8166 ub4 tailchk @8188 BBED&gt; p *kdbr[0]rowdata[0]----------ub1 rowdata[0] @8166 0x3c 修改offset 8166中的3c为2c，然后验证被删除的数据是否有被找回：12345678910111213141516BBED&gt; m /x 2c dba 5,212 offset 8166Warning: contents of previous BIFILE will be lost. Proceed? (Y/N) y File: /oradata/datafile/linora/fung01.dbf (5) Block: 212 Offsets: 8166 to 8191 Dba:0x014000d4------------------------------------------------------------------------ 2c010203 30303204 4b79756e 2c000201 32044b6f 6e670106 ade7 &lt;32 bytes per line&gt;BBED&gt; sum applyCheck value for File 5, Block 212:current = 0x5f63, required = 0x5f63SYS@linora&gt; alter system flush buffer_cache;System altered.SYS@linora&gt; select * from fung.test;ID NAME---------- --------------------002 Kyun 3. 归档缺失的情况下增进文件头SCN在数据文件恢复的时候，如果缺失部分归档日志，此时数据文件因为SCN值跟控制文件记录的SCN不一致，而导致无法Online，我们可以通过BBED修改文件头的SCN值去人为的控制，但会丢失部分数据。下面模拟删除一个数据文件，同时删除所有归档，然后recovery，但由于缺少归档，recovery肯定会失败，此时可以使用BBED修改文件头SCN进行人为的同步。1234567891011121314151617[oracle@linora:/oradata/arch]$ rm -rf /oradata/datafile/linora/test01.dbfSYS@linora&gt; startup forceRMAN&gt; restore datafile &apos;/oradata/datafile/linora/test01.dbf&apos;; RMAN&gt; recover datafile &apos;/oradata/datafile/linora/test01.dbf&apos;;Starting recover at 2014-09-10 17:01:54using channel ORA_DISK_1starting media recoveryRMAN-00571: ===========================================================RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============RMAN-00571: ===========================================================RMAN-03002: failure of recover command at 09/10/2014 17:01:54RMAN-06053: unable to perform media recovery because of missing logRMAN-06025: no backup of archived log for thread 1 with sequence 194 and starting SCN of 3631541 found to restoreRMAN-06025: no backup of archived log for thread 1 with sequence 193 and starting SCN of 3631538 found to restoreRMAN-06025: no backup of archived log for thread 1 with sequence 192 and starting SCN of 3631535 found to restoreRMAN-06025: no backup of archived log for thread 1 with sequence 191 and starting SCN of 3631234 found to restoreRMAN-06025: no backup of archived log for thread 1 with sequence 190 and starting SCN of 3606559 found to restore 分别查看控制文件和数据文件头SCN：12345678910111213141516171819202122232425262728293031323334353637--控制文件SCNSYS@linora&gt; select file#,checkpoint_change# from v$datafile; FILE# CHECKPOINT_CHANGE#---------- ------------------ 1 3653096 2 3653096 3 3653096 4 3653096 5 3653096 6 3653096 7 3653096 8 3653096 9 3653096 10 3653096 11 365309611 rows selected.--数据文件头SCNSYS@linora&gt; select file#,checkpoint_change# from v$datafile_header; FILE# CHECKPOINT_CHANGE#---------- ------------------ 1 3653096 2 3653096 3 3653096 4 3653096 5 3653096 6 3653096 7 3653096 8 3653096 9 3653096 10 3653096 11 360656611 rows selected.SYS@linora&gt; select change# from v$recover_file; CHANGE#---------- 3606566 可以确定，file 11的SCN不一致，但又缺少归档，因此，media recovery无法进行。文件头信息存储在数据文件的第一个块内，在前文BBED Structure，块头仅有一个结构--kcvfh，数据文件是否与其他数据文件同步，Oracle会考虑到此结构中的四个属性： kscnbas(offset 484)--SCN of last change to the file kcvcptim(offset 492)--Time of last change to the file kcvfhcpc(offset 140)--Checkpoint count,v$datafile_header.CHECKPOINT_COUNT，数据文件发生Checkpoint的次数 kcvfhccc(offset 148)--控制文件检查点次数使用bbed分别对比1号文件和11号文件的上述四个属性值： 1号文件1234567891011121314151617181920212223242526BBED&gt; set dba 1,1 DBA 0x00400001 (4194305 1,1)BBED&gt; p kcvfhckpstruct kcvfhckp, 36 bytes @484 struct kcvcpscn, 8 bytes @484 ub4 kscnbas @484 0x0037bde8--检查点SCN ub2 kscnwrp @488 0x0000 ub4 kcvcptim @492 0x3322ed7b--检查点时间 ub2 kcvcpthr @496 0x0001 union u, 12 bytes @500 struct kcvcprba, 12 bytes @500 ub4 kcrbaseq @500 0x000000c3 ub4 kcrbabno @504 0x00000561 ub2 kcrbabof @508 0x0010 ub1 kcvcpetb[0] @512 0x02 ub1 kcvcpetb[1] @513 0x00 ub1 kcvcpetb[2] @514 0x00 ub1 kcvcpetb[3] @515 0x00 ub1 kcvcpetb[4] @516 0x00 ub1 kcvcpetb[5] @517 0x00 ub1 kcvcpetb[6] @518 0x00 ub1 kcvcpetb[7] @519 0x00BBED&gt; p kcvfhcpcub4 kcvfhcpc @140 0x00000287--数据文件ckpt次数BBED&gt; p kcvfhcccub4 kcvfhccc @148 0x00000286--控制文件ckpt次数 11号文件1234567891011121314151617181920212223242526BBED&gt; set dba 11,1 DBA 0x02c00001 (46137345 11,1)BBED&gt; p kcvfhckpstruct kcvfhckp, 36 bytes @484 struct kcvcpscn, 8 bytes @484 ub4 kscnbas @484 0x00370826 ub2 kscnwrp @488 0x0000 ub4 kcvcptim @492 0x3322df58 ub2 kcvcpthr @496 0x0001 union u, 12 bytes @500 struct kcvcprba, 12 bytes @500 ub4 kcrbaseq @500 0x000000be ub4 kcrbabno @504 0x00000002 ub2 kcrbabof @508 0x0010 ub1 kcvcpetb[0] @512 0x02 ub1 kcvcpetb[1] @513 0x00 ub1 kcvcpetb[2] @514 0x00 ub1 kcvcpetb[3] @515 0x00 ub1 kcvcpetb[4] @516 0x00 ub1 kcvcpetb[5] @517 0x00 ub1 kcvcpetb[6] @518 0x00 ub1 kcvcpetb[7] @519 0x00BBED&gt; p kcvfhcpcub4 kcvfhcpc @140 0x00000044BBED&gt; p kcvfhcccub4 kcvfhccc @148 0x00000043 从上述结果中可以看到，正常的数据文件中，SCN值为0x0037bde8，即为10进制的3653096，Checkpoint的时间为0x3322ed7b，而需要media recovery的11号文件SCN值为0x00370826，即10进制的3606566，四个属性跟正常文件都不相同。1234SYS@linora&gt; select to_number(&apos;37bde8&apos;,&apos;xxxxxxxx&apos;) from dual; TO_NUMBER(&apos;37BDE8&apos;,&apos;XXXXXXXX&apos;)------------------------------ 3653096 再来dump一下各个offset的值(11号数据文件)：123456789101112131415161718192021222324252627--dump SCN值BBED&gt; set dba 11,1 offset 484 DBA 0x02c00001 (46137345 11,1) OFFSET 484BBED&gt; d /v count 16 File: /oradata/datafile/linora/test01.dbf (11) Block: 1 Offsets: 484 to 499 Dba:0x02c00001------------------------------------------------------- 26083700 00000000 58df2233 01000000 l &amp;.7.....X.&quot;3....--Checkpoint 时间BBED&gt; d /v dba 11,1 offset 492 File: /oradata/datafile/linora/test01.dbf (11) Block: 1 Offsets: 492 to 507 Dba:0x02c00001------------------------------------------------------- 58df2233 01000000 be000000 02000000 l X.&quot;3............--数据文件Checkpoint次数BBED&gt; d /v dba 11,1 offset 140 File: /oradata/datafile/linora/test01.dbf (11) Block: 1 Offsets: 140 to 155 Dba:0x02c00001------------------------------------------------------- 44000000 c0ed2233 43000000 00000000 l D.....&quot;3C.......--控制文件Checkpoint次数BBED&gt; d /v dba 11,1 offset 148 File: /oradata/datafile/linora/test01.dbf (11) Block: 1 Offsets: 148 to 163 Dba:0x02c00001------------------------------------------------------- 43000000 00000000 00000000 00000000 l C............... 因为此平台为Linux，属于little-endian，存储字节顺序是由左至右，因此，四个属性值和存储值对应有如下关系(0x代表16进制)：123400370826--&gt;260837003322df58--&gt;58df223300000044--&gt;4400000000000043--&gt;43000000 由此，我们可以得出，只需要将上述四个属性值修改为1号文件相同值即可123456789101112131415161718192021222324252627282930313233343536373839404142434445464748--修改文件Checkpoint scnBBED&gt; d /v dba 1,1 offset 484 count 16 File: /oradata/datafile/linora/system01.dbf (1) Block: 1 Offsets: 484 to 499 Dba:0x00400001------------------------------------------------------- e8bd3700 00000000 7bed2233 01000000 l ..7.....&#123;.&quot;3....BBED&gt; m /x e8bd37 dba 11,1 offset 484Warning: contents of previous BIFILE will be lost. Proceed? (Y/N) y File: /oradata/datafile/linora/test01.dbf (11) Block: 1 Offsets: 484 to 499 Dba:0x02c00001------------------------------------------------------------------------ e8bd3700 00000000 58df2233 01000000 --修改文件Checkpoint 时间BBED&gt; d /v dba 1,1 offset 492 File: /oradata/datafile/linora/system01.dbf (1) Block: 1 Offsets: 492 to 507 Dba:0x00400001------------------------------------------------------- 7bed2233 01000000 c3000000 61050000 l &#123;.&quot;3........a...BBED&gt; m /x 7bed2233 dba 11,1 offset 492 File: /oradata/datafile/linora/test01.dbf (11) Block: 1 Offsets: 492 to 507 Dba:0x02c00001------------------------------------------------------------------------ 7bed2233 01000000 be000000 02000000 --修改文件Checkpoint次数BBED&gt; d /v dba 1,1 offset 140 File: /oradata/datafile/linora/system01.dbf (1) Block: 1 Offsets: 140 to 155 Dba:0x00400001------------------------------------------------------- 87020000 b3ec2233 86020000 00000000 l ......&quot;3........BBED&gt; m /x 8702 dba 11,1 offset 140 File: /oradata/datafile/linora/test01.dbf (11) Block: 1 Offsets: 140 to 155 Dba:0x02c00001------------------------------------------------------------------------ 87020000 c0ed2233 43000000 00000000--修改控制文件Checkpoint次数BBED&gt; d /v dba 1,1 offset 148 File: /oradata/datafile/linora/system01.dbf (1) Block: 1 Offsets: 148 to 163 Dba:0x00400001------------------------------------------------------- 86020000 00000000 00000000 00000000 l ...............BBED&gt; m /x 8602 dba 11,1 offset 148 File: /oradata/datafile/linora/test01.dbf (11) Block: 1 Offsets: 148 to 163 Dba:0x02c00001------------------------------------------------------------------------ 86020000 00000000 00000000 00000000 BBED&gt; sum apply Check value for File 11, Block 1:current = 0x90d7, required = 0x90d7 然而，当我修改完这四个属性值之后，启动数据库提示如下错误：1234567SYS@linora&gt; alter database open;alter database open*ERROR at line 1:ORA-01122: database file 11 failed verification checkORA-01110: data file 11: &apos;/oradata/datafile/linora/test01.dbf&apos;ORA-01207: file is more recent than control file - old control file 个人觉得kcvfhcpc和kcvfhccc因数据文件而异，因为有些数据文件创建时间早，因此Checkpoint的次数就多，有些数据文件创建晚，Checkpoint的次数就少，因此，如果要修改这两个属性，必须重建控制文件。我的做法是：不修改这两个值，直接开启数据库，提示错误&quot;ORA-01113: file 11 needs media recovery&quot;，在rman下执行recovery，此时不会提示要apply归档日志，且数据库能正常打开了，但是，存在着数据丢失。12345678910RMAN&gt; recover datafile 11;Starting recover at 2014-09-11 10:15:11using target database control file instead of recovery catalogallocated channel: ORA_DISK_1channel ORA_DISK_1: SID=245 device type=DISKstarting media recoverymedia recovery complete, elapsed time: 00:00:01Finished recover at 2014-09-11 10:15:13SYS@linora&gt; alter database open; Database altered. Reference：dissassembling_the_data_block","link":"/bbed-demo.html"},{"title":"Linux下编译BBED","text":"BBED全称Block Browser and EDitor，是Oracle内部用于查看和修改数据块的工具。由于使用BBED需要对块结构有相当的了解，使用bbed风险很高，Oracle也不会对bbed提供任何技术支持，研究bbed只是为了更深入的了解Oracle的数据块结构，并不建议使用bbed去修改生产数据。本文主要示范Oracle 10g和11g版本下在Linux环境的安装。 1. 10g的安装10g的安装比较简单：12345[oracle@ora10g:/home/oracle]$ make -f $ORACLE_HOME/rdbms/lib/ins_rdbms.mk $ORACLE_HOME/rdbms/lib/bbedLinking BBED utility (bbed)rm -f /u01/app/oracle/product/10.2.0/db_1/rdbms/lib/bbedgcc -o /u01/app/oracle/product/10.2.0/db_1/rdbms/lib/bbed -L/u01/app/oracle/product/10.2.0/db_1/rdbms/lib/ -L/u01/app/oracle/product/10.2.0/db_1/lib/ -L/u01/app/oracle/product/10.2.0/db_1/lib/stubs/ /u01/app/oracle/product/10.2.0/db_1/lib/s0main.o /u01/app/oracle/product/10.2.0/db_1/rdbms/lib/ssbbded.o /u01/app/oracle/product/10.2.0/db_1/rdbms/lib/sbbdpt.o `cat /u01/app/oracle/product/10.2.0/db_1/lib/ldflags` -lnsslb10 -lncrypt10 -lnsgr10 -lnzjs10 -ln10 -lnnz10 -lnl10 /u01/app/oracle/product/10.2.0/db_1/rdbms/lib/defopt.o -ldbtools10 -lclntsh `cat /u01/app/oracle/product/10.2.0/db_1/lib/ldflags` -lnsslb10 -lncrypt10 -lnsgr10 -lnzjs10 -ln10 -lnnz10 -lnl10 -lnro10 `cat /u01/app/oracle/product/10.2.0/db_1/lib/ldflags` -lnsslb10 -lncrypt10 -lnsgr10 -lnzjs10 -ln10 -lnnz10 -lnl10 -lclient10 -lnnetd10 -lvsn10 -lcommon10 -lgeneric10 -lmm -lsnls10 -lnls10 -lcore10 -lsnls10 -lnls10 -lcore10 -lsnls10 -lnls10 -lxml10 -lcore10 -lunls10 -lsnls10 -lnls10 -lcore10 -lnls10 `cat /u01/app/oracle/product/10.2.0/db_1/lib/ldflags` -lnsslb10 -lncrypt10 -lnsgr10 -lnzjs10 -ln10 -lnnz10 -lnl10 -lnro10 `cat /u01/app/oracle/product/10.2.0/db_1/lib/ldflags` -lnsslb10 -lncrypt10 -lnsgr10 -lnzjs10 -ln10 -lnnz10 -lnl10 -lclient10 -lnnetd10 -lvsn10 -lcommon10 -lgeneric10 -lsnls10 -lnls10 -lcore10 -lsnls10 -lnls10 -lcore10 -lsnls10 -lnls10 -lxml10 -lcore10 -lunls10 -lsnls10 -lnls10 -lcore10 -lnls10 -lclient10 -lnnetd10 -lvsn10 -lcommon10 -lgeneric10 -lsnls10 -lnls10 -lcore10 -lsnls10 -lnls10 -lcore10 -lsnls10 -lnls10 -lxml10 -lcore10 -lunls10 -lsnls10 -lnls10 -lcore10 -lnls10 `cat /u01/app/oracle/product/10.2.0/db_1/lib/sysliblist` -Wl,-rpath,/u01/app/oracle/product/10.2.0/db_1/lib -lm `cat /u01/app/oracle/product/10.2.0/db_1/lib/sysliblist` -ldl -lm -L/u01/app/oracle/product/10.2.0/db_1/lib 不妨将bbed命令加入$BIN环境变量：12345[oracle@ora10g:/home/oracle]$ ll $ORACLE_HOME/rdbms/lib/bbed-rwxr-xr-x 1 oracle oinstall 548768 Sep 1 10:34 /u01/app/oracle/product/10.2.0/db_1/rdbms/lib/bbed[oracle@ora10g:/home/oracle]$ cp $ORACLE_HOME/rdbms/lib/bbed $ORACLE_HOME/bin[oracle@ora10g:/home/oracle]$ ll $ORACLE_HOME/bin/bbed-rwxr-xr-x 1 oracle oinstall 548768 Sep 1 10:35 /u01/app/oracle/product/10.2.0/db_1/bin/bbed 2. 11g的安装11g及以上版本已经没有bbed相关的库文件了，需要从10g复制过来，需要复制以下几个文件：123456789[oracle@linora:/home/oracle]$ make -f $ORACLE_HOME/rdbms/lib/ins_rdbms.mk $ORACLE_HOME/rdbms/lib/bbed...gcc: /u01/app/oracle/product/11gr2//rdbms/lib/ssbbded.o: No such file or directorygcc: /u01/app/oracle/product/11gr2//rdbms/lib/sbbdpt.o: No such file or directory--从10g及以前版本copy过来以下几个文件$ORACLE_HOME/rdbms/lib/ssbbded.o$ORACLE_HOME/rdbms/lib/sbbdpt.o$ORACLE_HOME/rdbms/mesg/bbedus.msb$ORACLE_HOME/rdbms/mesg/bbedus.msg 编译过程跟10g的一样。 3. 运行bbedbbed默认密码为blockedit，一般会使用参数文件：1234567[oracle@linora:/home/oracle]$ cat parfile.txt blocksize=8192listfile=filelist.txtmode=edit[oracle@linora:/home/oracle]$ cat filelist.txt 1 /oradata/datafile/linora/system01.dbf 11 /oradata/datafile/linora/test01.dbf filelist中记录的是需要查看或者修改的数据文件，第一个字段是file_id，第二个字段是file_name，第三个字段是bytes(上例中省略了)，其对应关系可用以下语句查出：1234567891011121314SYS@linora&gt; select file#||&apos; &apos;||name||&apos; &apos;||bytes listfile from v$datafile;LISTFILE--------------------------------------------------------------------------------1 /oradata/datafile/linora/system01.dbf 7549747202 /oradata/datafile/linora/sysaux01.dbf 7025459203 /oradata/datafile/linora/undotbs01.dbf 5662310404 /oradata/datafile/linora/users01.dbf 367001605 /oradata/datafile/linora/fung01.dbf 2464153606 /oradata/datafile/linora/undotbs02.dbf 10485767 /oradata/datafile/linora/fung02.dbf 104857608 /oradata/datafile/linora/perf01.dbf 3145728009 /oradata/datafile/linora/demotsdata.dbf 10485760010 /oradata/datafile/linora/demotsidx.dbf 10485760011 /oradata/datafile/linora/test01.dbf 1048576 以上两个文件须在同一层目录。BBED使用帮助，包括上述参数的一些说明：12345678910111213141516[oracle@linora:/home/oracle]$ bbed helpLRM-00108: invalid positional parameter value &apos;help&apos;PASSWORD - Required parameterFILENAME - Database file nameBLOCKSIZE - Database block sizeLISTFILE - List file nameMODE - [browse/edit]SPOOL - Spool to logfile [no/yes]CMDFILE - BBED command file nameLOGFILE - BBED log file namePARFILE - Parameter file nameBIFILE - BBED before-image file nameREVERT - Rollback changes from BIFILE [no/yes]SILENT - Hide banner [no/yes]HELP - Show all valid parameters [no/yes]BBED-00105: LRM error 108 occurred during command line parsing 调用bbed：123456[oracle@linora:/home/oracle]$ bbed parfile=parfile.txt Password: BBED: Release 2.0.0.0.0 - Limited Production on Mon Sep 1 11:11:15 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.************* !!! For Oracle Internal Use only !!! ***************BBED&gt; Reference：dissassembling_the_data_block","link":"/bbed-in-linux.html"},{"title":"BBED基本命令","text":"前文Linux下编译BBED描述了如何在Linux下编译使用bbed，本文介绍bbed常用的一些命令。BBED命令帮助:12345678BBED&gt; help allSET DBA [ dba | file#, block# ]SET FILENAME &apos;filename&apos;...UNDOHELP [ &lt;bbed command&gt; | ALL ]VERIFY [ DBA | FILE | FILENAME | BLOCK ]CORRUPT [ DBA | FILE | FILENAME | BLOCK ] 1. set命令set主要用于定位所修改的记录所在的数据块的具体位置。在Oracle内部，数据块记录的具体位置是由RDBA和偏移量offset决定，RDBA表示修改的记录所在的数据块在数据文件的位置，offset表示修改的记录在数据块内的具体位置。123456789--查找数据dbaSYS@linora&gt; SELECT DBMS_ROWID.ROWID_OBJECT(rowid) &quot;OBJECT&quot;, 2 DBMS_ROWID.ROWID_RELATIVE_FNO(rowid) &quot;FILE&quot;, 3 DBMS_ROWID.ROWID_BLOCK_NUMBER(rowid) &quot;BLOCK&quot;, 4 DBMS_ROWID.ROWID_ROW_NUMBER(rowid) &quot;ROW&quot; 5 FROM hr.employees where employee_id=200; OBJECT FILE BLOCK ROW---------- ---------- ---------- ---------- 84737 8 11477 2 bbed参数文件设置：12345678910111213141516[oracle@linora:/home/oracle/bbed]$ cat parfile.txt blocksize=8192listfile=filelist.txtmode=edit[oracle@linora:/home/oracle/bbed]$ cat filelist.txt 1 /oradata/datafile/linora/system01.dbf 7549747202 /oradata/datafile/linora/sysaux01.dbf 7025459203 /oradata/datafile/linora/undotbs01.dbf 5662310404 /oradata/datafile/linora/users01.dbf 367001605 /oradata/datafile/linora/fung01.dbf 2464153606 /oradata/datafile/linora/undotbs02.dbf 10485767 /oradata/datafile/linora/fung02.dbf 104857608 /oradata/datafile/linora/perf01.dbf 3145728009 /oradata/datafile/linora/demotsdata.dbf 10485760010 /oradata/datafile/linora/demotsidx.dbf 10485760011 /oradata/datafile/linora/test01.dbf 1048576 set dba使用DBA定位数据块位置，默认offset为0，也可以指定offset。123456BBED&gt; set dba 8,11477 DBA 0x02002cd5 (33565909 8,11477)BBED&gt; d File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 0 to 511 Dba:0x02002cd5--默认offset为0 set filename以数据文件名指定当前修改的数据文件，需要绝对路径12BBED&gt; set filename &apos;/oradata/datafile/linora/perf01.dbf&apos; FILENAME /oradata/datafile/linora/perf01.dbf set file以file_id指定当前修改的数据文件12BBED&gt; set file 8 FILE# 8 set block指定当前修改的块号，在设定块号之前，需要先指定数据文件，可使用绝对块号，或者使用&#39;+&#39;，&#39;-&#39;号指定离当前块号距离的目标块号1234BBED&gt; set block 11476 BLOCK# 11476BBED&gt; set block +1 BLOCK# 11477 set offset指定当前块内的起始偏移量，用法跟set block类似，也可用&#39;+&#39;，&#39;-&#39;号来表示跟当前offset的相对offset123456789101112BBED&gt; set offset 10 OFFSET 10BBED&gt; d File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 10 to 521 Dba:0x02002cd5--offset为10BBED&gt; set offset +10 OFFSET 20BBED&gt; d File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 20 to 531 Dba:0x02002cd5--offset为20 set blocksize设置当前数据文件的块大小，必须是当前数据文件的块大小，否则报错1234BBED&gt; set blocksize 8192 BLOCKSIZE 8192BBED&gt; set blocksize 16384BBED-00307: incorrect blocksize (8192) or truncated file set listfile设置使用的listfile文件，listfile文件包含bbed所要编辑的数据文件列表12BBED&gt; set listfile &apos;filelist.txt&apos; LISTFILE filelist.txt set count设置dump命令显示的对应数据块的字节数，默认为512个字节。如果需要看到一个8k数据块的整个块内容，可以设置count为8192或者更大123456789101112BBED&gt; set dba 8,11477 DBA 0x02002cd5 (33565909 8,11477)BBED&gt; d File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 0 to 511 Dba:0x02002cd5--默认dump显示为0~511即512个字节BBED&gt; set count 8192 COUNT 8192BBED&gt; d File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 0 to 8191 Dba:0x02002cd5--设置count为8k后，显示字节为0~8191即8192个字节 set ibase设置使用set block,set file,set offset使用的进制:Dec-十进制 Hex-十六进制 Oct-八进制，默认为10进制12BBED&gt; show ibase IBASE Dec set obase此命令未知。 set mode设置bbed模式是编辑(edit)还是浏览(browse)，浏览模式无法对数据块进行修改123456BBED&gt; show mode MODE EditBBED&gt; set mode browse MODE BrowseBBED&gt; show mode MODE Browse 2. show命令显示当前bbed的配置12345678910111213141516171819BBED&gt; set dba 8, 11476 DBA 0x02002cd4 (33565908 8,11476)BBED&gt; show FILE# 8 BLOCK# 11476 OFFSET 0 DBA 0x02002cd4 (33565908 8,11476) FILENAME /oradata/datafile/linora/perf01.dbf BIFILE bifile.bbd LISTFILE filelist.txt BLOCKSIZE 8192 MODE Edit EDIT Unrecoverable IBASE Dec OBASE Dec WIDTH 80 COUNT 512 LOGFILE log.bbd SPOOL No 3. info命令显示当前的listfile内容1234567891011121314BBED&gt; info File# Name Size(blks) ----- ---- ---------- 1 /oradata/datafile/linora/system01.dbf 92160 2 /oradata/datafile/linora/sysaux01.dbf 85760 3 /oradata/datafile/linora/undotbs01.dbf 69120 4 /oradata/datafile/linora/users01.dbf 4480 5 /oradata/datafile/linora/fung01.dbf 30080 6 /oradata/datafile/linora/undotbs02.dbf 128 7 /oradata/datafile/linora/fung02.dbf 1280 8 /oradata/datafile/linora/perf01.dbf 38400 9 /oradata/datafile/linora/demotsdata.dbf 12800 10 /oradata/datafile/linora/demotsidx.dbf 12800 11 /oradata/datafile/linora/test01.dbf 128 4. map命令map显示数据块结构，如果加上/v则表示显示数据块结构的同时显示结构体(Oracle 定义的Structure)的每个字段。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152--map不加dba表示显示当前块结构及字段，加上dba表示显示指定的块结构和字段BBED&gt; map /v dba 8,11476BBED&gt; map /v dba 8,11476 File: /oradata/datafile/linora/perf01.dbf (8) Block: 11476 Dba:0x02002cd4------------------------------------------------------------ KTB Data Block (Table/Cluster) struct kcbh, 20 bytes @0 ub1 type_kcbh @0 ub1 frmt_kcbh @1 ub1 spare1_kcbh @2 ub1 spare2_kcbh @3 ub4 rdba_kcbh @4 ub4 bas_kcbh @8 ub2 wrp_kcbh @12 ub1 seq_kcbh @14 ub1 flg_kcbh @15 ub2 chkval_kcbh @16 ub2 spare3_kcbh @18 struct ktbbh, 72 bytes @20 ub1 ktbbhtyp @20 union ktbbhsid, 4 bytes @24 struct ktbbhcsc, 8 bytes @28 sb2 ktbbhict @36 ub1 ktbbhflg @38 ub1 ktbbhfsl @39 ub4 ktbbhfnx @40 struct ktbbhitl[2], 48 bytes @44 struct kdbh, 14 bytes @100 ub1 kdbhflag @100 sb1 kdbhntab @101 sb2 kdbhnrow @102 sb2 kdbhfrre @104 sb2 kdbhfsbo @106 sb2 kdbhfseo @108 sb2 kdbhavsp @110 sb2 kdbhtosp @112 struct kdbt[1], 4 bytes @114 sb2 kdbtoffs @114 sb2 kdbtnrow @116 sb2 kdbr[98] @118 ub1 freespace[686] @314 ub1 rowdata[7188] @1000 ub4 tailchk @8188 5. dump命令dump命令用于查看指定block、指定offset的数据块内记录的内容，这些内容以16进制记载。相当于对当前block进行strings操作。此命令可缩写为d。1234567891011121314151617181920BBED&gt; set dba 8, 11476 offset 1024 count 20 DBA 0x02002cd4 (33565908 8,11476) OFFSET 1024 COUNT 20BBED&gt; d /v File: /oradata/datafile/linora/perf01.dbf (8) Block: 11476 Offsets: 1024 to 1043 Dba:0x02002cd4------------------------------------------------------- 0c353135 2e313233 2e343536 37077867 l .515.123.4567.xg 06110101 l ....&lt;16 bytes per line&gt;--或者BBED&gt; d /v dba 8,11476 offset 1024 count 50 File: /oradata/datafile/linora/perf01.dbf (8) Block: 11476 Offsets: 1024 to 1073 Dba:0x02002cd4------------------------------------------------------- 0c353135 2e313233 2e343536 37077867 l .515.123.4567.xg 06110101 01074144 5f505245 5304c304 l ......AD_PRES... 2e3dffff 02c15b2c 000b02c2 02065374 l .=....[,......St 6576 l ev 6. print命令显示数据块中offset位置的块结构。12345--打印指定dba offset，下面是返回kcbh及数据块头(Data Block Header)BBED&gt; p dba 8,11476 offset 0kcbh.type_kcbh--------------ub1 type_kcbh @0 0x06 打印指定数据结构，下面的例子中，分三列，第三列是具体值12345678910111213BBED&gt; p kcbhstruct kcbh, 20 bytes @0 ub1 type_kcbh @0 0x06 ub1 frmt_kcbh @1 0xa2 ub1 spare1_kcbh @2 0x00 ub1 spare2_kcbh @3 0x00 ub4 rdba_kcbh @4 0x02002cd4 ub4 bas_kcbh @8 0x00316808 ub2 wrp_kcbh @12 0x0000 ub1 seq_kcbh @14 0x01 ub1 flg_kcbh @15 0x06 (KCBHFDLC, KCBHFCKV) ub2 chkval_kcbh @16 0x8920 ub2 spare3_kcbh @18 0x0000 跟dump结果对应下，可以看到，data block Header，dump存储的数据跟print的数据存在一定的关系。1234567BBED&gt; set count 20 COUNT 20BBED&gt; d File: /oradata/datafile/linora/perf01.dbf (8) Block: 11476 Offsets: 0 to 19 Dba:0x02002cd4------------------------------------------------------------------------ 06a20000 d42c0002 08683100 00000106 20890000 print还可以通过kdbr[n]来定位到当前块的第n行记录，数据块存储记录是有0行开始。12345--定位数据块内第三行记录BBED&gt; p dba 8,11477 *kdbr[2]rowdata[410]------------ub1 rowdata[410] @7976 0x2c 显示当前偏移量的值为2c，和dump出来的第一个字节相同，即普通数据块中行记录所在的行头的标识。12345678910111213141516171819BBED&gt; d /v dba 8,11477 offset 7976 count 512 File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 7976 to 8191 Dba:0x02002cd5------------------------------------------------------- 2c010b02 c203084a 656e6e69 66657206 l ,......Jennifer. 5768616c 656e074a 5748414c 454e0c35 l Whalen.JWHALEN.5 31352e31 32332e34 34343407 78670911 l 15.123.4444.xg.. 01010107 41445f41 53535402 c22dff03 l ....AD_ASST..-.. c2020202 c10b2c01 0b03c202 6407446f l ......,.....d.Do 75676c61 73054772 616e7406 44475241 l uglas.Grant.DGRA 4e540c36 35302e35 30372e39 38343407 l NT.650.507.9844. 786c010d 01010108 53485f43 4c45524b l xl......SH_CLERK 02c21bff 03c20219 02c1332c 010b03c2 l ..........3,.... 02630644 6f6e616c 64084f43 6f6e6e65 l .c.Donald.OConne 6c6c0844 4f434f4e 4e454c0c 3635302e l ll.DOCONNEL.650. 3530372e 39383333 07786b06 15010101 l 507.9833.xk..... 0853485f 434c4552 4b02c21b ff03c202 l .SH_CLERK....... 1902c133 010695d7 l ...3.... &lt;32 bytes per line&gt; print的参数如下： parameters format /x 十六进制 /d 带符号十进制 /u 无符号十进制 /o 八进制 /c 字符 /n number /t Oracle时间类型 /i Oracle rowid 1234567891011121314BBED&gt; p /c rowdata ub1 rowdata[0] @7566 ,ub1 rowdata[1] @7567 .ub1 rowdata[2] @7568 ....ub1 rowdata[603] @8169 Sub1 rowdata[604] @8170 Hub1 rowdata[605] @8171 _ub1 rowdata[606] @8172 Cub1 rowdata[607] @8173 Lub1 rowdata[608] @8174 Eub1 rowdata[609] @8175 Rub1 rowdata[610] @8176 K... 7. examine命令此命令用于将当前数据块的行记录从16进制翻译成文本,其后可接参数/r，表示read，且/r后可接一堆参数，其中n表示number，c表示character，即varchar或者varchar2类型的字符串，t表示日期类型。1234567891011121314151617181920212223--table bigtable字段为ccnc类型FUNG@linora&gt; desc bigtable Name Null? Type ------------------------------ -------- ------------------- ID VARCHAR2(10) INC_DATETIME VARCHAR2(19) RANDOM_ID NUMBER RANDOM_STRING VARCHAR2(4000)--查找某条记录FUNG@linora&gt; select * from bigtable where id=&apos;101401999&apos;;ID INC_DATETIME RANDOM_ID RANDOM_STRING---------- ------------------- ---------- ----------------------------101401999 2014-07-16 11:01:37 10 EST7QUM940KAEOZSV2ZF--查找某条记录的dbaFUNG@linora&gt; SELECT DBMS_ROWID.ROWID_OBJECT(rowid) &quot;OBJECT&quot;, 2 DBMS_ROWID.ROWID_RELATIVE_FNO(rowid) &quot;FILE&quot;, 3 DBMS_ROWID.ROWID_BLOCK_NUMBER(rowid) &quot;BLOCK&quot;, 4 DBMS_ROWID.ROWID_ROW_NUMBER(rowid) &quot;ROW&quot; 5 FROM fung.bigtable where id=&apos;101401999&apos;; OBJECT FILE BLOCK ROW---------- ---------- ---------- ---------- 85368 5 243 0 使用bbed的examine命令打印当前行记录。1234567891011121314151617BBED&gt; set dba 5,243 DBA 0x014000f3 (20971763 5,243)BBED&gt; p *kdbr[0]rowdata[7703]-------------ub1 rowdata[7703] @8131 0x2cBBED&gt; x /rccncrowdata[7703] @8131 -------------flag@8131: 0x2c (KDRHFL, KDRHFF, KDRHFH)lock@8132: 0x00cols@8133: 4col 0[9] @8134: 101401999col 1[19] @8144: 2014-07-16 11:01:37col 2[2] @8164: 10 col 3[20] @8167: EST7QUM940KAEOZSV2ZF 可以看到bbed出来的结果记录和select语句一致，如果/r后的c和n调换位置，则会出现其他情况：1234567891011BBED&gt; x /rnncrowdata[7703] @8131 -------------flag@8131: 0x2c (KDRHFL, KDRHFF, KDRHFH)lock@8132: 0x00cols@8133: 4col 0[9] @8134: ######################################### col 1[19] @8144: ######################################### col 2[2] @8164: ..col 3[20] @8167: EST7QUM940KAEOZSV2ZF 由此可得知，使用x命令进行read的时候，要和表定义的数据类型一致。 8. find命令find用于查找指定字符串在指定数据块的具体位置，可简写为f，查找出符合条件后，再输入f会显示下一条符合条件的记录。find命令参数如下表所示 parameter datatype /x 十六进制 /d 十进制 /u 无符号十进制 /o 八进制 /c 字符 123456789101112131415161718192021222324252627282930313233BBED&gt; set dba 8,11477 DBA 0x02002cd5 (33565909 8,11477)--从当前offset查找BBED&gt; find /c Jen CURR BBED-00212: search string not found--从offset=0开始查找BBED&gt; find /c Jen TOP File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 7983 to 8191 Dba:0x02002cd5------------------------------------------------------------------------ 4a656e6e 69666572 06576861 6c656e07 4a574841 4c454e0c 3531352e 3132332e 34343434 07786709 11010101 0741445f 41535354 02c22dff 03c20202 02c10b2c 010b03c2 02640744 6f75676c 61730547 72616e74 06444752 414e540c 3635302e 3530372e 39383434 07786c01 0d010101 0853485f 434c4552 4b02c21b ff03c202 1902c133 2c010b03 c2026306 446f6e61 6c64084f 436f6e6e 656c6c08 444f434f 4e4e454c 0c363530 2e353037 2e393833 3307786b 06150101 01085348 5f434c45 524b02c2 1bff03c2 021902c1 33010695 d7 --此时的offset被设置为匹配搜索的第一个位置BBED&gt; show offset OFFSET 7983--验证当前offset是否为JenBBED&gt; p /c rowdata[417]------------ub1 rowdata[417] @7983 JBBED&gt; p /c offset +1rowdata[418]------------ub1 rowdata[418] @7984 eBBED&gt; p /c offset +1rowdata[419]------------ub1 rowdata[419] @7985 n 9. copy命令copy用于复制一个数据块到另一个地方，如：1BBED&gt; copy dba 8,11476 to dba 11,10240 10. modify命令modify为修改块内数据的命令，其命令指定的数据格式跟find相同，可简写为m。如修改dba 8,block 11477的Jen为JAN：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162--查找Jen所在offsetBBED&gt; f /c Jen TOP File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 7983 to 8191 Dba:0x02002cd5------------------------------------------------------------------------ 4a656e6e 69666572 06576861 6c656e07 4a574841 4c454e0c 3531352e 3132332e 34343434 07786709 11010101 0741445f 41535354 02c22dff 03c20202 02c10b2c 010b03c2 02640744 6f75676c 61730547 72616e74 06444752 414e540c 3635302e 3530372e 39383434 07786c01 0d010101 0853485f 434c4552 4b02c21b ff03c202 1902c133 2c010b03 c2026306 446f6e61 6c64084f 436f6e6e 656c6c08 444f434f 4e4e454c 0c363530 2e353037 2e393833 3307786b 06150101 01085348 5f434c45 524b02c2 1bff03c2 021902c1 33010695 d7 --验证offset是否以Jen开头BBED&gt; d /v File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 7983 to 8191 Dba:0x02002cd5------------------------------------------------------- 4a656e6e 69666572 06576861 6c656e07 l Jennifer.Whalen. 4a574841 4c454e0c 3531352e 3132332e l JWHALEN.515.123. 34343434 07786709 11010101 0741445f l 4444.xg......AD_ 41535354 02c22dff 03c20202 02c10b2c l ASST..-........, 010b03c2 02640744 6f75676c 61730547 l .....d.Douglas.G 72616e74 06444752 414e540c 3635302e l rant.DGRANT.650. 3530372e 39383434 07786c01 0d010101 l 507.9844.xl..... 0853485f 434c4552 4b02c21b ff03c202 l .SH_CLERK....... 1902c133 2c010b03 c2026306 446f6e61 l ...3,.....c.Dona 6c64084f 436f6e6e 656c6c08 444f434f l ld.OConnell.DOCO 4e4e454c 0c363530 2e353037 2e393833 l NNEL.650.507.983 3307786b 06150101 01085348 5f434c45 l 3.xk......SH_CLE 524b02c2 1bff03c2 021902c1 33010695 l RK..........3... d7 l .--以字符格式进行修改BBED&gt; m /c JAN dba 8,11477 offset 7983 File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 7983 to 8191 Dba:0x02002cd5------------------------------------------------------------------------ 4a414e6e 69666572 06576861 6c656e07 4a574841 4c454e0c 3531352e 3132332e 34343434 07786709 11010101 0741445f 41535354 02c22dff 03c20202 02c10b2c 010b03c2 02640744 6f75676c 61730547 72616e74 06444752 414e540c 3635302e 3530372e 39383434 07786c01 0d010101 0853485f 434c4552 4b02c21b ff03c202 1902c133 2c010b03 c2026306 446f6e61 6c64084f 436f6e6e 656c6c08 444f434f 4e4e454c 0c363530 2e353037 2e393833 3307786b 06150101 01085348 5f434c45 524b02c2 1bff03c2 021902c1 33010695 d7 --验证修改结果BBED&gt; d /v File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 7983 to 8191 Dba:0x02002cd5------------------------------------------------------- 4a414e6e 69666572 06576861 6c656e07 l JANnifer.Whalen. 4a574841 4c454e0c 3531352e 3132332e l JWHALEN.515.123. 34343434 07786709 11010101 0741445f l 4444.xg......AD_ 41535354 02c22dff 03c20202 02c10b2c l ASST..-........, 010b03c2 02640744 6f75676c 61730547 l .....d.Douglas.G 72616e74 06444752 414e540c 3635302e l rant.DGRANT.650. 3530372e 39383434 07786c01 0d010101 l 507.9844.xl..... 0853485f 434c4552 4b02c21b ff03c202 l .SH_CLERK....... 1902c133 2c010b03 c2026306 446f6e61 l ...3,.....c.Dona 6c64084f 436f6e6e 656c6c08 444f434f l ld.OConnell.DOCO 4e4e454c 0c363530 2e353037 2e393833 l NNEL.650.507.983 3307786b 06150101 01085348 5f434c45 l 3.xk......SH_CLE 524b02c2 1bff03c2 021902c1 33010695 l RK..........3... d7 l . 注意，在以前的bbed版本中进行修改，会以交互模式提醒是否确定要修改，但11g以后已经没有了这个提示。 11. sum命令sum命令用来检测和设置block的Checksum。12345678--验证数据块ChecksumBBED&gt; sum dba 8,11477Check value for File 8, Block 11477:current = 0x62bf, required = 0x429b--更新数据块ChecksumBBED&gt; sum dba 8,11477 applyCheck value for File 8, Block 11477:current = 0x429b, required = 0x429b 更新完毕后，可以刷新缓冲池，在数据库内查看修改结果。123456789SYS@linora&gt; alter system flush buffer_cache;System altered.SYS@linora&gt; SELECT DBMS_ROWID.ROWID_RELATIVE_FNO(rowid) &quot;FILE&quot;, 2 DBMS_ROWID.ROWID_BLOCK_NUMBER(rowid) &quot;BLOCK&quot;,first_name 3 FROM hr.employees where employee_id=200; FILE BLOCK FIRST_NAME---------- ---------- -------------------- 8 11477 JANnifer Reference：dissassembling_the_data_block","link":"/bbed-command.html"},{"title":"BBED Structure","text":"BBED中map命令能显示数据块的数据结构，本文以bbed分析数据块头及数据块为例，说明map中的具体结构。 1. 数据块头结构123456789101112131415161718192021222324252627282930313233343536373839404142434445464748BBED&gt; set dba 1,1 DBA 0x00400001 (4194305 1,1)BBED&gt; map /v File: /oradata/datafile/linora/system01.dbf (1) Block: 1 Dba:0x00400001------------------------------------------------------------ Data File Header --表示文件头 struct kcvfh, 860 bytes @0 --此块只有一个Structure，kcvfh struct kcvfhbfh, 20 bytes @0 struct kcvfhhdr, 76 bytes @20 ub4 kcvfhrdb @96 struct kcvfhcrs, 8 bytes @100 ub4 kcvfhcrt @108 ub4 kcvfhrlc @112 struct kcvfhrls, 8 bytes @116 ub4 kcvfhbti @124 struct kcvfhbsc, 8 bytes @128 ub2 kcvfhbth @136 ub2 kcvfhsta @138 struct kcvfhckp, 36 bytes @484 ub4 kcvfhcpc @140 ub4 kcvfhrts @144 ub4 kcvfhccc @148 struct kcvfhbcp, 36 bytes @152 ub4 kcvfhbhz @312 struct kcvfhxcd, 16 bytes @316 sword kcvfhtsn @332 ub2 kcvfhtln @336 text kcvfhtnm[30] @338 ub4 kcvfhrfn @368 struct kcvfhrfs, 8 bytes @372 ub4 kcvfhrft @380 struct kcvfhafs, 8 bytes @384 ub4 kcvfhbbc @392 ub4 kcvfhncb @396 ub4 kcvfhmcb @400 ub4 kcvfhlcb @404 ub4 kcvfhbcs @408 ub2 kcvfhofb @412 ub2 kcvfhnfb @414 ub4 kcvfhprc @416 struct kcvfhprs, 8 bytes @420 struct kcvfhprfs, 8 bytes @428 ub4 kcvfhtrt @444 ub4 tailchk @8188 print kcvfh看看具体内容：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248BBED&gt; p kcvfhstruct kcvfh, 860 bytes @0 struct kcvfhbfh, 20 bytes @0 --数据块头 --前20个字节对应如图一所示 ub1 type_kcbh @0 0x0b --Header Block Type，如图二 --此处转换为10进制是11，正是file header ub1 frmt_kcbh @1 0xa2 --块格式，1为Oracle 7,2为Oracle 8后 ub1 spare1_kcbh @2 0x00 ub1 spare2_kcbh @3 0x00 ub4 rdba_kcbh @4 0x00400001 --RDBA,相对块地址 ub4 bas_kcbh @8 0x00000000 --SCN base ub2 wrp_kcbh @12 0x0000 --SCN Wrap ub1 seq_kcbh @14 0x01 --序列号，同一个SCN不同的序列号，标记块版本 ub1 flg_kcbh @15 0x04 (KCBHFCKV) --标记号 --0x01新块 --0x02 Delayed Logging Chang advanced SCN/seq --0x04 Check value saved ub2 chkval_kcbh @16 0x1375 --块校验值 ub2 spare3_kcbh @18 0x0000 struct kcvfhhdr, 76 bytes @20 --文件头通用数据类型 ub4 kccfhswv @20 0x00000000 ub4 kccfhcvn @24 0x0b200400 ub4 kccfhdbi @28 0xc9cffd9d --dbid text kccfhdbn[0] @32 L --接下来8个字符为Oracle SID，只能&lt;=8个字符 text kccfhdbn[1] @33 I text kccfhdbn[2] @34 N text kccfhdbn[3] @35 O text kccfhdbn[4] @36 R text kccfhdbn[5] @37 A text kccfhdbn[6] @38 text kccfhdbn[7] @39 ub4 kccfhcsq @40 0x00002353 --Controlfile sequence number ub4 kccfhfsz @44 0x00016800 --所在数据文件块数=dba_data_files.blocks s_blkz kccfhbsz @48 0x00 ub2 kccfhfno @52 0x0001 --文件号file_id ub2 kccfhtyp @54 0x0003 --文件类型，03表示数据文件，06表示undo ub4 kccfhacid @56 0x00000000 ub4 kccfhcks @60 0x00000000 text kccfhtag[0] @64 text kccfhtag[1] @65 text kccfhtag[2] @66 text kccfhtag[3] @67 text kccfhtag[4] @68 text kccfhtag[5] @69 text kccfhtag[6] @70 text kccfhtag[7] @71 text kccfhtag[8] @72 text kccfhtag[9] @73 text kccfhtag[10] @74 text kccfhtag[11] @75 text kccfhtag[12] @76 text kccfhtag[13] @77 text kccfhtag[14] @78 text kccfhtag[15] @79 text kccfhtag[16] @80 text kccfhtag[17] @81 text kccfhtag[18] @82 text kccfhtag[19] @83 text kccfhtag[20] @84 text kccfhtag[21] @85 text kccfhtag[22] @86 text kccfhtag[23] @87 text kccfhtag[24] @88 text kccfhtag[25] @89 text kccfhtag[26] @90 text kccfhtag[27] @91 text kccfhtag[28] @92 text kccfhtag[29] @93 text kccfhtag[30] @94 text kccfhtag[31] @95 ub4 kcvfhrdb @96 0x00400208 --仅1号文件有值，代表root dba，本例中转换为10进制为4194824， --通过dbms_utility可以查看到正是1号文件520 Block。 --在11g中，dba 1,520 代表的是bootstrap$，10g是dba 1,377，10g以前是dba 1,417 --查询语句： --col SEGMENT_NAME for a15 --select segment_name,segment_type,header_file,header_block from dba_segments where header_block=520; struct kcvfhcrs, 8 bytes @100 --数据文件创建scn ub4 kscnbas @100 0x0000000e ub2 kscnwrp @104 0x0000 ub4 kcvfhcrt @108 0x3201eb02 --数据文件创建时间 ub4 kcvfhrlc @112 0x32a6fb05 --resetlog时间 struct kcvfhrls, 8 bytes @116 --resetlog scn ub4 kscnbas @116 0x00170c23 ub2 kscnwrp @120 0x0000 ub4 kcvfhbti @124 0x00000000 --begin hot backup time struct kcvfhbsc, 8 bytes @128 --last backup stared scn ub4 kscnbas @128 0x00000000 ub2 kscnwrp @132 0x0000 ub2 kcvfhbth @136 0x0000 --begin hot backup redo thread ub2 kcvfhsta @138 0x2004 (KCVFHOFZ) --数据文件状态，04为正常，00为关闭，01为begin backup struct kcvfhckp, 36 bytes @484 --检查点信息 struct kcvcpscn, 8 bytes @484 --检查点scn ub4 kscnbas @484 0x003443f4 ub2 kscnwrp @488 0x0000 ub4 kcvcptim @492 0x331aa11c --检查点时间 ub2 kcvcpthr @496 0x0001 --检查点线程号 union u, 12 bytes @500 struct kcvcprba, 12 bytes @500 --Checkpoint scn redo rda(参照前文[重做日志]关于rba的描述) ub4 kcrbaseq @500 0x000000ae --log序列号 ub4 kcrbabno @504 0x00000002 --块号 ub2 kcrbabof @508 0x0010 --偏移量 ub1 kcvcpetb[0] @512 0x02 --最大线程数 ub1 kcvcpetb[1] @513 0x00 ub1 kcvcpetb[2] @514 0x00 ub1 kcvcpetb[3] @515 0x00 ub1 kcvcpetb[4] @516 0x00 ub1 kcvcpetb[5] @517 0x00 ub1 kcvcpetb[6] @518 0x00 ub1 kcvcpetb[7] @519 0x00 ub4 kcvfhcpc @140 0x00000253 --v$datafile_header.CHECKPOINT_COUNT，数据文件发生Checkpoint的次数 ub4 kcvfhrts @144 0x331aa119 --recoved time ub4 kcvfhccc @148 0x00000252 --控制文件检查点次数 struct kcvfhbcp, 36 bytes @152 --backup Checkpoint struct kcvcpscn, 8 bytes @152 --begin backup checkpoint scn ub4 kscnbas @152 0x00000000 ub2 kscnwrp @156 0x0000 ub4 kcvcptim @160 0x00000000 --begin backup checkpoint time ub2 kcvcpthr @164 0x0000 --begin backup checkpoint thread union u, 12 bytes @168 struct kcvcprba, 12 bytes @168 --begin backup checkpoint rba ub4 kcrbaseq @168 0x00000000 ub4 kcrbabno @172 0x00000000 ub2 kcrbabof @176 0x0000 ub1 kcvcpetb[0] @180 0x00 ub1 kcvcpetb[1] @181 0x00 ub1 kcvcpetb[2] @182 0x00 ub1 kcvcpetb[3] @183 0x00 ub1 kcvcpetb[4] @184 0x00 ub1 kcvcpetb[5] @185 0x00 ub1 kcvcpetb[6] @186 0x00 ub1 kcvcpetb[7] @187 0x00 ub4 kcvfhbhz @312 0x00000000 struct kcvfhxcd, 16 bytes @316 ub4 space_kcvmxcd[0] @316 0x00000000 ub4 space_kcvmxcd[1] @320 0x00000000 ub4 space_kcvmxcd[2] @324 0x00000000 ub4 space_kcvmxcd[3] @328 0x00000000 sword kcvfhtsn @332 0 --表空间号:v$tablespace.ts$ ub2 kcvfhtln @336 0x0006 --表空间名字，最大为30字节 text kcvfhtnm[0] @338 S text kcvfhtnm[1] @339 Y text kcvfhtnm[2] @340 S text kcvfhtnm[3] @341 T text kcvfhtnm[4] @342 E text kcvfhtnm[5] @343 M text kcvfhtnm[6] @344 text kcvfhtnm[7] @345 text kcvfhtnm[8] @346 text kcvfhtnm[9] @347 text kcvfhtnm[10] @348 text kcvfhtnm[11] @349 text kcvfhtnm[12] @350 text kcvfhtnm[13] @351 text kcvfhtnm[14] @352 text kcvfhtnm[15] @353 text kcvfhtnm[16] @354 text kcvfhtnm[17] @355 text kcvfhtnm[18] @356 text kcvfhtnm[19] @357 text kcvfhtnm[20] @358 text kcvfhtnm[21] @359 text kcvfhtnm[22] @360 text kcvfhtnm[23] @361 text kcvfhtnm[24] @362 text kcvfhtnm[25] @363 text kcvfhtnm[26] @364 text kcvfhtnm[27] @365 text kcvfhtnm[28] @366 text kcvfhtnm[29] @367 ub4 kcvfhrfn @368 0x00000001 --相对文件号 struct kcvfhrfs, 8 bytes @372 --Recovery fuzzy scn ub4 kscnbas @372 0x00000000 ub2 kscnwrp @376 0x0000 ub4 kcvfhrft @380 0x00000000 --Recovery fuzzy time struct kcvfhafs, 8 bytes @384 --Absolute fuzzy scn ub4 kscnbas @384 0x00000000 ub2 kscnwrp @388 0x0000 ub4 kcvfhbbc @392 0x00000000 --Backup Block Count ub4 kcvfhncb @396 0x00000000 --marked media Corrupt Blocks ub4 kcvfhmcb @400 0x00000000 --Media Corrupt Blocks ub4 kcvfhlcb @404 0x00000000 --Logically Corrupt Blocks ub4 kcvfhbcs @408 0x00000000 --Backup Completion timeStamp ub2 kcvfhofb @412 0x000a ub2 kcvfhnfb @414 0x000a ub4 kcvfhprc @416 0x323c286e --prev reset logs time struct kcvfhprs, 8 bytes @420 --prev reset logs scn ub4 kscnbas @420 0x001084e6 ub2 kscnwrp @424 0x0000 struct kcvfhprfs, 8 bytes @428 ub4 kscnbas @428 0x00000000 ub2 kscnwrp @432 0x0000 ub4 kcvfhtrt @444 0x00000000 --Terminal Recovery Stamp 图1 Block Structure图2 Header block type 2. 数据块结构数据块的结构如图三所示，包括cache层，事务层和数据层。图3 Data Block Structure123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051BBED&gt; set dba 8,11477 DBA 0x02002cd5 (33565909 8,11477)BBED&gt; map /v File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Dba:0x02002cd5------------------------------------------------------------ KTB Data Block (Table/Cluster) --表示属于KTB数据块 struct kcbh, 20 bytes @0 --数据块头，其定义跟kcvfh一样 ub1 type_kcbh @0 ub1 frmt_kcbh @1 ub1 spare1_kcbh @2 ub1 spare2_kcbh @3 ub4 rdba_kcbh @4 ub4 bas_kcbh @8 ub2 wrp_kcbh @12 ub1 seq_kcbh @14 ub1 flg_kcbh @15 ub2 chkval_kcbh @16 ub2 spare3_kcbh @18 struct ktbbh, 72 bytes @20 --事务层 ub1 ktbbhtyp @20 union ktbbhsid, 4 bytes @24 struct ktbbhcsc, 8 bytes @28 sb2 ktbbhict @36 ub1 ktbbhflg @38 ub1 ktbbhfsl @39 ub4 ktbbhfnx @40 struct ktbbhitl[2], 48 bytes @44 struct kdbh, 14 bytes @100 --数据层 ub1 kdbhflag @100 sb1 kdbhntab @101 sb2 kdbhnrow @102 sb2 kdbhfrre @104 sb2 kdbhfsbo @106 sb2 kdbhfseo @108 sb2 kdbhavsp @110 sb2 kdbhtosp @112 struct kdbt[1], 4 bytes @114 --表目录层 sb2 kdbtoffs @114 sb2 kdbtnrow @116 sb2 kdbr[9] @118 --行目录层 ub1 freespace[7430] @136 --空闲空间 ub1 rowdata[622] @7566 --实际行数据 ub4 tailchk @8188 分别打印上述结构，看看具体内容(kcbh(block header structure)定义如kcvfh.kcvfhbfh一致，均为数据块头，此处不在赘述)。 2.1 ktbbh(Transaction Fixed Header Structure)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354BBED&gt; p ktbbhstruct ktbbh, 72 bytes @20 ub1 ktbbhtyp @20 0x01 (KDDBTDATA) --块类型，1为data，2为index union ktbbhsid, 4 bytes @24 --Segment/Object ID，如果两者一致，表示对象没有被Truncate过 ub4 ktbbhsg1 @24 0x00014b01 ub4 ktbbhod1 @24 0x00014b01 struct ktbbhcsc, 8 bytes @28 --块最后清除的SCN ub4 kscnbas @28 0x0021d786 ub2 kscnwrp @32 0x0000 sb2 ktbbhict @36 2 --ITL slot number，事务槽号 ub1 ktbbhflg @38 0x32 (NONE) --0=on the free list ub1 ktbbhfsl @39 0x00 --ITL free list slot ub4 ktbbhfnx @40 0x02002cd0 --DBA of next block on the freelist struct ktbbhitl[0], 24 bytes @44 --ITL list index struct ktbitxid, 8 bytes @44 --ITL xid ub2 kxidusn @44 0x0003 --usn ub2 kxidslt @46 0x000b --slot ub4 kxidsqn @48 0x0000050d --Sequence struct ktbituba, 8 bytes @52 --uba ub4 kubadba @52 0x00c006d4 ub2 kubaseq @56 0x00d2 ub1 kubarec @58 0x34 ub2 ktbitflg @60 0x2009 (KTBFUPB) union _ktbitun, 2 bytes @62 sb2 _ktbitfsc @62 0 ub2 _ktbitwrp @62 0x0000 ub4 ktbitbas @64 0x0021d795 struct ktbbhitl[1], 24 bytes @68 struct ktbitxid, 8 bytes @68 ub2 kxidusn @68 0x0000 ub2 kxidslt @70 0x0000 ub4 kxidsqn @72 0x00000000 struct ktbituba, 8 bytes @76 ub4 kubadba @76 0x00000000 ub2 kubaseq @80 0x0000 ub1 kubarec @82 0x00 ub2 ktbitflg @84 0x0000 (NONE) union _ktbitun, 2 bytes @86 sb2 _ktbitfsc @86 0 ub2 _ktbitwrp @86 0x0000 ub4 ktbitbas @88 0x00000000 2.2 kdbh(Data Header Structure)1234567891011121314151617BBED&gt; p kdbhstruct kdbh, 14 bytes @100 ub1 kdbhflag @100 0x00 (NONE) sb1 kdbhntab @101 1 --表的个数，clusters&gt;1 sb2 kdbhnrow @102 9 --块中包含的行数 sb2 kdbhfrre @104 -1 --是否在空闲列表，-1表示不在空闲列表 sb2 kdbhfsbo @106 36 --freespace start offset sb2 kdbhfseo @108 7466 --freespace end offset sb2 kdbhavsp @110 7430 --块内可用空间 sb2 kdbhtosp @112 7430 --事务提交后所有的可用空间 2.3 kdbt(Table Directory Entry Structure)1234BBED&gt; p kdbtstruct kdbt[0], 4 bytes @114 sb2 kdbtoffs @114 0 sb2 kdbtnrow @116 9 2.4 kdbr(Row Directory)kdbr代表行目录，后面的n是代表该块中存储了多少行数据记录，从第0行开始计算。下例中，表示该块中存储了9行数据。12345678910BBED&gt; p kdbrsb2 kdbr[0] @118 8015sb2 kdbr[1] @120 7946sb2 kdbr[2] @122 7876sb2 kdbr[3] @124 7803sb2 kdbr[4] @126 7744sb2 kdbr[5] @128 7677sb2 kdbr[6] @130 7612sb2 kdbr[7] @132 7538sb2 kdbr[8] @134 7466 结合*号可以打印此块中的第n行数据1234567891011121314151617181920212223242526272829303132333435363738394041BBED&gt; p *kdbr[2]rowdata[410]------------ub1 rowdata[410] @7976 0x2c--2c代表正常为删除数据，3c代表标记为删除的数据行，第二列是该行数据的偏移量，第三列为标识符fb。BBED&gt; d /v File: /oradata/datafile/linora/perf01.dbf (8) Block: 11477 Offsets: 7976 to 8191 Dba:0x02002cd5------------------------------------------------------- 2c010b02 c203084a 414e6e69 66657206 l ,......JANnifer. 5768616c 656e074a 5748414c 454e0c35 l Whalen.JWHALEN.5 31352e31 32332e34 34343407 78670911 l 15.123.4444.xg.. 01010107 41445f41 53535402 c22dff03 l ....AD_ASST..-.. c2020202 c10b2c01 0b03c202 6407446f l ......,.....d.Do 75676c61 73054772 616e7406 44475241 l uglas.Grant.DGRA 4e540c36 35302e35 30372e39 38343407 l NT.650.507.9844. 786c010d 01010108 53485f43 4c45524b l xl......SH_CLERK 02c21bff 03c20219 02c1332c 010b03c2 l ..........3,.... 02630644 6f6e616c 64084f43 6f6e6e65 l .c.Donald.OConne 6c6c0844 4f434f4e 4e454c0c 3635302e l ll.DOCONNEL.650. 3530372e 39383333 07786b06 15010101 l 507.9833.xk..... 0853485f 434c4552 4b02c21b ff03c202 l .SH_CLERK....... 1902c133 010695d7 l ...3....BBED&gt; x /rncccctcnnnnrowdata[410] @7976 ------------flag@7976: 0x2c (KDRHFL, KDRHFF, KDRHFH)lock@7977: 0x01cols@7978: 11col 0[2] @7979: 200 col 1[8] @7982: JANnifercol 2[6] @7991: Whalencol 3[7] @7998: JWHALENcol 4[12] @8006: 515.123.4444col 5[7] @8019: 2003-09-17 00:00:00 col 6[7] @8027: AD_ASSTcol 7[2] @8035: 4400 col 8[0] @8038: *NULL*col 9[3] @8039: 101 col 10[2] @8043: 10 Reference：dissassembling_the_data_block","link":"/bbed-structure.html"},{"title":"Oracle修改数据库名称","text":"在DBA日常维护中，有时候会遇到需要修改数据库名称或者dbid的情况，可利用nid的工具对dbid和db_name进行修改，在某些情况下，还可以利用重建控制文件对db_name进行修改。 1. nid工具 1.1 nid修改dbid查询当前dbid1234567SQL&gt; select dbid from v$database; DBID----------1375890310SQL&gt; nid工具语法123456789101112131415[oracle@:/home/oracle]$ nid help=yDBNEWID: Release 11.2.0.3.0 - Production on Sat Jun 28 07:19:12 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.Keyword Description (Default)----------------------------------------------------TARGET Username/Password (NONE)DBNAME New database name (NONE)LOGFILE Output Log (NONE)REVERT Revert failed change NOSETNAME Set a new database name only NOAPPEND Append to output log NOHELP Displays these messages NO 启动数据库至mount状态：1234567891011121314SQL&gt; startup mount pfile=&apos;/oracle/test/pfile.ora&apos;;ORACLE instance started.Total System Global Area 1570009088 bytesFixed Size 2221840 bytesVariable Size 922749168 bytesDatabase Buffers 637534208 bytesRedo Buffers 7503872 bytesDatabase mounted.SQL&gt; select dbid,name,open_mode,activation#,created from v$database; DBID NAME OPEN_MODE ACTIVATION# CREATED---------- --------- -------------------- ----------- ---------1375890310 ORCLTEST MOUNTED 2598928391 28-JUN-14 调用nid修改dbid12345678910111213141516171819202122232425262728293031323334[oracle@:/oracle]$ nid TARGET=sysDBNEWID: Release 11.2.0.3.0 - Production on Sat Jun 28 07:37:11 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.Password: Connected to database ORCLTEST (DBID=1375890310)Connected to server version 11.2.0Control Files in database: /oracle/oradata/orcltest/control01.ctl /oracle/oradata/orcltest/control02.ctlChange database ID of database ORCLTEST? (Y/[N]) =&gt; yProceeding with operationChanging database ID from 1375890310 to 2598911656 Control File /oracle/oradata/orcltest/control01.ctl - modified Control File /oracle/oradata/orcltest/control02.ctl - modified Datafile /oracle/oradata/orcltest/system01.db - dbid changed Datafile /oracle/oradata/orcltest/sysaux01.db - dbid changed Datafile /oracle/oradata/orcltest/undotbs01.db - dbid changed Datafile /oracle/oradata/orcltest/users01.db - dbid changed Control File /oracle/oradata/orcltest/control01.ctl - dbid changed Control File /oracle/oradata/orcltest/control02.ctl - dbid changed Instance shut downDatabase ID for database ORCLTEST changed to 2598911656.All previous backups and archived redo logs for this database are unusable.Database has been shutdown, open database with RESETLOGS option.Succesfully changed database ID.DBNEWID - Completed succesfully. 查看dbid，发现已经改变。123456789101112131415161718192021SQL&gt; startupORACLE instance started.Total System Global Area 1570009088 bytesFixed Size 2221840 bytesVariable Size 922749168 bytesDatabase Buffers 637534208 bytesRedo Buffers 7503872 bytesDatabase mounted.ORA-01589: must use RESETLOGS or NORESETLOGS option for database openSQL&gt; alter database open resetlogs;Database altered.SQL&gt; select dbid,name,open_mode,activation#,created from v$database; DBID NAME OPEN_MODE ACTIVATION# CREATED---------- --------- -------------------- ----------- ---------2598911656 ORCLTEST READ WRITE 2598914511 28-JUN-14 注意，使用nid需要在mount状态下，且上一次关闭必须是干净的shutdown，否则会报NID-00135: There are 1 active threads的错误。 1.2 nid修改dbname同样启动至mount状态进行修改1234567891011121314151617181920212223242526272829303132[oracle@:/home/oracle]$ nid TARGET=sys/oracle DBNAME=oratest SETNAME=yesDBNEWID: Release 11.2.0.3.0 - Production on Sat Jun 28 07:43:44 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.Connected to database ORCLTEST (DBID=2598911656)Connected to server version 11.2.0Control Files in database: /oracle/oradata/orcltest/control01.ctl /oracle/oradata/orcltest/control02.ctlChange database name of database ORCLTEST to ORATEST? (Y/[N]) =&gt; yProceeding with operationChanging database name from ORCLTEST to ORATEST Control File /oracle/oradata/orcltest/control01.ctl - modified Control File /oracle/oradata/orcltest/control02.ctl - modified Datafile /oracle/oradata/orcltest/system01.db - wrote new name Datafile /oracle/oradata/orcltest/sysaux01.db - wrote new name Datafile /oracle/oradata/orcltest/undotbs01.db - wrote new name Datafile /oracle/oradata/orcltest/users01.db - wrote new name Control File /oracle/oradata/orcltest/control01.ctl - wrote new name Control File /oracle/oradata/orcltest/control02.ctl - wrote new name Instance shut downDatabase name changed to ORATEST.Modify parameter file and generate a new password file before restarting.Succesfully changed database name.DBNEWID - Completed succesfully. 修改原有的pfile，将dbname改为目前的，至修改dbname，不需要resetlogs开启。12345SQL&gt; select dbid,name,open_mode,activation#,created from v$database; DBID NAME OPEN_MODE ACTIVATION# CREATED---------- --------- -------------------- ----------- ---------2598911656 ORATEST READ WRITE 2598914511 28-JUN-14 如果需要同时修改dbname及dbid，则在nid TARGET=sys/oracle DBNAME=oratest SETNAME=yes中取消掉setname=yes即可。 2. 修改控制文件通过修改控制文件去修改dbname，在这里模拟一种极端情况：7*24关键系统中，用户早上8点误删除数据，在下午5点发现，要求DBA恢复出8点误删除的数据，再没有多余的机器下，又不可能直接还原，只能通过备份还原到本机的不同目录，然后将丢失的数据重新插入。首先在生产库查找原有备份，并且恢复spfile到指定目录。12345678910111213141516171819202122232425262728RMAN&gt; list backup of spfile;using target database control file instead of recovery catalogList of Backup Sets===================BS Key Type LV Size Device Type Elapsed Time Completion Time ------- ---- -- ---------- ----------- ------------ -------------------9 Full 7.42M DISK 00:00:01 2014-06-28 07:03:01 BP Key: 9 Status: AVAILABLE Compressed: NO Tag: HOT_DB_BK_LEVEL0 Piece Name: /oracle/backup/bk_9_1_851410980_ORCL SPFILE Included: Modification time: 2014-06-28 02:46:09 SPFILE db_unique_name: ORCLRMAN&gt; restore spfile to &apos;/oracle/test/spfile.ora&apos; from &apos;/oracle/backup/bk_9_1_851410980_ORCL&apos;;Starting restore at 2014-06-28 08:14:54allocated channel: ORA_DISK_1channel ORA_DISK_1: SID=136 device type=DISKchannel ORA_DISK_1: restoring spfile from AUTOBACKUP /oracle/backup/bk_9_1_851410980_ORCLchannel ORA_DISK_1: SPFILE restore from AUTOBACKUP completeFinished restore at 2014-06-28 08:14:55[oracle@:/home/oracle]$ export ORACLE_SID=orcltestSQL&gt; create pfile from spfile=&apos;/oracle/test/spfile.ora&apos;;File created. 使用vi编辑pfile，调整相应参数，包括db_name，控制文件存放路径及dump，adr存放目录，同时创建相关目录并且授权。从生产端备份控制文件至trace file。123SQL&gt; alter database backup controlfile to trace as &apos;/oracle/test/ctl.txt&apos;;Database altered. ctl.txt的关键内容12345678910111213141516171819CREATE CONTROLFILE REUSE DATABASE &quot;ORCL&quot; RESETLOGS ARCHIVELOG MAXLOGFILES 16 MAXLOGMEMBERS 3 MAXDATAFILES 100 MAXINSTANCES 8 MAXLOGHISTORY 292LOGFILE GROUP 1 &apos;/oracle/oradata/orcl/redo01.log&apos; SIZE 50M BLOCKSIZE 512, GROUP 2 &apos;/oracle/oradata/orcl/redo02.log&apos; SIZE 50M BLOCKSIZE 512, GROUP 3 &apos;/oracle/oradata/orcl/redo03.log&apos; SIZE 50M BLOCKSIZE 512-- STANDBY LOGFILEDATAFILE &apos;/oracle/oradata/orcl/system01.dbf&apos;, &apos;/oracle/oradata/orcl/sysaux01.dbf&apos;, &apos;/oracle/oradata/orcl/undotbs01.dbf&apos;, &apos;/oracle/oradata/orcl/users01.dbf&apos;, &apos;/oracle/oradata/orcl/fung01.dbf&apos;CHARACTER SET AL32UTF8; 需要修改为如下内容12345678910111213141516171819CREATE CONTROLFILE set DATABASE &quot;ORCLTEST&quot; RESETLOGS ARCHIVELOG MAXLOGFILES 16 MAXLOGMEMBERS 3 MAXDATAFILES 100 MAXINSTANCES 8 MAXLOGHISTORY 292LOGFILE GROUP 1 &apos;/oracle/oradata/orcltest/redo01.log&apos; SIZE 50M BLOCKSIZE 512, GROUP 2 &apos;/oracle/oradata/orcltest/redo02.log&apos; SIZE 50M BLOCKSIZE 512, GROUP 3 &apos;/oracle/oradata/orcltest/redo03.log&apos; SIZE 50M BLOCKSIZE 512-- STANDBY LOGFILEDATAFILE &apos;/oracle/oradata/orcltest/system01.dbf&apos;, &apos;/oracle/oradata/orcltest/sysaux01.dbf&apos;, &apos;/oracle/oradata/orcltest/undotbs01.dbf&apos;, &apos;/oracle/oradata/orcltest/users01.dbf&apos;, &apos;/oracle/oradata/orcltest/fung01.dbf&apos;CHARACTER SET AL32UTF8; 在执行创建语句之前，需要创建好相应的目录，并且利用rman在生产的SID上restore数据文件至相应目录，此例中为/oracle/oradata/orcltest。12345678910111213141516171819202122232425262728293031323334353637383940RMAN&gt; run&#123;2&gt; allocate channel c1 type disk;3&gt; set newname for datafile 1 to &apos;/oracle/oradata/orcltest/system01.dbf&apos;;4&gt; set newname for datafile 2 to &apos;/oracle/oradata/orcltest/sysaux01.dbf&apos;;5&gt; set newname for datafile 3 to &apos;/oracle/oradata/orcltest/undotbs01.dbf&apos;;6&gt; set newname for datafile 4 to &apos;/oracle/oradata/orcltest/users01.dbf&apos;;7&gt; set newname for datafile 5 to &apos;/oracle/oradata/orcltest/fung01.dbf&apos;;8&gt; restore database;9&gt; release channel c1;10&gt; &#125;allocated channel: c1channel c1: SID=72 device type=DISKexecuting command: SET NEWNAMEexecuting command: SET NEWNAMEexecuting command: SET NEWNAMEexecuting command: SET NEWNAMEexecuting command: SET NEWNAMEStarting restore at 2014-06-28 08:30:41channel c1: starting datafile backup set restorechannel c1: specifying datafile(s) to restore from backup setchannel c1: restoring datafile 00001 to /oracle/oradata/orcltest/system01.dbfchannel c1: restoring datafile 00002 to /oracle/oradata/orcltest/sysaux01.dbfchannel c1: restoring datafile 00003 to /oracle/oradata/orcltest/undotbs01.dbfchannel c1: restoring datafile 00004 to /oracle/oradata/orcltest/users01.dbfchannel c1: restoring datafile 00005 to /oracle/oradata/orcltest/fung01.dbfchannel c1: reading from backup piece /oracle/backup/bk_8_1_851410965_ORCLchannel c1: piece handle=/oracle/backup/bk_8_1_851410965_ORCL tag=HOT_DB_BK_LEVEL0channel c1: restored backup piece 1channel c1: restore complete, elapsed time: 00:00:25Finished restore at 2014-06-28 08:31:06released channel: c1 注意上述语句，不要执行switch datafile命令，因为我们仅仅需要还原数据文件，recover的动作交由后续创建好了的control file去完成。restore完后，在sid=orcltest上创建控制文件，之后进行恢复。123456789101112131415161718192021SQL&gt; CREATE CONTROLFILE set DATABASE &quot;ORCLTEST&quot; RESETLOGS ARCHIVELOG 2 MAXLOGFILES 16 3 MAXLOGMEMBERS 3 4 MAXDATAFILES 100 5 MAXINSTANCES 8 6 MAXLOGHISTORY 292 7 LOGFILE 8 GROUP 1 &apos;/oracle/oradata/orcltest/redo01.log&apos; SIZE 50M BLOCKSIZE 512, 9 GROUP 2 &apos;/oracle/oradata/orcltest/redo02.log&apos; SIZE 50M BLOCKSIZE 512, 10 GROUP 3 &apos;/oracle/oradata/orcltest/redo03.log&apos; SIZE 50M BLOCKSIZE 512 11 -- STANDBY LOGFILE 12 DATAFILE 13 &apos;/oracle/oradata/orcltest/system01.dbf&apos;, 14 &apos;/oracle/oradata/orcltest/sysaux01.dbf&apos;, 15 &apos;/oracle/oradata/orcltest/undotbs01.dbf&apos;, 16 &apos;/oracle/oradata/orcltest/users01.dbf&apos;, 17 &apos;/oracle/oradata/orcltest/fung01.dbf&apos; 18 CHARACTER SET AL32UTF8 19 ;Control file created. 创建完成后，数据库会自动进入mount状态，执行recover。1234567891011121314151617181920212223242526272829303132333435363738394041RMAN&gt; recover database until time &quot;to_date(&apos;2014-07-24 05:20:00&apos;,&apos;yyyy-mm-dd HH24:mi:ss&apos;)&quot;;Starting recover at 2014-06-28 08:40:33using channel ORA_DISK_1starting media recoveryarchived log for thread 1 with sequence 25 is already on disk as file /oracle/arch/1_25_848109574.arcarchived log for thread 1 with sequence 26 is already on disk as file /oracle/arch/1_26_848109574.arcarchived log for thread 1 with sequence 27 is already on disk as file /oracle/arch/1_27_848109574.arcarchived log for thread 1 with sequence 28 is already on disk as file /oracle/arch/1_28_848109574.arcarchived log for thread 1 with sequence 29 is already on disk as file /oracle/arch/1_29_848109574.arcarchived log for thread 1 with sequence 30 is already on disk as file /oracle/arch/1_30_848109574.arcarchived log for thread 1 with sequence 31 is already on disk as file /oracle/arch/1_31_848109574.arcarchived log for thread 1 with sequence 32 is already on disk as file /oracle/arch/1_32_848109574.arcarchived log for thread 1 with sequence 33 is already on disk as file /oracle/arch/1_33_848109574.arcarchived log for thread 1 with sequence 34 is already on disk as file /oracle/arch/1_34_848109574.arcarchived log file name=/oracle/arch/1_25_848109574.arc thread=1 sequence=25archived log file name=/oracle/arch/1_26_848109574.arc thread=1 sequence=26archived log file name=/oracle/arch/1_27_848109574.arc thread=1 sequence=27archived log file name=/oracle/arch/1_28_848109574.arc thread=1 sequence=28archived log file name=/oracle/arch/1_29_848109574.arc thread=1 sequence=29archived log file name=/oracle/arch/1_30_848109574.arc thread=1 sequence=30archived log file name=/oracle/arch/1_31_848109574.arc thread=1 sequence=31archived log file name=/oracle/arch/1_32_848109574.arc thread=1 sequence=32archived log file name=/oracle/arch/1_33_848109574.arc thread=1 sequence=33archived log file name=/oracle/arch/1_34_848109574.arc thread=1 sequence=34unable to find archived logarchived log thread=1 sequence=35RMAN-00571: ===========================================================RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============RMAN-00571: ===========================================================RMAN-03002: failure of recover command at 06/28/2014 08:40:36RMAN-06054: media recovery requesting unknown archived log for thread 1 with sequence 35 and starting SCN of 328834RMAN&gt; sql &apos;alter database open resetlogs&apos;;sql statement: alter database open resetlogsSQL&gt; select dbid,name,open_mode,activation#,created from v$database; DBID NAME OPEN_MODE ACTIVATION# CREATED---------- --------- -------------------- ----------- ---------1375890310 ORCLTEST READ WRITE 2598924579 28-JUN-14 对于新库，需要的话可用以下命令创建密码文件。1orapwd file=$ORACLE_HOME/dbs/orapw$ORACLE_SID password=oracle entries=5 force=y 在以上所有操作中，特别是生产环境下，oracle对所有open resetlogs的操作都有个建议：先备份数据库，在执行修改，修改完成后立即再次执行全备。Reference:ID 224266.1ID 136183.1ID 15390.1ID 18070.1Oracle® Database Utilities 11g Release 2 (11.2)","link":"/change-database-name-in-oracle.html"},{"title":"12C CDB简介","text":"2012年9月，Larry Ellison与旧金山OOW中透露12c的最重要的新特性：Pluggable Database。随后于2013年六月发布Linux 12c版本。 1. 关于多租户环境Oracle database 12c包含了过百项的新特色，其中最引人注目的还是Pluggable Database，中文翻译为可插拔数据库或者叫多租户环境。在过去的数据库服务器上，比较常见的是一台服务器只包含一个数据库或实例(RAC)，然后很多情况下，这种结构对资源的利用不够经济。在一些硬体条件足够的环境下，一台服务器可能支持多个数据库，或者一个数据库以schema分开对多个应用系统提供服务。但以上方案均有缺点： 主机数据库一对一软硬件资源无法共享，造成资源浪费；每个DB都要存储一份Oracle DB提供的组件，如DBMS_XXX，因此，额外带来存储的开销。 一台主机对应多个数据库每个数据库需要对应的实例，因此，内存无法由Oracle管理系统自动调用；每个DB都要存储一份Oracle DB提供的组件，如DBMS_XXX，因此，额外带来存储的开销。 以schema方式提供多个应用服务各个应用的资料无法独立管理，且schema命名须规范，避免重复；无法将一个应用资料快速转移到其他数据库。为了解决资源共享而管理独立的问题，Oracle从12C开始推出多租户环境，即可插拔数据库。 2. 多租户架构Oracle多租户环境主要有两个组成部分：多租户容器数据库(multitenant container database, CDB)及可插拔数据库(pluggable database, PDB)。CDB是由一个数据库组成，可由一个或者多个instance(RAC)管理，如上图所示，每个CDB可包含root container(CDB$ROOT)，seed pluggable database container (PDB$SEED)和pluggable database container(PDBs)。 Root每个CDB有且只能有一个root container。CDB$ROOT存储Oracle提供的元数据(如数据字典或者Oracle提供的pl/sql包)及common user的账户资料，这个common user是每个容器都存在的用户，它可登入管理每个它有适当权限的PDB。 SeedSeed是创建PDB的模版，在每个CDB中，有且仅有一个，在PDB$SEED中，用户不能添加及修改其中对象。 PDBs每个CDB至多个包含252个PDB。PDB对于普通用户及开发人员来说，和以前版本的数据库没什么区别，从这个角度来说，如果某个PDB要搬迁至其他主机，并不需要进行任何修改，只需要将PDB搬迁至其他CDB即可。被拔除的PDB以一个XML文件形式存在，记录了此PDB相关的信息。 总结1.PDB允许我们快速建立空数据库(create pdb from pdb$seed)2.将non-CDB数据库导入PDB(使用Export/Import或者DBMS_PDB)3.快速复制PDB(Clone PDB)4.快速搬迁PDB至其他CDB(unplug &amp; plug-in pdb)每个PDB是单独的数据库，相互独立存在(但在同一个CDB中，共用同一个实例)，Oracle将本身的数据字典和PDB上的数据字典彻底分开，分别存放于root，seed及PDB中，因此，每一个PDB将系统本身的资料，数据字典及程序代码等单独存放在各自的PDB中，这样就能方便管理者快速拔除及插入。同时，每一个PDB都会有自己的system表空间，用于存放本身相关的数据字典等元数据。而由Oracle本身提供的，各个PDB共享的元数据及物件，则存入CBD$ROOT的数据字典中。在升级数据库的时候，只需要升级CDB$ROOT，其下所有的PDB会一起更新。 To be continued! Reference：Oracle® Database New Features Guide 12c Release 1 (12.1)Managing a Multitenant Environment","link":"/cdb-overview.html"},{"title":"Clustering Factor聚簇因子","text":"聚簇因子记录了当扫描索引时所读取数据块的数量。普通表即堆表，数据存放在磁盘都是无序的， 因此，根据索引查找的数据有可能在同一个块里，有可能在不同块里，聚簇因子正是衡量这个的标准。由上述可知，聚簇因子越小，表示一个表的数据越聚簇，即查询表的操作时候，扫描数据块的数量比较少。如果聚簇因子很高，很明显，相应的IO操作就要多。 如果聚簇因子接近于这个表的存储数据块数量，那么，这张表是按照索引字段的顺序存储的。如果聚簇因子接近于这个表的行数，那说明这张表不是按索引字段顺序存储的。 1）如果越有序，即相邻的键值存储在相同的block，那么这时候Clustering Factor 的值就越低 2）如果不是很有序，即键值是随机的存储在block上，这样在读取键值时，可能就需要一次又一次的去访问相同的block，从而增加了I/O 聚簇因子的计算方法如下： 1） 索引扫描 2） 比较某行的rowid和前一行的rowid，如果这两个rowid不属于同一个数据块，那么cluster factor增加 3） 整个索引扫描完毕后，就得到了该索引的cluster factor 从USER_INDEXES视图可以查看Clustering Factor的大小： 1234567SELECT a.table_name, a.index_name, a.CLUSTERING_FACTOR, a.distinct_keys / a.num_rows selectivity, b.blocks FROM user_indexes a, user_tables b WHERE a.num_rows &gt; 0 AND a.table_name = b.table_name 示例： 1. 创建空表 12345CREATE TABLE obj AS SELECT * FROM dba_objects WHERE 1 = 2; 2. 无序插入数据使得数据不均匀分布 123456789101112131415161718192021222324252627282930BEGIN FOR i IN 1 .. 10 LOOP INSERT /*+append*/ INTO obj SELECT * FROM dba_objects ORDER BY i; COMMIT; END LOOP; END; /SQL&gt; select count(*) from obj; COUNT(*) ---------- 501320 --查看表大小 set wrap off col owner for a10 col segment_name for a15 SELECT owner, segment_name, blocks, extents, bytes / 1024 / 1024 || &apos;M&apos; &quot;size&quot; FROM dba_segments WHERE owner = &apos;FUNG&apos; AND segment_name = &apos;OBJ&apos;; OWNER SEGMENT_NAME BLOCKS EXTENTS size ---------- --------------- ---------- ----------------- FUNG OBJ 7040 70 55M 3. 创建索引 123456789101112create index obj_id_idx on fung.obj(object_id); --查看索引大小 SELECT owner, segment_name, blocks, extents, bytes / 1024 / 1024 || &apos;M&apos; &quot;size&quot; FROM dba_segments WHERE owner = &apos;FUNG&apos; AND segment_name = upper(&apos;obj_id_idx&apos;); OWNER SEGMENT_NAME BLOCKS EXTENTS size ---------- --------------- ---------- ------------ FUNG OBJ_ID_IDX 1152 24 9M 4. 收集统计信息 12345678910111213141516171819202122--未收集统计前聚簇因子 SELECT owner, index_name, clustering_factor, num_rows FROM dba_indexes WHERE owner = &apos;FUNG&apos; AND index_name = UPPER (&apos;obj_id_idx&apos;); OWNER INDEX_NAME CLUSTERING_FACTOR NUM_ROWS ---------- ------------------------------ ----------------- ---------- FUNG OBJ_ID_IDX 501310 501310 --收集统计信息 exec dbms_stats.gather_table_stats(&apos;FUNG&apos;,&apos;OBJ&apos;,cascade =&gt; true); --再次查看Inex Clustering Factor SELECT owner, index_name, clustering_factor, num_rows FROM dba_indexes WHERE owner = &apos;FUNG&apos; AND index_name = UPPER (&apos;obj_id_idx&apos;); OWNER INDEX_NAME CLUSTERING_FACTOR NUM_ROWS ---------- ------------------------------ ----------------- ---------- FUNG OBJ_ID_IDX 501310 501310 收集统计信息前后聚簇因子并没有变化，表示在创建索引的时候，会收集表中数据真正的行数。并且聚簇因子等于行数，表示表的聚簇因子是无序的。 5. 查询一个确定值的执行计划 1234567891011121314151617181920212223242526272829303132SQL&gt; set autot on exp stat SQL&gt; select * from obj where object_id=1501; Execution Plan ---------------------------------------------------------- Plan hash value: 1410530163 ------------------------------------------------------------------------------------------ | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | ------------------------------------------------------------------------------------------ | 0 | SELECT STATEMENT | | 10 | 930 | 14 (0)| 00:00:01 | | 1 | TABLE ACCESS BY INDEX ROWID| OBJ | 10 | 930 | 14 (0)| 00:00:01 | |* 2 | INDEX RANGE SCAN | OBJ_ID_IDX | 10 | | 3 (0)| 00:00:01 | ------------------------------------------------------------------------------------------ Predicate Information (identified by operation id): --------------------------------------------------- 2 - access(&quot;OBJECT_ID&quot;=1501) Statistics ---------------------------------------------------------- 1 recursive calls 0 db block gets 19 consistent gets 0 physical reads 404 redo size 1509 bytes sent via SQL*Net to client 492 bytes received via SQL*Net from client 2 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 10 rows processed 由执行计划可以看出，这个语句是走了索引的，cost值为13。 6. 查询一个范围值的执行计划 123456789101112131415161718192021222324252627282930SQL&gt; select * from obj where object_id&gt;1000 and object_id&lt;2000; Execution Plan ---------------------------------------------------------- Plan hash value: 730912574&lt;/div&gt; -------------------------------------------------------------------------- | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | -------------------------------------------------------------------------- | 0 | SELECT STATEMENT | | 8400 | 762K| 1576 (1)| 00:00:19 | |* 1 | TABLE ACCESS FULL| OBJ | 8400 | 762K| 1576 (1)| 00:00:19 | -------------------------------------------------------------------------- Predicate Information (identified by operation id): --------------------------------------------------- 1 - filter(&quot;OBJECT_ID&quot;1000) Statistics ---------------------------------------------------------- 1 recursive calls 0 db block gets 7693 consistent gets 0 physical reads 404 redo size 523611 bytes sent via SQL*Net to client 7807 bytes received via SQL*Net from client 667 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 9990 rows processed 全表扫描，cost为1576. 7. 刷新缓冲池，查看物理读跟执行计划 12345678910111213141516171819202122232425262728293031FUNG@linora&gt;alter system flush buffer_cache; FUNG@linora&gt;select * from obj where object_id&gt;1000 and object_id&lt;2000; Execution Plan ---------------------------------------------------------- Plan hash value: 730912574 -------------------------------------------------------------------------- | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | -------------------------------------------------------------------------- | 0 | SELECT STATEMENT | | 8400 | 762K| 1576 (1)| 00:00:19 | |* 1 | TABLE ACCESS FULL| OBJ | 8400 | 762K| 1576 (1)| 00:00:19 | -------------------------------------------------------------------------- Predicate Information (identified by operation id): --------------------------------------------------- 1 - filter(&quot;OBJECT_ID&quot;1000) Statistics ---------------------------------------------------------- 0 recursive calls 0 db block gets 7698 consistent gets 7025 physical reads 764 redo size 523611 bytes sent via SQL*Net to client 7807 bytes received via SQL*Net from client 667 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 9990 rows processed 产生了7025个物理读。 8. 强制索引，查看执行计划 12345678910111213141516171819202122232425262728293031FUNG@linora&gt;select /*+ index(obj obj_id_idx) */ * from obj where object_id&gt;1000 and object_id&lt;2000; Execution Plan ---------------------------------------------------------- Plan hash value: 1410530163 ------------------------------------------------------------------------------------------ | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | ------------------------------------------------------------------------------------------ | 0 | SELECT STATEMENT | | 8400 | 762K| 8426 (1)| 00:01:42 | | 1 | TABLE ACCESS BY INDEX ROWID| OBJ | 8400 | 762K| 8426 (1)| 00:01:42 | |* 2 | INDEX RANGE SCAN | OBJ_ID_IDX | 8400 | | 21 (0)| 00:00:01 | ------------------------------------------------------------------------------------------ Predicate Information (identified by operation id): --------------------------------------------------- 2 - access(&quot;OBJECT_ID&quot;&gt;1000 AND &quot;OBJECT_ID&quot;&lt;2000) Statistics ---------------------------------------------------------- 1 recursive calls 0 db block gets 10796 consistent gets 40 physical reads 8468 redo size 217089 bytes sent via SQL*Net to client 7807 bytes received via SQL*Net from client 667 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 9990 rows processed 强制索引后，使用了index range scan，cost由原来的1546变成了8615，即说明Oracle认为全表扫描还更为好。 9. 查看强制索引的物理读 1234567891011121314151617181920212223242526272829303132FUNG@linora&gt;alter system flush buffer_cache; select /*+ index(obj obj_id_idx) */ * from obj where object_id&gt;1000 and object_id&lt;2000 Execution Plan ---------------------------------------------------------- Plan hash value: 1410530163 ------------------------------------------------------------------------------------------ | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | ------------------------------------------------------------------------------------------ | 0 | SELECT STATEMENT | | 8400 | 762K| 8426 (1)| 00:01:42 | | 1 | TABLE ACCESS BY INDEX ROWID| OBJ | 8400 | 762K| 8426 (1)| 00:01:42 | |* 2 | INDEX RANGE SCAN | OBJ_ID_IDX | 8400 | | 21 (0)| 00:00:01 | ------------------------------------------------------------------------------------------ Predicate Information (identified by operation id): --------------------------------------------------- 2 - access(&quot;OBJECT_ID&quot;&gt;1000 AND &quot;OBJECT_ID&quot;&lt;2000) Statistics ---------------------------------------------------------- 0 recursive calls 0 db block gets 10680 consistent gets 257 physical reads 116 redo size 217089 bytes sent via SQL*Net to client 7807 bytes received via SQL*Net from client 667 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 9990 rows processed 这里的物理读要比全表扫描低很多，但为什么默认的执行计划Oracle却不选择走索引呢？因为Oracle认为走索引的cost会比全表扫描要大。而CBO就是基于cost来决定执行计划的。 对于索引的Cost，Oracle 是根据Clustering Factor参数来计算的，而我们的数据Clustering Factor参数很高，数据存储无序。 这就造成了Oracle 认为走索引的cost 比全表扫描大。 10. 降低聚簇因子 123456FUNG@linora&gt;truncate table obj; Table truncated. FUNG@linora&gt;insert /*+append */ into obj select * from obj1; 510370 rows created. FUNG@linora&gt;commit; Commit complete. 11. 查看表及索引信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253--obj表 SELECT owner, segment_name, blocks, extents, bytes / 1024 / 1024 || &apos;M&apos; &quot;size&quot; FROM dba_segments WHERE owner = &apos;FUNG&apos; AND segment_name = &apos;OBJ&apos;; OWNER SEGMENT_NAME BLOCKS EXTENTS size ---------- --------------- ---------- ---------- ----- FUNG OBJ 7040 70 55M --索引信息 SELECT owner, segment_name, segment_type, blocks, extents, bytes / 1024 / 1024 || &apos;M&apos; &quot;SIZE&quot; FROM dba_segments WHERE owner = &apos;FUNG&apos; AND segment_name = UPPER (&apos;obj_id_idx&apos;); OWNER SEGMENT_NAME SEGMENT_TYPE BLOCKS EXTENTS SIZE ---------- --------------- ---------------------- ---------- ----- FUNG OBJ_ID_IDX INDEX 1024 23 8M --索引聚餐因子 SELECT owner, index_name, clustering_factor, num_rows FROM dba_indexes WHERE owner = &apos;FUNG&apos; AND index_name = &apos;OBJ_ID_IDX&apos;; OWNER INDEX_NAME CLUSTERING_FACTOR NUM_ROWS ---------- ------------------------------ ----------------- ---------- FUNG OBJ_ID_IDX 501310 501310 --重建索引 SQL&gt; alter index obj_id_idx rebuild; --再次查看聚簇因子 SELECT owner, index_name, clustering_factor, num_rows FROM dba_indexes WHERE owner = &apos;FUNG&apos; AND index_name = &apos;OBJ_ID_IDX&apos;; OWNER INDEX_NAME CLUSTERING_FACTOR NUM_ROWS ---------- ---------- ----------------- ---------- FUNG OBJ_ID_IDX 7009 510310 --聚簇因子已经降为6883了。接着对表进行统计，然后与表的block再比较一次： exec dbms_stats.gather_table_stats(&apos;FUNG&apos;,&apos;OBJ&apos;,cascade =&gt; true); FUNG@linora&gt;select blocks from user_tables where table_name=&apos;OBJ&apos;; BLOCKS ---------- 7129 聚簇因子为7129，而表的block为7040，已经很接近了，说明相邻的行是存储在同一个数据块中的。 12. 再查看之前的执行计划 12345678910111213141516171819202122232425262728293031FUNG@linora&gt;select * from obj where object_id&gt;1000 and object_id&lt;2000 Execution Plan ---------------------------------------------------------- Plan hash value: 1410530163 ------------------------------------------------------------------------------------------ | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | ------------------------------------------------------------------------------------------ | 0 | SELECT STATEMENT | | 8374 | 760K| 137 (0)| 00:00:02 | | 1 | TABLE ACCESS BY INDEX ROWID| OBJ | 8374 | 760K| 137 (0)| 00:00:02 | |* 2 | INDEX RANGE SCAN | OBJ_ID_IDX | 8374 | | 21 (0)| 00:00:01 | ------------------------------------------------------------------------------------------ Predicate Information (identified by operation id): --------------------------------------------------- 2 - access(&quot;OBJECT_ID&quot;&gt;1000 AND &quot;OBJECT_ID&quot;&lt;2000) Statistics ---------------------------------------------------------- 1 recursive calls 0 db block gets 1468 consistent gets 0 physical reads 116 redo size 217089 bytes sent via SQL*Net to client 7807 bytes received via SQL*Net from client 667 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 9990 rows processed 很明显，已经走索引了，且cost值也从1546降低到137。 13. 再看看物理读 12345678910111213141516171819202122232425262728293031323334FUNG@linora&gt;alter system flush buffer_cache; System altered. FUNG@linora&gt;select * from obj where object_id&gt;1000 and object_id&lt;2000; Execution Plan ---------------------------------------------------------- Plan hash value: 1410530163 ------------------------------------------------------------------------------------------ | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | ------------------------------------------------------------------------------------------ | 0 | SELECT STATEMENT | | 8374 | 760K| 137 (0)| 00:00:02 | | 1 | TABLE ACCESS BY INDEX ROWID| OBJ | 8374 | 760K| 137 (0)| 00:00:02 | |* 2 | INDEX RANGE SCAN | OBJ_ID_IDX | 8374 | | 21 (0)| 00:00:01 | ------------------------------------------------------------------------------------------ Predicate Information (identified by operation id): --------------------------------------------------- 2 - access(&quot;OBJECT_ID&quot;&gt;1000 AND &quot;OBJECT_ID&quot;&lt;2000) Statistics ---------------------------------------------------------- 0 recursive calls 0 db block gets 1467 consistent gets 176 physical reads 0 redo size 217089 bytes sent via SQL*Net to client 7807 bytes received via SQL*Net from client 667 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 9990 rows processed 物理读也降低到了176，性能的提升还是挺大的。 通过以上说明和测试，可以看到Clustering Factor 也是索引健康的一个重要判断的标准。 其值越低越好。 它会影响CBO 选择正确的执行计划。但是要注意一点，Clustering Factor 总是趋势与不断恶化的。 EOF","link":"/clustering-factor.html"},{"title":"RAC DataGuard配置","text":"1.本文目的DataGuard 是 Oracle 数据库的一个功能，能够提供数据库的冗余。冗余是通过创建一个备用（物理复制）数据库实现，备库最好是在不同的地理位置或者在不同的磁盘上。备库通过应用主库上的变化来保持数据同步。备库可以使用重做日志应用同步(物理备库)。物理备库只安装软件，不创建实例。本文目的在于介绍Oracle 11gr2 RAC快速创建创建单机节点DataGuard的过程。 2.环境12345678主库：11gr2 RAC+ASM，DB_UNIQUE_NAME: rac11g 备库：11gr2 Single+ASM/FS，DB_UNIQUE_NAME: stdby ORACLE_SID:rac11g Primary hostname：fung01，fung02 Standby hostname：fung03 Oracle数据库软件版本： Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit Production操作系统版本均为OEL 5.8 x64 DataGuard配置日志接收方式，本文采用LGWR。 3.收集前期信息IP规划12345678910111213141516171819202122[grid@fung02:/home/grid]$ cat /etc/hosts# Do not remove the following line, or various programs# that require network functionality will fail.127.0.0.1 fung01 localhost.localdomain localhost#public IP 192.168.192.101 fung01 192.168.192.102 fung02#priv 10.10.10.101 fung01-priv 10.10.10.102 fung02-priv#Virtual IP 192.168.192.103 fung01-vip 192.168.192.104 fung02-vip#SCAN 192.168.192.105 rac11g-scan#dataguard192.168.192.107 fung03 主库日志文件123456789101112131415161718SQL&gt; select group#, thread#, bytes, blocksize, members from v$log; GROUP# THREAD# BYTES BLOCKSIZE MEMBERS---------- ---------- ---------- ---------- ---------- 1 1 52428800 512 1 2 1 52428800 512 1 3 2 52428800 512 1 4 2 52428800 512 1SQL&gt; set linesize 200SQL&gt; col member for a50SQL&gt; select member, group# from v$logfile order by 2;MEMBER GROUP#-------------------------------------------------- ----------+DATA/rac11g/onlinelog/group_1.257.848925419 1+DATA/rac11g/onlinelog/group_2.258.848925421 2+DATA/rac11g/onlinelog/group_3.265.848926807 3+DATA/rac11g/onlinelog/group_4.266.848926809 4 主库数据文件信息12345678910SQL&gt; col name for a80SQL&gt; select name from v$datafile;NAME--------------------------------------------------------------------------------+DATA/rac11g/datafile/system.259.848925423+DATA/rac11g/datafile/sysaux.260.848925443+DATA/rac11g/datafile/undotbs1.261.848925457+DATA/rac11g/datafile/undotbs2.263.848925475+DATA/rac11g/datafile/users.264.848925483 服务名及其他1234567891011121314SQL&gt; show parameter nameNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------cell_offloadgroup_name stringdb_file_name_convert stringdb_name string rac11gdb_unique_name string rac11gglobal_names boolean FALSEinstance_name string rac11g1lock_name_space stringlog_file_name_convert stringprocessor_group_name stringservice_names string rac11g 4.配置DataGuard4.1修改logging模式备库要成为主库完全相同的复本，它必须接收来自主库的重做日志，Oracle数据库中，用户可以指定某些操作不产生日志(NOLOGGING子句)，对于备库来说，这是个很大的问题，因此，我们必须确认用户无法指示数据库不产生重做日志，即启用数据库的强制日志功能。123456789SQL&gt; alter database force logging;Database altered.SQL&gt; select name, force_logging from v$database;NAME FORCE_-------------------------------------------------------------------------------- ------RAC11G YES 4.2为备库创建密码文件1234567891011[oracle@fung03:/home/oracle]$ orapwd file=$ORACLE_HOME/dbs/orapw$ORACLE_SID \\password=oracle entries=5 force=y ignorecase=y[oracle@fung03:/home/oracle]$ cd -/u01/app/oracle/product/11gr2/dbs[oracle@fung03:/u01/app/oracle/product/11gr2/dbs]$ ls -lttotal 20-rw-r----- 1 oracle oinstall 2048 May 30 15:15 orapwrac11g-rw-rw---- 1 oracle oinstall 1544 May 30 15:05 hc_rac11g.dat-rw-r--r-- 1 oracle oinstall 1229 May 30 15:05 initrac11g.ora-rw-r----- 1 oracle oinstall 3584 May 30 15:04 spfilerac11g.ora-rw-r--r-- 1 oracle oinstall 2851 May 15 2009 init.ora 4.3更新网络配置文件在创建备库之前，要确认两台服务器的数据库之间能通信，首先要配置主备库监听，使用RMAN的duplicate命令创建备库，备库必须首先处于NOMOUNT状态。在NOMOUNT状态下，数据库实例不会自动注册监听，必须配置静态监听。将以下信息添加进主库及备库的tnsnames.ora文档。1234567891011121314151617RAC11G = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = rac11g-scan)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = rac11g) ) )STDBY = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = fung03)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = rac11g) ) ) 添加备库listener信息，静态注册备库listener.ora12345678910111213141516[oracle@fung03:/u01/app/oracle/product/11gr2/network/admin]$ cat listener.ora SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_NAME= stdby) (ORACLE_HOME = /u01/app/oracle/product/11gr2) (SID_NAME = rac11g) ) )LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = fung03)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC0)) ) ) 同时启动备库监听1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[oracle@fung03:/u01/app/oracle/product/11gr2/network/admin]$ lsnrctl startLSNRCTL for Linux: Version 11.2.0.4.0 - Production on 30-MAY-2014 15:21:42Copyright (c) 1991, 2013, Oracle. All rights reserved.Starting /u01/app/oracle/product/11gr2//bin/tnslsnr: please wait...TNSLSNR for Linux: Version 11.2.0.4.0 - ProductionSystem parameter file is /u01/app/oracle/product/11gr2/network/admin/listener.oraLog messages written to /u01/app/oracle/diag/tnslsnr/fung03/listener/alert/log.xmlListening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=fung03)(PORT=1521)))Listening on: (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC0)))Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=fung03)(PORT=1521)))STATUS of the LISTENER------------------------Alias LISTENERVersion TNSLSNR for Linux: Version 11.2.0.4.0 - ProductionStart Date 30-MAY-2014 15:21:44Uptime 0 days 0 hr. 0 min. 1 secTrace Level offSecurity ON: Local OS AuthenticationSNMP OFFListener Parameter File /u01/app/oracle/product/11gr2/network/admin/listener.oraListener Log File /u01/app/oracle/diag/tnslsnr/fung03/listener/alert/log.xmlListening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=fung03)(PORT=1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=EXTPROC0)))Services Summary...Service &quot;rac11g&quot; has 1 instance(s). Instance &quot;rac11g&quot;, status UNKNOWN, has 1 handler(s) for this service...The command completed successfully[oracle@fung03:/u01/app/oracle/product/11gr2/network/admin]$ lsnrctl serviceLSNRCTL for Linux: Version 11.2.0.4.0 - Production on 30-MAY-2014 15:21:49Copyright (c) 1991, 2013, Oracle. All rights reserved.Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=fung03)(PORT=1521)))Services Summary...Service &quot;rac11g&quot; has 1 instance(s). Instance &quot;rac11g&quot;, status UNKNOWN, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 LOCAL SERVERThe command completed successfully 4.4创建跟pfile中相同的文件目录需要注意的是，这些路径要跟pfile中相对应。123[oracle@fung03:/home/oracle]$ mkdir -p /u01/app/oracle/diag/rdbms/rac11g/rac11g/trace[oracle@fung03:/home/oracle]$ mkdir -p /u01/app/oracle/diag/rdbms/rac11g/rac11g/cdump[oracle@fung03:/home/oracle]$ mkdir -p /u01/app/oracle/admin/rac11g/adump 5.创建DataGuard5.1配置主库DataGuard参数1234567891011121314#让主库知道DataGuard配置里的另一个库的名字SQL&gt; alter system set log_archive_config=&apos;dg_config=(rac11g,stdby)&apos; scope=both;System altered.#配置主库本地归档路径SQL&gt; alter system set log_archive_dest_1=&apos;location=+DATA/arch valid_for=(all_logfiles,all_roles) db_unique_name=rac11g&apos; scope=both;System altered.#配置主库远程归档路径SQL&gt; alter system set log_archive_dest_2=&apos;service=STDBY LGWR ASYNC NOAFFIRM valid_for=(online_logfiles,primary_role) db_unique_name=stdby&apos; scope=both;System altered.以上归档切换时是用lgwr的异步传输方式 对于以上参数的简单说明：AFFIRM and NOAFFIRMAFFIRM：在写入到standby redo log 后，指定重做传输目标接受重做传输日志。NOAFFIRM：在写入到standby redo log前，重做传输日志可以传输到目的地。LOCATION and SERVICELOCATION: 表示归档到本地。SERVICE: 表示归档到远程，跟tnsname.ora文件中的tnsname相同。SYNC and ASYNC指定使用同步还是异步传输模式。VALID_FOR指定数据库运行在主还是从数据库的角色。是否online redo log files, standby redo log files 或是他们都将归档到该目的地，这里配置的是不管是online log还是standy log，也不管当前数据库是主库还是备库，都将归档到service=STDBY的远程归档上。123456789101112#开启归档路径1和归档路径2SQL&gt; alter system set log_archive_dest_state_1=&apos;enable&apos; scope=both;System altered.SQL&gt; alter system set log_archive_dest_state_2=&apos;enable&apos; scope=both;System altered.SQL&gt; alter system set log_archive_max_processes=10 scope=both;System altered. 添加备库自动管理文件功能，即当主库添加或删除数据文件时，这些文件也会在备库添加或删除。123SQL&gt; alter system set standby_file_management=&apos;AUTO&apos; scope=both;System altered. 设置FAL_SERVER参数，此参数指定当日志传输出问题时，备库到哪里去找缺失的归档日志。它用在备库接收的到的重做日志间有gap的时候。这种情况会发生在日志传输出现中断时，如对备库需要维护而主库仍然正常运行，这时候，备库维护期间，没有日志传输过来，gap就出现了，设置了这个参数，备库会主动去寻找那些缺失的日志，并要求主库进行传输。123SQL&gt; alter system set fal_server=&apos;stdby&apos; scope=both;System altered. 至此，主库DataGuard相关参数修改完毕，用以下语句确认是否有误。123456789101112131415161718192021222324252627282930313233SQL&gt; set linesize 500 pages 0SQL&gt; col value for a120SQL&gt; col name for a50SQL&gt; select name, value 2 from v$parameter 3 where name in (&apos;db_name&apos;,&apos;db_unique_name&apos;, 4 &apos;log_archive_config&apos;, 5 &apos;log_archive_dest_1&apos;,&apos;log_archive_dest_2&apos;, 6 &apos;log_archive_dest_state_1&apos;, 7 &apos;log_archive_dest_state_2&apos;, 8 &apos;remote_login_passwordfile&apos;, 9 &apos;log_archive_format&apos;, 10 &apos;log_archive_max_processes&apos;, 11 &apos;fal_server&apos;,&apos;db_file_name_convert&apos;, 12 &apos;log_file_name_convert&apos;, 13 &apos;standby_file_management&apos;) 14 /db_file_name_convertlog_file_name_convertlog_archive_dest_1 location=+DATA/arch valid_for=(all_logfiles,all_roles) db_unique_name=rac11glog_archive_dest_2 service=STDBY LGWR ASYNC NOAFFIRM valid_for=(online_logfiles,primary_role) db_unique_name=stdbylog_archive_dest_state_1 enablelog_archive_dest_state_2 enablefal_server stdbylog_archive_config dg_config=(rac11g,stdby)log_archive_format %t_%s_%r.arclog_archive_max_processes 10standby_file_management AUTOremote_login_passwordfile EXCLUSIVEdb_name rac11gdb_unique_name rac11g14 rows selected. 5.2主库添加standby redo log添加原则standby redo log的文件大小与primary 数据库online redo log 文件大小相同 standby redo log日志文件组的个数依照下面的原则进行计算Standby redo log组数公式&gt;=(每个instance日志组个数+1)*instance个数，例如在我的环境中，有两个节点，每个节点有2组redo，所以Standby redo log组数公式&gt;=(2+1)*2 == 6，所以需要创建6组Standby redo log。 每一日志组为了安全起见，可以包含多个成员文件123456alter database add standby logfile group 5 size 50M;alter database add standby logfile group 6 size 50M;alter database add standby logfile group 7 size 50M;alter database add standby logfile group 8 size 50M;alter database add standby logfile group 9 size 50M;alter database add standby logfile group 10 size 50M; 查看结果123456789101112131415SQL&gt; col member for a50SQL&gt; select member,type from v$logfile;MEMBER TYPE-------------------------------------------------- --------------+DATA/rac11g/onlinelog/group_1.257.848925419 ONLINE+DATA/rac11g/onlinelog/group_2.258.848925421 ONLINE+DATA/rac11g/onlinelog/group_3.265.848926807 ONLINE+DATA/rac11g/onlinelog/group_4.266.848926809 ONLINE+DATA/rac11g/onlinelog/group_5.333.849348597 STANDBY+DATA/rac11g/onlinelog/group_6.334.849348599 STANDBY+DATA/rac11g/onlinelog/group_7.335.849348601 STANDBY+DATA/rac11g/onlinelog/group_8.336.849348603 STANDBY+DATA/rac11g/onlinelog/group_9.337.849348605 STANDBY+DATA/rac11g/onlinelog/group_10.338.849348607 STANDBY 6.编辑备库pfile从主库创建pfile，取消RAC相关参数，并且添加以下参数：12345678910*.db_name=&apos;rac11g&apos;*.db_unique_name=&apos;stdby&apos;*.standby_file_management=&apos;AUTO&apos;*.undo_tablespace=&apos;UNDOTBS1&apos;*.fal_server=&apos;rac11g&apos;*.log_archive_config=&apos;dg_config=(rac11g,stdby)&apos;*.log_archive_dest_1=&apos;location=/oradata/arch valid_for=(all_logfiles,all_roles) db_unique_name=stdby&apos;*.log_archive_dest_2=&apos;service=rac11g LGWR ASYNC NOAFFIRM valid_for=(online_logfiles,primary_role) db_unique_name=rac11g&apos;*.log_archive_dest_state_1=&apos;enable&apos;*.log_archive_dest_state_2=&apos;enable&apos; 7.利用rman创建Standby11g以后，可以利用duplicate active database或者从备份直接创建DataGuard，分别以两种不同方式创建，第一种以duplicate active standby还原至file system，第二种方式采用备份还原至ASM。先将备库启动至nomount模式。 7.1duplicate active standby由ASM还原至文件系统，需要经过set newname参数。同时因为日志文件路径也不同，需要在pfile中添加LOG_FILE_NAME_CONVERT参数进行变换，否则会报错:123456RMAN-05535: WARNING: All redo log files were not defined properly.ORACLE error from auxiliary database: ORA-00344: unable to re-create online log &apos;+data&apos;ORA-17502: ksfdcre:4 Failed to create file +dataORA-15001: diskgroup &quot;DATA&quot; does not exist or is not mountedORA-15040: diskgroup is incompleteORA-15040: diskgroup is incomplete 执行复制脚本如下：123456789101112131415[oracle@fung03:/u01/app/oracle/product/11gr2/dbs]$ rman target sys/oracle@rac11g \\auxiliary sys/oracle@stdby msglog=/home/oracle/rac11g_`date &apos;+%Y%m%d%H%M&apos;`.log&lt;&lt;EOFrun&#123;allocate channel c1 type disk;allocate auxiliary channel ch1 TYPE disk;set newname for datafile 1 to &apos;/oradata/rac11g/system01.dbf&apos;;set newname for datafile 3 to &apos;/oradata/rac11g/undotbs01.dbf&apos;;set newname for datafile 2 to &apos;/oradata/rac11g/sysaux01.dbf&apos;;set newname for datafile 5 to &apos;/oradata/rac11g/users01.dbf&apos;;set newname for datafile 4 to &apos;/oradata/rac11g/undotbs02.dbf&apos;;set newname for tempfile 1 to &apos;/oradata/rac11g/temp01.dbf&apos;;DUPLICATE TARGET DATABASE FOR STANDBY FROM ACTIVE DATABASE DORECOVER;&#125;exit;EOF 11g新特性，增加PARAMETER_VALUE_CONVERT参数，可参见Duplicate Database With RMAN最后一点。123456789101112131415161718192021222324#For single to singleDUPLICATE TARGET DATABASE FOR STANDBY FROM ACTIVE DATABASESPFILEPARAMETER_VALUE_CONVERT &apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;SET &quot;DB_UNIQUE_NAME&quot;=&quot;stdby&quot;SET SGA_MAX_SIZE = &apos;250M&apos;SET SGA_TARGET = &apos;250M&apos;SET log_archive_dest_1 = &apos;LOCATION=/dup/arch/&apos;SET LOG_FILE_NAME_CONVERT=&apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;DB_FILE_NAME_CONVERT=&apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;;#For rac to singleDUPLICATE TARGET DATABASE FOR STANDBY FROM ACTIVE DATABASESPFILEPARAMETER_VALUE_CONVERT &apos;rac11g&apos;,&apos;stdby&apos;SET &quot;DB_UNIQUE_NAME&quot;=&quot;stdby&quot;SET LOG_FILE_NAME_CONVERT=&apos;rac11g&apos;,&apos;stdby&apos;SET &quot;CLUSTER_DATABASE&quot;=&quot;FALSE&quot;SET &quot;FAL_SERVER&quot;=&quot;rac11g&quot;SET &quot;FAL_CLIENT&quot;=&quot;stdby&quot;SET &quot;LOG_ARCHIVE_DEST_2&quot;=&quot;service=rac11g LGWR ASYNC NOAFFIRM valid_for=(online_logfiles,primary_role) db_unique_name=rac11g&quot;SET &quot;LOG_ARCHIVE_DEST_STATE_1&quot;=&quot;enable&quot;SET &quot;LOG_ARCHIVE_DEST_STATE_2&quot;=&quot;enable&quot;RESET REMOTE_LISTENERDB_FILE_NAME_CONVERT=&apos;rac11g&apos;,&apos;stdby&apos;; 7.2使用备份创建DataGuard至ASM11g ASM管理需要安装GI，然后把磁盘挂载即可。123456SQL&gt; select name,state,type,total_mb,free_mb 2 from v$asm_diskgroup; NAME STATE TYPE TOTAL_MB FREE_MB------------------------------ ----------- ------ ---------- ----------DATA MOUNTED NORMAL 20480 20360 创建主库rman备份123456[oracle@fung01:/home/oracle]$ mkdir -p /worktmp/backup[oracle@fung01:/home/oracle]$ rman target /RMAN&gt; backup database format &apos;/worktmp/backup/bfull_%T_%u_%s_%p&apos;;RMAN&gt; backup current controlfile for standby format &apos;/worktmp/backup/ctl_%T_%u_%s_%p&apos;;RMAN&gt; sql &apos;alter system archive log current&apos;;RMAN&gt; backup archivelog all format &apos;/worktmp/backup/arc_%T_%u_%s_%p&apos;; 将备份集传送到备库相同目录，修改pfile，调整相关参数(主要是文件路径)，同时在ASM DATA磁盘组创建相关目录。并启动备库至nomount状态，rman中恢复备库12[oracle@fung03:/home/oracle]$ rman target sys/oracle@rac11g auxiliary sys/oracle@stdbyRMAN&gt; duplicate target database for standby nofilenamecheck dorecover; 在过程中遇到个问题：1234567891011121314151617RMAN&gt; duplicate target database for standby nofilenamecheck dorecover;Starting Duplicate Db at 2014-06-04 09:32:04using target database control file instead of recovery catalogallocated channel: ORA_AUX_DISK_1channel ORA_AUX_DISK_1: SID=192 device type=DISKRMAN-00571: ===========================================================RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============RMAN-00571: ===========================================================RMAN-03002: failure of Duplicate Db command at 06/04/2014 09:32:06RMAN-05501: aborting duplication of target databaseRMAN-06136: ORACLE error from auxiliary database: ORA-00200: control file could not be createdORA-00202: control file: &apos;+data&apos;ORA-17502: ksfdcre:4 Failed to create file +dataORA-15001: diskgroup &quot;DATA&quot; does not exist or is not mountedORA-15040: diskgroup is incompleteORA-15040: diskgroup is incomplete 跟主库对比$ORACLE_HOME/bin/oracle的权限及asmdisk权限，发现都没错：123456789101112131415161718192021[oracle@fung03:/home/oracle]$ ls -la $ORACLE_HOME/bin/oracle-rwxr-x--x 1 oracle oinstall 239627073 May 30 15:00 /u01/app/oracle/product/11gr2//bin/oracle[oracle@fung01:/home/oracle]$ ls -la $ORACLE_HOME/bin/oracle-rwsr-s--x 1 oracle asmadmin 239627031 May 30 12:17 /u01/app/oracle/product/11gr2//bin/oracle[oracle@fung01:/home/oracle]$ ll /dev/asm*brw-rw---- 1 grid asmadmin 8, 16 Jun 4 09:55 /dev/asm-diskbbrw-rw---- 1 grid asmadmin 8, 32 Jun 4 09:55 /dev/asm-diskcbrw-rw---- 1 grid asmadmin 8, 48 Jun 4 09:55 /dev/asm-diskdbrw-rw---- 1 grid asmadmin 8, 64 Jun 4 09:55 /dev/asm-diskebrw-rw---- 1 grid asmadmin 8, 80 Jun 4 09:55 /dev/asm-diskf[oracle@fung03:/home/oracle]$ ll /dev/asm*brw-rw---- 1 grid asmadmin 8, 64 Jun 4 09:51 /dev/asm-diskebrw-rw---- 1 grid asmadmin 8, 80 Jun 4 09:51 /dev/asm-diskf[oracle@fung03:/home/oracle]$ id oracleuid=54321(oracle) gid=54321(oinstall) groups=54321(oinstall),54322(dba),54323(asmdba)[oracle@fung03:/home/oracle]$ id griduid=54322(grid) gid=54321(oinstall) groups=54321(oinstall),54322(dba),54323(asmdba),54324(asmadmin)[oracle@fung01:/home/oracle]$ id oracleuid=54321(oracle) gid=54321(oinstall) groups=54321(oinstall),54322(dba),54323(asmdba)[root@fung01 ~]# id griduid=54322(grid) gid=54321(oinstall) groups=54321(oinstall),54322(dba),54323(asmdba),54324(asmadmin) 备库后台一直报错：1234567Additional information: 9ORA-15025: could not open disk &quot;/dev/asm-diskf&quot;ORA-27041: unable to open fileLinux-x86_64 Error: 13: Permission deniedAdditional information: 9SUCCESS: diskgroup DATA was dismountedERROR: diskgroup DATA was not mounted 发现是ORACLE_HOME/bin/oracle权限不对，解决方法:1234To correct the proper group for the Database oracle executable, do:As the &lt;asm_home sfw owner&gt;:$ cd &lt;asm_home&gt;/bin$ ./setasmgidwrap o=&lt;db_home&gt;/bin/oracle 再次执行duplicate动作，OK了。 8.备库开启实时应用1234SQL&gt; shutdown immediate;SQL&gt; startup nomountSQL&gt; alter database mount standby database;SQL&gt; alter database recover managed standby database using current logfile disconnect; 后台日志开始同步12345678910111213Completed: alter database recover managed standby database using current logfile disconnectMedia Recovery Log +DATA/arch/1_65_848925414.arcMedia Recovery Log +DATA/arch/2_52_848925414.arcMedia Recovery Log +DATA/arch/2_53_848925414.arcMedia Recovery Log +DATA/arch/1_66_848925414.arcMedia Recovery Log +DATA/arch/2_54_848925414.arcMedia Recovery Log +DATA/arch/2_55_848925414.arcMedia Recovery Waiting for thread 2 sequence 56 (in transit)Recovery of Online Redo Log: Thread 2 Group 6 Seq 56 Reading mem 0 Mem# 0: +DATA/stdby/onlinelog/group_6.308.849351751Media Recovery Waiting for thread 1 sequence 67 (in transit)Recovery of Online Redo Log: Thread 1 Group 7 Seq 67 Reading mem 0 Mem# 0: +DATA/stdby/onlinelog/group_7.307.849351753 主备库可用以下SQL检测log sequence是否一致：123select name,replace(database_role,&apos; &apos;,&apos;&apos;) as database_role,thread,seq from v$database,(select max(sequence#) seq,THREAD# thread from v$log_history group by THREAD#); 在主库添加数据文件，备库后台日志会同步相关信息1234567SQL&gt; create tablespace fung datafile &apos;+DATA&apos; size 10M autoextend off;Tablespace created.#备库日志Recovery created file +dataSuccessfully added datafile 6 to media recoveryDatafile # 6: &apos;+DATA/stdby/datafile/fung.325.849353435&apos; 9.为备库添加standby redo log为备库添加standby log需要先停止MPR进程，添加完成后再重启MPR进程1234567891011121314151617181920212223SQL&gt; alter database recover managed standby database cancel;Database altered.SQL&gt; alter database add standby logfile group 5 (&apos;+DATA&apos;) size 50M;SQL&gt; alter database recover managed standby database using current logfile disconnect;Database altered.SQL&gt; col member for a50SQL&gt; select member,type from v$logfile;MEMBER TYPE-------------------------------------------------- --------------+DATA/stdby/onlinelog/group_1.312.849351735 ONLINE+DATA/stdby/onlinelog/group_2.311.849351739 ONLINE+DATA/stdby/onlinelog/group_3.313.849351741 ONLINE+DATA/stdby/onlinelog/group_4.310.849351745 ONLINE+DATA/stdby/onlinelog/group_5.309.849351747 STANDBY+DATA/stdby/onlinelog/group_6.308.849351751 STANDBY+DATA/stdby/onlinelog/group_7.307.849351753 STANDBY+DATA/stdby/onlinelog/group_8.314.849351757 STANDBY+DATA/stdby/onlinelog/group_9.306.849351759 STANDBY+DATA/stdby/onlinelog/group_10.300.849351763 STANDBY 10.验证DataGuard验证日志是否从主库传输过来，最后一个栏位为yes表示日志已经传输过来1SELECT RESETLOGS_ID,THREAD#,SEQUENCE#,STATUS,ARCHIVED FROM V$ARCHIVED_LOG; 如果日志传输失败，请用以下命令查看主备库日志传输路径是否valid的1234567SQL&gt; set line 200SQL&gt; col dest_name for a20SQL&gt; col error for a50SQL&gt; select dest_name,status,error from v$archive_dest where dest_name=&apos;LOG_ARCHIVE_DEST_2&apos;;DEST_NAME STATUS ERROR-------------------- ------------------ --------------------------------------------------LOG_ARCHIVE_DEST_2 VALID 如果status为其他，则查看是什么原因导致无法归档到备库，调整完后用以下命令重启远程归档进程12SQL&gt; alter system set log_archive_dest_state_2 = &apos;defer&apos;;SQL&gt; alter system set log_archive_dest_state_2 = &apos;enable&apos;; 备库查看lag 延时，正常所有lag应该接近0或者为0123456789101112SQL&gt; col name for a30SQL&gt; col value for a30SQL&gt; col datum_time for a30SQL&gt; col TIME_COMPUTED for a20SQL&gt; set line 200SQL&gt; SELECT name, value, datum_time, time_computed FROM V$DATAGUARD_STATS;NAME VALUE DATUM_TIME TIME_COMPUTED------------------------------ ------------------------------ ------------------------------ --------------------transport lag +00 00:00:00 06/04/2014 11:43:01 06/04/2014 11:43:02apply lag +00 00:00:00 06/04/2014 11:43:01 06/04/2014 11:43:02apply finish time +00 00:00:00.000 06/04/2014 11:43:02estimated startup time 33 06/04/2014 11:43:02 查看DataGuard message1234567891011121314SQL&gt; SELECT MESSAGE FROM V$DATAGUARD_STATUS;MESSAGE---------------------------------------------------------------------------Media Recovery Waiting for thread 1 sequence 78 (in transit)Media Recovery Waiting for thread 2 sequence 59 (in transit)MRP0: Background Media Recovery cancelled with status 16037Managed Standby Recovery not using Real Time ApplyMRP0: Background Media Recovery process shutdownManaged Standby Recovery CanceledAttempt to start background Managed Standby Recovery processMRP0: Background Managed Standby Recovery process startedManaged Standby Recovery starting Real Time ApplyMedia Recovery Waiting for thread 2 sequence 59 (in transit)Media Recovery Waiting for thread 1 sequence 78 (in transit) 查看日志应用状态1SQL&gt; select thread#,sequence#,applied from v$archived_log; 11.11gR2 DataGuard提供实时查询功能查看standby目前状态为mount状态12345SQL&gt; select open_mode from v$database;OPEN_MODE----------------------------------------MOUNTED 开启实时查询123456789#暂停MPR进程SQL&gt; alter database recover managed standby database cancel;Database altered.#开启real-time querySQL&gt; alter database open;Database altered.#开启MPR进程SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT;Database altered. 验证实时查询123456789101112131415161718192021222324#主库添加数据SQL&gt; create table t as select username from dba_users;Table created.#备库进行查询SQL&gt; select open_mode from v$database;OPEN_MODE----------------------------------------READ ONLY WITH APPLYSQL&gt; select * from t;USERNAME------------------------------------------------------------SYSSYSTEMOUTLNAPPQOSSYSDBSNMPWMSYSDIPORACLE_OCM8 rows selected. 12.删除standby归档脚本12345grep &quot;Media Recovery Log&quot; /u01/app/oracle/diag/rdbms/stdby/rac11g/trace/alert_rac11g.log|sed -e &apos;s/Media Recovery Log/rm -if/g&apos; &gt;/home/oracle/rman/dellog.shchmod u+x /home/oracle/rman/dellog.shsh /home/oracle/rman/dellog.shcat /u01/app/oracle/diag/rdbms/stdby/rac11g/trace/alert_rac11g.log &gt;&gt;/u01/app/oracle/diag/rdbms/stdby/rac11g/trace/alert_rac11g_old.logcat /dev/null &gt; /u01/app/oracle/diag/rdbms/stdby/rac11g/trace/alert_rac11g.log See more details in:Oracle® Data Guard Concepts and Administration 11g Release 2 (11.2)","link":"/configure-dataguard-in-rac.html"},{"title":"Create database with command line","text":"1. Setting environment variables, ORACLE_SID,ORACLE_BASE,ORACLE_HOME ect., see ~/.bash_profile 12345678910111213141516export EDITOR=vi export TMP=/tmp export TMPDIR=$TMP export ORACLE_BASE=/u01/oracle export ORACLE_HOME=$ORACLE_BASE/product/11gr2 export JAVA_HOME=$ORACLE_HOME/jdk export ORACLE_SID=ora11g export ORACLE_TERM=xterm export PATH=/usr/sbin:$ORACLE_HOME/bin:$JAVA_HOME:$PATH export ORA_NLS11=$ORACLE_HOME/nls/data export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib export CLASSPATH=$ORACLE_HOME/JRE:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlib export NLS_DATE_FORMAT=&quot;yyyy-mm-dd HH24:MI:SS&quot; export NLS_LANG=AMERICAN_AMERICA.ZHS16GBK export PS1=&apos;[$LOGNAME@$HOSTNAME:$PWD]$ &apos; umask 022 2. Create a password with orapwd command,remember that,in 11g,password is case-sensitive $orapwd file=$ORACLE_HOME/dbs/orapwora11g password=oracle force=y 3. Create an initialization parameter file 1234567891011$vi $ORACLE_HOME/dbs/initora11g.ora DB_NAME=ora11g CONTROL_FILE=&apos;/oradata/ora11g/control01.ctl&apos;,&apos;/oradata/ora11g/control02.ctl&apos;,&apos;/oradata/ora11g/control03.ctl&apos; DB_BLOCK_SIZE=16384 PROCESSES=300 open_cursors=300 remote_login_passwordfile=&apos;EXCLUSIVE&apos; undo_tablespace=&apos;UNDOTBS1&apos; UNDO_MANAGEMENT=&apos;AUTO&apos; audit_file_dest=&apos;/opt/oracle/admin/ora11g/adump&apos; compatible =&apos;11.2.0&apos; 4. Connect to the Instance $sqlplus / as sysdba 5. Create spfile from pfile SQL> create spfile from pfile='$ORACLE_HOME/dbs/initora11g.ora'; 6. startup the instance in nomount mode SQL> startup nomount; 7. Issue the CREATE DATABASE Statement 123456789101112131415161718192021222324252627282930spool createdb.log CREATE DATABASE ora11g USER SYS IDENTIFIED BY oracle USER SYSTEM IDENTIFIED BY oracle LOGFILE GROUP 1 (&apos;/oradata/ora11g/redo01a.log&apos;,&apos;/oradata/ora11g/redo01b.log&apos;) SIZE 100M, GROUP 2 (&apos;/oradata/ora11g/redo02a.log&apos;,&apos;/oradata/ora11g/redo02b.log&apos;) SIZE 100M, GROUP 3 (&apos;/oradata/ora11g/redo03a.log&apos;,&apos;/oradata/ora11g/redo03b.log&apos;) SIZE 100M MAXLOGFILES 10 MAXLOGMEMBERS 5 MAXLOGHISTORY 1 MAXDATAFILES 300 CHARACTER set ZHS16GBK NATIONAL CHARACTER SET AL16UTF16 EXTENT MANAGEMENT LOCAL DATAFILE &apos;/oradata/ora11g/system01.dbf&apos; SIZE 325M REUSE SYSAUX DATAFILE &apos;/oradata/ora11g/sysaux01.dbf&apos; SIZE 325M REUSE DEFAULT TABLESPACE users DATAFILE &apos;/oradata/ora11g/users01.dbf&apos; SIZE 500M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED DEFAULT TEMPORARY TABLESPACE tempts1 TEMPFILE &apos;/oradata/ora11g/temp01.dbf&apos; SIZE 20M REUSE UNDO TABLESPACE UNDOTBS1 DATAFILE &apos;/oradata/ora11g/undotbs01.dbf&apos; SIZE 200M REUSE AUTOEXTEND ON MAXSIZE UNLIMITED; exit spool off 8. Run Scripts to Build Data Dictionary Views 123@?/rdbms/admin/catalog.sql @?/rdbms/admin/catproc.sql @?/sqlplus/admin/pupbld.sql Reference:Oracle® Database Administrator's Guide 11g Release 2 (11.2)","link":"/create-database-command-line.html"},{"title":"DataGuard主备切换及故障切换","text":"DataGuard是从Oracle7.3开始引进的，在8i之前叫standby database，9i后更名为DataGuard，是Oracle提供的灾备手段之一。 1. 11g DataGuard新特性10g的DataGuard提供了实时应用(real time apply)功能，通过使用Standby redo log，当日志被写入Standby Redo Log时，在standby会立刻应用这些redo，大大减少了故障发生时数据丢失的概率。123456789#standby开启实时应用SQL&gt; startup nomountSQL&gt; alter database mount standby database;SQL&gt; alter database recover managed standby database using current logfile disconnect;SQL&gt; Select recovery_mode from v$archive_dest_status;RECOVERY_MODE----------------------------------------------MANAGED REAL TIME APPLY 11g提供active DataGuard(需要单独授权，如果没有授权，不应该使用它)功能，能在open read only下进行实时查询(real time query)，在10g中，查询standby跟redo apply只能两者选其一，因而有资源浪费嫌疑。11g的这个功能可大大提高的资源的利用率。查询事务在standby上，DML在Primary上。11g ADG配置可参照前文Configure DataGuard in RAC。12345678910111213141516171819202122#开启实时查询SQL&gt; alter database recover managed standby database cancel;SQL&gt; alter database open;SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT;SQL&gt; select open_mode from v$database;OPEN_MODE----------------------------------------READ ONLY WITH APPLY#查询redo apply blocks是否增加，增加则表示在进行apply#主库SQL&gt; select sequence#,status,thread#,block# from v$managed_standby; SEQUENCE# STATUS THREAD# BLOCK#---------- ------------------------ ---------- ---------- 0 CONNECTED 0 0 97 WRITING 1 737#备库SQL&gt; select sequence#,status,thread#,block# from v$managed_standby; SEQUENCE# STATUS THREAD# BLOCK#---------- ------------------------ ---------- ---------- 0 CONNECTED 0 0 73 APPLYING_LOG 2 792 2. DataGuard三种保护模式2.1 最大保护(Maximum Protection)这种模式提供最高级别数据丢失保护，以保证在Primary数据库故障时，零数据丢失。在这种模式下，日志传输必须是SYNC,LGWR,AFFIRM模式，在事务提交前，standby必须确认primary传送过来的redo被安全的写入至少一个standby database中的standby redo log，同时也要保证在primary也已经写好。如果primary无法往standby数据库的redo log中写日志，则primary会关闭。因此，在这种机制下，一般最大保护模式的standby都是设置多台，这样，单一standby故障并不会导致primary shutdown。 2.2 最大性能(Maximum Performance)这种模式是默认模式，表明主库的性能和可用性不受备库影响。且主库事务提交跟备库独立，虽然primary日志也一样至少写入一个可用的standby log，但是这种写可以是ASYNC的。且不要求使用standby redo log。 2.3 最大可用性(Maximum Availability)这种模式是前面两种模式的混合平衡体。即配置跟最大保护一样，但是primary往standby写日志遇到问题的时候，primary不会直接关闭，而是降级为最大性能模式，等standby修复好之后，自动切换为最大可用性。三种保护模式对日志传输的要求如下：Minimum Requirements for Data Protection Modes 3.SwitchoverSwitchover表示事先已经计划好的主备库角色切换。例如减少维护停机时间。最常用的是迁移及升级。Switchover分以下几个步骤：1.告知主库即将要进行switchover。2.取消主库用户连接。3.产生特殊的日志记录，标记为End Of Redo(EOR)。4.转换主库为standby。5.一旦备库应用到最后的EOR，表明没有数据丢失，则转换备库为primary。 4. FailoverFailover指的是意外导致的主备库角色切换，Failover后主备库DataGuard关系消失，需重新创建DataGuard。而switchover则保持主备关系，只不过角色切换过来而已。转换过程也跟switchover类似，只是因为是意外事件，所以主库是没机会写EOR redo记录的。Failover分为手动和自动，手动模式管理员完全控制Failover的角色切换，然后，手动模式需要人去探知，从而增长了业务停机时间。相反的，DataGuard的Fast-Start Failover特性自动检测失败信息，自动评估DataGuard配置信息，如果有需要，会自动选择指定的standby进行Failover，此功能需开启DataGuard Broker。根据保护模式不同，Failover存在丢失数据的可能。 5. 示例123ENV:primary:11gr2 2 nodes rac ASM + Linuxstandby:11gr2 1 node single ASM +Linux 5.1 RAC DataGuard Switch over#####查询主备库状态12345678910SQL&gt; set line 200SQL&gt; select inst_id,database_role,OPEN_MODE from gv$database; INST_ID DATABASE_ROLE OPEN_MODE---------- -------------------------------- ---------------------------------------- 2 PRIMARY READ WRITE 1 PRIMARY READ WRITESQL&gt; select inst_id,database_role,OPEN_MODE from gv$database; INST_ID DATABASE_ROLE OPEN_MODE---------- -------------------------------- ---------------------------------------- 1 PHYSICAL STANDBY READ ONLY WITH APPLY #####主库检查switchover状态如果是to standby或者sessions active表明可以进行切换，sessions active意味着主备库有活动sessions关联，在switchover前需要将这些sessions关闭(with session shutdown)。1234SQL&gt; select switchover_status from v$database;SWITCHOVER_STATUS----------------------------------------TO STANDBY #####主库操作主库如果是RAC，则要求只保留其中一个节点，其他的关闭。1234[oracle@fung01:/home/oracle]$ srvctl stop instance -d rac11g -i rac11g2[oracle@fung01:/home/oracle]$ srvctl status database -d rac11gInstance rac11g1 is running on node fung01Instance rac11g2 is not running on node fung02 主库切换日志，并在主备端查看日志同步情况，对于open resetlogs后的数据库不适合用此语句查看，因为sequence会被重置，可以通过查看后台评估主备节点同步状态。1234567891011SQL&gt; ALTER SYSTEM ARCHIVE LOG CURRENT;System altered.SQL&gt; select thread#, max(sequence#) 2 from v$archived_log a, v$database b 3 where a.resetlogs_change# = b.resetlogs_change# 4 group by thread# order by 1; THREAD# MAX(SEQUENCE#)---------- -------------- 1 105 2 79 #####主库切换12SQL&gt; ALTER DATABASE COMMIT TO SWITCHOVER TO STANDBY WITH SESSION SHUTDOWN;Database altered. #####备库切换1234SQL&gt; ALTER DATABASE COMMIT TO SWITCHOVER TO PRIMARY WITH SESSION SHUTDOWN;Database altered.SQL&gt; ALTER DATABASE OPEN;Database altered. #####后续工作原主库mount到standby状态12SQL&gt; shutdown immediateSQL&gt; startup mount 原主库停止远程归档路径12SQL&gt; alter system set log_archive_dest_state_2=defer;System altered. 原主库启用实时查询123456789101112131415161718SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT;Database altered.SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE cancel;Database altered.SQL&gt; alter database open;Database altered.SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT;Database altered.#后台日志Fri Jun 13 10:54:31 2014Media Recovery Log +DATA/arch/1_107_848925414.arcCompleted: ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECTMedia Recovery Log +DATA/arch/1_108_848925414.arcMedia Recovery Log +DATA/arch/1_109_848925414.arcMedia Recovery Log +DATA/arch/1_110_848925414.arcMedia Recovery Waiting for thread 1 sequence 111 (in transit)Recovery of Online Redo Log: Thread 1 Group 5 Seq 111 Reading mem 0 Mem# 0: +DATA/rac11g/onlinelog/group_5.333.849348597 这时新主库状态为to standby,在新备库recovery前，其状态为FAILED DESTINATION，而备库状态为RECOVERY NEEDED。1234SQL&gt; select switchover_status from v$database;SWITCHOVER_STATUS----------------------------------------TO STANDBY 开启备库另一个节点1[oracle@fung02:/home/oracle]$ srvctl start instance -d rac11g -i rac11g2 主库切换几次日志，主备库查看后台及日志同步信息。1234567891011SQL&gt; alter system switch logfile;System altered.SQL&gt; select thread#, max(sequence#) 2 from v$archived_log a, v$database b 3 where a.resetlogs_change# = b.resetlogs_change# 4 group by thread# order by 1; THREAD# MAX(SEQUENCE#)---------- -------------- 1 112 2 79 5.2 RAC DataGuard Failover由于各种可能会导致主库无法开启，这里模拟一种最简单的模式，手动abort两个实例。这样，在RAC端，还是能mount数据库(故障类型最理想状态)，只要主库能启动到mount状态，那么Flush 就可以把没有发送的归档和current online redo 发送到备库，如果Flush成功，数据不会丢失。123456789#主库模拟故障，仅开启一个实例至mount状态[oracle@fung02:/home/oracle]$ srvctl stop database -d rac11g -o abortSQL&gt; startup mountORACLE instance started.SQL&gt; select open_mode from v$database;OPEN_MODE----------------------------------------MOUNTED 主库刷新日志1234567891011121314151617181920212223242526272829SQL&gt; alter system flush redo to &apos;stdby&apos;;System altered.#主库后台日志明显有EOR信息ARCH: End-Of-Redo Branch archival of thread 1 sequence 120ARCH: LGWR is scheduled to archive destination LOG_ARCHIVE_DEST_2 after log switchARCH: Standby redo logfile selected for thread 1 sequence 120 for destination LOG_ARCHIVE_DEST_2Flush End-Of-Redo Log thread 1 sequence 120Archived Log entry 271 added for thread 1 sequence 120 ID 0x71630fe3 dest 1:ARCH: Noswitch archival of thread 2, sequence 83ARCH: End-Of-Redo Branch archival of thread 2 sequence 83ARCH: LGWR is scheduled to archive destination LOG_ARCHIVE_DEST_2 after log switchARCH: Standby redo logfile selected for thread 2 sequence 83 for destination LOG_ARCHIVE_DEST_2Flush End-Of-Redo Log thread 2 sequence 83#备库后台日志Standby switchover readiness check: Checking whether recoveryapplied all redo..Database not available for switchover End-Of-REDO archived log file has not been recovered Incomplete recovery SCN:0:648156 archive SCN:0:670380Physical Standby did not apply all the redo from the primary.Fri Jun 13 12:01:38 2014Resetting standby activation ID 1902317539 (0x71630fe3)Standby switchover readiness check: Checking whether recoveryapplied all redo..Physical Standby applied all the redo from the primary.Media Recovery Waiting for thread 1 sequence 121Fri Jun 13 12:01:39 2014Standby switchover readiness check: Checking whether recoveryapplied all redo..Physical Standby applied all the redo from the primary.Standby switchover readiness check: Checking whether recoveryapplied all redo..Physical Standby applied all the redo from the primary. 如果主库不能至mount状态，或者不是11g，上述步骤可以跳过，但有数据丢失的可能。 #####备库操作查询gap，如果有，将对应的归档文件copy到备库，并registered。1234SQL&gt; select thread#, low_sequence#, high_sequence# from v$archive_gap;no rows selected#如果有gap，copy后注册alter database register physical logfile &apos;/arch/oradata/dg01/1_332800.dbf&apos;; 取消和停止应用123456SQL&gt; alter database recover managed standby database cancel;Database altered.SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE FINISH;Database altered.#如果主库和备库之间的网络中断了，那么备库的RFS进程就会等待网络的连接，直到TCP超时。此时需要加上force关键字ALTER DATABASE RECOVER MANAGED STANDBY DATABASE FINISH force; 此时standby状态1234SQL&gt; select open_mode, switchover_status from v$database;OPEN_MODE SWITCHOVER_STATUS---------------------------------------- --------------------READ ONLY TO PRIMARY #####进行切换12SQL&gt; ALTER DATABASE COMMIT TO SWITCHOVER TO PRIMARY WITH SESSION SHUTDOWN;Database altered. #####重启数据库重启新主库，对外提供服务12345678910111213141516SQL&gt; shutdown immediate;ORA-01109: database not openDatabase dismounted.ORACLE instance shut down.SQL&gt; startupORACLE instance started.Total System Global Area 835104768 bytesFixed Size 2257840 bytesVariable Size 746589264 bytesDatabase Buffers 79691776 bytesRedo Buffers 6565888 bytesDatabase mounted.Database opened. #####Failover后的还原由于Failover后主备关系消失，是迫不得已的操作，当主库fix完后，需要重启还原，如果开启了flashback功能，则flashback至Failover时的SCN，再重新应用备库日志。或者重新创建standby，然后再switchover。 #####使用闪回还原主库123456789SQL&gt; SELECT to_char(STANDBY_BECAME_PRIMARY_SCN) from V$DATABASE;SQL&gt; SHUTDOWN IMMEDIATE;SQL&gt; STARTUP MOUNT;SQL&gt; FLASHBACK DATABASE TO SCN &amp;standby_became_primary_scn;#将原主库转换成物理备库，并启动日志应用进程SQL&gt; ALTER DATABASE CONVERT TO PHYSICAL STANDBY;SQL&gt; SHUTDOWN IMMEDIATE;SQL&gt; STARTUP MOUNT;SQL&gt; ALTER DATABASE RECOVER MANAGED STANDBY DATABASE USING CURRENT LOGFILE DISCONNECT FROM SESSION; Reference:Quick Guide to configuring Oracle 11gR2 Data Guard Physical Standby Part1Quick Guide to configuring Oracle 11gR2 Data Guard Physical Standby Part2","link":"/dataguard-switchover-and-failover.html"},{"title":"DataGuard Broker","text":"Dataguard broker是9i开始引进的，随同Oracle企业版(Enterprise Edtion,EE)跟DataGuard一起内置的管理监控工具。通过DataGuard Broker，DBA能简化部署、监控DataGuard，以及主备角色切换。 1. Broker简介Broker由三部分组成：主备库各自的Broker后台进程，一系列的配置文件和命令行工具dgmgrl。需要注意的是，如果使用Broker管理或配置DataGuard，则不应该使用SQL命令再进行配置管理，否则会导致Broker参数配置或者数据库配置不一致的情况。Broker处理流程如下图所示，这些进程是在数据库及Broker启动自动运行，DBA无法介入。进程说明如下： DataGuard Monitor(DMON)：Broker主进程，所有进程中，最先启动DMON，它的主要任务是协调Broker的其他进程，包括维护Broker配置文件，这个进程通过DG_BROKER_START进行激活和取消。 Broker Resource Manager(RSM)：RSM处理Broker在任何一个数据库中进行配置所执行的所有SQL命令。 DataGuard Net Server (NSVn)：NSVn负责跟远程数据库连接。当创建配置文件时候需要指定连接符，NSVn就是通过这个连接符去连接远程数据库。 DRCn：网络接收进程，负责建立与source端NSVn进程的联系。NSVn到DRCn类似于在日志传输时的LogWriter Network Service(LNS)到Remote File Server(RSF)的连接，当日志传输时，Broker需要发送数据或者SQL命令，会使用NSV及DRC进行连接，这些连接只会在需要的情况下启动。 Configuration files：配置文件为在主库和备库上的常规二进制文件，它储存了DataGuard的所有参数配置。可以存储在OS文件系统上或者ASM存储上，它是通过Broker去进行维护，而不是认为去维护，类似SPIFLE。在Broker配置中，主库的DMON进程对DG配置有拥有权，不管在哪一个节点上对配置进行修改，都是在主节点完成。任何时候DMON需要执行一些SQL，它都会调用主库的RSM进行辅助。如果SQL执行目标是主库，它会直接执行；如果SQL执行目标是备库，RSM会要求NSVn进程将这些SQL命令传送到备库端，通过DRCn进程执行。使用Broker可通过Enterprises Manager Grid Control或者命令行工具dgmgrl。本文只介绍命令行工具的使用。dgmgrl工具是整合在EE版本中，包括Client端。我们甚至可以用Windows平台的dgmgrl去管理Linux平台的Broker配置，但一般不建议这么做。 2. Broker配置配置Broker先决条件： 由于Broker在配置过程中需要动态调整数据库参数，因此，必须要使用SPFILE。 RAC环境中，配置文件必须存储在共享磁盘上，如ASM，通过调整DG_BROKER_CONFIG_FILEn指定配置文件存放路径。 主备库数据库版本必须相同。 为了DMON能自动启动，DG_BROKER_START参数必须设置为TRUE。 2.1 设置配置文件12345678910111213141516171819#实验环境为11gR2 RAC + Single DataGuard#主备库同时修改[grid@fung02:/home/grid]$ asmcmd -pASMCMD [+] &gt; cd dataASMCMD [+data] &gt; mkdir BROKERSQL&gt; ALTER SYSTEM SET DG_BROKER_CONFIG_FILE1 = &apos;+DATA/BROKER/dr1rac11g.dat&apos; scope=both SID=&apos;*&apos;;System altered.SQL&gt; ALTER SYSTEM SET DG_BROKER_CONFIG_FILE2 = &apos;+DATA/BROKER/dr2rac11g.dat&apos; scope=both SID=&apos;*&apos;;System altered.SQL&gt; select name,value from v$parameter where name like &apos;dg_broker_config_file%&apos;;NAME VALUE------------------------------ --------------------------------------------------dg_broker_config_file1 +DATA/BROKER/dr1rac11g.datdg_broker_config_file2 +DATA/BROKER/dr2rac11g.datSQL&gt; show parameter spfileNAME TYPE VALUE--------------------- ---------------------- ------------------------------spfile string +DATA/rac11g/spfilerac11g.ora 2.2 Enable DMON12345678#主备库启动DMONSQL&gt; ALTER SYSTEM SET DG_BROKER_START=TRUE SCOPE=BOTH sid=&apos;*&apos;;System altered.SQL&gt; SHOW PARAMETER DG_BROKER_STARTNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------dg_broker_start boolean TRUE 顺序不能颠倒，必须要先设置好dg_broker_config_file，否则会报错：123456SQL&gt; ALTER SYSTEM SET dg_broker_config_file1 = &apos;+DATA/mfg/dr1mfg.dat&apos; scope=both sid=&apos;*&apos;; ALTER SYSTEM SET dg_broker_config_file1 = &apos;+DATA/mfg/dr1mfg.dat&apos; scope=both sid=&apos;*&apos;*ERROR at line 1:ORA-02097: parameter cannot be modified because specified value is invalidORA-16573: attempt to change or access configuration file for an enabled broker configuration 2.3 配置网络监听Broker需要在监听中增加${ORACLE_SID}_DGMGRL.db_domain的条目。所以，在各自节点对主备库都进行静态监听。在主备库grid用户下，增加相关条目至listener.ora12345678910111213141516171819#For node2, please change SID_NAME with node2s SID#primarySID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_DBNAME = rac11g_DGMGRL) (ORACLE_HOME = /u01/app/oracle/product/11gr2) (SID_NAME = rac11g1) ) )#standbySID_LIST_LISTENER = (SID_LIST = (SID_DESC = (GLOBAL_NAME = stdby_DGMGRL) (ORACLE_HOME = /u01/app/oracle/product/11gr2) (SID_NAME = rac11g) ) ) 主备库重启监听123456789101112131415161718192021222324252627282930[grid@fung01:/u01/app/11gr2/grid/network/admin]$ srvctl stop listener[grid@fung01:/u01/app/11gr2/grid/network/admin]$ srvctl start listener[grid@fung01:/u01/app/11gr2/grid/network/admin]$ lsnrctl statusLSNRCTL for Linux: Version 11.2.0.4.0 - Production on 17-JUN-2014 10:43:42Copyright (c) 1991, 2013, Oracle. All rights reserved.Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=IPC)(KEY=LISTENER)))STATUS of the LISTENER------------------------Alias LISTENERVersion TNSLSNR for Linux: Version 11.2.0.4.0 - ProductionStart Date 17-JUN-2014 10:43:36Uptime 0 days 0 hr. 0 min. 5 secTrace Level offSecurity ON: Local OS AuthenticationSNMP OFFListener Parameter File /u01/app/11gr2/grid/network/admin/listener.oraListener Log File /u01/app/grid/diag/tnslsnr/fung01/listener/alert/log.xmlListening Endpoints Summary... (DESCRIPTION=(ADDRESS=(PROTOCOL=ipc)(KEY=LISTENER))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=127.0.0.1)(PORT=1521))) (DESCRIPTION=(ADDRESS=(PROTOCOL=tcp)(HOST=192.168.192.103)(PORT=1521)))Services Summary...Service &quot;rac11g&quot; has 1 instance(s). Instance &quot;rac11g1&quot;, status READY, has 1 handler(s) for this service...Service &quot;rac11g_DGMGRL&quot; has 1 instance(s). Instance &quot;rac11g1&quot;, status UNKNOWN, has 1 handler(s) for this service...The command completed successfully 2.4 配置Broker1234567891011[oracle@fung01:/home/oracle]$ dgmgrl /DGMGRL for Linux: Version 11.2.0.4.0 - 64bit ProductionCopyright (c) 2000, 2009, Oracle. All rights reserved.Welcome to DGMGRL, type &quot;help&quot; for information.Connected.DGMGRL&gt; create configuration drrac11g as&gt; primary database is RAC11G&gt; connect identifier is RAC11G;Configuration &quot;drrac11g&quot; created with primary database &quot;rac11g&quot; 如果名称错了，可用DGMGRL&gt; remove configuration;移除配置，上一步骤指定了主库，包括其所有实例。下一步指定备库到Broker。1234567891011121314151617181920212223242526272829303132DGMGRL&gt; add database stdby as connect identifier is stdby maintained as physical;Database &quot;stdby&quot; addedDGMGRL&gt; enable configuration;Enabled.DGMGRL&gt; show database STDBYDatabase - stdby Role: PHYSICAL STANDBY Intended State: APPLY-ON Transport Lag: 0 seconds (computed 1 second ago) Apply Lag: 0 seconds (computed 1 second ago) Apply Rate: 79.00 KByte/s Real Time Query: ON Instance(s): rac11gDatabase Status:SUCCESSDGMGRL&gt; SHOW CONFIGURATION;Configuration - drrac11g Protection Mode: MaxPerformance Databases: rac11g - Primary database stdby - Physical standby databaseFast-Start Failover: DISABLEDConfiguration Status:SUCCESS 2.5 通过broker设置参数查询当前数据库配置详细信息:1show database verbose primary; 修改同步模式 12EDIT DATABASE 'STANDBY' SET PROPERTY 'LogXptMode'='SYNC';EDIT DATABASE 'STANDBY' SET PROPERTY 'LogXptMode'='ASYNC'; 修改备库日志应用模式 12EDIT DATABASE 'STANDBY' SET STATE='APPLY-OFF';EDIT DATABASE 'STANDBY' SET STATE='APPLY-ON'; 修改保护模式 1EDIT CONFIGURATION SET PROTECTION MODE AS MAXAVAILABILITY; 修改主库传输模式 12edit database 'PRIMARY' set STATE='TRANSPORT-OFF';edit database 'PRIMARY' set STATE='TRANSPORT-ON'; 3. switchover 切换前validate备库 1DGMGRL&gt; validate database verbose standby 如果是RAC，无论主备库，只保留一个节点实例，其他的关闭：1[oracle@fung02:/home/oracle]$ srvctl stop instance -d rac11g -o immediate -i rac11g2 进行switchover切换1234567891011DGMGRL&gt; connect sys/oracle@stdbyConnected.DGMGRL&gt; switchover to stdbyPerforming switchover NOW, please wait...New primary database &quot;stdby&quot; is opening...Operation requires startup of instance &quot;rac11g1&quot; on database &quot;rac11g&quot;Starting instance &quot;rac11g1&quot;...ORACLE instance started.Database mounted.Database opened.Switchover succeeded, new primary is &quot;stdby&quot; 不像手动切换一样，需要手动将另一个实例起来，dgmrl会自动启动node2的实例。123456SQL&gt; select inst_id,database_role,OPEN_MODE from gv$database; INST_ID DATABASE_ROLE OPEN_MODE---------- -------------------------------- ---------------------------------------- 2 PHYSICAL STANDBY READ ONLY WITH APPLY 1 PHYSICAL STANDBY READ ONLY WITH APPLY 4. 配置Fast-Start FailoverFast-Start Failover是建立在broker基础上的一个快速故障转换的机制，通过fast-start failover可以自动检测primary的故障，然后自动的failover到预先指定的standby上面，这样可以最大化的减少故障时间，提高数据库的可用性。Fast-Start Failover是在broker的基础上再增加了一个单独的observer server，用来监控primary和standby数据库的状态，一旦primary不可用，observer就会自动的切换到指定的standby上面。12DGMGRL&gt; show fast_start failover;Fast-Start Failover: DISABLED 启动Fast-Start Failover需要先开启闪回数据库(Flashback Database).且DataGuard必须在最大可用性模式下才能进行Fast-Start Failover。123456789SQL&gt; Alter system set db_recovery_file_dest_size=2G;SQL&gt; Alter system set db_recovery_file_dest=&apos;+DATA&apos;;$srvctl stop database -d rac11g -o immediate$srvctl start database -d rac11g -o mountSQL&gt; Alter database flashback on;#备库如果在open状态也要先重启至mount状态，如果备库在mount状态，则要先取消redo applySQL&gt; alter database recover managed standby database cancel;SQL&gt; Alter database flashback on;SQL&gt; alter database recover managed standby database disconnect from session; #####修改DataGuard保护模式12345678910#查询当前保护模式SQL&gt;select protection_mode,protection_level from v$database;#修改日志接收方式SQL&gt; ALTER SYSTEM SET LOG_ARCHIVE_DEST_2=&apos;SERVICE=stdby LGWR SYNC AFFIRM VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE) DB_UNIQUE_NAME=stdby&apos;; $srvctl stop database -d rac11g$srvctl start database -d rac11g -o mountSQL&gt;alter database set standby database to maximize availability;$srvctl start database -d rac11g -o open#为了切换，同时修改standby日志接收参数SQL&gt; ALTER SYSTEM SET LOG_ARCHIVE_DEST_2=&apos;SERVICE=rac11g OPTIONAL LGWR ASYNC AFFIRM VALID_FOR=(ONLINE_LOGFILES,PRIMARY_ROLE) DB_UNIQUE_NAME=rac11g&apos;; #####配置Fast-Start Failove参数12345678-- 配置rac11g failover的目标dgmgrl&gt; edit database rac11g set property &apos;FastStartFailoverTarget&apos;=&apos;stdby&apos;;-- 配置stdby failover的目标dgmgrl&gt; edit database stdby set property &apos;FastStartFailoverTarget&apos;=&apos;rac11g&apos;;--配置延时参数dgmgrl&gt; EDIT CONFIGURATION SET PROPERTY FastStartFailoverThreshold = 30;DGMGRL&gt; ENABLE FAST_START FAILOVER;DGMGRL&gt; start observer; EOF","link":"/dataguard-broker.html"},{"title":"DB_FILE_MULTIBLOCK_READ_COUNT","text":"db_file_multiblock_read_count参数代表Oracle在执行table full scan、index full scan或者index fast full scan时每次IO操作可以读取的数据块的数量。 1. 相关等待事件当数据的访问方式符合上面三种的时候，为了保障性能，尽量一次读取多个块，即Multi Block I/O。每次执行Multi Block I/O，都会等待物理I/O结束，此时产生等待db file scattered read事件。11g中有一个新特性，全表扫描可以通过直接路径读(direct path read)的方式来执行。 db file scattered read 等待事件：是由于多数据块读操作产生的，当检索数据时从磁盘上读数据到内存中，一次I/O读取多个数据块，而数据块在内存中是分散分布并不是连续的，当数据块读取到内存这个过程中会产生&#39;db file scattered read&#39;事件 direct path read 等待事件：11g中，大表全表扫描时数据块不经过sga而直接读取到会话私有PGA中，一般是PGA的sort area区。在这个过程中将会发生&#39;direct path read&#39;等待事件 1.1 direct path read1234567891011121314151617181920SYS@linora&gt; select * from v$version where rownum&lt;2;BANNER--------------------------------------------------------------------------------Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit ProductionSYS@linora&gt; alter session set db_file_multiblock_read_count=16;Session altered.SYS@linora&gt; alter session set events &apos;10046 trace name context forever, level 12&apos;;Session altered.SYS@linora&gt; select /*+ FULL(t) */ count(*) from sys.source$ t; COUNT(*)---------- 611684SYS@linora&gt; alter session set events &apos;10046 trace name context off&apos;;Session altered.SYS@linora&gt; col value for a80SYS@linora&gt; select value from v$diag_info where name=&apos;Default Trace File&apos;;VALUE--------------------------------------------------------------------------------/u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_4222.trc 部分trace文件：12345678910111213select /*+ FULL(t) */ count(*) from sys.source$ tEND OF STMT...WAIT # 140711463500848: nam=&apos;direct path read&apos; ela= 185 file number=1 first dba=1505 block cnt=7 obj#=224 tim=1408604487942484WAIT # 140711463500848: nam=&apos;direct path read&apos; ela= 109 file number=1 first dba=8168 block cnt=16 obj#=224 tim=1408604487942701...WAIT # 140711463500848: nam=&apos;direct path read&apos; ela= 100 file number=1 first dba=10272 block cnt=8 obj#=224 tim=1408604487948483WAIT # 140711463500848: nam=&apos;direct path read&apos; ela= 80 file number=1 first dba=10312 block cnt=8 obj#=224 tim=1408604487949419WAIT # 140711463500848: nam=&apos;direct path read&apos; ela= 262 file number=1 first dba=10360 block cnt=8 obj#=224 tim=1408604487950114WAIT # 140711463500848: nam=&apos;direct path read&apos; ela= 130 file number=1 first dba=10368 block cnt=16 obj#=224 tim=1408604487951202WAIT # 140711463500848: nam=&apos;direct path read&apos; ela= 113 file number=1 first dba=10408 block cnt=16 obj#=224 tim=1408604487952832...STAT # 140711463500848 id=2 cnt=611684 pid=1 pos=1 obj=224 op=&apos;TABLE ACCESS FULL SOURCE$ (cr=8058 pr=8055 pw=0 time=2716063 us cost=1773 size=0 card=611677)&apos; 从以上可以看到等待事件为&#39;direct path read&#39;，访问数据的方式为&#39;TABLE ACCESS FULL SOURCE$&#39;，且每次最多只能读取16个块(block cnt=16)。 1.2 db file scattered read在11g中，全表扫描已经使用direct path read，但可以设置隐含参数_serial_direct_read来禁止串行直接路径读，或者设置10949事件屏蔽11g的这个新特性，返回11g以前的模式上。1234567891011121314151617SYS@linora&gt; alter session set events &apos;10949 trace name context forever, level 1&apos;;Session altered.SYS@linora&gt; alter session set events &apos;10046 trace name context forever, level 12&apos;;Session altered.SYS@linora&gt; alter session set db_file_multiblock_read_count=16;Session altered.SYS@linora&gt; select /*+ FULL(t) */ count(*) from sys.source$ t; COUNT(*)---------- 611684SYS@linora&gt; alter session set events &apos;10046 trace name context off&apos;;Session altered.SYS@linora&gt; col value for a80SYS@linora&gt; select value from v$diag_info where name=&apos;Default Trace File&apos;;VALUE--------------------------------------------------------------------------------/u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_4502.trc 部分trace文件：12345678910select /*+ FULL(t) */ count(*) from sys.source$ tEND OF STMTWAIT # 140430667434504: nam=&apos;db file scattered read&apos; ela= 83 file#=1 block#=1505 blocks=7 obj#=224 tim=1408605703478759WAIT # 140430667434504: nam=&apos;db file scattered read&apos; ela= 67 file#=1 block#=8168 blocks=8 obj#=224 tim=1408605703479239WAIT # 140430667434504: nam=&apos;db file scattered read&apos; ela= 44 file#=1 block#=8176 blocks=8 obj#=224 tim=1408605703479634...WAIT # 140430667434504: nam=&apos;db file scattered read&apos; ela= 33 file#=1 block#=10864 blocks=16 obj#=224 tim=1408605703488577WAIT # 140430667434504: nam=&apos;db file scattered read&apos; ela= 34 file#=1 block#=16128 blocks=16 obj#=224 tim=1408605703489184...STAT # 140430667434504 id=2 cnt=611684 pid=1 pos=1 obj=224 op=&apos;TABLE ACCESS FULL SOURCE$ (cr=8064 pr=8055 pw=0 time=2097213 us cost=1773 size=0 card=611677)&apos; 从以上可以看到等待事件变为&#39;db file scattered read&#39;，访问数据的方式为&#39;TABLE ACCESS FULL SOURCE$&#39;，且每次最多只能读取16个块(blocks=16)。对隐含参数的描述：123456789101112131415SYS@linora&gt; set linesize 120SYS@linora&gt; col name for a30SYS@linora&gt; col value for a10SYS@linora&gt; col PDESC for a50SYS@linora&gt; SELECT x.ksppinm NAME, y.ksppstvl VALUE, x.KSPPDESC PDESC 2 FROM SYS.x$ksppi x, SYS.x$ksppcv y 3 WHERE x.indx = y.indx 4 AND x.ksppinm LIKE &apos;%&amp;par%&apos;;Enter value for par: _serial_direct_readold 4: AND x.ksppinm LIKE &apos;%&amp;par%&apos;new 4: AND x.ksppinm LIKE &apos;%_serial_direct_read%&apos;NAME VALUE PDESC------------------------------ ---------- --------------------------------------------------_serial_direct_read auto enable direct read in serial 该隐含参数是动态参数，我们可以通过alter system set方式修改 _serial_direct_read = FALSE，禁用direct path read _serial_direct_read = TURE，重新启用direct path read 2. db_file_multiblock_read_count最大值1234FUNG@linora&gt; show parameter db_block_sizeNAME TYPE VALUE------------------------------------ ----------- -------------------db_block_size integer 8192 将db_file_multiblock_read_count设置成无限大12345678SYS@linora&gt; col value for a10SYS@linora&gt; alter session set db_file_multiblock_read_count = 9999999;Session altered.SYS@linora&gt; select value from v$parameter where name = &apos;db_file_multiblock_read_count&apos;;VALUE----------4096 可以看到，本机的blocksize=8K，db_file_multiblock_read_count=4096，因此，在此OS上，理论最大一次可读取8K*4096=32M数据。理论上，最大的mbrc和系统IO有如下关系：1max(db_file_multiblock_read_count)=max os io size/db_block_size 但是，由于Oracle的一次IO不能跨extent，因此，Oracle的IO还要受到extent的影响，本例中extent均为默认的1M大小。即Oracle一次IO最大能扫描128块(1M)数据。123456789101112FUNG@linora&gt; alter session set events &apos;10949 trace name context forever, level 1&apos;;Session altered.FUNG@linora&gt; alter session set db_file_multiblock_read_count=99999;Session altered.FUNG@linora&gt; show parameter db_file_multiblock_read_countNAME TYPE VALUE------------------------------------ ----------- ------------------------------db_file_multiblock_read_count integer 4096FUNG@linora&gt; alter session set events &apos;10046 trace name context forever, level 12&apos;;Session altered.FUNG@linora&gt; select /*+ FULL(t) */ count(*) from sys.source$ t;FUNG@linora&gt; alter session set events &apos;10046 trace name context off&apos;; trace文件部分信息：12345WAIT # 139908117497232: nam=&apos;db file scattered read&apos; ela= 546 file#=1 block#=77056 blocks=128 obj#=224 tim=1408611829156495WAIT # 139908117497232: nam=&apos;db file scattered read&apos; ela= 581 file#=1 block#=78336 blocks=128 obj#=224 tim=1408611829159201WAIT # 139908117497232: nam=&apos;db file scattered read&apos; ela= 1274 file#=1 block#=78464 blocks=128 obj#=224 tim=1408611829162572WAIT # 139908117497232: nam=&apos;db file scattered read&apos; ela= 350 file#=1 block#=78592 blocks=128 obj#=224 tim=1408611829164950WAIT # 139908117497232: nam=&apos;db file scattered read&apos; ela= 664 file#=1 block#=78848 blocks=128 obj#=224 tim=1408611829167615 这里确实显示最大读取了128个块。但如果使用11G新特性，全表扫描用&#39;direct path read&#39;，会显示不同结果：1WAIT # 140535124395624: nam=&apos;direct path read&apos; ela= 3269 file number=1 first dba=83712 block cnt=1024 obj#=224 tim=1408612856901580 此时最大的读取块为1024个，即8M，估计11g有其他限制，以后有时间再研究。 3. 不同大小对性能的影响1234567891011121314151617181920212223242526272829FUNG@linora&gt; create table t as select * from dba_objects;Table created.FUNG@linora&gt; create index i_owner on t(owner);Index created.FUNG@linora&gt; analyze table t compute statistics for tablefor all indexesfor all indexed columns;FUNG@linora&gt; alter system flush buffer_cache;System altered.FUNG@linora&gt; set autotrace traceonly explainFUNG@linora&gt; alter session set db_file_multiblock_read_count=8;Session altered.FUNG@linora&gt; select * from t where owner=&apos;PUBLIC&apos;;33346 rows selected.Execution Plan----------------------------------------------------------Plan hash value: 1601196873--------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |--------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 33346 | 3289K| 339 (1)| 00:00:05 ||* 1 | TABLE ACCESS FULL| T | 33346 | 3289K| 339 (1)| 00:00:05 |--------------------------------------------------------------------------Predicate Information (identified by operation id):--------------------------------------------------- 1 - filter(&quot;OWNER&quot;=&apos;PUBLIC&apos;) 将db_file_multiblock_read_count设置为64：1234567891011121314151617181920FUNG@linora&gt; alter system flush buffer_cache;System altered.FUNG@linora&gt; alter session set db_file_multiblock_read_count=64;Session altered.FUNG@linora&gt; select * from t where owner=&apos;PUBLIC&apos;;33346 rows selected.Execution Plan----------------------------------------------------------Plan hash value: 1601196873--------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |--------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 33346 | 3289K| 226 (1)| 00:00:03 ||* 1 | TABLE ACCESS FULL| T | 33346 | 3289K| 226 (1)| 00:00:03 |--------------------------------------------------------------------------Predicate Information (identified by operation id):--------------------------------------------------- 1 - filter(&quot;OWNER&quot;=&apos;PUBLIC&apos;) 可以看到在全表扫描时，随着mbrc的增大，CPU cost从339降到226。 4. 总结在Oracle10gR2之后的版本（10gR2和11g）中，Oracle数据库已经可以根据系统的IO能力以及Buffer Cache的大小来动态调整该参数值，Oracle建议不要显式设置该参数值。在OLAP系统中，如果确实有大量需要全表扫描的SQL，可以考虑设置比较大一点。 Reference:深入解析OracleOracle 11g全表扫描以Direct Path Read方式执行","link":"/db-file-multiblock-read-count.html"},{"title":"DB2 Backup and Recovery","text":"Backup always essential. This post will show how to backup and recover a DB2 database. 1. Offline backupKeep db2 instance running and deactivate the databases: 123456789[db2inst1@db2srv ~]$ /worktmp/fptool.ksh -d+++Forcing applications and deactivating databases TESTDB...+++DB20000I The FORCE APPLICATION command completed successfully.DB21024I This command is asynchronous and may not be effective immediately.DB20000I The DEACTIVATE DATABASE command completed successfully.[db2inst1@db2srv ~]$ db2 backup db testdb to /db2backup/ PARALLELISM 4 compressBackup successful. The timestamp for this backup image is : 20170822140451 Use below command to figure out the backup progress: 12345678910111213141516[db2inst1@db2srv ~]$ db2 list utilities show detailID = 3Type = BACKUPDatabase Name = TESTDBMember Number = 0Description = offline dbStart Time = 08/22/2017 14:04:50.296195State = ExecutingInvocation Type = UserThrottling: Priority = UnthrottledProgress Monitoring: Estimated Percentage Complete = 20 Total Work = 160078696 bytes Completed Work = 32618320 bytes Start Time = 08/22/2017 14:04:50.296209 2. Online backupOnline backup always a little bit more complicated then offline backup, because whenever refer to the &quot;online&quot;, it means the database must enable archive log mode. Besides, the TRACKMOD must be enabled if the incremental backup is needed. 2.1 Enabling the archive log on DB2Below error means the database aren&#39;t in archive log mode. 12345[db2inst1@db2srv ~]$ db2 activate db testdbDB20000I The ACTIVATE DATABASE command completed successfully.[db2inst1@db2srv ~]$ db2 backup db testdb online to /db2backup include logsSQL2413N Online backup is not allowed because the database is not recoverableor a backup pending condition is in effect. Enabling the archive log mode: 1[db2inst1@db2srv ~]$ db2 update db cfg for testdb using LOGARCHMETH1 disk:/db2/archive/ 2.2 Enabling the TRACKMOD123[db2inst1@db2srv ~]$ db2 get db cfg for testdb |grep -i track Track modified pages (TRACKMOD) = NO[db2inst1@db2srv ~]$ db2 update db cfg for testdb using trackmod yes immediate 2.3 Take an online backup/incremental backupTake a offline backup before the online backup. 12345678[db2inst1@db2srv ~]$ db2 deactivate db testdbDB20000I The DEACTIVATE DATABASE command completed successfully.[db2inst1@db2srv ~]$ db2 activate db testdbSQL1116N A connection to or activation of database &quot;TESTDB&quot; failed becausethe database is in BACKUP PENDING state. SQLSTATE=57019[db2inst1@db2srv ~]$ db2 backup db testdb to /dev/nullBackup successful. The timestamp for this backup image is : 20170822144259 For the online backup and incremental backup: 1234567[db2inst1@db2srv ~]$ db2 activate db testdbDB20000I The ACTIVATE DATABASE command completed successfully.[db2inst1@db2srv ~]$ db2 backup db testdb online to /db2backup/ include logsBackup successful. The timestamp for this backup image is : 20170822144415[db2inst1@db2srv ~]$ db2 backup db testdb online incremental to /db2backup/ include logsBackup successful. The timestamp for this backup image is : 20170822144533 2.4 Verification of the backup imageDB2 provide db2ckbkp to check the integrity of the backup images. 123[db2inst1@db2srv db2backup]$ db2ckbkp TESTDB.0.db2inst1.DBPART000.20170822140451.001[1] Buffers processed: #############Image Verification Complete - successful. To check the backup image file header: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[db2inst1@db2srv db2backup]$ db2ckbkp -h TESTDB.0.db2inst1.DBPART000.20170822140451.001=====================MEDIA HEADER REACHED:===================== Server Database Name -- TESTDB Server Database Alias -- TESTDB Client Database Alias -- TESTDB Timestamp -- 20170822140451 Database Partition Number -- 0 Instance -- db2inst1 Database Configuration Type -- 0 (Non-shared data) Sequence Number -- 1 Database Member ID -- 0 Release ID -- 0x1400 (DB2 v11.1.2.2) AL version -- V:11 R:1 M:2 F:2 I:0 SB:0 Database Seed -- 0x6ABD4EE0 DB Comment&apos;s Codepage (Volume) -- 0 DB Comment (Volume) -- DB Comment&apos;s Codepage (System) -- 0 DB Comment (System) -- Authentication Value -- 255 (Not specified) Backup Mode -- 0 (Offline) Includes Logs -- 0 (No) Compression -- 1 (Compressed) Backup Type -- 0 (Database-level) Backup Granularity -- 0 (Non-incremental) Merged Backup Image -- 0 (No) Status Flags -- 0x1 Consistent on this member System Catalogs in this image -- 1 (Yes) Catalog Partition Number -- 0 DB Codeset -- UTF-8 DB Territory -- US LogID -- 1503316320 LogPath -- /db2/db2inst1/NODE0000/SQL00001/LOGSTREAM0000/ Backup Buffer Size -- 2101248 (513 4K pages) Number of Sessions -- 1 Platform -- 0x1E (Linux-x86-64) Encrypt Info Flags -- 0x0 The proper image file name would be:TESTDB.0.db2inst1.DBPART000.20170822140451.001[1] Buffers processed: #############Image Verification Complete - successful. To check the logs needed for roll forward: 1234[db2inst1@db2srv db2backup]$ db2ckbkp -a TESTDB.0.db2inst1.DBPART000.20170822144533.001 |grep -i &quot;File Number&quot; File Number [000] = 1 File Number [001] = 2 File Number [002] = 3 Display the LFH (Log File Header) and MFH (Mirror LFH) data: 12345678910111213[db2inst1@db2srv db2backup]$ db2ckbkp -l TESTDB.0.db2inst1.DBPART000.20170822144533.001 |grep -i lsn Database activation LSN = 0000000000040391 ... Min LSN To Undo = 0000000000000000 .... lowtranlsn = 0000000000040393 minbufflsn = 0000000000040393 groupMinBuffLSN = 0000000000040393 headlsn = 0000000000040393 groupHeadLsn = 0000000000040393 initialRecoveryStartingLFSLSN = 0/0000000000000000 startupLsn = 0000000000040391 myRegLsn = 0000000000000000 Use db2flsn to figure out the log sequence according to above result: 12[db2inst1@db2srv db2backup]$ db2flsn -db testdb 0000000000040393Given LSN is in log file S0000001.LOG 3. Disaster recovery3.1 Incomplete restore1234567891011121314[db2inst1@db2srv backup]$ dateFri Aug 7 10:59:14 CST 2015[db2inst1@db2srv backup]$[db2inst1@db2srv backup]$ db2 &quot;delete from (select * from t where id=&apos;51369&apos;)&quot;DB20000I The SQL command completed successfully.[db2inst1@db2srv backup]$ db2 commitDB20000I The SQL command completed successfully.[db2inst1@db2srv backup]$ db2 restore db testdb incremental automatic from /data2/backup/ taken at 20150807105110[db2inst1@db2srv backup]$ db2 rollforward db testdb to 2015-08-07.10.57.41.00000 using local time[db2inst1@db2srv backup]$ db2 rollforward db testdb stop[db2inst1@db2srv backup]$ db2 &quot;select * from t&quot;ID NAME----------- -------------------- 51369 Fung 3.2 Table space level restore12[db2inst1@db2srv backup]$ db2 &quot;restore db testdb tablespace (FUNG) online from /data2/backup taken at 20150807101213&quot;[db2inst1@db2srv backup]$ db2 &quot;rollforward db testdb to end of logs tablespace (FUNG)&quot; 3.3 Incremental recoveryFinding which backup set should be used for incremental recovery: 123456789[db2inst1@db2srv db2backup]$ db2ckrst -d testdb -t 20170822144533Suggested restore order of images using timestamp 20170822144533 fordatabase testdb.==================================================================== restore db testdb incremental taken at 20170822144533 restore db testdb incremental taken at 20170822144415 restore db testdb incremental taken at 20170822144533==================================================================== Example for incremental restore: 12345[db2inst1@db2srv db2backup]$ db2 drop db testdbDB20000I The DROP DATABASE command completed successfully.[db2inst1@db2srv db2backup]$ db2 restore db testdb incremental automatic taken at 20170822144533DB20000I The RESTORE DATABASE command completed successfully.[db2inst1@db2srv db2backup]$ db2 rollforward db testdb to end of logs and stop 3.4 Restoring the logsFor the include log backup, user can only restore the logs, and roll forward using these logs: 12345678[db2inst1@db2srv backup]$ db2 backup db testdb online to /data2/backup include logsBackup successful. The timestamp for this backup image is : 20150807145504[db2inst1@db2srv backup]$ db2 restore db testdb logs from /data2/backup/ taken at 20150807145504 logtarget /data2/logs/DB20000I The RESTORE DATABASE command completed successfully.[db2inst1@db2srv backup]$ ll /data2/logs/total 12-rw-------. 1 db2inst1 db2iadm1 12288 Aug 7 15:02 S0000022.LOG If restore with the database, the LOGS keyword not necessary:12db2 restore db testdb from /data2/backup/ taken at 20150807145504 logtarget /data2/logs/db2 &quot;rollforward db testdb to end of logs and stop overflow log path (/data2/logs) &quot; The overflow path is db2 looking for logs where rollforward needed 3.5 Restore to a different machineWhile performing migrating to another machine, there are three parameters which indicates where the database path are: TO target_directory DBPATH ON target_directory ON path_list If the target database doesn&#39;t exist, the TO and DBPATH ON keyword will specify the target database&#39;s catalog, ON specify the AutoStorage path, and database catalog will be placed in the first directory where ON specify. 123db2 restore db testdb into testdb taken at TIMESTAMP to /datadb2 restore db testdb into testdb taken at TIMESTAMP DBPATH ON /datadb2 restore db testdb into testdb taken at TIMESTAMP on '/data', '/data2' 3.6 Redirect restoreRedirect option can modify the container directory(except Auto Storage), you can generate a redirect script and modify it to meet your business needed. 12[db2inst1@db2srv db2backup]$ db2 restore db testdb taken at 20170822140451 redirect generate script redirect.dlldb2 -tvf redirect.dll 3.7 Roll forward usagesquery status : query current database status, to see if in rollforward pending. stop/complate : stop the rolling forward of log records, and completes the rollforward recovery process by rolling back incomplete transactions and turning off the rollforward pending state of the database. cancel : cancels the rollforward recovery operation. This puts the database in restore pending state. ONLINE : Tablespace level recovery to be done online. Makes the database can be accessible while rollforward in progress. 12345678910[db2inst1@db2srv db2backup]$ db2 rollforward db testdb query status Rollforward Status Input database alias = testdb Number of members have returned status = 1 Member ID = 0 Rollforward status = not pending Next log file to be read = Log files processed = S0000001.LOG - S0000001.LOG Last committed transaction = 2017-08-22-07.14.14.000000 UTC EOF","link":"/db2-backup-and-recovery.html"},{"title":"DB2 Runstats and Reorgs","text":"DB2 provide multiple tools and utilities for the maintenance, with these tools and utilities, it&#39;s more convenient for DBA to manage the DB2 database. 1. runstats and reorgsrunstats is for collecting indexes and tables statistics information which to enable the DB2 optimizer to generate efficient access plan.reorgs is for reorganizing tables and indexes. 1.1 runstatsCollect table and indexes information, including data distribution information:1db2 runstats on table db2inst1.employee on all columns with distribution and detailed indexes all Collect indexes statistics information:1db2 runstats on table db2inst1.employee for indexes all Collect table and indexes statistics information:1db2 runstats on table db2inst1.employee and detailed indexes all Collect table statistics information with histogram distribution of column empid and empname, and give the table with read access:1db2 runstats on table db2inst1.employee with distribution on columns ( empid, empname ) allow read access Verify if the tables have statistics or not:1234[db2inst1@db2srv db2backup]$ db2 &quot;select char(tabname,10) as tabname, stats_time from syscat.tables where tabname=&apos;EMPLOYEE&apos;&quot;TABNAME STATS_TIME---------- --------------------------EMPLOYEE 2017-08-22-17.20.12.999433 Scripts for generate the runstats: 1234567891011121314#!/bin/bashif [ &quot;$#&quot; &lt; 3 ] ; thenecho &quot;USAGE:$0 DB_NAME DB_USER_NAME DB_PASSWORD&quot;exitfiDB=$1DB_USER=$2DB_PWD=$3db2 connect to $DB user $DB_USER using $DB_PWDdb2 &quot;select trim(&apos;RUNSTATS ON TABLE &apos; || trim(tabschema) || &apos;.&apos; || tabname || &apos;\\ON ALL COLUMNS WITH DISTRIBUTION ON ALL COLUMNS AND SAMPLED DETAILED \\INDEXES ALL ALLOW WRITE ACCESS;&apos;) from syscat.tables where type=&apos;T&apos;&quot; \\|grep RUNSTATS &gt; runstats_detailed.sql#db2 -tvf runstats_detailed.sql 1.2 reorgs and reorgchkUse reorgchk to determine if a table/index need to be reorged or not.12db2 reorgchk on table db2inst1.employeedb2 reorgchk on schema db2inst1 if the column of reorgchk output F1~F3 marked as &quot;&quot;, it means the tables need to be reorged, if the F4~F8 columns marked as &quot;&quot;, it means the indexes need to be reorged There have two different ways to reorgs, for 24*7 mission critical database, recommend the in-place reorgs, but it will generate lots of logs, and it can be terminated at any time; another way is called classic reorgs, with more fast and indexes will be built in more perfect order. Advantage and disadvantages for in-place and classic reorgs In-place Classic Advantages Allow applications access during reorgs Fastest Can be paused and resumed Index built in perfect order Disadvantage Imperfect indexes reorganization Large space required Longer time to complete Limited table access Required more logs space All or nothing process Classic reorgs The offline reorgs phases: 1. Sort, 2. Build, 3. Replace or copy, 4. Index rebuild Specify temporary tablespace1db2 reorg table db2inst1.employee use TEMPSPACE1 Use the original tablespace which the table reside in1db2 reorg table db2inst1.employee In-place reorgs 1db2 reorg table db2inst1.employee index i1 inplace allow write access Monitoring the reorgs123456789101112131415161718192021222324252627282930313233343536373839[db2inst1@db2srv db2backup]$ db2 get snapshot for tables on testdb |grep -i employee -A 25 Table Name = EMPLOYEE Table Type = User Data Object Pages = 1 Index Object Pages = 6 Rows Read = Not Collected Rows Written = 0 Overflows = 0 Page Reorgs = 0 Table Reorg Information: Reorg Type = Reclaiming Table Reorg Allow Read Access Reorg Data Only Reorg Index = 0 Reorg Tablespace = 1 Start Time = 08/22/2017 19:21:03.312249 Reorg Phase = 3 - Index Recreate Max Phase = 3 Phase Start Time = 08/22/2017 19:21:03.423726 Status = Completed Current Counter = 0 Max Counter = 0 Completion = 0 End Time = 08/22/2017 19:21:03.527966[db2inst1@db2srv db2backup]$ db2pd -d testdb -reorgs file=reorg.outSending -reorgs output to /db2backup/reorg.out.[db2inst1@db2srv db2backup]$ db2 list history reorg all for testdbdb2 &quot;select * from sysibmadm.snaptab_reorg&quot;db2 select * from table(sysproc.admin_list_hist( )) as listhistory$HOME/sqllib/db2dump/&lt;instance_name&gt;db2 &quot;SELECT SUBSTR(TABNAME, 1, 15) AS TAB_NAME,SUBSTR(TABSCHEMA, 1, 15) AS TAB_SCHEMA,REORG_PHASE, SUBSTR(REORG_TYPE, 1, 20) AS REORG_TYPE,REORG_STATUS, REORG_COMPLETION, DBPARTITIONNUMFROM SYSIBMADM.SNAPTAB_REORG ORDER BY DBPARTITIONNUM&quot; EOF","link":"/db2-runstats-and-reorgs.html"},{"title":"11g新特性—FDI简介","text":"1.FDI简介 从11g开始，Oracle增强了自动化错误诊断的功能。诊断数据包括以前版本的trace files，dumps，core file等等。 FDI（Fault Diagnosability Infrastructure）在于阻止、检测、诊断及解决问题。当数据库检测到critical errors，会将这些诊断数据保存到Automatic Diagnostic Repository(ADR)里面。ADR类似OFA，在诊断文件中，也有了系统的存储规划架构。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556SQL&gt; show parameter diagnostic_dest NAME TYPE VALUE ------------------------------------ ----------- ------------------------------ diagnostic_dest string /u01/app/oracle SQL&gt; !tree -d /u01/app/oracle/diag /u01/app/oracle/diag |-- asm |-- clients |-- crs |-- diagtool |-- lsnrctl |-- netcman |-- ofm |-- rdbms | `-- racdb | `-- racdb1 | |-- alert | |-- cdump | |-- hm | |-- incident | |-- incpkg | |-- ir | |-- lck | |-- metadata | |-- metadata_dgif | |-- metadata_pv | |-- stage | |-- sweep | `-- trace `-- tnslsnr 24 directories SQL&gt; col name for a30 SQL&gt; col value for a80 SQL&gt; set linesize 200 SQL&gt; select * from v$diag_info; INST_ID NAME VALUE ---------- ------------------------------ -------------------------------------------------------------------------------- 1 Diag Enabled TRUE 1 ADR Base /u01/app/oracle 1 ADR Home /u01/app/oracle/diag/rdbms/racdb/racdb1 1 Diag Trace /u01/app/oracle/diag/rdbms/racdb/racdb1/trace 1 Diag Alert /u01/app/oracle/diag/rdbms/racdb/racdb1/alert 1 Diag Incident /u01/app/oracle/diag/rdbms/racdb/racdb1/incident 1 Diag Cdump /u01/app/oracle/diag/rdbms/racdb/racdb1/cdump 1 Health Monitor /u01/app/oracle/diag/rdbms/racdb/racdb1/hm 1 Default Trace File /u01/app/oracle/diag/rdbms/racdb/racdb1/trace/racdb1_ora_27059.trc 1 Active Problem Count 0 1 Active Incident Count 0 11 rows selected. SQL&gt; 2.FDI核心组件FDI的核心组件包括ADR、alter log、trace files，dumps，core files。 2.1. ADRADR是一个小型的外部XML数据库，它用于存储数据库，ASM，CRS等的诊断信息，每个实例拥有各自的ADR home目录，例如在一个RAC环境下，分别以grid及Oracle用户查询，将会得到不同的ADR HOME：1234567891011121314151617181920212223[oracle@orcl1:/home/oracle]$ adrci ADRCI: Release 11.2.0.4.0 - Production on Mon Sep 9 12:33:23 2013 Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved. ADR base = &quot;/u01/app/oracle&quot; adrci&gt; show home ADR Homes: diag/rdbms/racdb/racdb1 [grid@orcl1:/home/grid]$ adrci ADRCI: Release 11.2.0.4.0 - Production on Mon Sep 9 12:33:40 2013 Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved. ADR base = &quot;/u01/app/grid&quot; adrci&gt; show home ADR Homes: diag/tnslsnr/orcl1/listener diag/asm/+asm/+ASM1 adrci&gt; 因为从11g开始，所有的诊断文件，包括alter log都包含在ADR中，因此，BACKUPGROUND_DUMP_DEST及USER_DUMP_DESTl两个参数已经被废弃了，取而代之的是代表ADR目录的DIAGNOSTIC_DEST。如果此参数没有被设置，那么它将依靠以下两点进行设置默认值： 如果ORACLE_BASE环境变量设置生效了，此参数将被设为ORACLE_BASE 如果ORACLE_HOME没有设置，那么，此参数将会设置成ORACLE_HOME/log 2.2. ADRCI工具在11g中的alter log已经是一个XML文件了，需要通过adrci工具或者EM工具才能查看，它包含了以下信息： 严重错误、事件 管理数据的一些动作，如启停数据库，恢复数据库或者创建删除表空间等 自动刷新MView的错误 其他数据库事件信息 2.3. ADRCI示例首先模拟一个ora错误：123456789101112131415161718192021222324252627SQL&gt; create undo tablespace undotbs2 datafile &apos;/oradata/datafile/linora/undotbs02.dbf&apos; size 1m;Tablespace created.SQL&gt; SQL&gt; alter system set undo_tablespace=undotbs2;System altered.SQL&gt; show parameter undo;NAME TYPE VALUE------------------------------------ ----------- ------------------------------undo_management string AUTOundo_retention integer 900undo_tablespace string UNDOTBS2SQL&gt; conn fung/oracle;Connected.SQL&gt; create table test as select object_id,object_name from dba_objects;Table created.SQL&gt; insert into test select * FROM TEST;insert into test select * FROM TEST *ERROR at line 1:ORA-30036: unable to extend segment by 8 in undo tablespace &apos;UNDOTBS2&apos; 切换至adrci命令行查找：1234567891011121314151617181920212223[root@linora ~]# su - oracle[oracle@linora:/home/oracle]$ adrciADRCI: Release 11.2.0.4.0 - Production on Thu May 15 09:52:49 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.ADR base = &quot;/u01/app/oracle&quot;adrci&gt; show problemADR Home = /u01/app/oracle/diag/tnslsnr/linora/listener:*************************************************************************0 rows fetchedADR Home = /u01/app/oracle/diag/diagtool/user_oracle/host_1587426630_80:*************************************************************************PROBLEM_ID PROBLEM_KEY LAST_INCIDENT LASTINC_TIME -------------------- ----------------------------------------------------------- -------------------- ---------------------------------------- 1 DIA 48001 [dbgvcis_ostream_write_1] 1 2014-05-15 09:26:41.240000 +08:00 ADR Home = /u01/app/oracle/diag/rdbms/linora/linora:*************************************************************************0 rows fetched 上述结果显示了，在2014年5月15日，发生了一个dia-48001的错误。但这并不是一个rdbms的错误，因为ADR HOME目录是在diagtool下面。通过show incident可以查找出这个错误究竟影响了哪些东西：123456789101112131415adrci&gt; show incidentADR Home = /u01/app/oracle/diag/tnslsnr/linora/listener:*************************************************************************0 rows fetchedADR Home = /u01/app/oracle/diag/diagtool/user_oracle/host_1587426630_80:*************************************************************************INCIDENT_ID PROBLEM_KEY CREATE_TIME -------------------- ----------------------------------------------------------- ---------------------------------------- 1 DIA 48001 [dbgvcis_ostream_write_1] 2014-05-15 09:26:41.240000 +08:00 ADR Home = /u01/app/oracle/diag/rdbms/linora/linora:*************************************************************************0 rows fetched 在本例中，并无影响。通过以下命令，可以查找这个错误的trace file及trace file的详细信息：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859adrci&gt; show tracefile -I 1 diag/diagtool/user_oracle/host_1587426630_80/incident/incdir_1/ora_2011_139919799314176_i1.trcadrci&gt; show incident -mode detail -p &quot;incident_id=1&quot; ADR Home = /u01/app/oracle/diag/tnslsnr/linora/listener:*************************************************************************0 rows fetched&lt;INCIDENT_INFO mode=&quot;detail&quot;&gt;&lt;ADR_HOME name=&quot;/u01/app/oracle/diag/tnslsnr/linora/listener&quot;&gt;ADR Home = /u01/app/oracle/diag/diagtool/user_oracle/host_1587426630_80:***********************************************************************************************************************************INCIDENT INFO RECORD 1********************************************************** INCIDENT_ID 1 STATUS ready CREATE_TIME 2014-05-15 09:26:41.240000 +08:00 PROBLEM_ID 1 CLOSE_TIME &lt;NULL&gt; FLOOD_CONTROLLED none ERROR_FACILITY DIA ERROR_NUMBER 48001 ERROR_ARG1 dbgvcis_ostream_write_1 ERROR_ARG2 &lt;NULL&gt; ERROR_ARG3 &lt;NULL&gt; ERROR_ARG4 &lt;NULL&gt; ERROR_ARG5 &lt;NULL&gt; ERROR_ARG6 &lt;NULL&gt; ERROR_ARG7 &lt;NULL&gt; ERROR_ARG8 &lt;NULL&gt; ERROR_ARG9 &lt;NULL&gt; ERROR_ARG10 &lt;NULL&gt; ERROR_ARG11 &lt;NULL&gt; ERROR_ARG12 &lt;NULL&gt; SIGNALLING_COMPONENT diag_fmwk SIGNALLING_SUBCOMPONENT &lt;NULL&gt; SUSPECT_COMPONENT &lt;NULL&gt; SUSPECT_SUBCOMPONENT &lt;NULL&gt; ECID &lt;NULL&gt; IMPACTS 0 PROBLEM_KEY DIA 48001 [dbgvcis_ostream_write_1] FIRST_INCIDENT 1 FIRSTINC_TIME 2014-05-15 09:26:41.240000 +08:00 LAST_INCIDENT 1 LASTINC_TIME 2014-05-15 09:26:41.240000 +08:00 IMPACT1 0 IMPACT2 0 IMPACT3 0 IMPACT4 0 OWNER_ID 1 INCIDENT_FILE /u01/app/oracle/diag/diagtool/user_oracle/host_1587426630_80/trace/ora_2011_139919799314176.trc OWNER_ID 1 INCIDENT_FILE /u01/app/oracle/diag/diagtool/user_oracle/host_1587426630_80/incident/incdir_1/ora_2011_139919799314176_i1.trcADR Home = /u01/app/oracle/diag/rdbms/linora/linora:*************************************************************************0 rows fetched 最后，可以通过create package对trace file进行打包，以便作为sr中的附件给oracle support分析。123456789adrci&gt; set home diag/diagtool/user_oracle/host_1587426630_80adrci&gt; ips create package incident 1Created package 1 based on incident id 1, correlation level typicaladrci&gt; ips add incident 1 package 1Added incident 1 to package 1adrci&gt; ips add file /u01/app/oracle/diag/rdbms/linora/linora/trace/alert_linora.log package 1Added file /u01/app/oracle/diag/rdbms/linora/linora/trace/alert_linora.log to package 1adrci&gt; ips generate package 1 in /home/oracleGenerated package 1 in file /home/oracle/DIA48001d_20140515100720_COM_1.zip, mode complete 解压上述包，可用如下命令：12345678910111213141516171819202122232425262728adrci&gt; ips get metadata from file /home/oracle/DIA48001d_20140515100720_COM_1.zipIPS metadata from file /home/oracle/DIA48001d_20140515100720_COM_1.zip:----------------------------------------------------------&lt;?xml version=&quot;1.0&quot; encoding=&quot;US-ASCII&quot;?&gt;&lt;PACKAGE&gt; &lt;PACKAGE_ID&gt;1&lt;/PACKAGE_ID&gt; &lt;PACKAGE_NAME&gt;DIA48001d_20140515100720&lt;/PACKAGE_NAME&gt; &lt;MODE&gt;Complete&lt;/MODE&gt; &lt;SEQUENCE&gt;1&lt;/SEQUENCE&gt; &lt;LAST_COMPLETE&gt;1&lt;/LAST_COMPLETE&gt; &lt;DATE&gt;2014-05-15 10:12:10.050452 +08:00&lt;/DATE&gt; &lt;ADR_BASE&gt;/u01/app/oracle&lt;/ADR_BASE&gt; &lt;ADR_HOME&gt;/u01/app/oracle/diag/diagtool/user_oracle/host_1587426630_80&lt;/ADR_HOME&gt; &lt;PROD_NAME&gt;diagtool&lt;/PROD_NAME&gt; &lt;PROD_ID&gt;user_oracle&lt;/PROD_ID&gt; &lt;INST_ID&gt;host_1587426630_80&lt;/INST_ID&gt; &lt;OCM_GUID/&gt; &lt;OCM_ANNOTATION/&gt; &lt;FINALIZED&gt;1&lt;/FINALIZED&gt;&lt;/PACKAGE&gt;----------------------------------------------------------adrci&gt; ips unpack file /home/oracle/DIA48001d_20140515100720_COM_1.zipUnpacking file /home/oracle/DIA48001d_20140515100720_COM_1.zip into current working directory[oracle@linora ~]$ ls -ltotal 102816-rw-r--r-- 1 oracle oinstall 76421 May 15 10:12 DIA48001d_20140515100720_COM_1.zipdrwxrwxr-x 3 oracle oinstall 4096 May 15 10:20 diag 2.4. ADRCI基本命令12345678910111213141516171819adrci&gt; show baseADR base is &quot;/u01/app/oracle&quot;adrci&gt; show homeADR Homes: diag/tnslsnr/linora/listenerdiag/diagtool/user_oracle/host_1587426630_80diag/rdbms/linora/linoraadrci&gt; set home diag/rdbms/linora/linoraadrci&gt; show alert -tail 52014-05-15 09:51:15.569000 +08:00ORA-1119 signalled during: create undo tablespace undotbs2 datafile &apos;/oradata/datafile/linora/undotbs02.dbf&apos;...2014-05-15 09:51:47.709000 +08:00create undo tablespace undotbs2 datafile &apos;/oradata/datafile/linora/undotbs02.dbf&apos; size 1mORA-1652: unable to extend temp segment by 8 in tablespace UNDOTBS2 Completed: create undo tablespace undotbs2 datafile &apos;/oradata/datafile/linora/undotbs02.dbf&apos; size 1m2014-05-15 09:51:55.397000 +08:00[2048] Successfully onlined Undo Tablespace 6.[2048] Undo Tablespace 2 successfully switched out.ALTER SYSTEM SET undo_tablespace=&apos;UNDOTBS2&apos; SCOPE=BOTH; 其他详细命令请参照手册：Oracle® Database Administrator&#39;s Guide 11g Release 2 (11.2) EOF","link":"/11g-fault-diagnosability-infrastructure.html"},{"title":"Deinstall Oracle 11g RAC","text":"11g提供了deinstall工具对11g数据库进行删除，以RAC为例，删除步骤为：先删除database，再删除database软件，最后以gi用户删除Grid Infrastructure软件。 1.以oracle用户登录，调用dbca删除database 2.以oracle用户登录，进入$ORACLE_HOME/deintall/，执行deinstall脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183[oracle@oel1:/home/oracle]$ /u01/app/oracle/product/11.2.0/db_1/deinstall/deinstallChecking for required files and bootstrapping ...Please wait ...Location of logs /u01/app/oracle/oraInventory/logs/ ############ ORACLE DEINSTALL &amp; DECONFIG TOOL START ############ ######################### CHECK OPERATION START ########################### [START] Install check configuration ##Checking for existence of the Oracle home location /u01/app/oracle/product/11.2.0/db_1Oracle Home type selected for deinstall is: Oracle Real Application Cluster DatabaseOracle Base selected for deinstall is: /u01/app/oracleChecking for existence of central inventory location /u01/app/oracle/oraInventoryChecking for existence of the Oracle Grid Infrastructure home /u01/app/11gr2/gridThe following nodes are part of this cluster: oel1,oel2Checking for sufficient temp space availability on node(s) : &apos;oel1,oel2&apos; ## [END] Install check configuration ## Network Configuration check config START Network de-configuration trace file location: /u01/app/oracle/oraInventory/logs/netdc_check2014-03-29_11-21-30-PM.log Specify all RAC listeners (do not include SCAN listener) that are to be de-configured [ORCL_LISTENER]: Network Configuration check config END Database Check Configuration START Database de-configuration trace file location: /u01/app/oracle/oraInventory/logs/databasedc_check2014-03-29_11-21-39-PM.log Use comma as separator when specifying list of values as input Specify the list of database names that are configured in this Oracle home []: orcl ###### For Database &apos;orcl&apos; ###### Specify the type of this database (1.Single Instance Database|2.Oracle Restart Enabled Database|3.RAC Database|4.RAC One Node Database) [2]: 3Specify the list of nodes on which this database has instances []: oel1,oel2Specify the list of instance names [orcl]: orcl1,orcl2Specify the local instance name on node []: orcl1Specify the diagnostic destination location of the database [/u01/app/oracle/diag/rdbms/orcl]:Specify the storage type used by the Database ASM|FS []: ASM Database Check Configuration END Enterprise Manager Configuration Assistant START EMCA de-configuration trace file location: /u01/app/oracle/oraInventory/logs/emcadc_check2014-03-29_11-22-27-PM.log Checking configuration for database orclEnterprise Manager Configuration Assistant ENDOracle Configuration Manager check STARTOCM check log file location : /u01/app/oracle/oraInventory/logs//ocm_check6234.logOracle Configuration Manager check END ######################### CHECK OPERATION END ######################### ####################### CHECK OPERATION SUMMARY #######################Oracle Grid Infrastructure Home is: /u01/app/11gr2/gridThe cluster node(s) on which the Oracle home deinstallation will be performed are:oel1,oel2Oracle Home selected for deinstall is: /u01/app/oracle/product/11.2.0/db_1Inventory Location where the Oracle home registered is: /u01/app/oracle/oraInventoryFollowing RAC listener(s) will be de-configured: ORCL_LISTENERThe following databases were selected for de-configuration : orclDatabase unique name : orclStorage used : ASMNo Enterprise Manager configuration to be updated for any database(s)No Enterprise Manager ASM targets to updateNo Enterprise Manager listener targets to migrateChecking the config status for CCRoel1 : Oracle Home exists with CCR directory, but CCR is not configuredoel2 : Oracle Home exists with CCR directory, but CCR is not configuredCCR check is finishedDo you want to continue (y - yes, n - no)? [n]: yA log of this session will be written to: &apos;/u01/app/oracle/oraInventory/logs/deinstall_deconfig2014-03-29_11-21-05-PM.out&apos;Any error messages from this session will be written to: &apos;/u01/app/oracle/oraInventory/logs/deinstall_deconfig2014-03-29_11-21-05-PM.err&apos; ######################## CLEAN OPERATION START ######################## Enterprise Manager Configuration Assistant START EMCA de-configuration trace file location: /u01/app/oracle/oraInventory/logs/emcadc_clean2014-03-29_11-22-27-PM.log Updating Enterprise Manager ASM targets (if any)Updating Enterprise Manager listener targets (if any)Enterprise Manager Configuration Assistant ENDDatabase de-configuration trace file location: /u01/app/oracle/oraInventory/logs/databasedc_clean2014-03-29_11-22-37-PM.logDatabase Clean Configuration START orclThis operation may take few minutes.Database Clean Configuration END orcl Network Configuration clean config START Network de-configuration trace file location: /u01/app/oracle/oraInventory/logs/netdc_clean2014-03-29_11-23-20-PM.log De-configuring RAC listener(s): ORCL_LISTENER De-configuring listener: ORCL_LISTENER Stopping listener: ORCL_LISTENER Listener stopped successfully. Unregistering listener: ORCL_LISTENER Listener unregistered successfully.Listener de-configured successfully. De-configuring Listener configuration file on all nodes...Listener configuration file de-configured successfully. De-configuring Naming Methods configuration file on all nodes...Naming Methods configuration file de-configured successfully. De-configuring Local Net Service Names configuration file on all nodes...Local Net Service Names configuration file de-configured successfully. De-configuring Directory Usage configuration file on all nodes...Directory Usage configuration file de-configured successfully. De-configuring backup files on all nodes...Backup files de-configured successfully. The network configuration has been cleaned up successfully. Network Configuration clean config END Oracle Configuration Manager clean STARTOCM clean log file location : /u01/app/oracle/oraInventory/logs//ocm_clean6234.logOracle Configuration Manager clean ENDSetting the force flag to falseSetting the force flag to cleanup the Oracle BaseOracle Universal Installer clean START Detach Oracle home &apos;/u01/app/oracle/product/11.2.0/db_1&apos; from the central inventory on the local node : Done Delete directory &apos;/u01/app/oracle/product/11.2.0/db_1&apos; on the local node : Done The Oracle Base directory &apos;/u01/app/oracle&apos; will not be removed on local node. The directory is in use by Oracle Home &apos;/u01/app/oracle/product/crs&apos;. The Oracle Base directory &apos;/u01/app/oracle&apos; will not be removed on local node. The directory is in use by central inventory. Detach Oracle home &apos;/u01/app/oracle/product/11.2.0/db_1&apos; from the central inventory on the remote nodes &apos;oel2&apos; : Done Delete directory &apos;/u01/app/oracle/product/11.2.0/db_1&apos; on the remote nodes &apos;oel2&apos; : Done The Oracle Base directory &apos;/u01/app/oracle&apos; will not be removed on node &apos;oel2&apos;. The directory is in use by Oracle Home &apos;/u01/app/oracle/product/crs&apos;. The Oracle Base directory &apos;/u01/app/oracle&apos; will not be removed on node &apos;oel2&apos;. The directory is in use by central inventory. Oracle Universal Installer cleanup was successful. Oracle Universal Installer clean END ## [START] Oracle install clean ## Clean install operation removing temporary directory &apos;/tmp/deinstall2014-03-29_11-18-22PM&apos; on node &apos;oel1&apos;Clean install operation removing temporary directory &apos;/tmp/deinstall2014-03-29_11-18-22PM&apos; on node &apos;oel2&apos; ## [END] Oracle install clean ## ######################### CLEAN OPERATION END ######################### ####################### CLEAN OPERATION SUMMARY #######################Successfully de-configured the following database instances : orclFollowing RAC listener(s) were de-configured successfully: ORCL_LISTENERCleaning the config for CCRAs CCR is not configured, so skipping the cleaning of CCR configurationCCR clean is finishedSuccessfully detached Oracle home &apos;/u01/app/oracle/product/11.2.0/db_1&apos; from the central inventory on the local node.Successfully deleted directory &apos;/u01/app/oracle/product/11.2.0/db_1&apos; on the local node.Successfully detached Oracle home &apos;/u01/app/oracle/product/11.2.0/db_1&apos; from the central inventory on the remote nodes &apos;oel2&apos;.Successfully deleted directory &apos;/u01/app/oracle/product/11.2.0/db_1&apos; on the remote nodes &apos;oel2&apos;.Oracle Universal Installer cleanup was successful. Run &apos;rm -rf /opt/ORCLfmap&apos; as root on node(s) &apos;oel2&apos; at the end of the session.Oracle deinstall tool successfully cleaned up temporary directories.####################################################################### ############# ORACLE DEINSTALL &amp; DECONFIG TOOL END ############# [oracle@oel1:/home/oracle]$[oracle@oel1:/home/oracle]$ ll /u01/app/oracle/product/11.2.0/total 0[root@oel2:/root]# rm -rf /opt/ORCLfmap 3.以root用户登录节点1，执行以下脚本 123456789101112131415161718192021222324252627282930313233343536373839404142434445[root@oel1:/root]# /u01/app/11gr2/grid/crs/install/rootcrs.pl -verbose -deconfig –forceUsing configuration parameter file: /u01/app/11gr2/grid/crs/install/crsconfig_paramsNetwork exists: 1/192.168.56.0/255.255.255.0/eth0, type staticVIP exists: /orcl1-vip/192.168.56.125/192.168.56.0/255.255.255.0/eth0, hosting node oel1VIP exists: /orcl2-vip/192.168.56.126/192.168.56.0/255.255.255.0/eth0, hosting node oel2GSD existsONS exists: Local port 6100, remote port 6200, EM port 2016CRS-2673: Attempting to stop &apos;ora.registry.acfs&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.registry.acfs&apos; on &apos;oel1&apos; succeededCRS-2791: Starting shutdown of Oracle High Availability Services-managed resources on &apos;oel1&apos;CRS-2673: Attempting to stop &apos;ora.crsd&apos; on &apos;oel1&apos;CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on &apos;oel1&apos;CRS-2673: Attempting to stop &apos;ora.DATA.dg&apos; on &apos;oel1&apos;CRS-2673: Attempting to stop &apos;ora.OCR.dg&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.DATA.dg&apos; on &apos;oel1&apos; succeededCRS-2677: Stop of &apos;ora.OCR.dg&apos; on &apos;oel1&apos; succeededCRS-2673: Attempting to stop &apos;ora.asm&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.asm&apos; on &apos;oel1&apos; succeededCRS-2792: Shutdown of Cluster Ready Services-managed resources on &apos;oel1&apos; has completedCRS-2677: Stop of &apos;ora.crsd&apos; on &apos;oel1&apos; succeededCRS-2673: Attempting to stop &apos;ora.drivers.acfs&apos; on &apos;oel1&apos;CRS-2673: Attempting to stop &apos;ora.ctssd&apos; on &apos;oel1&apos;CRS-2673: Attempting to stop &apos;ora.evmd&apos; on &apos;oel1&apos;CRS-2673: Attempting to stop &apos;ora.asm&apos; on &apos;oel1&apos;CRS-2673: Attempting to stop &apos;ora.mdnsd&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.evmd&apos; on &apos;oel1&apos; succeededCRS-2677: Stop of &apos;ora.ctssd&apos; on &apos;oel1&apos; succeededCRS-2677: Stop of &apos;ora.mdnsd&apos; on &apos;oel1&apos; succeededCRS-2677: Stop of &apos;ora.drivers.acfs&apos; on &apos;oel1&apos; succeededCRS-2677: Stop of &apos;ora.asm&apos; on &apos;oel1&apos; succeededCRS-2673: Attempting to stop &apos;ora.cluster_interconnect.haip&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.cluster_interconnect.haip&apos; on &apos;oel1&apos; succeededCRS-2673: Attempting to stop &apos;ora.cssd&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.cssd&apos; on &apos;oel1&apos; succeededCRS-2673: Attempting to stop &apos;ora.crf&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.crf&apos; on &apos;oel1&apos; succeededCRS-2673: Attempting to stop &apos;ora.gipcd&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.gipcd&apos; on &apos;oel1&apos; succeededCRS-2673: Attempting to stop &apos;ora.gpnpd&apos; on &apos;oel1&apos;CRS-2677: Stop of &apos;ora.gpnpd&apos; on &apos;oel1&apos; succeededCRS-2793: Shutdown of Oracle High Availability Services-managed resources on &apos;oel1&apos; has completedCRS-4133: Oracle High Availability Services has been stopped.Removing Trace File AnalyzerSuccessfully deconfigured Oracle clusterware stack on this node[root@oel1:/root]# 4.在第二个节点，以root用户执行以下脚本，以清除OCR及votedisk信息 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465[root@oel2:/root]# /u01/app/11gr2/grid/crs/install/rootcrs.pl -verbose -deconfig -force -lastnodeUsing configuration parameter file: /u01/app/11gr2/grid/crs/install/crsconfig_paramsCRS resources for listeners are still configuredNetwork exists: 1/192.168.56.0/255.255.255.0/eth0, type staticVIP exists: /orcl2-vip/192.168.56.126/192.168.56.0/255.255.255.0/eth0, hosting node oel2GSD existsONS exists: Local port 6100, remote port 6200, EM port 2016CRS-2673: Attempting to stop &apos;ora.registry.acfs&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.registry.acfs&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.crsd&apos; on &apos;oel2&apos;CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.DATA.dg&apos; on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.OCR.dg&apos; on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.oc4j&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.DATA.dg&apos; on &apos;oel2&apos; succeededCRS-2677: Stop of &apos;ora.OCR.dg&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.asm&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.asm&apos; on &apos;oel2&apos; succeededCRS-2677: Stop of &apos;ora.oc4j&apos; on &apos;oel2&apos; succeededCRS-2792: Shutdown of Cluster Ready Services-managed resources on &apos;oel2&apos; has completedCRS-2677: Stop of &apos;ora.crsd&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.ctssd&apos; on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.evmd&apos; on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.asm&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.evmd&apos; on &apos;oel2&apos; succeededCRS-2677: Stop of &apos;ora.asm&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.cluster_interconnect.haip&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.cluster_interconnect.haip&apos; on &apos;oel2&apos; succeededCRS-2677: Stop of &apos;ora.ctssd&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.cssd&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.cssd&apos; on &apos;oel2&apos; succeededCRS-2672: Attempting to start &apos;ora.cssdmonitor&apos; on &apos;oel2&apos;CRS-2676: Start of &apos;ora.cssdmonitor&apos; on &apos;oel2&apos; succeededCRS-2672: Attempting to start &apos;ora.cssd&apos; on &apos;oel2&apos;CRS-2672: Attempting to start &apos;ora.diskmon&apos; on &apos;oel2&apos;CRS-2676: Start of &apos;ora.diskmon&apos; on &apos;oel2&apos; succeededCRS-2676: Start of &apos;ora.cssd&apos; on &apos;oel2&apos; succeededCRS-4611: Successful deletion of voting disk +OCR.ASM de-configuration trace file location: /tmp/asmcadc_clean2014-03-29_11-48-42-PM.logASM Clean Configuration STARTASM Clean Configuration END ASM with SID +ASM1 deleted successfully. Check /tmp/asmcadc_clean2014-03-29_11-48-42-PM.log for details. CRS-2791: Starting shutdown of Oracle High Availability Services-managed resources on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.mdnsd&apos; on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.crf&apos; on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.ctssd&apos; on &apos;oel2&apos;CRS-2673: Attempting to stop &apos;ora.asm&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.crf&apos; on &apos;oel2&apos; succeededCRS-2677: Stop of &apos;ora.mdnsd&apos; on &apos;oel2&apos; succeededCRS-2677: Stop of &apos;ora.ctssd&apos; on &apos;oel2&apos; succeededCRS-2677: Stop of &apos;ora.asm&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.cluster_interconnect.haip&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.cluster_interconnect.haip&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.cssd&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.cssd&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.gipcd&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.gipcd&apos; on &apos;oel2&apos; succeededCRS-2673: Attempting to stop &apos;ora.gpnpd&apos; on &apos;oel2&apos;CRS-2677: Stop of &apos;ora.gpnpd&apos; on &apos;oel2&apos; succeededCRS-2793: Shutdown of Oracle High Availability Services-managed resources on &apos;oel2&apos; has completedCRS-4133: Oracle High Availability Services has been stopped.Removing Trace File AnalyzerSuccessfully deconfigured Oracle clusterware stack on this node 5.以GI用户(grid)删除GI软件 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141[grid@oel1:/home/grid]$ /u01/app/11gr2/grid/deinstall/deinstallChecking for required files and bootstrapping ...Please wait ...Location of logs /u01/app/oracle/oraInventory/logs/ ############ ORACLE DEINSTALL &amp; DECONFIG TOOL START ############ ######################### CHECK OPERATION START ########################### [START] Install check configuration ## Checking for existence of the Oracle home location /u01/app/11gr2/gridOracle Home type selected for deinstall is: Oracle Grid Infrastructure for a ClusterOracle Base selected for deinstall is: /u01/app/gridChecking for existence of central inventory location /u01/app/oracle/oraInventoryChecking for existence of the Oracle Grid Infrastructure homeThe following nodes are part of this cluster: oel1,oel2Checking for sufficient temp space availability on node(s) : &apos;oel1,oel2&apos; ## [END] Install check configuration ## Traces log file: /u01/app/oracle/oraInventory/logs//crsdc.logEnter an address or the name of the virtual IP used on node &quot;oel1&quot;[null] &gt;orcl1-vipThe following information can be collected by running &quot;/sbin/ifconfig -a&quot; on node &quot;oel1&quot;Enter the IP netmask of Virtual IP &quot;192.168.56.125&quot; on node &quot;oel1&quot;[255.255.255.0] &gt; Enter the network interface name on which the virtual IP address &quot;192.168.56.125&quot; is active &gt;eth0Enter an address or the name of the virtual IP used on node &quot;oel2&quot;[192.168.56.125] &gt;orcl2-vipThe following information can be collected by running &quot;/sbin/ifconfig -a&quot; on node &quot;oel2&quot;Enter the IP netmask of Virtual IP &quot;192.168.56.126&quot; on node &quot;oel2&quot;[255.255.255.0] &gt; Enter the network interface name on which the virtual IP address &quot;192.168.56.126&quot; is active[eth0] &gt; Enter an address or the name of the virtual IP[] &gt; Network Configuration check config START Network de-configuration trace file location: /u01/app/oracle/oraInventory/logs/netdc_check2014-03-29_11-55-42-PM.log Specify all RAC listeners (do not include SCAN listener) that are to be de-configured [LISTENER,LISTENER_SCAN3,LISTENER_SCAN2,LISTENER_SCAN1]: Network Configuration check config END Asm Check Configuration START ASM de-configuration trace file location: /u01/app/oracle/oraInventory/logs/asmcadc_check2014-03-29_11-55-50-PM.log ASM configuration was not detected in this Oracle home. Was ASM configured in this Oracle home (y|n) [n]: yIs OCR/Voting Disk placed in ASM y|n [n]: y Enter the OCR/Voting Disk diskgroup name []: OCRSpecify the ASM Diagnostic Destination [ ]: /u01/app/oracleSpecify the diskstring []: /dev/oracleasm/OCR*Specify the diskgroups that are managed by this ASM instance []: DATA De-configuring ASM will drop the diskgroups at cleanup time. Do you want deconfig tool to drop the diskgroups y|n [y]: ######################### CHECK OPERATION END ######################### ####################### CHECK OPERATION SUMMARY #######################Oracle Grid Infrastructure Home is:The cluster node(s) on which the Oracle home deinstallation will be performed are:oel1,oel2Oracle Home selected for deinstall is: /u01/app/11gr2/gridInventory Location where the Oracle home registered is: /u01/app/oracle/oraInventoryFollowing RAC listener(s) will be de-configured: LISTENER,LISTENER_SCAN3,LISTENER_SCAN2,LISTENER_SCAN1ASM instance will be de-configured from this Oracle homeDo you want to continue (y - yes, n - no)? [n]: yA log of this session will be written to: &apos;/u01/app/oracle/oraInventory/logs/deinstall_deconfig2014-03-29_11-53-59-PM.out&apos;Any error messages from this session will be written to: &apos;/u01/app/oracle/oraInventory/logs/deinstall_deconfig2014-03-29_11-53-59-PM.err&apos; ######################## CLEAN OPERATION START ########################ASM de-configuration trace file location: /u01/app/oracle/oraInventory/logs/asmcadc_clean2014-03-29_11-57-28-PM.logASM Clean Configuration STARTASM Clean Configuration END Network Configuration clean config START Network de-configuration trace file location: /u01/app/oracle/oraInventory/logs/netdc_clean2014-03-29_11-57-33-PM.log De-configuring RAC listener(s): LISTENER,LISTENER_SCAN3,LISTENER_SCAN2,LISTENER_SCAN1 De-configuring listener: LISTENER Stopping listener: LISTENER Warning: Failed to stop listener. Listener may not be running.Listener de-configured successfully. De-configuring listener: LISTENER_SCAN3 Stopping listener: LISTENER_SCAN3 Warning: Failed to stop listener. Listener may not be running.Listener de-configured successfully. De-configuring listener: LISTENER_SCAN2 Stopping listener: LISTENER_SCAN2 Warning: Failed to stop listener. Listener may not be running.Listener de-configured successfully. De-configuring listener: LISTENER_SCAN1 Stopping listener: LISTENER_SCAN1 Warning: Failed to stop listener. Listener may not be running.Listener de-configured successfully. De-configuring Naming Methods configuration file on all nodes...Naming Methods configuration file de-configured successfully. De-configuring Local Net Service Names configuration file on all nodes...Local Net Service Names configuration file de-configured successfully. De-configuring Directory Usage configuration file on all nodes...Directory Usage configuration file de-configured successfully. De-configuring backup files on all nodes...Backup files de-configured successfully. The network configuration has been cleaned up successfully. Network Configuration clean config END ----------------------------------------&gt; The deconfig command below can be executed in parallel on all the remote nodes. Execute the command on the local node after the execution completes on all the remote nodes. Run the following command as the root user or the administrator on node &quot;oel2&quot;. /tmp/deinstall2014-03-29_11-52-47PM/perl/bin/perl -I/tmp/deinstall2014-03-29_11-52-47PM/perl/lib -I/tmp/deinstall2014-03-29_11-52-47PM/crs/install /tmp/deinstall2014-03-29_11-52-47PM/crs/install/rootcrs.pl -force -deconfig -paramfile &quot;/tmp/deinstall2014-03-29_11-52-47PM/response/deinstall_Ora11g_gridinfrahome1.rsp&quot; Run the following command as the root user or the administrator on node &quot;oel1&quot;. /tmp/deinstall2014-03-29_11-52-47PM/perl/bin/perl -I/tmp/deinstall2014-03-29_11-52-47PM/perl/lib -I/tmp/deinstall2014-03-29_11-52-47PM/crs/install /tmp/deinstall2014-03-29_11-52-47PM/crs/install/rootcrs.pl -force -deconfig -paramfile &quot;/tmp/deinstall2014-03-29_11-52-47PM/response/deinstall_Ora11g_gridinfrahome1.rsp&quot; -lastnode Press Enter after you finish running the above commands &lt;---------------------------------------- 6.保持上述deinstall窗口，分别在两个节点执行上述最后两个脚本，这个脚本可以并行执行 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283node 2:[root@oel2:/root]# /tmp/deinstall2014-03-29_11-52-47PM/perl/bin/perl -I/tmp/deinstall2014-03-29_11-52-47PM/perl/lib -I/tmp/deinstall2014-03-29_11-52-47PM/crs/install /tmp/deinstall2014-03-29_11-52-47PM/crs/install/rootcrs.pl -force -deconfig -paramfile &quot;/tmp/deinstall2014-03-29_11-52-47PM/response/deinstall_Ora11g_gridinfrahome1.rsp&quot;Using configuration parameter file: /tmp/deinstall2014-03-29_11-52-47PM/response/deinstall_Ora11g_gridinfrahome1.rsp****Unable to retrieve Oracle Clusterware home.Start Oracle Clusterware stack and try again.CRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Stop failed, or completed with errors.Either /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessEither /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessCRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Modify failed, or completed with errors.CRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Delete failed, or completed with errors.CRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Stop failed, or completed with errors.################################################################# You must kill processes or reboot the system to properly ## cleanup the processes started by Oracle clusterware #################################################################ACFS-9313: No ADVM/ACFS installation detected.Either /etc/oracle/olr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessEither /etc/oracle/olr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessFailure in execution (rc=-1, 256, No such file or directory) for command /etc/init.d/ohasd deinstallerror: package cvuqdisk is not installedSuccessfully deconfigured Oracle clusterware stack on this node Node1:[root@oel1:/root]# /tmp/deinstall2014-03-29_11-52-47PM/perl/bin/perl -I/tmp/deinstall2014-03-29_11-52-47PM/perl/lib -I/tmp/deinstall2014-03-29_11-52-47PM/crs/install /tmp/deinstall2014-03-29_11-52-47PM/crs/install/rootcrs.pl -force -deconfig -paramfile &quot;/tmp/deinstall2014-03-29_11-52-47PM/response/deinstall_Ora11g_gridinfrahome1.rsp&quot; -lastnodeUsing configuration parameter file: /tmp/deinstall2014-03-29_11-52-47PM/response/deinstall_Ora11g_gridinfrahome1.rspAdding Clusterware entries to inittab/crs/install/inittab does not exist.****Unable to retrieve Oracle Clusterware home.Start Oracle Clusterware stack and try again.****Unable to retrieve Oracle Clusterware home.Start Oracle Clusterware stack and try again.****Unable to retrieve Oracle Clusterware home.Start Oracle Clusterware stack and try again.****Unable to retrieve Oracle Clusterware home.Start Oracle Clusterware stack and try again.****Unable to retrieve Oracle Clusterware home.Start Oracle Clusterware stack and try again.CRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Stop failed, or completed with errors.CRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Delete failed, or completed with errors.Either /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessEither /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessCRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Modify failed, or completed with errors.CRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Delete failed, or completed with errors.Either /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessEither /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessCRS-4047: No Oracle Clusterware components configured.CRS-4000: Command Stop failed, or completed with errors.Either /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessEither /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute access################################################################# You must kill processes or reboot the system to properly ## cleanup the processes started by Oracle clusterware #################################################################Either /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessEither /etc/oracle/ocr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessACFS-9313: No ADVM/ACFS installation detected.Either /etc/oracle/olr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessEither /etc/oracle/olr.loc does not exist or is not readableMake sure the file exists and it has read and execute accessFailure in execution (rc=-1, 256, No such file or directory) for command /etc/init.d/ohasd deinstallerror: package cvuqdisk is not installedSuccessfully deconfigured Oracle clusterware stack on this node 7.回到刚才deinstall窗口，按回车,完成删除动作 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657Press Enter after you finish running the above commands &lt;---------------------------------------- Setting the force flag to falseSetting the force flag to cleanup the Oracle BaseOracle Universal Installer clean START Detach Oracle home &apos;/u01/app/11gr2/grid&apos; from the central inventory on the local node : Done Delete directory &apos;/u01/app/11gr2/grid&apos; on the local node : Done Delete directory &apos;/u01/app/grid&apos; on the local node : Done Detach Oracle home &apos;/u01/app/11gr2/grid&apos; from the central inventory on the remote nodes &apos;oel2&apos; : Done Delete directory &apos;/u01/app/11gr2/grid&apos; on the remote nodes &apos;oel2&apos; : Done Delete directory &apos;/u01/app/grid&apos; on the remote nodes &apos;oel2&apos; : Done Oracle Universal Installer cleanup was successful. Oracle Universal Installer clean END ## [START] Oracle install clean ## Clean install operation removing temporary directory &apos;/tmp/deinstall2014-03-29_11-52-47PM&apos; on node &apos;oel1&apos;Clean install operation removing temporary directory &apos;/tmp/deinstall2014-03-29_11-52-47PM&apos; on node &apos;oel2&apos; ## [END] Oracle install clean ## ######################### CLEAN OPERATION END ######################### ####################### CLEAN OPERATION SUMMARY #######################ASM instance was de-configured successfully from the Oracle homeFollowing RAC listener(s) were de-configured successfully: LISTENER,LISTENER_SCAN3,LISTENER_SCAN2,LISTENER_SCAN1Oracle Clusterware is stopped and successfully de-configured on node &quot;oel1&quot;Oracle Clusterware is stopped and successfully de-configured on node &quot;oel2&quot;Oracle Clusterware is stopped and de-configured successfully.Successfully detached Oracle home &apos;/u01/app/11gr2/grid&apos; from the central inventory on the local node.Successfully deleted directory &apos;/u01/app/11gr2/grid&apos; on the local node.Successfully deleted directory &apos;/u01/app/grid&apos; on the local node.Successfully detached Oracle home &apos;/u01/app/11gr2/grid&apos; from the central inventory on the remote nodes &apos;oel2&apos;.Successfully deleted directory &apos;/u01/app/11gr2/grid&apos; on the remote nodes &apos;oel2&apos;.Successfully deleted directory &apos;/u01/app/grid&apos; on the remote nodes &apos;oel2&apos;.Oracle Universal Installer cleanup was successful. Oracle deinstall tool successfully cleaned up temporary directories.####################################################################### ############# ORACLE DEINSTALL &amp; DECONFIG TOOL END #############[grid@oel1:/home/grid]$[root@oel1:/root]# rm -rf /etc/oraInst.loc[root@oel2:/root]# rm -rf /etc/oraInst.loc[root@oel1:/root]# rm -rf /opt/ORCLfmap/","link":"/deinstall-oracle-11g-rac.html"},{"title":"Detect And Correct Corruption in Oracle","text":"Refernce: http://www.oracle-base.com/articles/misc/detect-and-correct-corruption.php Oracle提供了几种方法去检测及修复Oracle数据文件的坏块(corruption)。 ¨ DBVerify ¨ ANALYZE … VALIDATE STRUCTURE ¨ DB_BLOCK_CHECKING ¨ RMAN(BACKUP VALIDATE,RESTORE VALIDATE,VALIDATE) ¨ Block Media Recovery ¨ DBMS_REPAIR ¨ Others 1. DBVerify DBVerify允许对offline及Online的数据文件进行物理数据结构的完整性检查。但只能针对数据文件或是在缓存中的数据块，不能对控制文件及日志文件进行验证。 1234567891011121314151617[oracle@linora:/home/oracle]$ dbv file=/oradata/linora/bbed01.dbf feedback=10000 blocksize=8192DBVERIFY: Release 10.2.0.4.0 - Production on Wed Jun 26 04:01:24 2013Copyright (c) 1982, 2007, Oracle. All rights reserved.DBVERIFY - Verification starting : FILE = /oradata/linora/bbed01.dbfDBVERIFY - Verification completeTotal Pages Examined : 12800 Total Pages Processed (Data) : 1446 Total Pages Failing (Data) : 0 Total Pages Processed (Index): 229 Total Pages Failing (Index): 0 Total Pages Processed (Other): 11074 Total Pages Processed (Seg) : 0 Total Pages Failing (Seg) : 0 Total Pages Empty : 51 Total Pages Marked Corrupt : 0 Total Pages Influx : 0 Highest block SCN : 3414890 (0.3414890) 1.1 对数据文件的数据块检查 123456789BBED@linora&gt;create table t as select * from user_objects;Table created. --查找T表所在数据文件及开始的块ID及块数量 BBED@linora&gt;select a.file_id,a.block_id,a.blocks,b.name from dba_extents a,v$datafile b where a.file_id=b.file# and a.owner=&apos;BBED&apos; and a.segment_name=&apos;T&apos;; FILE_ID BLOCK_ID BLOCKS NAME ---------- ---------- ---------- ------------------------------ 9 1841 8 /oradata/linora/bbed01.dbf 1234567891011121314151617181920212223242526272829303132333435363738---查出表中记录所在的块 BBED@linora&gt;select distinct dbms_rowid.rowid_block_number(rowid) trowid from bbed.t; TROWID ---------- 1844 BBED@linora&gt;col owner for a10 BBED@linora&gt;col segment_name for a20 BBED@linora&gt;col SEGMENT_TYPE for a10 BBED@linora&gt;select owner,segment_name,segment_type,extent_id,file_id,block_id,bytes from dba_extents where owner=&apos;BBED&apos;; OWNER SEGMENT_NAME SEGMENT_TY EXTENT_ID FILE_ID BLOCK_ID BYTES ---------- -------------------- ---------- ---------- ---------- ---------- ---------- BBED PK_EMP INDEX 0 9 1817 65536 BBED INVALID_ROWS TABLE 0 9 905 65536 BBED T TABLE 0 9 1841 65536 BBED BLOCK_LAB TABLE 0 9 1825 65536 BBED EMP TABLE 0 9 1809 65536 select substr(&apos;free space&apos;,1,10) owner , substr(&apos; &apos;,1,20) segment , file_id , block_id , blocks , bytes/1024/1024 &quot;SizeMb&quot; , (block_id+blocks-1)*8192/1024/1024 &quot;FileSizeMb&quot; from dba_free_space where tablespace_name = upper(&apos;&amp;&amp;tbs_name&apos;) union select substr(owner,1,10) , substr(segment_name,1,20) , file_id , block_id , blocks , bytes/1024/1024 &quot;SizeMb&quot; , (block_id+blocks-1)*8192/1024/1024 &quot;FileSizeMb&quot; from dba_extents where tablespace_name = upper(&apos;&amp;&amp;tbs_name&apos;) order by 3,4; 模拟数据坏块 ---破坏有记录的数据块 1234567891011121314151617181920212223242526272829303132333435[oracle@linora:/home/oracle]$ dd of=/oradata/linora/bbed01.dbf bs=8192 conv=notrunc seek=1844 &lt;&lt;EOF&lt;abcdeEOF0+1 records in0+1 records out15 bytes (15 B) copied, 0.000112 seconds, 134 kB/s--使用DBV进行检测[oracle@linora:/home/oracle]$ dbv file=/oradata/linora/bbed01.dbf feedback=10000 blocksize=8192DBVERIFY: Release 10.2.0.4.0 - Production on Wed Jun 26 04:29:12 2013Copyright (c) 1982, 2007, Oracle. All rights reservedDBVERIFY - Verification starting : FILE = /oradata/linora/bbed01.dbf Page 1844 is marked corrupt--1844块标记为坏块 Corrupt block relative dba: 0x02400734 (file 9, block 1844) Bad header found during dbv: Data in bad block: type: 97 format: 2 rdba: 0x68676665 last change scn: 0x6e6d.6c6b6369 seq: 0xa flg: 0x04 spare1: 0x63 spare2: 0x64 spare3: 0x0 consistency value in tail: 0xe1c00602 check value in block header: 0x117d computed block checksum: 0x2fe1..DBVERIFY - Verification completeTotal Pages Examined : 12800 Total Pages Processed (Data) : 1446 Total Pages Failing (Data) : 0 Total Pages Processed (Index): 229 Total Pages Failing (Index): 0 Total Pages Processed (Other): 11073 Total Pages Processed (Seg) : 0 Total Pages Failing (Seg) : 0 Total Pages Empty : 51 Total Pages Marked Corrupt : 1 Total Pages Influx : 0 Highest block SCN : 3465666 (0.3465666) ==================================================Pages--表示数据块 =Total Pages Examined --表示文件中的数据块总数量 =Total Pages Processed--表示已检查数据块的数量 =Total Pages Failing--表示检查失败的数据块数量 =Total Pages Marked Corrupt--表示数据块已损坏 =Total Pages Influx--表示同一时间正在读和写的数据块数量。如果数据库是打开状态，当DBV运行时多次读数据块得到一个一致的映像，但是因为数据库是打开的，可能同一数据块在读的时候又有写入的动作，DBV不能得到一个一致的数据块映像 123456789101112--根据file_id跟block_id查找损坏的块包含什么数据 col tablespace_name for a20 col segment_type for a10 col segment_name for a20 col owner for a8 SELECT tablespace_name, segment_type, owner, segment_name FROM dba_extents WHERE file_id = &amp;fileid and &amp;blockid between block_id AND block_id + blocks - 1;TABLESPACE_NAME SEGMENT_TY OWNER SEGMENT_NAME -------------------- ---------- -------- -------------------- BBED TABLE BBED T 1.2 对Segment进行检测 验证段的时候要求数据库必须处在open状态，还需要提供拥有SYSDBA权限的帐号进行查询，查询段的命令格式例如：dbv userid=system/oracle segment_id=tsn.segfile.segblock tsn--表示表空间id segfile--表示段头所在数据文件号 segblock--表示段头数据块号 这三个值可以通过数据字典sys_dba_segs获取，相关的列分别是tablespace_id、 header_file和header_block 。 123456SYS@linora&gt;select tablespace_id,header_file,header_block from sys_dba_segs where owner=&apos;BBED&apos; and segment_name=&apos;T&apos;; TABLESPACE_ID HEADER_FILE HEADER_BLOCK ------------- ----------- ------------ 15 9 1843 --使用DBV对bbed.t进行验证 123456789101112131415161718192021222324252627[oracle@linora:/home/oracle]$ dbv userid=system/oracle segment_id=15.9.1843DBVERIFY: Release 10.2.0.4.0 - Production on Wed Jun 26 04:37:10 2013Copyright (c) 1982, 2007, Oracle. All rights reserved.DBVERIFY - Verification starting : SEGMENT_ID = 15.9.1843 Page 1844 is marked corrupt Corrupt block relative dba: 0x02400734 (file 9, block 1844) Bad header found during dbv: Data in bad block: type: 97 format: 2 rdba: 0x68676665 last change scn: 0x6e6d.6c6b6369 seq: 0xa flg: 0x04 spare1: 0x63 spare2: 0x64 spare3: 0x0 consistency value in tail: 0xe1c00602 check value in block header: 0x117d computed block checksum: 0x2fe1 DBVERIFY - Verification complete Total Pages Examined : 8 Total Pages Processed (Data) : 0 Total Pages Failing (Data) : 0 Total Pages Processed (Index): 0 Total Pages Failing (Index): 0 Total Pages Processed (Other): 6 Total Pages Processed (Seg) : 1 Total Pages Failing (Seg) : 0 Total Pages Empty : 0 Total Pages Marked Corrupt : 1 Total Pages Influx : 0 Highest block SCN : 3465666 (0.3465666) 2. ANALYZE … VALIDATE STRUCTURE Analyze能对被分析的对象中的每一个数据块进行验证，如果有坏块则加入INVALID_ROWS这个表。 12345678-- Create the INVALID_ROWS table BBED@linora&gt;@?/rdbms/admin/utlvalid Table created. -- Validate the table structure along with all it&apos;s indexes. BBED@linora&gt;ANALYZE TABLE bbed.t VALIDATE STRUCTURE CASCADE; Table analyzed. -- Validate the index structure. ANALYZE INDEX scott.pk_emp VALIDATE STRUCTURE; 3. DB_BLOCK_CHECKING 当使用DB_BLOCK_CHECKING方法验证时候，此参数需要设置为[TRUE|HIGH]，DBBLOCKCHECKING参数主要是用于数据块的逻辑（一致）检查（但只是块内，不包括块间的逻辑检查，比如索引项目的ROWID指向的是不存在的行等）。主要用于防止在内存中损坏或数据损坏。由于是逻辑检查，因此引起的额外负荷比较高，甚至可以达到10%，因此对于一个繁忙的系统，特别是插入或更新操作很多的系统，性能影响是比较明显的。该参数对SYSTEM表空间始终是处于“打开”状态，而不管该参数是否设置为FALSE。Allowable valuesinclude [OFF|FALSE], LOW, MEDIUM, [HIGH|TRUE]. 4. RMAN(BACKUP VALIDATE,RESTORE VALIDATE,VALIDATE) RMAN的VALIDATE功能能对整个数据库的备份、恢复进行验证，但不会真的去备份或者恢复。 12345678910111213141516171819RMAN&gt; backup validate datafile 9;Starting backup at 2013-06-26 04:41:21 using target database control file instead of recovery catalog allocated channel: ORA_DISK_1 channel ORA_DISK_1: sid=306 devtype=DISK channel ORA_DISK_1: starting compressed full datafile backupset channel ORA_DISK_1: specifying datafile(s) in backupset input datafile fno=00009 name=/oradata/linora/bbed01.dbf channel ORA_DISK_1: backup set complete, elapsed time: 00:00:01 Finished backup at 2013-06-26 04:41:24 --逻辑坏块检查 RMAN&gt; backup check logical validate datafile 9;Starting backup at 2013-06-26 04:41:41 using channel ORA_DISK_1 channel ORA_DISK_1: starting compressed full datafile backupset channel ORA_DISK_1: specifying datafile(s) in backupset input datafile fno=00009 name=/oradata/linora/bbed01.dbf channel ORA_DISK_1: backup set complete, elapsed time: 00:00:01 Finished backup at 2013-06-26 04:41:42 验证结果在V$DATABASE_BLOCK_CORRUPTION视图中。 1234BBED@linora&gt;select * from V$DATABASE_BLOCK_CORRUPTION; FILE# BLOCK# BLOCKS CORRUPTION_CHANGE# CORRUPTION_TYPE ---------- ---------- ---------- ------------------ ------------------ 9 1844 1 0 CORRUPT CORRUPTION_TYPE 类型： ALL ZERO：Blockheaderondisk contained only zeros. Theblock may be valid ifit was never filled andif it isin an Oracle7 file. Thebuffer will bereformatted tothe Oracle8 standardfor an empty block. FRACTURED：Blockheader looks reasonable, but the front and back ofthe blockare different versions. CHECKSUM： optional checkvalue shows that theblockisnotself-consistent.It is impossible to determine exactly why thecheckvalue fails, but itprobably fails because sectors inthe middle oftheblock are from differentversions. CORRUPT：Blockis wrongly identifiedorisnot a datablock (for example,thedatablock address is missing) LOGICAL: Specifies therangeisfor logically corrupt blocks.CORRUPTION_CHANGE# will have a nonzero value. 5. Block Media Recovery BMR，数据块级别修复，允许只对指定的数据块进行恢复而不影响到整个数据文件。BMR只能通过RMAN的BLOCKREOCVER命令进行修复。数据坏块信息可能会出现在以下几个地方： Error messages The alert log Trace File ANALYZE TABLE|INDEX DBVerify The V$BACKUPCORRUPTION & V$COPYCORRUPTION views list corrupt blocks in the backups, not the database itself. The V$DATABASEBLOCKCORRUPTION lists corrupt blocks in the database detected during a variety of RMAN operations. Recovered blocks will still be listed until the next backup is performed. 一旦在上述情况中检测到坏块，则可使用BMR的方式进行修复。CORRUPTIONLIST关键字可以修复所有在V$DATABASE_BLOCK_CORRUPTION视图中列出的坏块，但这些坏块清单只能在UNTIL子句下恢复。 BLOCKRECOVER DATAFILE 9 BLOCK 12; BLOCKRECOVER CORRUPTION LIST RESTORE UNTIL TIME 'SYSDATE - 7'; 6. DBMS_REPAIR，会丢失数据 DBMS_REPAIR包可以在无备份情况下对坏块进行修复。它需要两张管理表用于存放坏块信息及指向这些坏块的索引信息。但跳过坏块会丢失数据。 12345678910111213BEGIN DBMS_REPAIR.admin_tables ( table_name =&gt; &apos;REPAIR_TABLE&apos;, --表名 table_type =&gt; DBMS_REPAIR.repair_table, action =&gt; DBMS_REPAIR.create_action, tablespace =&gt; &apos;BBED&apos;);--用于存放此表的表空间 DBMS_REPAIR.admin_tables ( table_name =&gt; &apos;ORPHAN_KEY_TABLE&apos;, table_type =&gt; DBMS_REPAIR.orphan_table, action =&gt; DBMS_REPAIR.create_action, tablespace =&gt; &apos;BBED&apos;); END; / 表创建完后，可以对表进行检测： 1234567891011121314151617181920212223--使用dbms_repair.check_object进行坏块检测 SYS@linora&gt;SET SERVEROUTPUT ON DECLARE v_num_corrupt INT; BEGIN v_num_corrupt := 0; DBMS_REPAIR.check_object ( schema_name =&gt; &apos;BBED&apos;, object_name =&gt; &apos;T&apos;, repair_table_name =&gt; &apos;REPAIR_TABLE&apos;, corrupt_count =&gt; v_num_corrupt); DBMS_OUTPUT.put_line(&apos;number corrupt: &apos; || TO_CHAR (v_num_corrupt)); END; /number corrupt: 1 --检测到一个坏块PL/SQL procedure successfully completed. BBED@linora&gt;select count(*) from t 2 / select count(*) from t * ERROR at line 1: ORA-01578: ORACLE data block corrupted (file # 9, block # 12) ORA-01110: data file 9: &apos;/oradata/linora/bbed01.dbf&apos; 通过运行DBMS_REPAIR.check_object，将坏块信息存放到了repairtable表中，其中有个字段markedcorrupt，用于标识该块是否被标识为坏块，当被标识为true时，即该块被标识为坏块。其中这一步跟oracle文档中的描述有点进入，根据oracle文档，当执行完DBMS_REPAIR.check_object时，并不会进行坏块标识，也就是markedcorrupt列的值应该为false，而只有当执行DBMS_REPAIR.fix_corrupt_blocks过程后才会进行坏块标识。 –使用DBMS_REPAIR.fix_corrupt_blocks进行坏块标识 12345678910111213141516SET SERVEROUTPUT ON DECLARE v_num_fix INT; BEGIN v_num_fix := 0; DBMS_REPAIR.fix_corrupt_blocks ( schema_name =&gt; &apos;BBED&apos;, object_name =&gt; &apos;T&apos;, object_type =&gt; Dbms_Repair.table_object, repair_table_name =&gt; &apos;REPAIR_TABLE&apos;, fix_count =&gt; v_num_fix); DBMS_OUTPUT.put_line(&apos;num fix: &apos; || TO_CHAR(v_num_fix)); END; /num fix: 0PL/SQL procedure successfully completed. 我们可以见到到num fix=0，估计在上一步进行check_object时已经进行了坏块标识了，这一步其实可以省略。 使用DBMS_REPAIR.dump_orphan_keys过程来保存坏块的索引键值，然后再执行skipcorruptblocks过程之后，我们才能重建索引，不然重建索引时新的索引仍然会引用坏块。 首先要建立ORPHANKEY_TABLE，此表就是用来存放坏块的索引键值。 123456789101112131415SET SERVEROUTPUT ON DECLARE v_num_orphans INT; BEGIN v_num_orphans := 0; DBMS_REPAIR.dump_orphan_keys ( schema_name =&gt; &apos;SCOTT&apos;, object_name =&gt; &apos;PK_DEPT&apos;, object_type =&gt; DBMS_REPAIR.index_object, repair_table_name =&gt; &apos;REPAIR_TABLE&apos;, orphan_table_name =&gt; &apos;ORPHAN_KEY_TABLE&apos;, key_count =&gt; v_num_orphans); DBMS_OUTPUT.put_line(&apos;orphan key count: &apos; || TO_CHAR(v_num_orphans)); END; / 使用dbms_repair.rebuild_freelists重建freelists，使得该块不再被放到freelists，当中，也就是该块将不会再被使用。 1234567891011121314151617181920212223242526BEGIN DBMS_REPAIR.rebuild_freelists ( schema_name =&gt; &apos;BBED&apos;, object_name =&gt; &apos;T&apos;, object_type =&gt; DBMS_REPAIR.table_object); END; /--使用skip_corrupt_blocks，使查询或者DML时跳过坏块 BEGIN DBMS_REPAIR.skip_corrupt_blocks ( schema_name =&gt; &apos;BBED&apos;, object_name =&gt; &apos;T&apos;, object_type =&gt; DBMS_REPAIR.table_object, flags =&gt; DBMS_REPAIR.skip_flag); END; /BBED@linora&gt;select count(*) from t;COUNT(*) ---------- 0 通过查询DBA_TABLES的SKIP_CORRUPT可查询表是否有坏块被跳过。 BBED@linora&gt;select SKIP_CORRUPT from dba_tables where table_name=&apos;T&apos; and owner=&apos;BBED&apos;;SKIP_CORRUPT ---------------- ENABLED 7. 案例 7.1 无RMAN备份，corruption对象为table，使用10231跳过坏块进行全表扫描 --验证步骤略如果存在corruption block，exp导出会报错。 123456789101112131415[oracle@linora:/home/oracle]$ exp bbed/bbed tables=t file=./t.dmpExport: Release 10.2.0.4.0 - Production on Tue Jun 4 22:20:13 2013Copyright (c) 1982, 2007, Oracle. All rights reserved.Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options Export done in ZHS16GBK character set and AL16UTF16 NCHAR character set server uses WE8ISO8859P1 character set (possible charset conversion)About to export specified tables via Conventional Path ... . . exporting table T EXP-00056: ORACLE error 1578 encountered ORA-01578: ORACLE data block corrupted (file # 9, block # 12) ORA-01110: data file 9: &apos;/oradata/linora/bbed01.dbf&apos; Export terminated successfully with warnings. 1234567891011121314151617--设置session级别10231事件 BBED@linora&gt;ALTER SYSTEM SET EVENTS=&apos;10231 trace name context forever,level 10&apos;;[oracle@linora:/home/oracle]$ exp bbed/bbed tables=t file=./t.dmpExport: Release 10.2.0.4.0 - Production on Tue Jun 4 22:29:09 2013Copyright (c) 1982, 2007, Oracle. All rights reserved.Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options Export done in ZHS16GBK character set and AL16UTF16 NCHAR character set server uses WE8ISO8859P1 character set (possible charset conversionAbout to export specified tables via Conventional Path ... . . exporting table T 50979 rows exported EXP-00091: Exporting questionable statistics. EXP-00091: Exporting questionable statistics. Export terminated successfully with warnings. [oracle@linora:/home/oracle]$ 成功导出，drop table并且导入数据。导入后，会有部分数据丢失。10231事件仅支持exp或者create table as select from语句。 12345678910BBED@linora&gt;select count(*) from t;COUNT(*) ---------- 50979 BBED@linora&gt;select count(*) from dba_objects;COUNT(*) ---------- 51072 注意，此方法并不能修复坏块，只能跳过坏块，dbv检查的时候还是会有坏块出来。 8. 方法总结 How to identify the corrupt Object reported by ORA-1578 / RMAN / DBVERIFY [ID 819533.1] 8.1 确认损坏的数据文件及相关信息 12345678SELECT file_id AFN, relative_fno, tablespace_name FROM dba_data_files WHERE relative_fno=9; AFN RELATIVE_FNO TABLESPACE_NAME ---------- ------------ -------------------- 9 9 BBED --确认数据文件位置 select file#,name from v$datafile where file#=9; 8.2 根据错误信息，确认损坏的块所包含的对象信息 123456789101112131415161718BBED@linora&gt;select * from v$database_block_corruption;FILE# BLOCK# BLOCKS CORRUPTION_CHANGE# CORRUPTION_TYPE ---------- ---------- ---------- ------------------ ------------------ 9 1844 1 0 CORRUPT BBED@linora&gt;SELECT tablespace_name, segment_type, owner, segment_name 2 FROM dba_extents 3 WHERE file_id = &amp;AFN 4 AND &amp;BL between block_id AND block_id + blocks - 1; Enter value for afn: 9 old 3: WHERE file_id = &amp;AFN new 3: WHERE file_id = 9 Enter value for bl: 1844 old 4: AND &amp;BL between block_id AND block_id + blocks - 1 new 4: AND 1844 between block_id AND block_id + blocks - 1TABLESPACE_NAME SEGMENT_TY OWNER SEGMENT_NAME -------------------- ---------- -------- -------------------- BBED TABLE BBED T Identify the corrupt segments 1234567891011121314151617181920212223242526272829SELECT e.owner, e.segment_type, e.segment_name, e.partition_name, c.file# , greatest(e.block_id, c.block#) corr_start_block# , least(e.block_id+e.blocks-1, c.block#+c.blocks-1) corr_end_block# , least(e.block_id+e.blocks-1, c.block#+c.blocks-1) - greatest(e.block_id, c.block#) + 1 blocks_corrupted , null description FROM dba_extents e, v$database_block_corruption c WHERE e.file_id = c.file# AND e.block_id &lt;= c.block# + c.blocks - 1 AND e.block_id + e.blocks - 1 &gt;= c.block# UNION SELECT s.owner, s.segment_type, s.segment_name, s.partition_name, c.file# , header_block corr_start_block# , header_block corr_end_block# , 1 blocks_corrupted , &apos;Segment Header&apos; description FROM dba_segments s, v$database_block_corruption c WHERE s.header_file = c.file# AND s.header_block between c.block# and c.block# + c.blocks - 1 UNION SELECT null owner, null segment_type, null segment_name, null partition_name, c.file# , greatest(f.block_id, c.block#) corr_start_block# , least(f.block_id+f.blocks-1, c.block#+c.blocks-1) corr_end_block# , least(f.block_id+f.blocks-1, c.block#+c.blocks-1) - greatest(f.block_id, c.block#) + 1 blocks_corrupted , &apos;Free Block&apos; description FROM dba_free_space f, v$database_block_corruption c WHERE f.file_id = c.file# AND f.block_id &lt;= c.block# + c.blocks - 1 AND f.block_id + f.blocks - 1 &gt;= c.block# order by file#, corr_start_block#; 还有上述查询没结果的情况，即表面这个坏块是在LMT(Locally Managed Tablespace)文件头中，当出现这种情况的时候，查询不会失败；如果出现上述情况，请用一下语句查询： 12345678SELECT owner, segment_name, segment_type, partition_name FROM dba_segments WHERE header_file = &amp;AFN AND header_block = &amp;BL; --如果知道database block address 也可以查找出相关内容： SELECT dbms_utility.data_block_address_file(&amp;&amp;rdba) RFN, dbms_utility.data_block_address_block(&amp;&amp;rdba) BL FROM dual; 8.3 根据以上查询，来确认哪些对象受了影响 123456789101112131415161718192021222324252627282930313233343536373839404142434445--如果Segment type为index Partition，那么，通过以下语句确认哪个分区受影响。 SELECT partition_name FROM dba_extents WHERE file_id = &amp;AFN AND &amp;BL BETWEEN block_id AND block_id + blocks - 1; 此时只需要rebuild index即可： ALTER INDEX xxx REBUILD PARTITION ppp; --如果segment type是index，那么找出该index 属于哪一张表。 SELECT table_owner, table_name FROM dba_indexes WHERE owner=&apos;&amp;OWNER&apos; AND index_name=&apos;&amp;SEGMENT_NAME&apos;; --确认该索引是否有约束条件： SELECT owner, constraint_name, constraint_type, table_name FROM dba_constraints WHERE owner=&apos;&amp;TABLE_OWNER&apos; AND constraint_name=&apos;&amp;INDEX_NAME&apos;; --如果是“P”类型的，查看其是否有外键约束： SELECT owner, constraint_name, constraint_type, table_name FROM dba_constraints WHERE r_owner=&apos;&amp;TABLE_OWNER&apos; AND r_constraint_name=&apos;&amp;INDEX_NAME&apos;; --如果类型是分区表,确认是哪个分区受影响： SELECT partition_name FROM dba_extents WHERE file_id = &amp;AFN AND &amp;BL BETWEEN block_id AND block_id + blocks - 1; 如果损坏的数据在一个分区表里面，那么EXCHANGE该数据到一张空表里，保证应用能够继续，后续再提数据。 ALTER TABLE .. EXCHANGE PARTITION .. WITH TABLE ..; --如果类型是Table，那么首先确认该表是否含有index： SELECT owner, index_name, index_type FROM dba_indexes WHERE table_owner=&apos;&amp;OWNER&apos; AND table_name=&apos;&amp;SEGMENT_NAME&apos;;--然后进一步确认是否含有主键索引： SELECT owner, constraint_name, constraint_type, table_name FROM dba_constraints WHERE owner=&apos;&amp;OWNER&apos; AND table_name=&apos;&amp;SEGMENT_NAME&apos; AND constraint_type=&apos;P&apos;; --如果含有主键索引，再查看是否有外键约束： SELECT owner, constraint_name, constraint_type, table_name FROM dba_constraints WHERE r_owner=&apos;&amp;OWNER&apos; AND r_constraint_name=&apos;&amp;CONSTRAINT_NAME&apos;; 此时可以抽取数据，然后recreate table。也可以使用dbms_repair 包skip坏块。 修复的方法这里就省略了。 9. 附录—10231事件说明 Subject: Extracting Data from a Corrupt Table using SKIP CORRUPT BLOCKS or Event 10231 Doc ID: Note:33405.1","link":"/detect-and-correct-corruption-in-oracle.html"},{"title":"dbbp bundle patch installed in the cdb but not in the pdb","text":"从远程数据库复制过来后，由于DBBP版本不一致，开启PDB的时候出现错误，且PDB处于restricted模式:123456SQL&gt; show pdbs CON_ID CON_NAME OPEN MODE RESTRICTED---------- ------------------------------ ---------- ---------- 2 PDB$SEED READ ONLY NO 3 SLDB1 READ WRITE YES 查询pdb_plug_in_violations1234567891011121314MESSAGE STATUS ACTION---------------------------------------- ------------------ ----------------------------------------DBBP bundle patch 190115 (DATABASE BUNDL PENDING Call datapatch to install in the PDB orE PATCH 12.1.0.2.190115): Installed in t the CDBhe PDB but not in the CDB.DBBP bundle patch 190416 (DATABASE BUNDL PENDING Call datapatch to install in the PDB orE PATCH 12.1.0.2.190416): Installed in t the CDBhe CDB but not in the PDB.SQL patch ID/UID 28790654/22620251 (Data PENDING Call datapatch to install in the PDB orbase PSU 12.1.0.2.190115, Oracle JavaVM the CDBComponent (JAN2019)): Installed in the PDB but not in the CDB. 相关版本 Linora为源库，是non-cdb; db2srv是目标库，是cdb1234567891011121314 /u01/app/oracle/product/12c/db_1 (opatch version 12.2.0.1.17)------------------------------ Patch ID | linora |------------------------------ 28731800 | - | Database Bundle Patch : 12.1.0.2.190115 (28731800) 28790654 | - | Database PSU 12.1.0.2.190115, Oracle JavaVM Component (JAN2019)------------------------------ /u02/app/oracle/product/12.1.0.2/db_1 (opatch version 12.2.0.1.17)------------------------------ Patch ID | db2srv |------------------------------ 29141038 | - | Database Bundle Patch : 12.1.0.2.190416 (29141038) 29251241 | - | Database PSU 12.1.0.2.190416, Oracle JavaVM Component (APR2019) datapatch衍生问题 根据pdb_plug_in_violations提示，执行datapatch, 结果因为两边jvm版本不一致，发生如下错误:有些情况下，需要将CDB/PDB启动到startup upgrade模式下，才能进行datapatch 123456789101112131415161718192021222324252627cd $ORACLE_HOME/Opatch./datapatch -verboseAdding patches to installation queue and performing prereq checks...Installation queue: For the following PDBs: CDB$ROOT PDB$SEED SLDB1 Nothing to roll back The following patches will be applied: 29251241 (Database PSU 12.1.0.2.190416, Oracle JavaVM Component (APR2019)) For the following PDBs: SLDB2 The following patches will be rolled back: 28790654 (Database PSU 12.1.0.2.190115, Oracle JavaVM Component (JAN2019)) The following patches will be applied: 29251241 (Database PSU 12.1.0.2.190416, Oracle JavaVM Component (APR2019)) 29141038 (DATABASE BUNDLE PATCH 12.1.0.2.190416)Validating logfiles...Patch 28790654 rollback (pdb SLDB2): WITH ERRORS logfile: /u02/app/oracle/cfgtoollogs/sqlpatch/28790654/22620251/28790654_rollback_CDB12C_SLDB1_2019Aug16_14_10_11.log (errors) Error at line 595: ORA-29548: Java system class reported: could not identify release specified in Error at line 627: ORA-29548: Java system class reported: could not identify release specified in Error at line 635: ORA-29548: Java system class reported: could not identify release specified inPatch 29251241 apply (pdb SLDB2): WITH ERRORS logfile: /u02/app/oracle/cfgtoollogs/sqlpatch/29251241/22839506/29251241_apply_CDB12C_SLDB1_2019Aug16_14_10_32.log (errors) Error at line 663: ORA-29548: Java system class reported: could not identify release specified in Error at line 695: ORA-29548: Java system class reported: could not identify release specified in Error at line 703: ORA-29548: Java system class reported: could not identify release specified in 此时查询pdb的dba_registry_sqlpatch, 会发现database的补丁已经应用，但是OJVM因为上述错误无法应用。123456789101112131415SQL&gt; alter session set container = sldb2;ACTION_TIME ACTION STATUS DESCRIPTION VERSION PATCH_ID BUNDLE_SER-------------------- ---------- ---------- --------------------------------------------- ---------- ---------- ----------16-AUG-2019 09:18:16 APPLY SUCCESS DATABASE BUNDLE PATCH 12.1.0.2.190115 12.1.0.2 28731800 DBBP16-AUG-2019 09:24:23 APPLY SUCCESS Database PSU 12.1.0.2.190115, Oracle JavaVM C 12.1.0.2 28790654 omponent (JAN2019)16-AUG-2019 15:38:08 ROLLBACK WITH ERROR Database PSU 12.1.0.2.190115, Oracle JavaVM C 12.1.0.2 28790654 S omponent (JAN2019)16-AUG-2019 15:38:08 APPLY WITH ERROR Database PSU 12.1.0.2.190416, Oracle JavaVM C 12.1.0.2 29251241 S omponent (APR2019)16-AUG-2019 15:38:09 APPLY SUCCESS DATABASE BUNDLE PATCH 12.1.0.2.190416 12.1.0.2 29141038 DBBP MOS查询出来两个bug：Bug 17610418 - ORA-29548 from plugged in different version non CDB as PDB [17610418.8]Bug 16986421 - ORA-29548 from plug in of lower version PDB with Java [16986421.8]但是这个两个bug是在12.1.0.2 server patch set已经fixed，已经找不到单独的patch。 解决方案 尝试在复制前，将目标库的OJVM补丁回退到原始状态，等PDB复制过来后，再进行补丁的安装，问题得到解决. 总结 PDB出现DBBP相关的错误时，查询CDB及PDB的dba_registry_sqlpatch，比较两者的区别 根据上述结果，评估是否可以进行datapatch 在进行远程复制的时候，如果两边OJVM版本不一致，可以考虑现在目标端回滚OJVM，再进行远程复制 Reference:After running datapatch, PDB plugin or cloned db returns violations shown in PDB_PLUG_IN_VIOLATION (Doc ID 1635482.1) EOF","link":"/dbbp-bundle-patch-installed-in-the-cdb-but-not-in-the-pdb.html"},{"title":"Easy Connect with ORA-12504","text":"Easy connect naming method will cause below error if you didn&#39;t specify user password:12345678[oracle@db2srv:/home/oracle]$ sqlplus system@192.168.56.101:1522/linoraSQL*Plus: Release 12.2.0.1.0 Production on Tue Aug 6 08:48:46 2019Copyright (c) 1982, 2016, Oracle. All rights reserved.ERROR:ORA-12504: TNS:listener was not given the SERVICE_NAME in CONNECT_DATA It&#39;s because Oracle will translate service_name as user password.The solution is using double quote and escape character for connect strings: 12345678910111213141516[oracle@db2srv:/home/oracle]$ sqlplus system@\\\"192.168.56.101:1522/linora\\\" as sysdbaSQL*Plus: Release 12.2.0.1.0 Production on Tue Aug 6 10:53:57 2019Copyright (c) 1982, 2016, Oracle. All rights reserved.Enter password:[oracle@db2srv:/home/oracle]$ sqlplus /nologSQL*Plus: Release 12.2.0.1.0 Production on Tue Aug 6 10:55:53 2019Copyright (c) 1982, 2016, Oracle. All rights reserved.idle&gt; conn system@\"192.168.56.101:1522/linora\"Enter password EOF","link":"/easy-connect-with-ORA-12504.html"},{"title":"11gr2 RAC删除节点","text":"RAC节点的删除跟添加的步骤刚好相反，先删除实例，再删除集群上此节点的信息，最后删除GI。 1. 删除实例 1.1. 使用DBCA图形界面删除 在节点1以Oracle用户登录执行dbca命令 选择RAC数据库 选择Instance Management 选择Delete an instance 键入sysdba用户名及密码 选择需要删除的节点 1.2. 使用DBCA静默删除 在节点1以Oracle用户登录，执行以下命令： 12345678910111213141516171819[oracle@orcl1:/home/oracle]$ dbca -silent -deleteInstance -nodeList orcl2 -gdbName racdb \\ &gt; -instanceName racdb2 -sysDBAUserName sys -sysDBAPassword oracle Deleting instance 1% complete 2% complete 6% complete 13% complete 20% complete 26% complete 33% complete 40% complete 46% complete 53% complete 60% complete 66% complete Completing instance management. 100% complete Look at the log file &quot;/u01/app/oracle/cfgtoollogs/dbca/racdb.log&quot; for further details. [oracle@orcl1:/home/oracle]$ 验证结果: 1234567891011121314151617181920[oracle@orcl1:/home/oracle]$ srvctl status database -d racdb Instance racdb1 is running on node orcl1 [oracle@orcl1:/home/oracle]$ srvctl config database -d racdb Database unique name: racdb Database name: racdb Oracle home: /u01/app/oracle/product/11gr2 Oracle user: oracle Spfile: +DATA/racdb/spfileracdb.ora Domain: Start options: open Stop options: immediate Database role: PRIMARY Management policy: AUTOMATIC Server pools: racdb Database instances: racdb1 Disk Groups: DATA Mount point paths: Services: Type: RAC Database is administrator managed 2. 删除RDBMS 2.1. 停止监听 在节点1上以grid用户使用以下命令停止要删除节点的监听： 12[grid@orcl1:/home/grid]$ srvctl disable listener -l LISTENER -n orcl2 [grid@orcl1:/home/grid]$ srvctl stop listener -l LISTENER -n orcl2 2.2. 更新inventory 以Oracle用户在被删除节点上上执行以下命令： 12345678[oracle@orcl2:/u01/app/oracle/product/11gr2/oui/bin]$ ./runInstaller -updateNodeList \\ &gt; ORACLE_HOME=/u01/app/oracle/product/11gr2 &quot;CLUSTER_NODES=orcl2&quot; -local Starting Oracle Universal Installer... Checking swap space: must be greater than 500 MB. Actual 3972 MB Passed The inventory pointer is located at /etc/oraInst.loc The inventory is located at /u01/app/oraInventory &apos;UpdateNodeList&apos; was successful. 2.3. 删除Oracle home 以Oracle用户在被删除节点上执行以下命令删除ORACLE HOME： 1[oracle@orcl2:/home/oracle]$ $ORACLE_HOME/deinstall/deinstall –local 部分输出结果： ####################### CLEAN OPERATION SUMMARY ####################### Cleaning the config for CCR As CCR is not configured, so skipping the cleaning of CCR configuration CCR clean is finished Successfully detached Oracle home '/u01/app/oracle/product/11gr2' from the central inventory on the local node. Successfully deleted directory '/u01/app/oracle/product/11gr2' on the local node. Failed to delete directory '/u01/app/oracle' on the local node. Oracle Universal Installer cleanup completed with errors. Oracle deinstall tool successfully cleaned up temporary directories. ####################################################################### ############# ORACLE DEINSTALL & DECONFIG TOOL END ############# [oracle@orcl2:/home/oracle]$ 2.4. 在节点1更新inventory 以Oracle用户执行以下命令更新inventory信息： 123456789[oracle@orcl1:/home/oracle]$ cd $ORACLE_HOME/oui/bin [oracle@orcl1:/u01/app/oracle/product/11gr2/oui/bin]$ ./runInstaller -updateNodeList \\ ORACLE_HOME=/u01/app/oracle/product/11gr2 &quot;CLUSTER_NODES=orcl1&quot; Starting Oracle Universal Installer... Checking swap space: must be greater than 500 MB. Actual 4012 MB Passed The inventory pointer is located at /etc/oraInst.loc The inventory is located at /u01/app/oraInventory &apos;UpdateNodeList&apos; was successful. 3. 删除Grid Infrastructure 3.1. 查看ONS资源 使用以下命令查看ONS资源是否为Unpinned： 123[grid@orcl2:/home/grid]$ olsnodes -t -s orcl1 Active Unpinned orcl2 Active Unpinned 如果是pinned状态，请执行以下命令更改为Unpinned状态： $crsctl unpin css -n node_name 3.2. 删除grid配置信息 在被删除节点，删除Clusterware后台进程，以root用户执行$GRID_HOME/crs/install/rootcrs.pl脚本清除grid配置信息： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950[root@orcl2:/root]# cd /u01/app/11.2.0/grid/crs/install/ [root@orcl2:/u01/app/11.2.0/grid/crs/install]# ./rootcrs.pl -deconfig -deinstall –force Using configuration parameter file: ./crsconfig_params Network exists: 1/192.168.56.0/255.255.255.0/eth0, type static VIP exists: /racdb1-vip/192.168.56.103/192.168.56.0/255.255.255.0/eth0, hosting node orcl1 VIP exists: /racdb2-vip/192.168.56.104/192.168.56.0/255.255.255.0/eth0, hosting node orcl2 GSD exists ONS exists: Local port 6100, remote port 6200, EM port 2016 CRS-2673: Attempting to stop &apos;ora.registry.acfs&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.registry.acfs&apos; on &apos;orcl2&apos; succeeded CRS-2791: Starting shutdown of Oracle High Availability Services-managed resources on &apos;orcl2&apos; CRS-2673: Attempting to stop &apos;ora.crsd&apos; on &apos;orcl2&apos; CRS-2790: Starting shutdown of Cluster Ready Services-managed resources on &apos;orcl2&apos; CRS-2673: Attempting to stop &apos;ora.oc4j&apos; on &apos;orcl2&apos; CRS-2673: Attempting to stop &apos;ora.CRS.dg&apos; on &apos;orcl2&apos; CRS-2673: Attempting to stop &apos;ora.DATA.dg&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.DATA.dg&apos; on &apos;orcl2&apos; succeeded CRS-2677: Stop of &apos;ora.CRS.dg&apos; on &apos;orcl2&apos; succeeded CRS-2673: Attempting to stop &apos;ora.asm&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.asm&apos; on &apos;orcl2&apos; succeeded CRS-2677: Stop of &apos;ora.oc4j&apos; on &apos;orcl2&apos; succeeded CRS-2672: Attempting to start &apos;ora.oc4j&apos; on &apos;orcl1&apos; CRS-2676: Start of &apos;ora.oc4j&apos; on &apos;orcl1&apos; succeeded CRS-2792: Shutdown of Cluster Ready Services-managed resources on &apos;orcl2&apos; has completed CRS-2677: Stop of &apos;ora.crsd&apos; on &apos;orcl2&apos; succeeded CRS-2673: Attempting to stop &apos;ora.ctssd&apos; on &apos;orcl2&apos; CRS-2673: Attempting to stop &apos;ora.evmd&apos; on &apos;orcl2&apos; CRS-2673: Attempting to stop &apos;ora.asm&apos; on &apos;orcl2&apos; CRS-2673: Attempting to stop &apos;ora.drivers.acfs&apos; on &apos;orcl2&apos; CRS-2673: Attempting to stop &apos;ora.mdnsd&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.evmd&apos; on &apos;orcl2&apos; succeeded CRS-2677: Stop of &apos;ora.ctssd&apos; on &apos;orcl2&apos; succeeded CRS-2677: Stop of &apos;ora.mdnsd&apos; on &apos;orcl2&apos; succeeded CRS-2677: Stop of &apos;ora.drivers.acfs&apos; on &apos;orcl2&apos; succeeded CRS-2677: Stop of &apos;ora.asm&apos; on &apos;orcl2&apos; succeeded CRS-2673: Attempting to stop &apos;ora.cluster_interconnect.haip&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.cluster_interconnect.haip&apos; on &apos;orcl2&apos; succeeded CRS-2673: Attempting to stop &apos;ora.cssd&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.cssd&apos; on &apos;orcl2&apos; succeeded CRS-2673: Attempting to stop &apos;ora.crf&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.crf&apos; on &apos;orcl2&apos; succeeded CRS-2673: Attempting to stop &apos;ora.gipcd&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.gipcd&apos; on &apos;orcl2&apos; succeeded CRS-2673: Attempting to stop &apos;ora.gpnpd&apos; on &apos;orcl2&apos; CRS-2677: Stop of &apos;ora.gpnpd&apos; on &apos;orcl2&apos; succeeded CRS-2763: Shutdown of Oracle High Availability Services-managed resources on &apos;orcl2&apos; has completed CRS-4133: Oracle High Availability Services has been stopped. Removing Trace File Analyzer Successfully deconfigured Oracle clusterware stack on this node [root@orcl2:/u01/app/11.2.0/grid/crs/install]# 3.3. 确认节点信息并删除 123[grid@orcl1:/home/grid]$ olsnodes -s -t orcl1 Active Unpinned orcl2 Inactive Unpinned 在节点1以root用户执行以下命令，删除RAC节点： 123[root@orcl1:/root]# /u01/app/11.2.0/grid/bin/crsctl delete node -n orcl2 CRS-4661: Node orcl2 successfully deleted. [root@orcl1:/root]# 再次确认集群节点信息： 123[grid@orcl1:/home/grid]$ olsnodes -s -t orcl1 Active Unpinned [grid@orcl1:/home/grid]$ 3.4. 更新inventory信息 在被删除节点，以grid用户执行以下命令更新集群inventory信息： 1234567891011[grid@orcl2:/home/grid]$ cd $ORACLE_HOME/oui/bin [grid@orcl2:/u01/app/11.2.0/grid/oui/bin]$ ./runInstaller -updateNodeList ORACLE_HOME=/u01/app/11.2.0/grid \\ &quot;CLUSTER_NODES=orcl2&quot; CRS=TRUE -silent -local Starting Oracle Universal Installer... Checking swap space: must be greater than 500 MB. Actual 4089 MB Passed The inventory pointer is located at /etc/oraInst.loc The inventory is located at /u01/app/oraInventory &apos;UpdateNodeList&apos; was successful. [grid@orcl2:/u01/app/11.2.0/grid/oui/bin]$ 3.5. 删除GI软件 在被删除节点，以grid用户登录，执行以下命令删除此节点GI软件（如果不指定-local选项，那么默认将会把所有的集群信息全部删除，这是非常危险的操作）： [grid@orcl2:/home/grid]$ $ORACLE_HOME/deinstall/deinstall -local Deinstall时，需要用户输入VIP、LISTENER等信息，并在中间步骤需要另开一个session，以root用户执行脚本，最后还需要手动删除部分文件(/etc/oraInst.log、/etc/oratab跟/opt/ORCLfmap)，要注意细心阅读output，请勿无视输出结果： 12345678910111213141516171819202122232425####################### CLEAN OPERATION SUMMARY ####################### Following RAC listener(s) were de-configured successfully: LISTENER Oracle Clusterware is stopped and successfully de-configured on node &quot;orcl2&quot; Oracle Clusterware is stopped and de-configured successfully. Successfully detached Oracle home &apos;/u01/app/11.2.0/grid&apos; from the central inventory on the local node. Successfully deleted directory &apos;/u01/app/11.2.0/grid&apos; on the local node. Successfully deleted directory &apos;/u01/app/oraInventory&apos; on the local node. Successfully deleted directory &apos;/u01/app/grid&apos; on the local node. Oracle Universal Installer cleanup was successful. Run &apos;rm -rf /etc/oraInst.loc&apos; as root on node(s) &apos;orcl2&apos; at the end of the session. Run &apos;rm -rf /opt/ORCLfmap&apos; as root on node(s) &apos;orcl2&apos; at the end of the session. Run &apos;rm -rf /etc/oratab&apos; as root on node(s) &apos;orcl2&apos; at the end of the session. Oracle deinstall tool successfully cleaned up temporary directories. ####################################################################### ############# ORACLE DEINSTALL &amp; DECONFIG TOOL END ############# [grid@orcl2:/home/grid]$ [grid@orcl2:/home/grid]$ [root@orcl2:/root]# rm -rf /etc/oraInst.loc [root@orcl2:/root]# rm -rf /opt/ORCLfmap [root@orcl2:/root]# rm -rf /etc/oratab [root@orcl2:/root]# 3.6. 更新剩余节点inventory 以grid用户执行以下命令，更新inventory： 1234567891011[grid@orcl1:/home/grid]$ cd $ORACLE_HOME/oui/bin [grid@orcl1:/u01/app/11.2.0/grid/oui/bin]$ ./runInstaller -updateNodeList \\ &gt; ORACLE_HOME=/u01/app/11.2.0/grid \\ &gt; &quot;CLUSTER_NODES=orcl1&quot; CRS=TRUE -silent Starting Oracle Universal Installer... Checking swap space: must be greater than 500 MB. Actual 3980 MB Passed The inventory pointer is located at /etc/oraInst.loc The inventory is located at /u01/app/oraInventory &apos;UpdateNodeList&apos; was successful. [grid@orcl1:/u01/app/11.2.0/grid/oui/bin]$ 4. 验证集群删除结果 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[grid@orcl1:/home/grid]$ cluvfy stage -post nodedel -n orcl2 -verbosePerforming post-checks for node removal Checking CRS integrity... Clusterware version consistency passed The Oracle Clusterware is healthy on node &quot;orcl1&quot; CRS integrity check passed Result: Node removal check passed Post-check for node removal was successful. [grid@orcl1:/home/grid]$ crsctl stat res -t -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.CRS.dg ONLINE ONLINE orcl1 ora.DATA.dg ONLINE ONLINE orcl1 ora.LISTENER.lsnr ONLINE ONLINE orcl1 ora.asm ONLINE ONLINE orcl1 Started ora.gsd OFFLINE OFFLINE orcl1 ora.net1.network ONLINE ONLINE orcl1 ora.ons ONLINE ONLINE orcl1 ora.registry.acfs ONLINE ONLINE orcl1 -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE orcl1 ora.cvu 1 ONLINE ONLINE orcl1 ora.oc4j 1 ONLINE ONLINE orcl1 ora.orcl1.vip 1 ONLINE ONLINE orcl1 ora.racdb.db 1 ONLINE ONLINE orcl1 Open ora.scan1.vip 1 ONLINE ONLINE orcl1 [grid@orcl1:/home/grid]$ Reference:Oracle® Real Application Clusters Administration and Deployment Guide 11g Release 2 (11.2) EOF","link":"/deletenodes-in-11g-rac.html"},{"title":"Duplicate Database With RMAN","text":"在DBA日常维护中，有时会接到开发人员要求部署一个跟生产环境相同的数据库，这个时候可以用到rman的Duplicate功能直接将目标数据库复制过来。本文以异机复制为例，简单阐述Duplicate的用法。 1.首先在duplicate端创建密码文件 跟异机恢复一样，在duplicate节点只需要安装相同版本的数据库软件，而不需要单独建库。 12[ora11g@:/home/oracle]$ export ORACLE_SID=dup[ora11g@:/home/oracle]$ orapwd file=$ORACLE_HOME/dbs/orapw$ORACLE_SID password=oracle entries=5 force=y 2.duplicate端静态注册监听 duplicate端因为没有实例，需要静态注册监听。同时在tnsnames.ora中添加两个库的tns。 123456789101112131415161718192021222324252627282930313233SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = PLSExtProc) (ORACLE_HOME = /oracle/app/oracle/product/11.2.0/db_1) (PROGRAM = extproc) ) (SID_DESC = (SID_NAME = dup) (ORACLE_HOME = /oracle/app/oracle/product/11.2.0/db_1) (GLOBAL_DBNAME=dup) ) )[ora11g@:/oracle]$ lsnrctl start[ora11g@:/home/ora11g]$ lsnrctl serviceLSNRCTL for IBM/AIX RISC System/6000: Version 11.2.0.3.0 - Production on 23-MAY-2014 17:33:57Copyright (c) 1991, 2011, Oracle. All rights reserved.Connecting to (DESCRIPTION=(ADDRESS=(PROTOCOL=TCP)(HOST=oratest)(PORT=1521)))Services Summary...Service &quot;PLSExtProc&quot; has 1 instance(s). Instance &quot;PLSExtProc&quot;, status UNKNOWN, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 LOCAL SERVERService &quot;dup&quot; has 1 instance(s). Instance &quot;dup&quot;, status UNKNOWN, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 LOCAL SERVERThe command completed successfully 3.创建初始化文件 如果是duplicate到本地的，需要在init文件上添加如下参数，以免数据文件路径冲突。注意其他文件的路径要先创建好。 12DB_FILE_NAME_CONVERT=(/original/path,/duplicate/path)LOG_FILE_NAME_CONVERT=(/original/path,/duplicate/path) 将dup数据库以创建的pfile启动至nomount状态。这个dup数据库将会是此次duplicate中rman的auxiliary instance。 12345678SQL&gt; startup nomountORACLE instance started.Total System Global Area 1570009088 bytesFixed Size 2221840 bytesVariable Size 973080816 bytesDatabase Buffers 587202560 bytesRedo Buffers 7503872 bytes 4.利用rman进行Active duplicate 使用rman工具，以dup实例作为辅助实例连接至目标数据库。duplicate的主要工作是在辅助实例完成，如restore database，recover database等。 1234567[ora11g@:/home/ora11g]$ rman target sys/oracle@orcl auxiliary sys/oracle@dupRecovery Manager: Release 11.2.0.3.0 - Production on Fri May 23 18:09:04 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.connected to target database: ORCL (DBID=1375890310)connected to auxiliary database: DUP (not mounted) 此时可用以下命令进行复制： 123DUPLICATE TARGET DATABASE TO DUP;DUPLICATE TARGET DATABASE TO DUP UNTIL TIME ‘SYSDATA-4’; --Duplicate database to target’s state 4 days ago. 上述指令是要通过备份去复制，下面这个指令是直接复制Active Database。这个功能是11g以后新增加的，可以利用这个功能创建DataGuard。两者的区别在于，rman备份产生的数据量要小，因为rman只备份含有数据的block，而Active模式则是整个数据文件copy过来，因此，使用Active模式复制，速度要慢很多。 123456789101112131415161718192021222324252627[ora11g@:/home/oracle]$ rman target sys/oracle@orcl \\auxiliary sys/oracle@dup msglog=/oracle/dup_`date &apos;+%Y%m%d%H%M&apos;`.log&lt;&lt;EOFrun&#123;allocate channel c1 type disk;allocate auxiliary channel ch1 TYPE disk;#set until time &quot;to_date(&apos;2014/05/23 12:00:00&apos;,&apos;YYYY/MM/DD HH24:MI:SS&apos;)&quot;;set newname for datafile 1 to &apos;/oracle/oradata/dup/system01.dbf&apos;;#or CONFIGURE AUXNAME FOR DATAFILE 1 to &apos;/oracle/oradata/dup/system01.dbf&apos;;set newname for datafile 2 to &apos;/oracle/oradata/dup/undotbs01.dbf&apos;;set newname for datafile 3 to &apos;/oracle/oradata/dup/sysaux01.dbf&apos;;set newname for datafile 4 to &apos;/oracle/oradata/dup/users01.dbf&apos;;set newname for datafile 5 to &apos;/oracle/oradata/dup/fung01.dbf&apos;;set newname for tempfile 1 to &apos;/oracle/oradata/dup/temp01.dbf&apos;;#/*SKIP TABLESPACE tools*/ skip read only tablespaceDUPLICATE TARGET DATABASE TO DUP FROM ACTIVE DATABASELOGFILEGROUP 1 (&apos;/oracle/oradata/dup/redo01a.log&apos;, &apos;/oracle/oradata/dup/redo01b.log&apos;) size 10240k reuse,GROUP 2 (&apos;/oracle/oradata/dup/redo02a.log&apos;, &apos;/oracle/oradata/dup/redo02b.log&apos;) size 10240k reuse,GROUP 3 (&apos;/oracle/oradata/dup/redo03a.log&apos;, &apos;/oracle/oradata/dup/redo03b.log&apos;) size 10240k reuse;switch datafile all;switch tempfile all;&#125;exit;EOF 如果dup存储目录跟目标数据库一致，则使用nofilenamecheck即可，当然，这只能在不同的机器上实现。 12345678run&#123;allocate auxiliary channel ch1 DEVICE TYPE disk;DUPLICATE TARGET DATABASE TO dupdb # specify client-side parameter file (on same host as RMAN executable) for # auxiliary instance if necessary PFILE = /dup/oracle/dbs/initDUPDB.ora NOFILENAMECHECK; &#125; 在我的环境中，遇到了一个bug [ID 1552916.1]，添加debug参数可解决，这个bug也只是在Active duplicate的时候触发的。 123456789101112131415161718192021222324252627[ora11g@:/home/oracle]$ rman target sys/oracle@orcl debug trace=rman.trc \\auxiliary sys/oracle@dup msglog=/oracle/dup_`date &apos;+%Y%m%d%H%M&apos;`.log&lt;&lt;EOFrun&#123;allocate channel c1 type disk;allocate auxiliary channel ch1 TYPE disk;#set until time &quot;to_date(&apos;2014/05/23 12:00:00&apos;,&apos;YYYY/MM/DD HH24:MI:SS&apos;)&quot;;set newname for datafile 1 to &apos;/oracle/oradata/dup/system01.dbf&apos;;#or CONFIGURE AUXNAME FOR DATAFILE 1 to &apos;/oracle/oradata/dup/system01.dbf&apos;;set newname for datafile 2 to &apos;/oracle/oradata/dup/undotbs01.dbf&apos;;set newname for datafile 3 to &apos;/oracle/oradata/dup/sysaux01.dbf&apos;;set newname for datafile 4 to &apos;/oracle/oradata/dup/users01.dbf&apos;;set newname for datafile 5 to &apos;/oracle/oradata/dup/fung01.dbf&apos;;set newname for tempfile 1 to &apos;/oracle/oradata/dup/temp01.dbf&apos;;#/*SKIP TABLESPACE tools*/ skip read only tablespaceDUPLICATE TARGET DATABASE TO DUP FROM ACTIVE DATABASELOGFILEGROUP 1 (&apos;/oracle/oradata/dup/redo01a.log&apos;, &apos;/oracle/oradata/dup/redo01b.log&apos;) size 10240k reuse,GROUP 2 (&apos;/oracle/oradata/dup/redo02a.log&apos;, &apos;/oracle/oradata/dup/redo02b.log&apos;) size 10240k reuse,GROUP 3 (&apos;/oracle/oradata/dup/redo03a.log&apos;, &apos;/oracle/oradata/dup/redo03b.log&apos;) size 10240k reuse;switch datafile all;switch tempfile all;&#125;exit;EOF 有关时间的输出： 12345678910111213141516Recovery Manager: Release 11.2.0.3.0 - Production on Fri May 23 19:30:52 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.RMAN-06005: connected to target database: ORCL (DBID=1375890310)RMAN-06549: connected to auxiliary database: DUP (not mounted)RMAN&gt; 2&gt; 3&gt; 4&gt; 5&gt; 6&gt; 7&gt; 8&gt; 9&gt; 10&gt; 11&gt; 12&gt; 13&gt; 14&gt; 15&gt; 16&gt; 17&gt; 18&gt; 19&gt; 20&gt; 21&gt; 22&gt; 23&gt; RMAN-06009: using target database control file instead of recovery catalog...RMAN-06400: database openedRMAN-03091: Finished Duplicate Db at 2014-05-23 19:58:04RMAN-08031: released channel: c1RMAN-08031: released channel: ch1 经历了近30分钟。 5. 使用备份进行duplicate 在目标数据库进行rman备份，并且将备份集传输到dup目录。由于没有控制文件，因此，备份集存放路径要跟原来的一样。 源库查询scn： 123456789101112131415161718192021RMAN&gt; list backup of archivelog all;List of Backup Sets===================BS Key Size Device Type Elapsed Time Completion Time ------- ---------- ----------- ------------ -------------------19 490.00K DISK 00:00:00 2014-06-29 09:52:03 BP Key: 19 Status: AVAILABLE Compressed: NO Tag: TAG20140629T095201 Piece Name: /oracle/backup/arch_16pc1ua3_1_1_20140629_ORCL List of Archived Logs in backup set 19 Thrd Seq Low SCN Low Time Next SCN Next Time ---- ------- ---------- ------------------- ---------- --------- 1 37 376337 2014-06-29 09:00:56 376374 2014-06-29 09:01:38 1 38 376374 2014-06-29 09:01:38 377772 2014-06-29 09:35:42 1 39 377772 2014-06-29 09:35:42 378694 2014-06-29 09:51:46 1 40 378694 2014-06-29 09:51:46 378719 2014-06-29 09:51:59 1 41 378719 2014-06-29 09:51:59 378728 2014-06-29 09:51:59 1 42 378728 2014-06-29 09:51:59 378737 2014-06-29 09:52:01 1 43 378737 2014-06-29 09:52:01 378745 2014-06-29 09:52:01 恢复的时候选取378745这个scn。 123456789101112131415161718192021222324252627[ora11g@:/home/oracle]$ rman target sys/oracle@orcl \\auxiliary sys/oracle@dup msglog=/oracle/dup_`date &apos;+%Y%m%d%H%M&apos;`.log&lt;&lt;EOFrun&#123;allocate channel c1 type disk;allocate auxiliary channel ch1 TYPE disk;set until scn 378745;set newname for datafile 1 to &apos;/oracle/oradata/dup/system01.dbf&apos;;#or CONFIGURE AUXNAME FOR DATAFILE 1 to &apos;/oracle/oradata/dup/system01.dbf&apos;;set newname for datafile 2 to &apos;/oracle/oradata/dup/undotbs01.dbf&apos;;set newname for datafile 3 to &apos;/oracle/oradata/dup/sysaux01.dbf&apos;;set newname for datafile 4 to &apos;/oracle/oradata/dup/users01.dbf&apos;;set newname for datafile 5 to &apos;/oracle/oradata/dup/fung01.dbf&apos;;set newname for tempfile 1 to &apos;/oracle/oradata/dup/temp01.dbf&apos;;#/*SKIP TABLESPACE tools*/ skip read only tablespaceDUPLICATE TARGET DATABASE TO DUPLOGFILEGROUP 1 (&apos;/oracle/oradata/dup/redo01a.log&apos;, &apos;/oracle/oradata/dup/redo01b.log&apos;) size 10240k reuse,GROUP 2 (&apos;/oracle/oradata/dup/redo02a.log&apos;, &apos;/oracle/oradata/dup/redo02b.log&apos;) size 10240k reuse,GROUP 3 (&apos;/oracle/oradata/dup/redo03a.log&apos;, &apos;/oracle/oradata/dup/redo03b.log&apos;) size 10240k reuse;switch datafile all;switch tempfile all;&#125;exit;EOF 恢复时间： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950Recovery Manager: Release 11.2.0.3.0 - Production on Fri May 23 20:23:42 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.connected to target database: ORCL (DBID=1375890310)connected to auxiliary database: DUP (not mounted)RMAN&gt; 2&gt; 3&gt; 4&gt; 5&gt; 6&gt; 7&gt; 8&gt; 9&gt; 10&gt; 11&gt; 12&gt; 13&gt; 14&gt; 15&gt; 16&gt; 17&gt; 18&gt; 19&gt; 20&gt; 21&gt; 22&gt; 23&gt; using target database control file instead of recovery catalog...Starting restore at 2014-05-23 20:24:01channel ch1: starting datafile backup set restorechannel ch1: restoring control filechannel ch1: reading from backup piece /oracle/backup/bk_34_1_12pc1u9q_1_1_20140629_ORCLchannel ch1: piece handle=/oracle/backup/bk_34_1_12pc1u9q_1_1_20140629_ORCL tag=HOT_DB_BK_LEVEL0channel ch1: restored backup piece 1channel ch1: restore complete, elapsed time: 00:00:01output file name=/oracle/oradata/dup/control01.ctloutput file name=/oracle/oradata/dup/control02.ctlFinished restore at 2014-05-23 20:24:02...Starting restore at 2014-05-23 20:24:07channel ch1: starting datafile backup set restorechannel ch1: specifying datafile(s) to restore from backup setchannel ch1: restoring datafile 00002 to /oracle/oradata/dup/undotbs01.dbfchannel ch1: restoring datafile 00003 to /oracle/oradata/dup/sysaux01.dbfchannel ch1: reading from backup piece /oracle/backup/bk_33_1_11pc1u9j_1_1_20140629_ORCLchannel ch1: piece handle=/oracle/backup/bk_33_1_11pc1u9j_1_1_20140629_ORCL tag=HOT_DB_BK_LEVEL0channel ch1: restored backup piece 1channel ch1: restore complete, elapsed time: 00:00:15channel ch1: starting datafile backup set restorechannel ch1: specifying datafile(s) to restore from backup setchannel ch1: restoring datafile 00001 to /oracle/oradata/dup/system01.dbfchannel ch1: restoring datafile 00004 to /oracle/oradata/dup/users01.dbfchannel ch1: restoring datafile 00005 to /oracle/oradata/dup/fung01.dbfchannel ch1: reading from backup piece /oracle/backup/bk_32_1_10pc1u9j_1_1_20140629_ORCLchannel ch1: piece handle=/oracle/backup/bk_32_1_10pc1u9j_1_1_20140629_ORCL tag=HOT_DB_BK_LEVEL0channel ch1: restored backup piece 1channel ch1: restore complete, elapsed time: 00:00:25Finished restore at 2014-05-23 20:24:48...database openedFinished Duplicate Db at 2014-05-23 20:25:20SQL&gt; select dbid,name,open_mode,activation#,created from v$database; DBID NAME OPEN_MODE ACTIVATION# CREATED---------- --------- -------------------- ----------- ------------------- 219153832 DUP READ WRITE 219158696 2014-05-23 20:25:12 在同等条件下，基于备份的duplicate只需要3分钟左右，而Active的duplicate则需要30分钟。 6. 总结 对于日志文件及数据文件的重命名方式，如果在spfile中同时指定LOGFILE和LOG_FILE_NAME_CONVERT，rman会使用LOGFILE。如果两者都不指定，那么，rman使用源数据库相同的路径。 Table 1-1 Order of Precedence for Redo Log Filename Creation .tg {border-collapse:collapse;border-spacing:0;border-color:#999;} .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#999;color:#444;background-color:#F7FDFA;} .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#999;color:#fff;background-color:#26ADE4;} Order Method Result 1 Specify the LOGFILE clause of DUPLICATE command. Creates redo logs as specified. 2 Set LOG_FILE_NAME_CONVERT initialization parameter. Transforms target filenames, for example, from log_* to duplog_*. Note that you can specify multiple conversion pairs. This parameter allows the redo log to exist as long as the size matches, because it uses the REUSE parameter when creating the logs. 3 Do none of the preceding steps. Makes the duplicate filenames the same as the target filenames. You must specify the NOFILENAMECHECK option when using this method and the duplicate database should be in a different host. Table 1-2 Order of Precedence for Datafile Filename Creation .tg {border-collapse:collapse;border-spacing:0;border-color:#999;} .tg td{font-family:Arial, sans-serif;font-size:14px;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#999;color:#444;background-color:#F7FDFA;} .tg th{font-family:Arial, sans-serif;font-size:14px;font-weight:normal;padding:10px 5px;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#999;color:#fff;background-color:#26ADE4;} Order Method Result 1 Issue SET NEWNAME command. Creates new datafile filenames. You must reissue this command each time you rename files. 2 Issue CONFIGURE AUXNAME command. Creates new datafile filenames. This setting stays in effect until disabled with a CONFIGURE AUXNAME ... CLEAR command. 3 Set DB_FILE_NAME_CONVERT initialization parameter. Transforms target filenames, for example, from /oracle/ to /dup/oracle/. Note that you can specify multiple conversion pairs. You can use this parameter for those files not renamed with either SET NEWNAME and CONFIGURE AUXNAME. 4 Do none of the preceding steps.,Reuses the target filenames. You must specify the NOFILENAMECHECK option when using this method and the duplicate database should be in a different host. 以上优先顺序决定了rman命名日志文件及数据文件的方法。如果你使用了以上所有的方法，那么rman只会使用到SET NEWNAME，如果同时使用CONFIGURE AUXNAME和DB_FILE_NAME_CONVERT，rman会以CONFIGURE AUXNAME优先。如果不使用以上所有的方法，rman将会使用跟源数据库一致的命名。 7. 其他 对于set newname可用如下语句进行转换，之后再用vi或者其他工具进行路径的替换。 12select &apos;set newname for tempfile &apos;||file_id||&apos; to &apos;&apos;&apos;||&apos;+DATA&apos;||&apos;&apos;&apos;;&apos; from dba_temp_files;select &apos;set newname for datafile &apos;||file# || &apos; to &apos; ||&apos;&apos;&apos;&apos;|| name ||&apos;&apos;&apos;;&apos; from v$datafile 8. 补充 active database duplication是11g新特性，在之前的版本中，对于duplicate动作都是要基于RMAN备份，而11g以后的版本提供了active database duplication，即不用源数据库的备份可以直接在线duplicate，包括DataGuard的创建。duplicate的数据库具有不同的DBID，如果使用catalog database，那么dup库和源库是可以在同一个catalog DB注册的。在duplicate过程中，可以去除一些表空间，如只读表空间。 8.1 Renaming Files in a Duplicate Database 11g还提供了parameter_value_convert参数，这个参数可以让DBA跳过手动创建密码文件和SPFILE的过程，通过指定SPFILE和set命令及parameter_value_convert参数结合，自动完成spfile的创建。在这之前，auxiliary instance只需要从pfile启动，且pfile内容仅仅包含DB_NAME即可。如： 12345DUPLICATE target DATABASE TO DUP FROM ACTIVE DATABASEDB_FILE_NAME_CONVERT &apos;/oracle/oradata/orcl/&apos;,&apos;/dup/&apos;SPFILE PARAMETER_VALUE_CONVERT &apos;/oracle/oradata/orcl/&apos;,&apos;/dup/&apos;SET LOG_FILE_NAME_CONVERT &apos;/oracle/oradata/orcl/&apos;,&apos;/dup/&apos;; 这些命令很方便就能帮你设置好spfile，同时，在正常的alter system set...scope=spfile中，你能都将相关的参数添加到duplicate里面去。对于ADR目录，PARAMETER_VALUE_CONVERT会当相应的ADR目录创建需要转换的目录，但对于数据文件和日志文件不能使用PARAMETER_VALUE_CONVERT参数进行转换。 123456789[oracle@linora:/home/oracle]$ rman target sys/oracle@linora \\&gt; auxiliary sys/oracle@dupRMAN&gt; DUPLICATE target DATABASE TO dup FROM ACTIVE DATABASE2&gt; SPFILE3&gt; PARAMETER_VALUE_CONVERT &apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;4&gt; SET SGA_MAX_SIZE = &apos;500M&apos;5&gt; SET SGA_TARGET = &apos;500M&apos;6&gt; SET LOG_FILE_NAME_CONVERT=&apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;7&gt; DB_FILE_NAME_CONVERT=&apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;; 在输出脚本中，可以看到duplicate一开始会先执行clone spfile的动作，后续的set命令是通过alter system set...scope=spfile去执行的。SPFILE子句表示在打开数据库之前还原和修改SPFILE。 1234567891011121314contents of Memory Script:&#123; backup as copy reuse targetfile &apos;/u01/app/oracle/product/11gr2/dbs/spfilelinora.ora&apos; auxiliary format &apos;/u01/app/oracle/product/11gr2/dbs/spfiledup.ora&apos; ; sql clone &quot;alter system set spfile= &apos;&apos;/u01/app/oracle/product/11gr2/dbs/spfiledup.ora&apos;&apos;&quot;;&#125;...sql statement: alter system set db_name = &apos;&apos;DUP&apos;&apos; comment= &apos;&apos;duplicate&apos;&apos; scope=spfilesql statement: alter system set control_files = &apos;&apos;/dup/control01.ctl&apos;&apos;, &apos;&apos;/dup/control02.ctl&apos;&apos; comment= &apos;&apos;&apos;&apos; scope=spfilesql statement: alter system set SGA_MAX_SIZE = 250M comment= &apos;&apos;&apos;&apos; scope=spfilesql statement: alter system set SGA_TARGET = 250M comment= &apos;&apos;&apos;&apos; scope=spfilesql statement: alter system set log_archive_dest_1 = &apos;&apos;LOCATION=/dup/arch/&apos;&apos; comment= &apos;&apos;&apos;&apos; scope=spfilesql statement: alter system set LOG_FILE_NAME_CONVERT = &apos;&apos;/oradata/datafile/linora/&apos;&apos;, &apos;&apos;/dup/&apos;&apos; comment= &apos;&apos;&apos;&apos; scope=spfile 使用SPFILE创建Active Standby，多加一个db_unique_name参数即可。 123456789DUPLICATE TARGET DATABASE FOR STANDBY FROM ACTIVE DATABASESPFILEPARAMETER_VALUE_CONVERT &apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;SET &quot;DB_UNIQUE_NAME&quot;=&quot;stdby&quot;SET SGA_MAX_SIZE = &apos;250M&apos;SET SGA_TARGET = &apos;250M&apos;SET log_archive_dest_1 = &apos;LOCATION=/dup/arch/&apos;SET LOG_FILE_NAME_CONVERT=&apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;DB_FILE_NAME_CONVERT=&apos;/oradata/datafile/linora/&apos;,&apos;/dup/&apos;; 8.2 Backup-base and active database duplication backup-base 如果不是使用远程Client操作auxiliary instance，或者不是使用active duplication，则auxiliary instance可以不需要密码文件 源数据库可以是CLOSED或者OPEN状态 源端和dup端操作系统版本需一致，但32bit和64bit认为是一致，只是从32bit到64bit duplicate完成后需要执行@?/rdbms/admin/utlrp.sql脚本 如果在duplicate database中指定password file子句，会将源端密码文件copy至dup端，且会强行覆盖dup原有密码文件 active database duplication 源端和dup端都需要在Oracle NET中注册，意味着rman连接auxiliary instance必须使用net service name 源端数据库必须为open或者mounted状态 如果源端为mounted状态，那么在关闭前一定是干净的关闭 源端如果为open状态，那么，一定要运行在archivelog模式下 More details in: Oracle® Database Backup and Recovery User's Guide 11g Release 2 (11.2)","link":"/duplicate-database-with-rman.html"},{"title":"Oracle Enterprise Management failed with locale failed","text":"1.SYMPTOMS调用emctl发生以下错误：12345678910scc:oracle $emctl status dbconsoleperl: warning: Setting locale failed.perl: warning: Please check that your locale settings: LC_ALL = (unset), LC__FASTMSG = &quot;true&quot;, LC_MESSAGES = &quot;&quot;, LANG = &quot;en_UN&quot; are supported and installed on your system.perl: warning: Falling back to the standard locale (&quot;C&quot;).OC4J Configuration issue. /u01/app/oracle/db_1/oc4j/j2ee/OC4J_DBConsole_scc_qffh not found. 2.CAUSE跟用户环境变量lang设置有关，这个变量设置不正确导致。oracle用户环境变量中：export NLS_LANG=American_America.ZHS16GBK ，怀疑OS没安装中文包。 3.SOLUTIONexoport LC_ALL=C&quot;C&quot;是指 US7ASCII，这意味着仅可显示 a-z、A-Z 和 0-9。注意上述报错，OC4J Configuration issue. /u01/app/oracle/db_1/oc4j/j2ee/OC4J_DBConsole_scc_qffh not found.，怀疑修改过主机名或者IP。通过emca重新创建EM：12emca -deconfig dbcontrol db -repos dropemca -config dbcontrol db -repos create create的时候又报错：12SEVERE: Failed to allocate port(s) in the specified range(s) for the following process(es): JMS [5540-5559],RMI [5520-5539],Database Control [5500-5519],EM Agent [3938] | [1830-1849]Refer to the log file at /u01/app/oracle/db_1/cfgtoollogs/emca/qffh/emca_2014-04-28_04-50-05-PM.log for more details. 通过指定端口，终于重新创建EM，并且能登录管理：1emca -config dbcontrol db -repos create -DBCONTROL_HTTP_PORT 5508 -AGENT_PORT 3940 -RMI_PORT 5524 -JMS_PORT 5545 4.EXPLANATION对于Linux/UNIX下locale的解析：在linux/UNIX上Locales用来定义用户所使用的语言。因为locales还定义了用户使用的字符集，所以，当语言中含有非ASCIIA字符时，设定好正确的locale就显得非常重要了。Locales是用以下的格式来定义的：1&lt;lang&gt;_&lt;territory&gt;.&lt;codeset&gt;[@&lt;modifiers&gt;] 要查看当前设置，请使用 “locale” 命令，如下所示：$ locale输出示例：123456789101112131415[root@oel1:/root]# localeLANG=en_US.UTF-8LC_CTYPE=&quot;en_US.UTF-8&quot;LC_NUMERIC=&quot;en_US.UTF-8&quot;LC_TIME=&quot;en_US.UTF-8&quot;LC_COLLATE=&quot;en_US.UTF-8&quot;LC_MONETARY=&quot;en_US.UTF-8&quot;LC_MESSAGES=&quot;en_US.UTF-8&quot;LC_PAPER=&quot;en_US.UTF-8&quot;LC_NAME=&quot;en_US.UTF-8&quot;LC_ADDRESS=&quot;en_US.UTF-8&quot;LC_TELEPHONE=&quot;en_US.UTF-8&quot;LC_MEASUREMENT=&quot;en_US.UTF-8&quot;LC_IDENTIFICATION=&quot;en_US.UTF-8&quot;LC_ALL= Oracle建议，local尽量使用uft-8。如果要查看所有安装了的locale，可以-a的参数，以下为部分输出：1234567891011121314151617[root@oel1:/root]# locale -azh_CNzh_CN.gb18030zh_CN.gb2312zh_CN.gbkzh_CN.utf8zh_HKzh_HK.big5hkscszh_HK.utf8zh_SGzh_SG.gb2312zh_SG.gbkzh_SG.utf8zh_TWzh_TW.big5zh_TW.euctwzh_TW.utf8 针对环境变量 NLS_LANG :NLS_LANG 的构成为：NLS_LANG=&lt;NLS_LANGUAGE&gt;_&lt;NLS_TERRITORY&gt;.以 locale &quot;en_US.UTF-8&quot;为例，这意味着应该将 NLS_LANG 设置为 =AMERICAN_AMERICA.AL32UTF8；如果 locale 设置为fr_FR.UTF-8，则相应的 NLS_LANG 设置将为 FRENCH_FRANCE.AL32UTF8。Locale 和 NLS_LANG 设置（如果适用，还包括 telnet/ssh config）需要互相匹配，但从技术角度看它们均与数据库字符集无关，并且它们仅针对该客户端环境相关。参照：International Language Environment Guide1548858.11602518.1","link":"/em-locale-failed.html"},{"title":"Linux Find Command","text":"Find在Linux/UNIX中，通过指定某个或者多个目录查找符合执行条件的文件，显示文件名或对这些文件进行特定的操作。 表达式 参数 含义 -type f/d 查找目标的类型(文件/目录) -size +n/-n/n 文件大小超过/小于/等于n blocks -mtime +/-x x天以前/x天以内被修改的文件 -perm mode 访问指定权限的文件(rwx) -user User 属于用户user的文件 -o 逻辑&#39;or&#39; 1.查找文件名为oracle的文件，并打印在屏幕上123456789101112# ls -l /oracletotal 2580304-rw-r----- 1 root system 1321110528 May 16 18:30 10gr2_aix5l64_database.cpiodrwxrwxr-x 4 oracle oinstall 256 May 16 17:19 appdrwxrwxr-x 2 oracle oinstall 256 May 16 14:45 lost+found-rw-r--r-- 1 root system 0 May 19 19:03 oracle# find / -type f -name oracle -print/oracle/oracle# find / -type d -name oracle -print/home/oracle/oracle/oracle/app/oracle 2.查找名为oracle的东西，且通过ls -l展示出来12345678910111213# find / -name &quot;oracle&quot; -exec ls -l &#123;&#125; \\;total 16drwxr-xr-x 3 oracle oinstall 256 May 16 17:19 .java-rwxr----- 1 oracle oinstall 857 May 16 18:15 .profile-rw------- 1 oracle oinstall 794 May 16 18:15 .sh_historytotal 2580304-rw-r----- 1 root system 1321110528 May 16 18:30 10gr2_aix5l64_database.cpiodrwxrwxr-x 4 oracle oinstall 256 May 16 17:19 appdrwxrwxr-x 2 oracle oinstall 256 May 16 14:45 lost+found-rw-r--r-- 1 root system 0 May 19 19:03 oracletotal 0drwxrwxr-x 4 oracle oinstall 256 May 16 18:15 product-rw-r--r-- 1 root system 0 May 19 19:03 /oracle/oracle 注意在例1中，以oracle为名的有三个目录，因此，例2中是列出了三个目录下的内容。1234567891011121314# ls -l /home/oracletotal 16drwxr-xr-x 3 oracle oinstall 256 May 16 17:19 .java-rwxr----- 1 oracle oinstall 857 May 16 18:15 .profile-rw------- 1 oracle oinstall 794 May 16 18:15 .sh_history# ls -l /oracletotal 2580304-rw-r----- 1 root system 1321110528 May 16 18:30 10gr2_aix5l64_database.cpiodrwxrwxr-x 4 oracle oinstall 256 May 16 17:19 appdrwxrwxr-x 2 oracle oinstall 256 May 16 14:45 lost+found-rw-r--r-- 1 root system 0 May 19 19:03 oracle# ls -l /oracle/app/oracletotal 0drwxrwxr-x 4 oracle oinstall 256 May 16 18:15 product 3.查找权限为777，且修改时间为四天内的文件12# find . -perm 777 -mtime -4 -print./oracle 4.删除N天前的文件1find . -type f -mtime +14 -exec rm -f &#123;&#125; \\; 将exec换成ok，表示每删除一次确定一次，以防止误操作。1find . -type f -mtime +14 -ok rm -f &#123;&#125; \\; 5.删除7天前所有名为a.out或者*.o的文件，且这些文件不是以nfs形式挂载的1find / \\( -name a.out -o -name &apos;*.o&apos; \\) -atime +7 ! -fstype nfs -exec rm -rf &#123;&#125; \\; 6.查找当前目录下，以&quot;*.trc&quot;结尾，且文件内容含有&quot;error&quot;字样的行，打印出来123# find ./ -name &quot;*.trc&quot; -exec grep -i &quot;error&quot; &apos;&#123;&#125;&apos; \\; -printerror: &quot;OUT_CFS_LINK &quot; exit=$D1 error=$D2 svp=$D3 tdvp=$D4 name=$D5./alter.trc 7.查找5个最大/最小的文件123456789101112# find . -type f -exec ls -s &#123;&#125; \\; | sort -n -r | head -51290152 ./10gr2_aix5l64_database.cpio114656 ./Disk1/stage/Components/oracle.rsf.hybrid/10.2.0.0.0/1/DataFiles/group.jar94456 ./Disk1/stage/Components/oracle.rsf.hybrid/10.2.0.0.0/1/DataFiles/group_new.jar93168 ./Disk1/stage/Components/oracle.rdbms.install.seeddb/10.2.0.1.0/1//Seed_Database.dfb44868 ./Disk1/stage/Components/oracle.sysman.console.db/10.2.0.1.0/1/DataFiles/filegroup8.jar# find . -type f -exec ls -s &#123;&#125; \\; | sort -n | head -5 0 ./oracle 4 ./Disk1/doc/dcommon/gifs/bookbig.gif 4 ./Disk1/doc/dcommon/gifs/bookicon.gif 4 ./Disk1/doc/dcommon/gifs/booklist.gif 4 ./Disk1/doc/dcommon/gifs/contbig.gif 对于windows server而言，Windows 2003 R2 SP2以上的版本中，自带有forfiles命令，功能跟find类型，目前win7也有带这个工具，forfiles的用法如下：在win2003 server有forfiles.exe命令刪除n天前的文件：1234567891011C:\\WINDOWS\\system32\\forfiles /P E:\\logbak\\ /S /M *.gz /D -8 /C &quot;cmd /c del @file&quot;FORFILES [/P pathname] [/M searchmask] [/S] [/C command] [/D [+ | -] &#123;yyyy-MM-dd | dd&#125;]/P pathname表示開始搜索的路徑，deault為當前目錄/M serchmask 根據搜索掩碼搜索文件/S 指導forfiles遞歸到子目錄/C command表示為每個file執行的命令，命令字符串應該用雙引號括起來/D date 選擇文件，其上一次時間大于或扽gui(+)，或者小于或等于(—)，用&quot;yyyy-MM-dd&quot;格式指定的日期； 或者選擇文件，其上一次修改日期大于或等于(+)當前日期加&quot;dd&quot;天，或者小于等于(-)當前日期減&quot;dd&quot;天 默認命令是&quot;cmd /c echo @file&quot;，以下變量可以用在命令字符串中： @file --返回文件名 @fname --返回不帶擴展名的文件名 find命令好像不能删除某段时间的问题，比如删除2012年的文件，可以尝试用如下脚本： 1234for filename in /home/oracle/other/*;do if [ `date -r $filename +%Y` == &quot;2012&quot; ]then rm -f $filenamefi done","link":"/find-command.html"},{"title":"如何获得SQL的执行计划","text":"Oracle中的执行计划显示在执行一条SQL语句时必须执行的详细步骤，通常以表格形式呈现，但其实是树形结构。查看Oracle中的执行计划一般有以下几种方法(包括但不限于)。 1. explain planexplain plan只显示一条SQL的执行计划，但不会真正去执行它。当使用此命令生成执行计划后，还需要调用dbms_xplan包去查看相关内容。在TOAD或者PL/SQL Developer查看的执行计划，其实也就是explain plan的变体，因此，有可能是不准确的执行计划。123456789101112131415161718192021222324252627SH@linora&gt; explain plan for 2 SELECT /*+ gather_plan_statistics */ --显示统计信息，相当于开启参数statistics_level=all; 3 p.prod_name as product, sum(s.quantity_sold) as units 4 FROM sales s, products p 5 WHERE s.prod_id =p.prod_id 6 GROUP BY p.prod_name;Explained.SH@linora&gt; select * from table(dbms_xplan.display());PLAN_TABLE_OUTPUT----------------------------------------------------------------------------------------------Plan hash value: 504757596----------------------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | Pstart| Pstop |----------------------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 71 | 3337 | 589 (12)| 00:00:08 | | || 1 | HASH GROUP BY | | 71 | 3337 | 589 (12)| 00:00:08 | | ||* 2 | HASH JOIN | | 72 | 3384 | 588 (12)| 00:00:08 | | || 3 | VIEW | VW_GBC_5 | 72 | 1224 | 585 (12)| 00:00:08 | | || 4 | HASH GROUP BY | | 72 | 504 | 585 (12)| 00:00:08 | | || 5 | PARTITION RANGE ALL| | 918K| 6281K| 533 (3)| 00:00:07 | 1 | 28 || 6 | TABLE ACCESS FULL | SALES | 918K| 6281K| 533 (3)| 00:00:07 | 1 | 28 || 7 | TABLE ACCESS FULL | PRODUCTS | 72 | 2160 | 3 (0)| 00:00:01 | | |----------------------------------------------------------------------------------------------------Predicate Information (identified by operation id):--------------------------------------------------- 2 - access(&quot;ITEM_1&quot;=&quot;P&quot;.&quot;PROD_ID&quot;)19 rows selected. explain plan其实是将Oracle所产生的执行计划步骤写入PLAN_TABLE$，此表是一个全局临时表，因此，各个session只能看到自己执行的SQL所产生的执行计划。12345678910111213141516171819202122232425262728293031323334353637383940414243SYS@linora&gt; set long 9999SYS@linora&gt; set pagesize 9999SYS@linora&gt; select dbms_metadata.get_ddl(&apos;TABLE&apos;,&apos;PLAN_TABLE$&apos;,&apos;SYS&apos;) from dual;DBMS_METADATA.GET_DDL(&apos;TABLE&apos;,&apos;PLAN_TABLE$&apos;,&apos;SYS&apos;)-------------------------------------------------------------------------------- CREATE GLOBAL TEMPORARY TABLE &quot;SYS&quot;.&quot;PLAN_TABLE$&quot; ( &quot;STATEMENT_ID&quot; VARCHAR2(30), &quot;PLAN_ID&quot; NUMBER, &quot;TIMESTAMP&quot; DATE, &quot;REMARKS&quot; VARCHAR2(4000), &quot;OPERATION&quot; VARCHAR2(30), &quot;OPTIONS&quot; VARCHAR2(255), &quot;OBJECT_NODE&quot; VARCHAR2(128), &quot;OBJECT_OWNER&quot; VARCHAR2(30), &quot;OBJECT_NAME&quot; VARCHAR2(30), &quot;OBJECT_ALIAS&quot; VARCHAR2(65), &quot;OBJECT_INSTANCE&quot; NUMBER(*,0), &quot;OBJECT_TYPE&quot; VARCHAR2(30), &quot;OPTIMIZER&quot; VARCHAR2(255), &quot;SEARCH_COLUMNS&quot; NUMBER, &quot;ID&quot; NUMBER(*,0), &quot;PARENT_ID&quot; NUMBER(*,0), &quot;DEPTH&quot; NUMBER(*,0), &quot;POSITION&quot; NUMBER(*,0), &quot;COST&quot; NUMBER(*,0), &quot;CARDINALITY&quot; NUMBER(*,0), &quot;BYTES&quot; NUMBER(*,0), &quot;OTHER_TAG&quot; VARCHAR2(255), &quot;PARTITION_START&quot; VARCHAR2(255), &quot;PARTITION_STOP&quot; VARCHAR2(255), &quot;PARTITION_ID&quot; NUMBER(*,0), &quot;OTHER&quot; LONG, &quot;OTHER_XML&quot; CLOB, &quot;DISTRIBUTION&quot; VARCHAR2(30), &quot;CPU_COST&quot; NUMBER(*,0), &quot;IO_COST&quot; NUMBER(*,0), &quot;TEMP_SPACE&quot; NUMBER(*,0), &quot;ACCESS_PREDICATES&quot; VARCHAR2(4000), &quot;FILTER_PREDICATES&quot; VARCHAR2(4000), &quot;PROJECTION&quot; VARCHAR2(4000), &quot;TIME&quot; NUMBER(*,0), &quot;QBLOCK_NAME&quot; VARCHAR2(30) ) ON COMMIT PRESERVE ROWS 2. dbms_xplandbms_xplan有好几种调用方法，以下仅列出常用的三种方法(后面两种适合数据库在10g及以上的版本)： display--输出plan table内容 display_cursor--用于显示内存中的SQL执行计划 display_awr--输出AWR中的历史SQL执行计划 2.1 DISPLAY语法：12345DBMS_XPLAN.DISPLAY( table_name IN VARCHAR2 DEFAULT &apos;PLAN_TABLE&apos;, statement_id IN VARCHAR2 DEFAULT NULL, format IN VARCHAR2 DEFAULT &apos;TYPICAL&apos;, filter_preds IN VARCHAR2 DEFAULT NULL); 不加任何参数：123456789101112131415161718192021222324SCOTT@linora&gt; EXPLAIN PLAN FOR 2 SELECT * FROM emp e, dept d 3 WHERE e.deptno = d.deptno 4 AND e.ename=&apos;benoit&apos;;Explained.SCOTT@linora&gt; SET LINESIZE 130SCOTT@linora&gt; SET PAGESIZE 0SCOTT@linora&gt; SELECT * FROM table(DBMS_XPLAN.DISPLAY);Plan hash value: 3625962092----------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |----------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 1 | 58 | 4 (0)| 00:00:01 || 1 | NESTED LOOPS | | 1 | 58 | 4 (0)| 00:00:01 || 2 | NESTED LOOPS | | 1 | 58 | 4 (0)| 00:00:01 ||* 3 | TABLE ACCESS FULL | EMP | 1 | 38 | 3 (0)| 00:00:01 ||* 4 | INDEX UNIQUE SCAN | PK_DEPT | 1 | | 0 (0)| 00:00:01 || 5 | TABLE ACCESS BY INDEX ROWID| DEPT | 1 | 20 | 1 (0)| 00:00:01 |----------------------------------------------------------------------------------------Predicate Information (identified by operation id):--------------------------------------------------- 3 - filter(&quot;E&quot;.&quot;ENAME&quot;=&apos;benoit&apos;) 4 - access(&quot;E&quot;.&quot;DEPTNO&quot;=&quot;D&quot;.&quot;DEPTNO&quot;)18 rows selected. 添加ADVANCED参数(显示所有信息)：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354SCOTT@linora&gt; SELECT * FROM table(DBMS_XPLAN.DISPLAY(&apos;&apos;,&apos;&apos;,&apos;ADVANCED&apos;));Plan hash value: 3625962092----------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |----------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 1 | 58 | 4 (0)| 00:00:01 || 1 | NESTED LOOPS | | 1 | 58 | 4 (0)| 00:00:01 || 2 | NESTED LOOPS | | 1 | 58 | 4 (0)| 00:00:01 ||* 3 | TABLE ACCESS FULL | EMP | 1 | 38 | 3 (0)| 00:00:01 ||* 4 | INDEX UNIQUE SCAN | PK_DEPT | 1 | | 0 (0)| 00:00:01 || 5 | TABLE ACCESS BY INDEX ROWID| DEPT | 1 | 20 | 1 (0)| 00:00:01 |----------------------------------------------------------------------------------------Query Block Name / Object Alias (identified by operation id):------------------------------------------------------------- 1 - SEL$1 3 - SEL$1 / E@SEL$1 4 - SEL$1 / D@SEL$1 5 - SEL$1 / D@SEL$1Outline Data------------- /*+ BEGIN_OUTLINE_DATA NLJ_BATCHING(@&quot;SEL$1&quot; &quot;D&quot;@&quot;SEL$1&quot;) USE_NL(@&quot;SEL$1&quot; &quot;D&quot;@&quot;SEL$1&quot;) LEADING(@&quot;SEL$1&quot; &quot;E&quot;@&quot;SEL$1&quot; &quot;D&quot;@&quot;SEL$1&quot;) INDEX(@&quot;SEL$1&quot; &quot;D&quot;@&quot;SEL$1&quot; (&quot;DEPT&quot;.&quot;DEPTNO&quot;)) FULL(@&quot;SEL$1&quot; &quot;E&quot;@&quot;SEL$1&quot;) OUTLINE_LEAF(@&quot;SEL$1&quot;) ALL_ROWS DB_VERSION(&apos;11.2.0.4&apos;) OPTIMIZER_FEATURES_ENABLE(&apos;11.2.0.4&apos;) IGNORE_OPTIM_EMBEDDED_HINTS END_OUTLINE_DATA */Predicate Information (identified by operation id):--------------------------------------------------- 3 - filter(&quot;E&quot;.&quot;ENAME&quot;=&apos;benoit&apos;) 4 - access(&quot;E&quot;.&quot;DEPTNO&quot;=&quot;D&quot;.&quot;DEPTNO&quot;)Column Projection Information (identified by operation id):----------------------------------------------------------- 1 - (#keys=0) &quot;E&quot;.&quot;EMPNO&quot;[NUMBER,22], &quot;E&quot;.&quot;ENAME&quot;[VARCHAR2,10], &quot;E&quot;.&quot;JOB&quot;[VARCHAR2,9], &quot;E&quot;.&quot;MGR&quot;[NUMBER,22], &quot;E&quot;.&quot;HIREDATE&quot;[DATE,7], &quot;E&quot;.&quot;SAL&quot;[NUMBER,22], &quot;E&quot;.&quot;COMM&quot;[NUMBER,22], &quot;E&quot;.&quot;DEPTNO&quot;[NUMBER,22], &quot;D&quot;.&quot;DEPTNO&quot;[NUMBER,22], &quot;D&quot;.&quot;DNAME&quot;[VARCHAR2,14], &quot;D&quot;.&quot;LOC&quot;[VARCHAR2,13] 2 - (#keys=0) &quot;E&quot;.&quot;EMPNO&quot;[NUMBER,22], &quot;E&quot;.&quot;ENAME&quot;[VARCHAR2,10], &quot;E&quot;.&quot;JOB&quot;[VARCHAR2,9], &quot;E&quot;.&quot;MGR&quot;[NUMBER,22], &quot;E&quot;.&quot;HIREDATE&quot;[DATE,7], &quot;E&quot;.&quot;SAL&quot;[NUMBER,22], &quot;E&quot;.&quot;COMM&quot;[NUMBER,22], &quot;E&quot;.&quot;DEPTNO&quot;[NUMBER,22], &quot;D&quot;.ROWID[ROWID,10], &quot;D&quot;.&quot;DEPTNO&quot;[NUMBER,22] 3 - &quot;E&quot;.&quot;EMPNO&quot;[NUMBER,22], &quot;E&quot;.&quot;ENAME&quot;[VARCHAR2,10], &quot;E&quot;.&quot;JOB&quot;[VARCHAR2,9], &quot;E&quot;.&quot;MGR&quot;[NUMBER,22], &quot;E&quot;.&quot;HIREDATE&quot;[DATE,7], &quot;E&quot;.&quot;SAL&quot;[NUMBER,22], &quot;E&quot;.&quot;COMM&quot;[NUMBER,22], &quot;E&quot;.&quot;DEPTNO&quot;[NUMBER,22] 4 - &quot;D&quot;.ROWID[ROWID,10], &quot;D&quot;.&quot;DEPTNO&quot;[NUMBER,22] 5 - &quot;D&quot;.&quot;DNAME&quot;[VARCHAR2,14], &quot;D&quot;.&quot;LOC&quot;[VARCHAR2,13]61 rows selected. DISPLAY仅仅针对预估的执行计划，而不是真实的执行计划，尤其当SQL语句包含绑定变量时。 2.2 DISPLAY_CURSOR语法：1234DBMS_XPLAN.DISPLAY_CURSOR( sql_id IN VARCHAR2 DEFAULT NULL, child_number IN NUMBER DEFAULT NULL, format IN VARCHAR2 DEFAULT &apos;TYPICAL&apos;); DISPLAY_CURSOR是显示内存中的执行计划，只要目标SQL的执行计划所在的child cursor还在shared pool中，就可以使用display_cursor来查看：123456789SCOTT@linora&gt; SELECT /*+ display_cursor_example */ * FROM emp e, dept d 2 WHERE e.deptno = d.deptno 3 AND e.ename=&apos;SCOTT&apos;;SCOTT@linora&gt; select sql_text,sql_id,hash_value,child_number from v$sql 2 where sql_text like &apos;SELECT /*+ display_cursor_example */%&apos;;SQL_TEXT SQL_ID HASH_VALUE CHILD_NUMBER------------------------------------------------------------ ------------- ---------- ------------SELECT /*+ display_cursor_example */ * FROM emp e, dept d WH 7p8g08wnrjn43 695783555 0ERE e.deptno = d.deptno AND e.ename=&apos;SCOTT&apos; 查看此语句的执行计划：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364SCOTT@linora&gt; set pagesize 9999SCOTT@linora&gt; col PLAN_TABLE_OUTPUT for a100SCOTT@linora&gt; select * from table(dbms_xplan.display_cursor(&apos;7p8g08wnrjn43&apos;,&apos;0&apos;,&apos;advanced&apos;));PLAN_TABLE_OUTPUT----------------------------------------------------------------------------------------------------SQL_ID 7p8g08wnrjn43, child number 0-------------------------------------SELECT /*+ display_cursor_example */ * FROM emp e, dept d WHEREe.deptno = d.deptno AND e.ename=&apos;SCOTT&apos;Plan hash value: 3625962092----------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |----------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | | | 4 (100)| || 1 | NESTED LOOPS | | 1 | 58 | 4 (0)| 00:00:01 || 2 | NESTED LOOPS | | 1 | 58 | 4 (0)| 00:00:01 ||* 3 | TABLE ACCESS FULL | EMP | 1 | 38 | 3 (0)| 00:00:01 ||* 4 | INDEX UNIQUE SCAN | PK_DEPT | 1 | | 0 (0)| || 5 | TABLE ACCESS BY INDEX ROWID| DEPT | 1 | 20 | 1 (0)| 00:00:01 |----------------------------------------------------------------------------------------Query Block Name / Object Alias (identified by operation id):------------------------------------------------------------- 1 - SEL$1 3 - SEL$1 / E@SEL$1 4 - SEL$1 / D@SEL$1 5 - SEL$1 / D@SEL$1Outline Data------------ /*+ BEGIN_OUTLINE_DATA IGNORE_OPTIM_EMBEDDED_HINTS OPTIMIZER_FEATURES_ENABLE(&apos;11.2.0.4&apos;) DB_VERSION(&apos;11.2.0.4&apos;) ALL_ROWS OUTLINE_LEAF(@&quot;SEL$1&quot;) FULL(@&quot;SEL$1&quot; &quot;E&quot;@&quot;SEL$1&quot;) INDEX(@&quot;SEL$1&quot; &quot;D&quot;@&quot;SEL$1&quot; (&quot;DEPT&quot;.&quot;DEPTNO&quot;)) LEADING(@&quot;SEL$1&quot; &quot;E&quot;@&quot;SEL$1&quot; &quot;D&quot;@&quot;SEL$1&quot;) USE_NL(@&quot;SEL$1&quot; &quot;D&quot;@&quot;SEL$1&quot;) NLJ_BATCHING(@&quot;SEL$1&quot; &quot;D&quot;@&quot;SEL$1&quot;) END_OUTLINE_DATA */Predicate Information (identified by operation id):--------------------------------------------------- 3 - filter(&quot;E&quot;.&quot;ENAME&quot;=&apos;SCOTT&apos;) 4 - access(&quot;E&quot;.&quot;DEPTNO&quot;=&quot;D&quot;.&quot;DEPTNO&quot;)Column Projection Information (identified by operation id):----------------------------------------------------------- 1 - &quot;E&quot;.&quot;EMPNO&quot;[NUMBER,22], &quot;E&quot;.&quot;ENAME&quot;[VARCHAR2,10], &quot;E&quot;.&quot;JOB&quot;[VARCHAR2,9], &quot;E&quot;.&quot;MGR&quot;[NUMBER,22], &quot;E&quot;.&quot;HIREDATE&quot;[DATE,7], &quot;E&quot;.&quot;SAL&quot;[NUMBER,22], &quot;E&quot;.&quot;COMM&quot;[NUMBER,22], &quot;E&quot;.&quot;DEPTNO&quot;[NUMBER,22], &quot;D&quot;.&quot;DEPTNO&quot;[NUMBER,22], &quot;D&quot;.&quot;DNAME&quot;[VARCHAR2,14], &quot;D&quot;.&quot;LOC&quot;[VARCHAR2,13] 2 - &quot;E&quot;.&quot;EMPNO&quot;[NUMBER,22], &quot;E&quot;.&quot;ENAME&quot;[VARCHAR2,10], &quot;E&quot;.&quot;JOB&quot;[VARCHAR2,9], &quot;E&quot;.&quot;MGR&quot;[NUMBER,22], &quot;E&quot;.&quot;HIREDATE&quot;[DATE,7], &quot;E&quot;.&quot;SAL&quot;[NUMBER,22], &quot;E&quot;.&quot;COMM&quot;[NUMBER,22], &quot;E&quot;.&quot;DEPTNO&quot;[NUMBER,22], &quot;D&quot;.ROWID[ROWID,10], &quot;D&quot;.&quot;DEPTNO&quot;[NUMBER,22] 3 - &quot;E&quot;.&quot;EMPNO&quot;[NUMBER,22], &quot;E&quot;.&quot;ENAME&quot;[VARCHAR2,10], &quot;E&quot;.&quot;JOB&quot;[VARCHAR2,9], &quot;E&quot;.&quot;MGR&quot;[NUMBER,22], &quot;E&quot;.&quot;HIREDATE&quot;[DATE,7], &quot;E&quot;.&quot;SAL&quot;[NUMBER,22], &quot;E&quot;.&quot;COMM&quot;[NUMBER,22], &quot;E&quot;.&quot;DEPTNO&quot;[NUMBER,22] 4 - &quot;D&quot;.ROWID[ROWID,10], &quot;D&quot;.&quot;DEPTNO&quot;[NUMBER,22] 5 - &quot;D&quot;.&quot;DNAME&quot;[VARCHAR2,14], &quot;D&quot;.&quot;LOC&quot;[VARCHAR2,13]67 rows selected. 如果display_cursor不添加前面两个参数，则表示查看刚刚执行过的SQL的执行计划。如：12SCOTT@linora&gt; SELECT * FROM emp e, dept d WHERE e.deptno = d.deptno;SCOTT@linora&gt; select * from table(dbms_xplan.display_cursor(&apos;&apos;,&apos;&apos;,&apos;advanced&apos;)); 2.3 DISPLAY_AWR语法：12345DBMS_XPLAN.DISPLAY_AWR( sql_id IN VARCHAR2, plan_hash_value IN NUMBER DEFAULT NULL, db_id IN NUMBER DEFAULT NULL, format IN VARCHAR2 DEFAULT TYPICAL); 如果某一条语句的执行计划已经从shared pool清除了，那么此时想要查看此SQL的执行计划，就只能从display_awr中查看了，通过display_awr获取的SQL执行计划来自dba_hist_sql_plan，但display_awr不能查看执行步骤中对应的谓词条件！1234567891011121314151617181920212223242526272829303132333435SCOTT@linora&gt; SELECT * FROM emp e, dept d WHERE e.deptno = d.deptno;SCOTT@linora&gt; select sql_text,sql_id,hash_value,child_number from v$sql 2 where sql_text like &apos;SELECT * FROM emp%&apos;;SQL_TEXT SQL_ID HASH_VALUE CHILD_NUMBER------------------------------------------------------------ ------------- ---------- ------------SELECT * FROM emp e, dept d WHERE e.deptno = d.deptno 8mfyh7m4tph6q 3461957154 0SCOTT@linora&gt; exec dbms_workload_repository.create_snapshot();PL/SQL procedure successfully completed.SCOTT@linora&gt; alter system flush shared_pool;System altered.SCOTT@linora&gt; select * from table(dbms_xplan.display_cursor(&apos;8mfyh7m4tph6q&apos;,&apos;0&apos;,&apos;advanced&apos;));PLAN_TABLE_OUTPUT----------------------------------------------------------------------------------------------------SQL_ID: 8mfyh7m4tph6q, child number: 0 cannot be foundSCOTT@linora&gt; select * from table(dbms_xplan.display_awr(&apos;8mfyh7m4tph6q&apos;));PLAN_TABLE_OUTPUT----------------------------------------------------------------------------------------------------SQL_ID 8mfyh7m4tph6q--------------------SELECT * FROM emp e, dept d WHERE e.deptno = d.deptnoPlan hash value: 844388907----------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |----------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | | | 6 (100)| || 1 | MERGE JOIN | | 14 | 812 | 6 (17)| 00:00:01 || 2 | TABLE ACCESS BY INDEX ROWID| DEPT | 4 | 80 | 2 (0)| 00:00:01 || 3 | INDEX FULL SCAN | PK_DEPT | 4 | | 1 (0)| 00:00:01 || 4 | SORT JOIN | | 14 | 532 | 4 (25)| 00:00:01 || 5 | TABLE ACCESS FULL | EMP | 14 | 532 | 3 (0)| 00:00:01 |---------------------------------------------------------------------------------------- 需要注意的是，如果某目标SQL的执行计划已经不在shared pool中了，SQL的执行计划已经被Oracle捕获并且存储到了AWR的Repository中，才可以使用display_awr，且版本是10g以上；如果是9i，则需要部署statspack，且采集的level必须大于6才可查看历史SQL的执行计划。 3. auto trace语法：12SCOTT@linora&gt; set autotrace -hUsage: SET AUTOT[RACE] &#123;OFF | ON | TRACE[ONLY]&#125; [EXP[LAIN]] [STAT[ISTICS]] set autot on/off在当前sessions完全打开/关闭autotrace，同时输出结果及执行计划和资源消耗123456789101112131415161718192021222324252627282930313233343536373839SCOTT@linora&gt; set autot onSCOTT@linora&gt; SELECT e.ename,e.job,e.sal,d.dname FROM emp e, dept d WHERE e.deptno = d.deptno and e.ename=&apos;SCOTT&apos;;ENAME JOB SAL DNAME---------- --------- ---------- --------------SCOTT ANALYST 3000 RESEARCHExecution Plan----------------------------------------------------------Plan hash value: 3625962092----------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |----------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 1 | 34 | 4 (0)| 00:00:01 || 1 | NESTED LOOPS | | 1 | 34 | 4 (0)| 00:00:01 || 2 | NESTED LOOPS | | 1 | 34 | 4 (0)| 00:00:01 ||* 3 | TABLE ACCESS FULL | EMP | 1 | 21 | 3 (0)| 00:00:01 ||* 4 | INDEX UNIQUE SCAN | PK_DEPT | 1 | | 0 (0)| 00:00:01 || 5 | TABLE ACCESS BY INDEX ROWID| DEPT | 1 | 13 | 1 (0)| 00:00:01 |----------------------------------------------------------------------------------------Predicate Information (identified by operation id):--------------------------------------------------- 3 - filter(&quot;E&quot;.&quot;ENAME&quot;=&apos;SCOTT&apos;) 4 - access(&quot;E&quot;.&quot;DEPTNO&quot;=&quot;D&quot;.&quot;DEPTNO&quot;)Statistics---------------------------------------------------------- 0 recursive calls 0 db block gets 9 consistent gets 0 physical reads 0 redo size 743 bytes sent via SQL*Net to client 519 bytes received via SQL*Net from client 2 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 1 rows processed set autot trace只输出目标SQL执行计划和资源消耗，对于SQL执行结果则只显示执行结果的数量12345678910111213141516171819202122232425262728293031323334SCOTT@linora&gt; set autot traceSCOTT@linora&gt; SELECT e.ename,e.job,e.sal,d.dname FROM emp e, dept d WHERE e.deptno = d.deptno and e.ename=&apos;SCOTT&apos;;Execution Plan----------------------------------------------------------Plan hash value: 3625962092----------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |----------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 1 | 34 | 4 (0)| 00:00:01 || 1 | NESTED LOOPS | | 1 | 34 | 4 (0)| 00:00:01 || 2 | NESTED LOOPS | | 1 | 34 | 4 (0)| 00:00:01 ||* 3 | TABLE ACCESS FULL | EMP | 1 | 21 | 3 (0)| 00:00:01 ||* 4 | INDEX UNIQUE SCAN | PK_DEPT | 1 | | 0 (0)| 00:00:01 || 5 | TABLE ACCESS BY INDEX ROWID| DEPT | 1 | 13 | 1 (0)| 00:00:01 |----------------------------------------------------------------------------------------Predicate Information (identified by operation id):--------------------------------------------------- 3 - filter(&quot;E&quot;.&quot;ENAME&quot;=&apos;SCOTT&apos;) 4 - access(&quot;E&quot;.&quot;DEPTNO&quot;=&quot;D&quot;.&quot;DEPTNO&quot;)Statistics---------------------------------------------------------- 0 recursive calls 0 db block gets 9 consistent gets 0 physical reads 0 redo size 743 bytes sent via SQL*Net to client 519 bytes received via SQL*Net from client 2 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 1 rows processed set autot trace exp只输出SQL执行计划，而不会显示目标SQL的执行结果和资源消耗123456789101112131415161718192021SCOTT@linora&gt; set autot trace expSCOTT@linora&gt; SELECT e.ename,e.job,e.sal,d.dname FROM emp e, dept d WHERE e.deptno = d.deptno and e.ename=&apos;SCOTT&apos;;Execution Plan----------------------------------------------------------Plan hash value: 3625962092----------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |----------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 1 | 34 | 4 (0)| 00:00:01 || 1 | NESTED LOOPS | | 1 | 34 | 4 (0)| 00:00:01 || 2 | NESTED LOOPS | | 1 | 34 | 4 (0)| 00:00:01 ||* 3 | TABLE ACCESS FULL | EMP | 1 | 21 | 3 (0)| 00:00:01 ||* 4 | INDEX UNIQUE SCAN | PK_DEPT | 1 | | 0 (0)| 00:00:01 || 5 | TABLE ACCESS BY INDEX ROWID| DEPT | 1 | 13 | 1 (0)| 00:00:01 |----------------------------------------------------------------------------------------Predicate Information (identified by operation id):--------------------------------------------------- 3 - filter(&quot;E&quot;.&quot;ENAME&quot;=&apos;SCOTT&apos;) 4 - access(&quot;E&quot;.&quot;DEPTNO&quot;=&quot;D&quot;.&quot;DEPTNO&quot;) set autot trace stat只输出SQL执行结果资源消耗，而不显示执行计划1234567891011121314151617SCOTT@linora&gt; set autot trace statSCOTT@linora&gt; SELECT e.ename,e.job,e.sal,d.dname FROM emp e, dept d WHERE e.deptno = d.deptno and e.ename=&apos;SCOTT&apos;;Statistics---------------------------------------------------------- 0 recursive calls 0 db block gets 9 consistent gets 0 physical reads 0 redo size 743 bytes sent via SQL*Net to client 519 bytes received via SQL*Net from client 2 SQL*Net roundtrips to/from client 0 sorts (memory) 0 sorts (disk) 1 rows processed 4. 10046事件请参照前文Oracle追踪SQL的方法 10046及tkprof的相关介绍。 5. 总结在以上四种方法中，都可以看到SQL的执行计划，但除了10046外，其他方法获得的执行计划，都有可能是不准确的。因此，如果要获得SQL的真实执行计划，最好使用10046事件进行跟踪(SQL_TRACE也是10046的一个级别)。 explain plan对于此方法而言，目标SQL根本就没有被执行过，因此，该执行计划极有可能是不准确的，特别是含有绑定变量的情况下，针对于bind peeking，Oracle可能会根据绑定变量窥视进行执行计划的调整。 dbms_xplan除了dbms_xplan.display执行计划可能不准确外，dbms_xplan.display_awr，dbms_xplan.display_cursor都是准确的执行计划，因为后面两个都表示目标SQL被真正执行过。 set autotraceautotrace设置为on或者traceonly时，目标SQL已经被实际执行过了，但当使用set autot trace exp时，如果执行的是select语句，则该SQL不会被Oracle执行，如果是DML修改，此时的SQL是会被实际执行的。虽然使用auto trace on/traceonly目标SQL都会被执行，但是用这种方法得到的执行计划还有可能是不准确的，因为使用auto trace命令所显示的执行计划都是源于explain plan的调用，跟TOAD和PL/SQL Developer一样。 要获得真实的执行计划，尽量采用10046事件或者dbms_xplan.display_cursor！！！ Reference:基于Oracle的SQL优化","link":"/execution-plan.html"},{"title":"Fixed Table统计信息","text":"Oracle有大量的内部视图供DBA使用，这些视图底层表以X$开头，Fixed Objects指的是这些以x$开头的表(下文中称为基表)及它们的索引。很多v$开头的视图基表都是x$表，包括动态性能视图，管理视图，如dba_free_space等，因此，这些fixed objects的统计信息就显得极其重要。 1. Fixed objects统计信息重要性优化器在生成执行计划的时候依赖于这些基表的统计信息，如果这些基表的统计信息缺失，不像用户对象的统计信息缺失，Oracle会使用dynamic sampling，优化器在这些缺失统计信息的基表上，会使用预设的默认值进行执行计划的评估。在这种情况下，执行计划可能是极其糟糕的。因此，可能存在查询某些动态性能视图或者数据字典时，出现很慢的情况。 例如, X$KTFBUE记录了数据文件、extent的位图等信息，在查询dba_free_space的时候，会使用到这个基表，如果这个表的统计信息为0，则有可能导致查询dba_free_space很慢. 当这个基表缺失统计信息时，该表的行数默认为10万行。 123456789column database_creation format a18column last_analyzed format a18select dbid ,to_char(created,'dd.mm.yyyy hh24:mi') database_creation ,version ,(select to_char(max(last_analyzed),'dd.mm.yyyy hh24:mi') last_analyzed from dba_tab_statistics where object_type='FIXED TABLE') last_analyzedfrom v$database,v$instance; 如何收集 在12c以前，基表的统计信息是不会通过Oracle自动任务去收集的，需要手动执行下面这个procedure, 用户需要有sysdba或者ANALYZE ANY DICTIONARY的权限。 1exec DBMS_STATS.GATHER_FIXED_OBJECTS_STATS; 上面这个procedure与DBMS_STATS.GATHER_TABLE_STATS的区别是，它不会收集表/索引的blocks信息，因为基表是存放在内存中随时动态变化的，它们的blocks永远设置为0. 统计信息的收集都是会消耗资源，不建议在业务高峰期对任何批量对象进行统计信息的收集。 12c以后，虽然自动任务窗口会收集基表统计信息，但是，其限制是在窗口时间内，其优先级是最低的，要先等到用户对象的统计信息收集完，等数据字典的统计信息收集完，同时这些基表的统计信息不存在，即是说，自动窗口不会去更新基表统计信息的；因此，建议定期手工对基表进行收集。 尽管基表生存周期是在内存中，但其统计信息是会保存在磁盘中，因此，实例重启后，除非负载有很大的变化，并没有必要重新收集统计信息。 2. Fixed tables统计信息对数据库的影响对dba_extents, v$access, V$RMAN_BACKUP_JOB_DETAILS, V$RMAN_STATUS,DBA_FREE_SPACE等视图有很大影响，很多时候查询这些视图很慢，极大可能就是因为基表统计信息缺失或者存在错误的统计信息。 Reference:How to Gather Statistics on Objects Owned by the &#39;SYS&#39; User and &#39;Fixed&#39; Objects (Doc ID 457926.1)Fixed Objects Statistics (GATHER_FIXED_OBJECTS_STATS) Considerations (Doc ID 798257.1)Best Practices for Gathering Optimizer Statistics with Oracle Database 12c Release 2ORA-01555 Caused By Auto Execute Of Job &quot;SYS&quot;.&quot;PMO_DEFERRED_GIDX_MAINT_JOB&quot; (Doc ID 2523018.1)Database SQL Tuning Guide - Gathering Statistics for Fixed Objects EOF","link":"/fixed-table-statistics.html"},{"title":"Git Commands","text":"Git is a powerful distributed version control system. In 2005, Linus Torvalds spent only two weeks developing this tool. The original purpose of git was version control for Linux OS source code. Since then, git become the most popular distributed version control system. In 2008, github was established for storing source code of open source projects. Now, more and more open source projects are moving to the github. This post introduces fundamentals of git commands. 1. InitializationThe git server setting based on setting git server. 1.1 InstallationYou can install git from source code Git for all platforms or by Linux software management tool, such as yum, apt-get. Here shows the second approach. 1234#For RHELyum install git#For ubuntusudo apt-get install git git-core When installed, you can find the version through the git --version command: 12git --versiongit version 2.7.4 1.2 Identify yourselfGit provide git config command enables you configure your username and email address with the github, global means all the configurations will use this setting for local machine. 1234git config --global user.name \"Your Name\"git config --global user.email \"YourEmail@YourDomain.com\"#Using git config -l show all your git configurationgit config -l After you configured your username and email address on the local machine, you also need to provide your SSH keys for authentication: 12#Generate ssh public keys from your local machine$ ssh-keygen -t rsa Paste your ~/.ssh/id_rsa.pub to github account setting&#39;s SSH keys. After uploaded, you can test the authentication from your local machine. For a private git server, please refer to setting git server for setting up ssh authentication. 12345ssh -T USERNAME@github.com# if successfully, will show:Hi USERNAME! You've successfully authenticated, but GitHub does not provide shell access.# Or showing the following messages while failed with authenticationPermission denied (publickey). 1.3 Initializing local repositoryBefore we go through the next section, we need to know two important terminologies of git: working directory and staging area. As its name implies, working directory is the local directory in our laptop/desktop. Besides, if we initialized the working directory as local repository, we would have a .git directory under the working directory, this file folder contains the git configurations, the version information, and most of all, the staging area(also are called index area). The command git add file1 actually puts the changes of file1 into the staging area, we issue the git commit command to commit all the changes of the staging area to the current branch. 123456789101112131415$ cd git-tutorial$ vim readme.md$ git init . #Initial local repository in git-tutorialInitialized empty Git repository in /worktmp/git-tutorial/.git/$ git add . #Add all the files in the current working directory to the staging area$ git commit -m \"commit messages\" #Commit the changes to the current branch# For github repository$ git remote add origin git@github.com:USERNAME/PROJECT_NAME.git# For private git server$ git remote add origin git@hostname:/project_dir/project.git# Push your code to master branch$ git push origin master 2. Repository commands2.1 PushAs its name implies, push is putting all of your committed changes from working directory to remote directory. 123456789[root@node2:/worktmp/git-tutorial]# cat hello.mdHello everyone, this is my second push.[root@node2:/worktmp/git-tutorial]# git status# On branch master# Untracked files:# (use \"git add &lt;file&gt;...\" to include in what will be committed)## hello.mdnothing added to commit but untracked files present (use \"git add\" to track) The git status result shows us that we changed a file, but haven&#39;t been committed. 12345[root@node2:/worktmp/git-tutorial]# git add .[root@node2:/worktmp/git-tutorial]# git commit -m \"second push\"[master b82094a] second push 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 hello.md If you modified some files, git diff would show you the difference with different versions. 1234567891011121314151617181920[root@node2:/worktmp/git-tutorial]# cat &gt;&gt;readme.md &lt;&lt;EOFdiff command to compare with before and after versionEOF[root@node2:/worktmp/git-tutorial]# git commit -m \"git diff command\"# On branch master# Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)# (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)## modified: readme.md#no changes added to commit (use \"git add\" and/or \"git commit -a\")[root@node2:/worktmp/git-tutorial]# git diff readme.mddiff --git a/readme.md b/readme.mdindex 18a27a1..7379c0f 100644--- a/readme.md+++ b/readme.md@@ -1 +1,2 @@ Hi, this is the first initial.+diff command to compare with before and after version After we committed the changed, we can push them to master branch now. 12345678[root@node2:/worktmp/git-tutorial]# git add .[root@node2:/worktmp/git-tutorial]# git push origin masterCounting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 313 bytes, done.Total 3 (delta 0), reused 0 (delta 0)To git@node1:/git/project.git ae69504..b82094a master -&gt; master 2.2 Pullgit pull command can let you update your local repository to the newest one, for example, when you updated your changes on your office desktop, but when you came home, you would like to modify something and push the changes to the remote repository, then you must pull from remote repository before you modified your local files. 123456789cd projectgit pull orgin master# For force pull, discard the modification of local repository by overwriting itgit reset --hardgit pull origin master# Orgit fetch origingit reset --hard origin/master git reset command will be introduced in the following sections. After you update your local repository, you can push your changes into the remote repository. 2.3 Branches management Creating and switching branches Git can have multiple branches, let&#39;s create another branch first. 123# Creating source branch[root@node2:/worktmp/git-tutorial]# git checkout -b sourceSwitched to a new branch 'source' With the -b option, it means create and switch to new branch, this command equals: 12git branch sourcegit checkout source git branch command can show you what branch are you in. 123[root@node2:/worktmp/git-tutorial]# git branch master * source Merging the branches We can commit and push changed data when we are in branches. Let&#39;s modify something, and push it to the remote repository. 12345678910# Do some modifications[root@node2:/worktmp/git-tutorial]# cat &gt;&gt;hello.md &lt;&lt;EOFnew branches.EOF# Commit the changes[root@node2:/worktmp/git-tutorial]# git add hello.md[root@node2:/worktmp/git-tutorial]# git commit -m \"adding branches\"[source 33e6404] adding branches 1 files changed, 1 insertions(+), 0 deletions(-) Now, guess what happen if we back to the master branch? The modifications we changed before are gone. 123456789[root@node2:/worktmp/git-tutorial]# git checkout masterSwitched to branch 'master'[root@node2:/worktmp/git-tutorial]# cat hello.mdHello everyone, this is my second push.[root@node2:/worktmp/git-tutorial]# git checkout sourceSwitched to branch 'source'[root@node2:/worktmp/git-tutorial]# cat hello.mdHello everyone, this is my second push.new branches. It&#39;s just because we committed at the source branch, not at the master branch. git merge command can merge multiple branches, and because of creating, merging, deleting branches is very fast, git recommend us using branches for some tasks, after merged the branches, delete those branches. This process just like what we did in master branch, but it&#39;s more safety. 123456789101112131415161718192021222324[root@node2:/worktmp/git-tutorial]# git checkout masterSwitched to branch 'master'[root@node2:/worktmp/git-tutorial]# git branch* master source[root@node2:/worktmp/git-tutorial]# git merge sourceUpdating b33f2a9..33e6404Fast-forward hello.md | 1 + 1 files changed, 1 insertions(+), 0 deletions(-)[root@node2:/worktmp/git-tutorial]# cat hello.mdHello everyone, this is my second push.new branches.[root@node2:/worktmp/git-tutorial]# git branch -d sourceDeleted branch source (was 33e6404).[root@node2:/worktmp/git-tutorial]# git branch* master[root@node2:/worktmp/git-tutorial]# git push origin masterCounting objects: 5, done.Compressing objects: 100% (3/3), done.Writing objects: 100% (3/3), 327 bytes, done.Total 3 (delta 0), reused 0 (delta 0)To git@node1:/git/project.git b33f2a9..33e6404 master -&gt; master If we want to keep the source branch, and do some different task from master branch, we also can treat it as master branch. 12345678910111213141516[root@node2:/worktmp/git-tutorial]# touch branches.md[root@node2:/worktmp/git-tutorial]# git add .[root@node2:/worktmp/git-tutorial]# git commit -m \"branches testing\"[source cd86d13] branches testing 0 files changed, 0 insertions(+), 0 deletions(-) create mode 100644 branches.md[root@node2:/worktmp/git-tutorial]# git branch master* source[root@node2:/worktmp/git-tutorial]# git push origin sourceCounting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 308 bytes, done.Total 3 (delta 0), reused 0 (delta 0)To git@node1:/git/project.git * [new branch] source -&gt; source Conflict resolution Switch to the source branch, and do some modifications to files. 123456789101112131415161718$ git status# On branch source# Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)# (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)## modified: readme.md#no changes added to commit (use \"git add\" and/or \"git commit -a\")$ git branch master* source$ git add readme.md $ git commit -m \"modified by source branch\"[source 6041c6f] modified by source branch 1 files changed, 1 insertions(+), 1 deletions(-) After that, we switch to the master branch, do some modifications, and commit it: 1234567891011121314151617181920$ git status# On branch master# Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)# (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)## modified: readme.md#no changes added to commit (use \"git add\" and/or \"git commit -a\")$ git add .$ git commit -m \"master branch\"[master 3e1a68c] master branch 1 files changed, 1 insertions(+), 0 deletions(-)$ git push origin masterCounting objects: 5, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 298 bytes, done.Total 3 (delta 1), reused 0 (delta 0)To git@node1:/git/git-tutorial.git 7a96d51..3e1a68c master -&gt; master Now, we have committed the changes on both source and master branch, if we try to merge them, it will warn you there&#39;re some conflicts need you to solve it manually before merge. 12345678910111213$ git merge sourceAuto-merging readme.mdCONFLICT (content): Merge conflict in readme.mdAutomatic merge failed; fix conflicts and then commit the result.$ git status# On branch master# Unmerged paths:# (use \"git add/rm &lt;file&gt;...\" as appropriate to mark resolution)## both modified: readme.md#no changes added to commit (use \"git add\" and/or \"git commit -a\") The contents of readme.md file changed to as following, you can modify it and re-commit again. 12345678$ cat readme.mdConflict Resolution.&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD1. adding some line from node2 and pushing it to remote repo.2. adding some line from node1=======Another change from master branch.&gt;&gt;&gt;&gt;&gt;&gt;&gt; source Clone multiple branches to local repository With multiple branches, if you want clone the whole repository, you need to clone all of the branches one by one. 1234# Clone multiple branches into local repogit clone -b source https://github.com/username/projectname.gitcd projectnamegit clone https://github.com/username/project master 2.4 Rollback to the before versionOnce we changed somethings wrong in the local repository, we need to revert the changes to the before version. Depending on what scenarios are, git provides kind of commands to let you rollback to the before version. Wrong modifications on the working directory 123456789101112$ cat &gt;&gt;readme.md &lt;&lt;EOFOnly Wrong modifications on the working directoryEOF$ git status# On branch master# Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)# (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)## modified: readme.md#no changes added to commit (use \"git add\" and/or \"git commit -a\") The git status command already told us what should we do if we want to discard the changes, by using git checkout -- file1 command. This command will let file1 back to the status of the last git commit or git add. 123456$ git checkout -- readme.md$ git status# On branch master nothing to commit (working directory clean)$ cat readme.md The first initial. Wrong modifications on the working directory and added the changes to the staging area The same example, you modified the readme.md file, and you added these changes to the staging area. 12345678910111213141516171819202122$ cat &gt;&gt;readme.md &lt;&lt;EOFOnly Wrong modifications on the working directoryEOF$ git status# On branch master# Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)# (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)## modified: readme.md#no changes added to commit (use \"git add\" and/or \"git commit -a\")$ git add readme.md$ git status# On branch master# Changes to be committed:# (use \"git reset HEAD &lt;file&gt;...\" to unstage)## modified: readme.md# After you added the changes to the staging area, git status showed you another recommendation for unstaging. 123$ git reset HEAD readme.mdUnstaged changes after reset:M readme.md After we resetted the HEAD of readme.md file, we&#39;re back to the before added version, so we can use git checkout -- filename to revert all the changes. 123456789$ git status# On branch master# Changed but not updated:# (use \"git add &lt;file&gt;...\" to update what will be committed)# (use \"git checkout -- &lt;file&gt;...\" to discard changes in working directory)## modified: readme.md#no changes added to commit (use \"git add\" and/or \"git commit -a\") Wrong modifications on the working directory and committed the changes to the current branch The above two scenarios both are not committed the changes, what if we do when the wrong modifications are committed but not being pushed to the remote repository? 123456$ cat &gt;&gt;readme.md &lt;&lt;EOFOnly Wrong modifications on the working directoryEOF$ git add readme.md$ git commit -m \"reverting committed changes testing\" git log can show us the committed history. git reflog can show us the commit id and HEAD version, we can revert our changes by using git reset --hadr/soft commit_id command. 12345$ git reflog4da4888 HEAD@&#123;0&#125;: commit: reverting committed changes testing3d88e42 HEAD@&#123;1&#125;: commit: adding hello.mde340212 HEAD@&#123;2&#125;: commit: adding hello.md5f9a0f6 HEAD@&#123;3&#125;: commit (initial): First initialize For our example, we need to back to the version of commit id 3d88e42, also the last committed version which can use HEAD^ to specify. 123456789$ git reset --hard 3d88e42# or$ git reset --hard HEAD^HEAD is now at 3d88e42 adding hello.md$ cat readme.mdThe first initial.$ git status# On branch masternothing to commit (working directory clean) Now the git reflog output as below: 123456$ git reflog3d88e42 HEAD@&#123;0&#125;: HEAD^: updating HEAD4da4888 HEAD@&#123;1&#125;: commit: reverting committed changes testing3d88e42 HEAD@&#123;2&#125;: commit: adding hello.mde340212 HEAD@&#123;3&#125;: commit: adding hello.md5f9a0f6 HEAD@&#123;4&#125;: commit (initial): First initialize If we regret for the reverting and want to back to the commit id 4da4888, we also can use git reset back to the specified version: 1234$ git reset --hard 4da4888$ cat readme.mdThe first initial.Only Wrong modifications on the working directory hard and soft HEAD stands for version, HEAD^ or HEAD~ option stands for the latest commit&#39;s parent, HEAD~10 means back to last 10 commit version. git reset --soft only revert the commit, but remain the modified files in the working directory. git reset --hard revert the changes to the last commit status, that means it will delete all the committed information, revert the file to the last committed status. For example: 1234567891011121314151617181920212223242526272829$ cat &gt;&gt;readme.md &lt;&lt;EOFdifferential of soft and hardEOF$ git add readme.md $ git commit -m \"soft and hard first commit\"[master c9fb3e9] soft and hard first commit 1 files changed, 1 insertions(+), 0 deletions(-)$ git reset --soft HEAD^$ git diff$ git diff --cacheddiff --git a/readme.md b/readme.mdindex ae00a84..8cc4a14 100644--- a/readme.md+++ b/readme.md@@ -1,2 +1,3 @@The first initial.Only Wrong modifications on the working directory+differential of soft and hard$ git diff HEADdiff --git a/readme.md b/readme.mdindex ae00a84..8cc4a14 100644--- a/readme.md+++ b/readme.md@@ -1,2 +1,3 @@ The first initial. Only Wrong modifications on the working directory+differential of soft and hard From the above outputs, the git diff shows nothing, but the git diff --cached and git diff HEAD shows the line we just added to readme.md file.So, if you just want to revert the commit and keep the modifications in the working directory, use --soft option. If you don&#39;t want keep the modifications and want to revert the commit, please use --hard option. 2.6 Reverting pushed committed changesLast example shows how to revert committed changes on the local repository, but those changes were not pushed yet. What if we pushed those wrong changes to the remote repository? 1234567891011121314151617181920# Add a new file to local repository and pushed it to remote repository$ git add reverting.md$ git status# On branch master# Changes to be committed:# (use \"git reset HEAD &lt;file&gt;...\" to unstage)## new file: reverting.md$ git commit -m \"adding reverting.md\"[master c727ce3] adding reverting.md 1 files changed, 1 insertions(+), 0 deletions(-) create mode 100644 reverting.md$ git push origin masterCounting objects: 4, done.Compressing objects: 100% (2/2), done.Writing objects: 100% (3/3), 344 bytes, done.Total 3 (delta 0), reused 0 (delta 0)To git@node1:/git/project/project.git/ 6c71346..c727ce3 master -&gt; master Reverting the pushed data by using git reset and git push with force option. 123456789101112$ git reflogc727ce3 HEAD@&#123;0&#125;: commit: adding reverting.md6c71346 HEAD@&#123;1&#125;: HEAD^: updating HEAD9b6bdd6 HEAD@&#123;2&#125;: commit: modified readme.md$ git reset --hard HEAD^HEAD is now at 6c71346 adding readme file$ git push origin -fTotal 0 (delta 0), reused 0 (delta 0)To git@node1:/git/project/project.git/ + c727ce3...6c71346 master -&gt; master (forced update) Above commands can be combined with one command: 1git push -f origin HEAD^:master 2.7 Deleting the filesBesides add, modify files, we also can delete the files we don&#39;t want any more with git rm command. Below example showing deleting the file from working directory and version repository, that is deleted permanently 12345678$ git rm hello.mdrm 'hello.md'$ git commit -m \"remove hello,md\"[master a7dd8e0] remove hello,md 1 files changed, 0 insertions(+), 2 deletions(-) delete mode 100644 hello.md$ lsreadme.md Below example showing the deleted files by OS rm command, and before commit it, the version repository still keeping the information, so we can use git checkout -- file command to restore it. 1234$ rm -f readme.md$ git checkout -- readme.md$ lsreadme.md EOF","link":"/git-commands.html"},{"title":"[shell学习笔记]正则表达式与grep","text":"1.正则表达式元字符 123[root@linora shell]# cat lettle Hi,Tom Tommy tomrrow! 需要将以上文本的Tom改为David，需注意到，其他单词也含有tom或者Tom字样。Vi命令模式中使用%s/[Tt]om/David/g显然是不行的，它会将其他单词中含有tom字样的全部取代为David。 正解： 正则表达式%/s/\\&lt;[Tt]om\\&gt;/David/g达成此目的或者:1,$s/\\&lt;[Tt]om\\&gt;/David/g。 :1,$s/\\&lt;[Tt]om\\&gt;/David/g 这条vi命令的意思是，从文件的第一行到末尾，用David替换单词Tom或者tom。正则表达式元字符\\&lt;和\\&gt;表示单词的开始和结束（vi跟grep支持）。表1-1列出了可以在所有版本的vi、ex、grep、egrep、sed和awk中使用的正则表达式元字符。 表1-1 正则表达式元字符 元字符 功能 示例 匹配对象 ^ 行首定位符 /^love/ 匹配所有以love开头的行 $ 行尾定位符 /love$/ 匹配所有以love结尾的行 . 匹配单个字符 /l..e/ 匹配包含一个l，后面跟两个字符，再跟一个e的行 * 匹配0或者多个重复的位于*前的字符 /*love/ 匹配包含跟在0个或者多个字符后的love的行 [] 匹配一组字符中的任意一个 /[Ll]ove/ 匹配Love或者love [x-y] 匹配指定范围内的一个字符 /[A-Z]ove/ 匹配后面跟着ove的一个A至Z的任意字符 [^] 匹配不在指定组内的字符 /[^A-Z]/ 匹配不在范围A至Z之间的任意一个字符 \\ 转义字符 /love\\./ 匹配包含love，后面跟一个句号 1.1.正则表达式范例 I had a lovely time on our little picnic. Lovers were all around us. It is springtime. Oh love, how much I adore you. Do you know the extent of my love? Oh, by the way, I think I lost my gloves somewhere out in that field of clover. Did you see them? I can only hope love is forever. I live for you. It's hard to get back in the groove. 说明: 1/love/ 解析：正则表达式为love，查找到的love可能是单个单词，也有可能是lovely,gloves或者clover。 注：为了减少篇幅冗余，以上文本省略，只挑出vi命令行查找命令。 1/^love/ ^为行首定义符，在上述短文中，vi只查找以love四个字符开头的行，前面不能有任何字符，包括空格。 1/love$/ $为行尾定义符，只查找以love结尾的行，且love后面跟着换行符。 /l.ve/ 单个字符匹配，查找结果为love和live的组合。 1/[Ll]ove/ 方括号匹配某组字符中的一个，即vi查找包含一个L或者l后面跟着ove的正则表达式。 1/ove[a-z]/ 方括号内的连字符表示匹配某个范围内的一个字符，即vi查找包含ove，后面接着a-z的任意一个ASCII码字符。 1/ove[^a-zA-Z0-9]/ 方括号内的^为否定，即上述查找表示vi查找ove开头，但后面不是接着A-Z、a-z及0-9之间的ASCII字符，如，vi可能找到ove后面接着句号，感叹号等的字符。 1.2.复合正则表达式元字符 --------------------------------------------------------------- 1 |Christian Scott lives here and will put on a Christmas party.| 2 |There are around 30 to 35 people invited. | 3 |They are: | 4 | Tom| 5 |Dan | 6 | Rhonda Savage | 7 |Nicky and Kimberly. | 8 |Steve, Suzanne, Ginger and Larry. | --------------------------------------------------------------- 说明： 1/^[A-Z]..$/ 查找文本中所有以大写字母开头，后跟两个任意字符，再跟一个换行符的行，查找结果是第五行的Dan。 1/^[A-Z][a-z ]*3[0-5]/ 查找所有以大写字母开头，后面跟0个或者多个小写字母或空格，再跟数字3和一个0~5之间的数字的行。查找结果是第二行。 1/[a-z]* \\./ 查找包含跟在0个或多个小写字母后的句点的行。结果是第1、2、7、8行。 1/^ *[A-Z][a-z][a-z]$/ 查找0个或者多个空格开头，后跟一个大写字母、两个小写字母跟换行符的行。结果是第四行及第五行。 1/^[A-Za-z]*[^,][A-Za-z]*$/ 查找以0个或者多个大小写字母开头，后面跟一个非逗号的字符，再跟0个或者多个大小写字母和一个换行符的行。结果是第五行。 1.3.其他正则表达式元字符 Unusual occurrences happened at the fair. Patty won fourth place in the 50 yard dash square and fair. Occurrences like this are rare. The winning ticket is 55222. The ticket I got is 54333 and Dee got 55544. Guy fell down while running around the south bend in his last event. 说明： 1/\\&lt;fourth\\&gt;/ 查找出每一行的单词fourth。\\是词尾定位符。 1/\\&lt;f.*th\\&gt;/ 查找以f开头、后跟0个或者多个任意字符，再跟以th结尾的字符穿的任意单词。 1:1,$s/\\([Oo]ccur\\)ence/\\1rence 上面取代例子采用\\(和\\)记录模式，编辑器查找完整的字符串[Oo]ccurence。如果找到了，就把圆括号中的这部分模式加上标签(即将occur或者Occur标记)。这是第一个被标记的地方（最多可标记9个），因此被称为标签1.这个模式被保存在标记为1的内存寄存器中。执行替换时候，将\\1替换为寄存器的内容，然后加上单词的剩余部分rence。这样，开始时的occurence被替换为occurrence。 1:s/\\(square\\) and \\(fair\\)/\\2 and \\1 编辑器查找正则表达式square and fair，将square标记为标签1，fair标记为标签2。执行替换时候，\\1被寄存器1的内容替换，\\2被寄存器2的内容替换，最后结果为fair and square。 1/5\\&#123;2\\&#125;2\\&#123;3\\&#125;\\./ 模式的重复\\{n\\},表示查找含有两个数字5，后面接三个数字2，最后接一个句点的行。 2.grep grep表示全局查找正则表达式并且打印结果行(global search regular expression and print out the line)。 使用grep的好处在于，不需要启动编辑器就可以执行查找操作，也不用把正则表达式括在正斜杠里。使用grep比vi快得多。 grep命令在一个或者多个文件中查找某个字符模式，如果这个模式中包含空格，就必须用引号把它括起来。 命令格式： grep oracle /etc/passwd 如果发现了要查找的模式，grep返回的退出状态为0，如果没找到，返回的退出状态为1，如果找不到指定文件，退出状态是2. 2.1. grep中的元字符 表2-1 grep使用的正则表达式元字符 元字符 功能 示例 匹配对象 ^ 行首定位符 '^love' 匹配所有以love开头的行 $ 行尾定位符 'love$' 匹配所有以love结尾的行 . 匹配单个字符 'l..e' 匹配包含一个l，后面跟两个字符，再跟一个e的行 * 匹配0或者多个重复的位于*前的字符 '*love' 匹配包含跟在0个或者多个字符后的love的行 [] 匹配一组字符中的任意一个 '[Ll]ove' 匹配Love或者love [^] 匹配不在指定组内的字符 '[^A-Z]' 匹配不在范围A至Z之间的任意一个字符 \\&lt; 词首定位符 '\\&lt;love' 匹配包含以love开头的词的行 \\&lt; 词尾定位符 'love/&gt;' 匹配包含以love结尾的词的行 \\(..\\) 标记匹配到的字符 '\\(love\\)ing' 模式love被保存在1号寄存器中，之后可用\\1引用它 x\\{m\\}或x\\{m,\\}或x\\{m,n\\} 字符x的重复次数：m次、至少m次、至少m次但不超过n次 'o\\{5\\}','o\\{5,\\}','o\\{5,10\\}' 匹配连续出现5个o、至少5个o或者5~10个o的行 表2-2 grep的选项 选项 功能 -b 在每一行前面加上其所在的块号，根据上下文定位磁盘时可能会用到 -c 只显示匹配到的行的数目，而不显示行的内容 -h 不显示文件名 -i 忽略大小写 -l 只列出匹配行所在文件的文件名，文件名之间用换行符分隔 -n 在每一行前面加上它所在文件中的相对行号 -s Silent mode，即只显示报错信息，以检查退出状态 -v 反向查找，只显示不匹配的行 -w 把表达式作为单词查找，就好像他被\\&lt;和\\&gt;所包含一样 2.2.grep的退出状态 grep在shell脚本中很有用，它总会返回一个退出状态，但是sed及awk是不使用退出状态来说明查找模式是否成功的。例如： 123456[root@linora shell]# grep -s oracle /etc/passwdddsf [root@linora shell]# echo $? 2[root@linora shell]# grep fung /etc/passwd [root@linora shell]# echo $? 1 对于在bash及ksh中的变量“?”的值都是上一条命令执行后的退出状态。 2.3.grep与pipe 12345678[root@linora shell]# ls -l total 12 drwxr-xr-x 2 root root 4096 Sep 24 01:22 dir1 drwxr-xr-x 2 root root 4096 Sep 24 01:22 dir2 -rw-r--r-- 1 root root 23 Sep 23 18:44 lettle [root@linora shell]# ls -l |grep &apos;^d&apos; drwxr-xr-x 2 root root 4096 Sep 24 01:22 dir1 drwxr-xr-x 2 root root 4096 Sep 24 01:22 dir2 说明： ls命令的输出通过pipe传给grep。输出结果中以字母d开头的所有行都被打印出来，及上述命令打印当前目录下所有子目录。 3.egrep egrep的好处是它在grep提供的正则表达式元字符集的基础上增加了很多元字符，但是egrep不允许\\{\\}和\\(\\)。同时egrep参数跟grep参数用法相同。 表3-1 egrep使用的正则表达式元字符 元字符 功能 示例 匹配对象 ^ 行首定位符 '^love' 匹配所有以love开头的行 $ 行尾定位符 'love$' 匹配所有以love结尾的行 . 匹配单个字符 'l..e' 匹配包含一个l，后面跟两个字符，再跟一个e的行 * 匹配0或者多个重复的位于*前的字符 '*love' 匹配包含跟在0个或者多个字符后的love的行 [] 匹配一组字符中的任意一个 '[Ll]ove' 匹配Love或者love [^] 匹配不在指定组内的字符 '[^A-Z]' 匹配不在范围A至Z之间的任意一个字符 + 匹配一个或者多个加号前的字符 '[a-z]+ove' 匹配一个或者多个小写字母后面跟ove的字符 ? 匹配零个或者一个前导字符 'lo?ve' 匹配l后跟一个或者零个字母o及vd的字符，即love或者lve a|b 匹配a或者b 'love|hate' 匹配love或hate () 字符组 'love(able|ly)(ov)+' 匹配lovable或lovely，匹配ov的一次或者多次出现 表3-2 egrep用法示例 命令 命令执行的操作 egrep '^ +' file 打印一个或者多个空格开头的行 egrep '^ *' file 打印零个或者多个空格开头的行 egrep '(Tom|Dan) Savage' file 打印Tom Savage或Dan Savage的行 egrep '(ab)+' file 打印一个或者多个ab的行 egrep '^X[0-9]?' file 打印X开头，后面接零个或者一个数字的行 egrep 'fun\\.$' file 打印fun.结尾的行 egrep '[A-Z]+' file 打印包含一个或者多个大写字母的行 egrep '[0-9]' file 打印包含数字的行 egrep '[A-Z]...[0-9]' file 打印大写字母后面跟着三个任意字符最后再跟数字的行，共计五个字符 egrep '[tT]est' file 打印包含test或Test的行 egrep '(Susan|Jean) Doe' file 打印包含Susan Doe或Jean Doe的行 EOF","link":"/grep-and-regular-expression.html"},{"title":"如何确认刚刚执行的SQL ID","text":"在一些特定场合，需要对刚刚执行的sql进行一些监控或者优化，因此需要找出SQL的sql_id，经常会用v$sql中的sql_text去关联查找。下面是另一种方法可以确定这个SQL ID。 在v$session中，PREV_SQL_ID就是表示上一次执行的SQL ID。但如果直接去查找，你会发现，不管你执行什么SQL，这个值都是9babjv8yq8ru3。123456select sql_text from v$sqltextwhere sql_id = '9babjv8yq8ru3';SQL_TEXT----------------------------------------------------------------BEGIN DBMS_OUTPUT.GET_LINES(:LINES, :NUMLINES); END; 这是因为默认配置下, serveroutput设置为ON；此时在后台数据库会将dbms_output的缓存内容打印到屏幕，这个语句就是调用这个功能。因此，只需要把serveroutput设置为OFF，我们的目的就达到了。 123set serveroutput off--run sql hereselect prev_sql_id from v$session where sid=sys_context('userenv','sid'); EOF","link":"/how-to-identify-sql-id-just-run.html"},{"title":"Oracle日志文件损坏的恢复","text":"如前文管理redo文件所述，Online redo log是记录数据所有操作的地方，它最大的目的就是在数据库需要恢复的时候提供恢复的依据。Oracle的日志是循环写，因此，它要求至少要有两组日志文件，每个组至少有一个成员，成员就是磁盘中的物理文件。类似控制文件，Oracle也强烈要求日志文件多路存储在不同磁盘或者路径上。但由于日志文件没有一个很好的保护机制，它不能用RMAN进行备份，如果因为人为(rm -rf *.log)或者磁盘故障等导致日志文件损坏，该如何修复日志文件呢？ 日志文件损坏信息都会被记录在alert log里面，因此，首先可以查看alert log确认是哪个日志的哪个成员损坏。 通过v$log和v$logfile，确认日志文件信息，这两个视图很有用。 如果仅仅是同一日志组的某一成员损坏，数据库仍会正常工作，只是在后台日志会报错。 日志文件状态决定了恢复策略。 12345678910111213141516171819202122SQL&gt; set linesize 200SQL&gt; col member for a50SQL&gt; selecta.group#, a.thread#,a.status grp_status,b.member member,b.status mem_statusfrom v$log a,v$logfile bwhere a.group# = b.group#order by a.group#, b.member; GROUP# THREAD# GRP_STATUS MEMBER MEM_STA---------- ---------- ---------------- -------------------------------------------------- ------- 1 1 CURRENT /oracle/backup/redo01b.rdo INVALID 1 1 CURRENT /oracle/oradata/orcl/redo01.log 2 1 INACTIVE /oracle/backup/redo02b.rdo INVALID 2 1 INACTIVE /oracle/oradata/orcl/redo02.log 3 1 INACTIVE /oracle/backup/redo03b.rdo INVALID 3 1 INACTIVE /oracle/oradata/orcl/redo03.log 5 1 UNUSED /oracle/backup/redo05b.log 5 1 UNUSED /oracle/oradata/orcl/redo05a.log v$log视图status含义 Status Meaning CURRENT 正在使用的日志组 ACTIVE 当前日志文件需要在crash recovery用到，且可能尚未归档 CLEARING 正在被清除(alter database clear logfile)，清除完毕后，状态变为UNUSED CLEARING_CURRENT 表明正在清除当前日志文件中的已关闭线程，如果切换时发生某些故障，如写入新日志标题时的I/O错误，则该日志可以停留在该状态 INACTIVE 表面此日志文件不需要在crash recovery用到，且可能尚未归档 UNUSED 表明从未对联机重做日志组进行写入，这种状态的日志文件要么而是刚增加的，要么是当日志不是current redo log时RESETLOGS操作后的状态 v$logfile视图status含义 Status Meaning INVALID 日志文件无法被访问，或者是新增加的 DELETED 日志文件已经被删除，已不再使用 STALE 表明该文件内容不完全，例如正在添加一个日志文件成员 NULL 日志文件正在被使用 两个视图status栏位有不同的含义，v$log反应的是日志组的状态，v$logfile反应的是日志组成员即物理日志文件的状态。 1. 丢失多个成员中的一个1234567SQL&gt; !rm -rf /oracle/backup/redo05b.logErrors in file /oracle/app/oracle/diag/rdbms/orcl/orcl/trace/orcl_m000_6226036.trc:ORA-00313: open failed for members of log group 5 of thread 1ORA-00313: open failed for members of log group 5 of thread 1ORA-00312: online log 5 thread 1: &apos;/oracle/backup/redo05b.log&apos;ORA-27037: unable to obtain file statusIBM AIX RISC System/6000 Error: 2: No such file or directory 由于仅仅是丢失其中一份copy，因此数据库仍旧会正常工作，解决方法：1234SQL&gt; alter database drop logfile member &apos;/oracle/backup/redo05b.log&apos;;Database altered.SQL&gt; alter database add logfile member &apos;/oracle/backup/redo05b.log&apos; to group 5;Database altered. 重新创建日志组成员可以在open或者mount状态下进行，但建议在mount下进行，这样能保证在drop和recreate过程中log group的状态不变。 2. 日志组状态inactive，丢失所有成员123456789101112131415161718SQL&gt; !rm -rf /oracle/backup/redo05b.logSQL&gt; !rm -rf /oracle/oradata/orcl/redo05a.logORA-00312: online log 5 thread 1: &apos;/oracle/oradata/orcl/redo05a.log&apos;ORA-27037: unable to obtain file statusIBM AIX RISC System/6000 Error: 2: No such file or directoryAdditional information: 3ORA-00313: open failed for members of log group 1 of thread ORA-00312: online log 5 thread 1: &apos;/oracle/oradata/orcl/redo05a.log&apos;ORA-00312: online log 5 thread 1: &apos;/oracle/backup/redo05b.log&apos;SQL&gt; startup mountSQL&gt; select group#, status, archived, thread#, sequence# from v$log; GROUP# STATUS ARC THREAD# SEQUENCE#---------- ---------------- --- ---------- ---------- 1 INACTIVE YES 1 46 5 INACTIVE YES 1 47 3 INACTIVE YES 1 45 2 CURRENT NO 1 48 确认损坏的日志组status为inactive，因为inactive状态的日志不需要在crash recovery中用到，因此，可以直接clear log方式恢复。如果尚未归档的，需要立刻对数据库进行备份。123456789SQL&gt; alter database clear logfile group 5;SQL&gt; select group#, status, archived, thread#, sequence# from v$log; GROUP# STATUS ARC THREAD# SEQUENCE#---------- ---------------- --- ---------- ---------- 1 INACTIVE YES 1 46 2 CURRENT NO 1 48 3 INACTIVE YES 1 45 5 UNUSED YES 1 0 对于尚未归档的日志组，需要用以下命令进行clear：1SQL&gt; alter database clear unarchived logfile group 5; 3. 日志组状态为active，丢失所有成员Active状态表示日志在crash recovery时候需要用到，且可能尚未归档。12345678910SQL&gt; select group#, status, archived, thread#, sequence# from v$log; GROUP# STATUS ARC THREAD# SEQUENCE#---------- ---------------- --- ---------- ---------- 1 INACTIVE YES 1 46 2 ACTIVE YES 1 48 3 INACTIVE YES 1 45 5 CURRENT NO 1 49[oracle@:/home/oracle]$ rm -rf /oracle/backup/redo02b.log[oracle@:/home/oracle]$ rm -rf /oracle/oradata/orcl/redo02a.log 首先尝试进行Checkpoinnt1SQL&gt; alter system checkpoint; 如果Checkpoinnt成功，那么，active状态的日志会变成inactive，Checkpoinnt成功后，所有被修改的脏块被写入磁盘，只有current状态的Online redo log才会被crash recovery用到。当日志组状态变为inactive后，clear log即可修复。同样，要是尚未归档，建议立刻进行备份。1234567891011SQL&gt; alter database clear logfile group 2;Database alteredSQL&gt; select group#, status, archived, thread#, sequence# from v$log; GROUP# STATUS ARC THREAD# SEQUENCE#---------- ---------------- --- ---------- ---------- 1 INACTIVE YES 1 46 2 UNUSED YES 1 0 3 INACTIVE YES 1 45 5 CURRENT NO 1 49 对于尚未归档的日志组，需要用以下命令进行clear：1SQL&gt; alter database clear unarchived logfile group 5; 4. 日志组状态为current，丢失所有成员如果所有current状态日志组成员损坏，则需要不完全恢复，或是使用flashback database功能闪回。如果是DataGuard，还可以进行Failover切换。在准备不完全恢复前，先通过查询v$log的first_change#栏位确定能恢复的SCN值。但是，只能恢复到这个SCN前，而不包含当前SCN。1234567891011121314151617181920212223242526SQL&gt; select group#, status, archived, thread#, sequence#, first_change# from v$log; GROUP# STATUS ARC THREAD# SEQUENCE# FIRST_CHANGE#---------- ---------------- --- ---------- ---------- ------------- 1 INACTIVE YES 1 46 439571 2 CURRENT NO 1 50 472169 3 INACTIVE YES 1 45 403581 5 UNUSED YES 1 0 471475[oracle@:/home/oracle]$ rm -rf /oracle/backup/redo02b.log[oracle@:/home/oracle]$ rm -rf /oracle/oradata/orcl/redo02a.logSQL&gt; startupORACLE instance started.Total System Global Area 1570009088 bytesFixed Size 2221840 bytesVariable Size 1006635248 bytesDatabase Buffers 553648128 bytesRedo Buffers 7503872 bytesDatabase mounted.ORA-03113: end-of-file on communication channelProcess ID: 10158148Session ID: 63 Serial number: 5#alert logORA-00313: open failed for members of log group 1 of thread ORA-00312: online log 2 thread 1: &apos;/oracle/oradata/orcl/redo02.log&apos;ORA-00312: online log 2 thread 1: &apos;/oracle/backup/redo02b.rdo&apos; 在此例中，能恢复到SCN=472169前的数据，但不包含SCN=472169。1234567891011121314151617181920212223242526run&#123;allocate channel c1 type disk;set until scn=472169;restore database;recover database;release channel c1;&#125;SQL&gt; alter database open RESETLOGS;SQL&gt; col member for a50SQL&gt; set line 200SQL&gt; select a.group#, a.thread#,a.status grp_status, 2 b.member member,b.status mem_status 3 from v$log a,v$logfile b 4 where a.group# = b.group# 5 order by a.group#, b.member; GROUP# THREAD# GRP_STATUS MEMBER MEM_STA---------- ---------- ---------------- -------------------------------------------------- ------- 1 1 CURRENT /oracle/backup/redo01b.rdo 1 1 CURRENT /oracle/oradata/orcl/redo01.log 2 1 UNUSED /oracle/backup/redo02b.rdo 2 1 UNUSED /oracle/oradata/orcl/redo02.log 3 1 UNUSED /oracle/backup/redo03b.rdo 3 1 UNUSED /oracle/oradata/orcl/redo03.log 5 1 UNUSED /oracle/backup/redo05b.log 5 1 UNUSED /oracle/oradata/orcl/redo05a.log EOFReference： RMAN recipes for oracle database 11g","link":"/handling-online-redo-log-failures.html"},{"title":"HADR in DB2","text":"HADR is an abbrevation of High Avaiablity Disaster Recovery, as it&#39;s names implies, HADR is a software solution providing high avaiablity and disaster recovery for databases, expecially for 24*7 mission critical systems. The technology can be classified as a replication solution. Basically, it replicates data by sending and replaying logs from a source database called primary database to a target database called standby database. HADR is currently avaliable for single-partitioned databases only. 1. Introduction1.1 RequirementsOS should be the same version including patches. If rolling update happening, you can violate this rules for a short time DB2 version and the level must be identical on both servers, including the bit size. (32bit or 64bit) Nerwork interface must be available on both server Bufferpool size should be the same The database name should be identical, that means they must be in different instances if they reside in a same server Tablespace must be identical The log file space also should be the same on both server The system clock must be sychronized on both servers 1.2 Drawback of HADRBackup operations are not supported on standby databases Not support infinite logging Not support no logging transaction Not support for DPF Not support in DB2 pureScale environments (v10.5 support) 1.3 What HADR can doRead on standby (supported db2 v9.7.1 and above)Read on standby can enable you to run read-only operations on standby. Rolling update without any downtime for running applicationsEnable you rolling update the database with minimal downtime or zero downtime when updating a fix pack version, but not supported upgrade from major version to a high major version, for example, it&#39;s supported update from 9.7.5 to 9.7.10, but not supported upgrade from 9.7 to 10.1. The main reason that HADR rolling update cannot cross major version boundary is that DB2 transaction logs from the new release may not be compatible with the old release, but HADR requires log compatibility on primary and standby. Delayed reply, new feature in 10.1This feature helps prevent data loss due to errant transactions. When standby server set the hadr_replay_delay database configuration parameter,it will keep standby database at a point in time that is earlier than primary database, if someone deleted some database by accidentally in primary, because standby didn&#39;t replay this errant transaction, so you can only copy the deleted data from standby to primary, or just take over in standby as primary. Log Spooling, new feature in 10.1This feature allows transactions on primary to make progress without having to wait for the log replay on the standby. When this feature is enabled, log data sent by the primary is spooled, or written, to disk on the standby, and that log data is later read by log replay. Mutilple standby, new feature in 10.1Before 10.1, HADR only supported one standby database, but from 10.1 and above, it&#39;s supported multiple standby database. For example, you can deploy a standby for delayed replying, and another standby for normal purpose. 2. Setup HADR with command lineSummary of testing information:123server name |instance name |hadr port |database namehadr01 db2v10i DB2_HADR01_P/51000 mysamplehadr02 db2v10i DB2_HADR02_S/51001 2.1 Prepare for the environmentIf it&#39;s a totally new build env, you can install and create DB2 database as Install DB2 in Linux. As in standby server, only install software and create instance, no need to create database. Also you need an identical env as primary, so do not forget to create necessery directories in standby server, set permissions on the new directories. 2.2 Setup the requirement of primaryturn on the archival log mode1db2 update db cfg for mysample using LOGARCHMETH1 disk:/db2/arch/mysample enable LOGINDEXBUILDSet the parameter LOGINDEXBUILD to ON so that index creation, recreation, or reorgnization operations are logged. If the parameter is set to OFF, then there&#39;s not enough logging information for building the indexes on the standby, therefore, the new indexes created or rebuilt are marked as invalid on the standby. Also will increase time consume when standby activate because of rebuilding the invalid indexes.1db2 update database configuration for mysample using LOGINDEXBUILD ON configure INDEXREC parameaterThis parameter controls the rebuild of invalid indexes on database startup, in HADR, this parameter should be set to RESTART on both servers.1db2 update dbm cfg using INDEXREC RESTART 2.3 Take an offline backup of primaryTake an offline backup and send the backup image to the standby, restore to rollforward pending status, DO NOT issue rollforward command. Because standby database needs in rollforward pending state for replaying logs.1234567891011--on primarydb2 backup db mysample to /db2/backup/scp /db2/backup/MYSAMPLE.0.db2v10i.NODE0000.CATN0000.20160308233246.001 hadr02:/db2/backup/--on standby[db2v10i@hadr02 ~]$ mkdir -p /db2/arch/mysample[db2v10i@hadr02 ~]$ mkdir -p /db2/data/db2v10i[db2v10i@hadr02 ~]$ mkdir -p /db2/log/mysample[db2v10i@hadr02 ~]$ db2 restore db mysample from /db2/backup taken at 20160308233246 DBPATH ON &apos;/db2/data/db2v10i&apos; redirect[db2v10@node2 ~]$ db2 restore db mysample continue--do not forget set LOGINDEXBUILD to ON in standby serverdb2 update database configuration for mysample using LOGINDEXBUILD ON 2.4 Configure database parameters of HADR on primary123456db2 update db cfg for mysample using HADR_LOCAL_HOST hadr01 --should be primary ip addr or hostnamedb2 update db cfg for mysample using HADR_LOCAL_SVC DB2_HADR01_P --should be primary hadr service portdb2 update db cfg for mysample using HADR_REMOTE_HOST hadr02 --should be standby ip add or hostnamedb2 update db cfg for mysample using HADR_REMOTE_SVC DB2_HADR02_S --should be standby hadr service portdb2 update db cfg for mysample using HADR_REMOTE_INST db2v10i --should be standy server&apos;s instancedb2 update db cfg for mySAMPLE using HADR_SYNCMODE nearsync --sychronization mode 2.5 Configure database parameters of HADR on standby123456db2 update db cfg for mysample using HADR_LOCAL_HOST hadr02 --should be standby ip addr or hostnamedb2 update db cfg for mysample using HADR_LOCAL_SVC DB2_HADR02_S --should be standby hadr service portdb2 update db cfg for mysample using HADR_REMOTE_HOST hadr01 --should be primary ip addr or hostnamedb2 update db cfg for mysample using HADR_REMOTE_SVC DB2_HADR01_P --should be primary hadr service portdb2 update db cfg for mysample using HADR_REMOTE_INST db2v10idb2 update db cfg for mySAMPLE using HADR_SYNCMODE nearsync Be aware, the value for hadr_local_svc on the primary or standby database systems cannot be the same as the value of svcename or svcename +1 on their corresponding hosts. For instance,my instance SVCENAME is 50000, then you cannot use 50000 or 50001 for the HADR service port. 2.6 Start HADR on primary and standbyRecommend startup standby first.1234--on standydb2 start hadr on database mysample as standby--on primarydb2 start hadr on database mysample as primary If maintenance tasks hanppened, such as OS upgrade, fix pack need to restart the HADR, do not issue any db2 stop hadr on db command at any host. Stop HADR123456--First on standbydb2 deactivate db mysampledb2stop--Then on primarydb2 deactivate database mysampledb2stop Start HADR123456--First on the primarydb2startdb2 activate db mysample--Then on standbydb2startdb2 activate db mysample 3. RoS in HADRFrom DB2 version v9.7.1, standby database is supported enable read on standby feature, this feature is enable query statements with UR isolation level in standby while log reply is happening simultaneously.123456789101112--enable RoS in standby[db2v10i@hadr02 ~]$ db2set DB2_HADR_ROS=ON[db2v10i@hadr02 ~]$ db2set DB2_STANDBY_ISO=UR[db2v10i@hadr02 ~]$ db2 terminateDB20000I The TERMINATE command completed successfully.[db2v10i@hadr02 ~]$ db2 deactivate db mysampleDB20000I The DEACTIVATE DATABASE command completed successfully.[db2v10i@hadr02 ~]$ db2stop &amp;&amp; db2start03/09/2016 18:42:53 0 0 SQL1064N DB2STOP processing was successful.SQL1064N DB2STOP processing was successful.03/09/2016 18:42:54 0 0 SQL1063N DB2START processing was successful.SQL1063N DB2START processing was successful. Let&#39;s start HADR and have a test.12[db2v10i@hadr02 ~]$ db2 start hadr on db mysample as standbyDB20000I The START HADR ON DATABASE command completed successfully. In primary, we create a new table, and insert some records into the table, see if it can be queried or not in standby.123456[db2v10i@hadr01 ~]$ db2 &quot;create table t like syscat.tables&quot;DB20000I The SQL command completed successfully.[db2v10i@hadr01 ~]$ db2 &quot;insert into t select * from syscat.tables&quot;DB20000I The SQL command completed successfully.[db2v10i@hadr01 ~]$ db2 &quot;select count(*) from t&quot; 438 Finding the result of standby server.123[db2v10i@hadr02 ~]$ db2 connect to mysample[db2v10i@hadr02 ~]$ db2 &quot;select count(*) from t with ur&quot; 438 There are till some restrictions on RoS, standby database only support UR isolation level, Automatic Client Reroute not supported in RoS, when DDL replaying on standby, user cannot access to the standby in RoS, also with some maintenance tasks such as runstats, reorg, so, it&#39;s recommended when doing maintenance tasks, choose a maintenance window to accomplish it. 4. Planned takeoverTakeover also call switch roles, when planning some maintenance tasks in primary server, to minimize the downtime, standby can takeover as a primary role. Switching roles only be avaliable when databases are in peer state. And do not forget to rerouter the clients either manually or by ACR after takeover.1234567891011121314151617--monitoring the states of HADR by db2pd or get snapshot command[db2v10i@hadr01 ~]$ db2 get snapshot for database on mysample |grep -i hadr -A 6HADR Status Role = Primary State = Peer Synchronization mode = Nearsync Connection status = Connected, 03/09/2016 18:44:10.197363 Heartbeats missed = 0 Local host = hadr01 Local service = HADR01 Remote host = hadr02 Remote service = HADR02 Remote instance = db2v10i timeout(seconds) = 120 Primary log position(file, page, LSN) = S0000004.LOG, 654, 000000000355638A Standby log position(file, page, LSN) = S0000004.LOG, 654, 000000000355638A Log gap running average(bytes) = 158 If the state is in peer, we can takeover now.1234567891011121314151617181920--on standby[db2v10i@hadr02 ~]$ db2 takeover hadr on db mysampleDB20000I The TAKEOVER HADR ON DATABASE command completed successfully.--finding the roles by using get snapshot command, you will find the roles are changed[db2v10i@hadr01 ~]$ db2 get snapshot for database on mysample |grep -i hadr -A 6HADR Status Role = Standby State = Peer Synchronization mode = Nearsync Connection status = Connected, 03/09/2016 18:44:10.197363 Heartbeats missed = 0 Local host = hadr01 Local service = HADR01 Remote host = hadr02 Remote service = HADR02 Remote instance = db2v10i timeout(seconds) = 120 Primary log position(file, page, LSN) = S0000004.LOG, 654, 0000000003556527 Standby log position(file, page, LSN) = S0000004.LOG, 654, 0000000003556527 Log gap running average(bytes) = 864220 When the maintenance jobs are done, you can switch over the roles.Besides switch over, there&#39;s a takeover called takeover by force, it means failover, if the primary not functional, you should use takeover by force. When failover happened, it means the HADR not functional anymore, you need re-build the HADR by backup image. 5. HADR monitoringYou can monitor HADR status by db2pd or db2 get snapshot command. 5.1 db2pd123456789101112131415161718192021222324252627282930313233343536373839[db2v10i@hadr01 ~]$ db2pd -d mysample -hadr show detailDatabase Member 0 -- Database MYSAMPLE -- Active -- Up 0 days 00:00:33 -- Date 03/14/2016 15:48:38 HADR_ROLE = PRIMARY REPLAY_TYPE = PHYSICAL HADR_SYNCMODE = NEARSYNC STANDBY_ID = 1 LOG_STREAM_ID = 0 HADR_STATE = PEER PRIMARY_MEMBER_HOST = hadr01 PRIMARY_INSTANCE = db2v10i PRIMARY_MEMBER = 0 STANDBY_MEMBER_HOST = hadr02 STANDBY_INSTANCE = db2v10i STANDBY_MEMBER = 0 HADR_CONNECT_STATUS = CONNECTED HADR_CONNECT_STATUS_TIME = 03/14/2016 15:48:06.525597 (1457941686) HEARTBEAT_INTERVAL(seconds) = 30 HADR_TIMEOUT(seconds) = 120 TIME_SINCE_LAST_RECV(seconds) = 3 PEER_WAIT_LIMIT(seconds) = 0 LOG_HADR_WAIT_CUR(seconds) = 0.000 LOG_HADR_WAIT_RECENT_AVG(seconds) = 0.000000 LOG_HADR_WAIT_ACCUMULATED(seconds) = 0.000 LOG_HADR_WAIT_COUNT = 0SOCK_SEND_BUF_REQUESTED,ACTUAL(bytes) = 0, 19800SOCK_RECV_BUF_REQUESTED,ACTUAL(bytes) = 0, 87380 PRIMARY_LOG_FILE,PAGE,POS = S0000001.LOG, 0, 44836001 STANDBY_LOG_FILE,PAGE,POS = S0000001.LOG, 0, 44836001 HADR_LOG_GAP(bytes) = 0 STANDBY_REPLAY_LOG_FILE,PAGE,POS = S0000001.LOG, 0, 44836001 STANDBY_RECV_REPLAY_GAP(bytes) = 0 PRIMARY_LOG_TIME = 03/10/2016 15:55:08.000000 (1457596508) STANDBY_LOG_TIME = 03/10/2016 15:55:08.000000 (1457596508) STANDBY_REPLAY_LOG_TIME = 03/10/2016 15:55:08.000000 (1457596508) STANDBY_RECV_BUF_SIZE(pages) = 512 STANDBY_RECV_BUF_PERCENT = 0 STANDBY_SPOOL_LIMIT(pages) = 0 PEER_WINDOW(seconds) = 0 READS_ON_STANDBY_ENABLED = N 5.2 db2 get snapshot123456789101112131415161718192021222324[db2v10i@hadr01 ~]$ db2 get snapshot for database on mysample |grep -i hadr -A 6Catalog network node name = hadr01Operating system running at database server= LINUXAMD64Location of the database = LocalFirst database connect timestamp = 03/14/2016 15:48:05.953771Last reset timestamp =Last backup timestamp = 03/10/2016 15:50:28.000000Snapshot timestamp = 03/14/2016 15:56:55.513115--HADR Status Role = Primary State = Peer Synchronization mode = Nearsync Connection status = Connected, 03/14/2016 15:48:06.525597 Heartbeats missed = 0 Local host = hadr01 Local service = 57000 Remote host = hadr02 Remote service = 58000 Remote instance = db2v10i timeout(seconds) = 120 Primary log position(file, page, LSN) = S0000001.LOG, 0, 0000000002AC24A1 Standby log position(file, page, LSN) = S0000001.LOG, 0, 0000000002AC24A1 Log gap running average(bytes) = 0 5.3 by catalog view12345678[db2v10i@hadr01 ~]$ db2 &quot;select substr(DB_NAME,1,10) as DBNAME,substr(HADR_CONNECT_STATUS,1,10) as connect_stat, \\substr(HADR_ROLE,1,10) as ROLE,substr(HADR_STATE,1,10) as state,substr(HADR_SYNCMODE,1,10) as syncmode, \\substr(HADR_HEARTBEAT,1,10) as heartbeat,substr(HADR_LOCAL_HOST,1,10) as local,\\substr(HADR_REMOTE_HOST,1,10) as remote, SNAPSHOT_TIMESTAMP from sysibmadm.snaphadr&quot;DBNAME CONNECT_STAT ROLE STATE SYNCMODE HEARTBEAT LOCAL REMOTE SNAPSHOT_TIMESTAMP---------- ------------ ---------- ---------- ---------- ---------- ---------- ---------- --------------------------MYSAMPLE CONNECTED PRIMARY PEER NEARSYNC 0 hadr01 hadr02 2016-03-14-15.58.03.220468 6. ACRAutomatic Client Reroute is a feature that enables a DB2 client to recover from a loss of connection to the DB2 server by rerouting the connection to an alternate server.This automatic connection rerouting occurs automatically. 6.1 Catalog primary DB on clients1234[db2cae@db2client ~]$ db2 catalog tcpip node hadr01 remote 192.168.56.101 server 50000DB20000I The CATALOG TCPIP NODE command completed successfully.[db2cae@db2client ~]$ db2 catalog database mysample as mysample at node hadr01DB20000I The CATALOG DATABASE command completed successfully. 6.2 Configure ACR in primary and standby123456--on primary[db2v10i@hadr01 ~]$ db2 update alternate server for database mysample using hostname hadr02 port 50000DB20000I The UPDATE ALTERNATE SERVER FOR DATABASE command completed successfully.--on standby[db2v10i@hadr02 ~]$ db2 update alternate server for database mysample using hostname hadr01 port 50000DB20000I The UPDATE ALTERNATE SERVER FOR DATABASE command completed successfully. 6.3 Running query in client while takeover occur123456[db2cae@db2client ~]$ db2 connect to mysample user db2v10i[db2cae@db2client ~]$ db2 &quot;select count(*) from t&quot;1----------- 438 1 record(s) selected. Let the standby takeover as primary, do not disconnect client&#39;s connection by manually.12345678910111213[db2v10i@hadr02 ~]$ db2 takeover hadr on db mysampleDB20000I The TAKEOVER HADR ON DATABASE command completed successfully.--query continue while takeover occur[db2cae@db2client ~]$ db2 &quot;select count(*) from t&quot;SQL30108N A connection failed in an automatic client reroute environment. Anyassociated transaction was rolled back. Host name or IP address: &quot;hadr02&quot;.Service name or port number: &quot;50000&quot;. Reason code: &quot;1&quot;. Connection failurecode: &quot;2&quot;. Underlying error: &quot;*&quot;. SQLSTATE=08506[db2cae@db2client ~]$ db2 &quot;select count(*) from t&quot;1----------- 438 1 record(s) selected. You cannot use the automatic client reroute (ACR) if you enable the read on standby feature. 7. New feature on HADR examples7.1 Delayed reply and log spoolingThe database configuration parameter HADR_REPLAY_DELAY define the amount time of delayed replay in seconds (this parameter should only be configured in standby), value zero means turn off this feature, which is the default value. Log delayed replay is depend on the following rules, it&#39;s important to sychronize the system clock between primary and standby system.123--log replay occurred follow below rules(current time on the standby - value of the hadr_replay_delay configuration parameter) &gt;= timestamp of the committed log record It&#39;s recommended to configure log spooling feature when enabling delayed replay. For the convience of query on the standby, I also enable the RoS on the standby.Restrictions on delayed relay: Only support superasync synchronization mode Not support take over while enable this feature 7.2 examples for delayed reply and log spoolingModify sychronization mode, the database configuration parameter HADR_SYNCMODE is not dynamic, every change to the sychronization mode requires a database restart for both primary and standby databases.123456--change sync mode to super-async[db2v10i@hadr01 ~]$ db2 update db cfg for mysample using HADR_SYNCMODE superasync[db2v10i@hadr02 ~]$ db2 update db cfg for mysample using HADR_SYNCMODE superasync--enable log spooling in standby[db2v10i@hadr02 ~]$ db2 update db cfg using HADR_SPOOL_LIMIT 25600DB20000I The UPDATE DATABASE CONFIGURATION command completed successfully. Enable RoS on standby:12345678910111213141516171819[db2v10i@hadr02 ~]$ db2set DB2_STANDBY_ISO=UR[db2v10i@hadr02 ~]$ db2set DB2_HADR_ROS=ON[db2v10i@hadr02 ~]$ db2setDB2_STANDBY_ISO=URDB2_HADR_ROS=ON--recycle the instance to enable RoS[db2v10i@hadr02 ~]$ db2 deactivate db mysampleDB20000I The DEACTIVATE DATABASE command completed successfully.[db2v10i@hadr02 ~]$ db2 stop hadr on db mysampleDB20000I The STOP HADR ON DATABASE command completed successfully.[db2v10i@hadr02 ~]$ db2stop &amp;&amp; db2start03/14/2016 16:48:26 0 0 SQL1064N DB2STOP processing was successful.SQL1064N DB2STOP processing was successful.03/14/2016 16:48:28 0 0 SQL1063N DB2START processing was successful.SQL1063N DB2START processing was successful.[db2v10i@hadr02 ~]$ db2 start hadr on db mysample as standbyDB20000I The START HADR ON DATABASE command completed successfully.[db2v10i@hadr01 ~]$ db2pd -d mysample -hadr|grep -i read READS_ON_STANDBY_ENABLED = Y Enable delayed replay feature:12345678--configure delay replay parameter on standby[db2v10i@hadr02 ~]$ db2 update db cfg for mysample using HADR_REPLAY_DELAY 600--restart hadr on both servers[db2v10i@hadr02 ~]$ db2 deactivate db mysample[db2v10i@hadr02 ~]$ db2 stop hadr on db mysample[db2v10i@hadr01 ~]$ db2 stop hadr on db mysample[db2v10i@hadr02 ~]$ db2 start hadr on db mysample as standby[db2v10i@hadr01 ~]$ db2 start hadr on db mysample as primary Now the HADR status should be catchup:12[db2v10i@hadr01 ~]$ db2pd -d mysample -hadr|grep -i state HADR_STATE = REMOTE_CATCHUP Create a test table and insert one rows in primary:1234[db2v10i@hadr01 ~]$ db2 &quot;create table t(id int, name char(20))&quot;DB20000I The SQL command completed successfully.[db2v10i@hadr01 ~]$ db2 &quot;insert into t values(51369,&apos;FUNG&apos;)&quot;DB20000I The SQL command completed successfully. Even if we enabled RoS on standby now, but because of RoS restrictions on DDL, when replaying DDL happened on standby, cannot access to the standby,123456[db2v10i@hadr02 ~]$ db2 connect to mysampleSQL1776N The command cannot be issued on an HADR standby database. Reason code = &quot;4&quot;.[db2v10i@hadr01 ~]$ db2pd -d mysample -hadr |grep -i replay_only STANDBY_REPLAY_ONLY_WINDOW_ACTIVE = Y #replay only window is active STANDBY_REPLAY_ONLY_WINDOW_START = 03/14/2016 16:56:19.000000 (1457945779)STANDBY_REPLAY_ONLY_WINDOW_TRAN_COUNT = 1 Trying to connect in standby 10 mins later:12345678910[db2v10i@hadr02 ~]$ db2 connect to mysample[db2v10i@hadr02 ~]$ dateMon Mar 14 17:06:27 CST 2016[db2v10i@hadr02 ~]$ db2 &quot;select * from t&quot;ID NAME----------- -------------------- 51369 FUNG 1 record(s) selected. Now we insert another rows and delete first rows in primary, and query the table from standby:1234567891011[db2v10i@hadr01 ~]$ db2 &quot;insert into t values(111,&apos;KONG&apos;)&quot;DB20000I The SQL command completed successfully.[db2v10i@hadr01 ~]$ db2 &quot;delete from t where name=&apos;FUNG&apos;&quot;DB20000I The SQL command completed successfully.[db2v10i@hadr02 ~]$ db2 &quot;select * from t&quot;ID NAME----------- -------------------- 51369 FUNG 111 KONG 2 record(s) selected. What happened? The deleted data still in the standby with inserted data? If delayed replay works, we should only see the first rows in the table. Actually, in the DB2, not all operations in the log recorded the timestamp, the automatic committed operation contains 2 operations: insert and commit, when insert operation is transferred to standby, this insert operation is replayed first,but not committed.So you can query this row by UR isolation. Next, I stop the HADR on the standby, and rollforward it as complete:1234567891011121314151617181920[db2v10i@hadr02 ~]$ db2 terminate[db2v10i@hadr02 ~]$ db2 deactivate db mysample[db2v10i@hadr02 ~]$ db2 stop hadr on db mysample[db2v10i@hadr02 ~]$ db2 rollforward db mysample complete Rollforward Status Input database alias = mysample Number of members have returned status = 1 Member ID = 0 Rollforward status = not pending Next log file to be read = Log files processed = S0000000.LOG - S0000001.LOG Last committed transaction = 2016-03-14-08.58.44.000000 UTCDB20000I The ROLLFORWARD command completed successfully.[db2v10i@hadr02 ~]$ db2 connect to mysample[db2v10i@hadr02 ~]$ db2 &quot;select * from t&quot;ID NAME----------- -------------------- 51369 FUNG 1 record(s) selected. The query result is what we expects, insert and delete operations are all delayed replay, so the only data we can see in the table is the original rows. but remember, if you issue rollforward command to the standby database, you should rebuild the HADR via backup image. Never do that in a production environment. 8. ConclusionsThe mechanism of HADR is primary database sends the log contents to be replayed on standby. There are 2 special euds processes to handle the log transmission,db2hadrp on primary and db2hadrs on standby.1234[db2v10i@hadr01 ~]$ db2pd -edus|grep -i hadr30 139899399300864 3405 db2hadrp (MYSAMPLE) 0 0.000000 0.020000[db2v10i@hadr02 ~]$ db2pd -edus |grep -i hadr30 140435959834368 3299 db2hadrs (MYSAMPLE) 0 0.010000 0.040000 There are 2 important parameters:HADR_TIMEOUT: Specified the amount of time (in seconds) to wait before HADR considers the communication lost between database pairs.If an HADR database does not receive any communication from its partner database for longer than the length of time specified by the hadr_timeout database configuration parameter, then the database concludes that the connection with the partner database is lost.HADR_PEER_WINDOW: Specified the amount of time (in seconds) in which the primary database suspends a transaction after the database pairs have entered disconnect state. Next topic will be how to rolling update (fix pack) in HADR.EOF","link":"/hadr-in-db2.html"},{"title":"11gr2 RAC Resource管理","text":"1.RAC中有哪些资源 RAC中定义了若干种资源，这些资源的定义被存放在OCR中，当GI启动后，产生了VIP，SCAN，ASM进程，磁盘组等资源。 此外，数据库被创建后，还有数据库，实例，监听等资源，对于这些各种各样的资源，可以通过SQLPLUS，EM，srvctl及crsctl等工具进行管理。 2.svrctl I．数据库管理 1234567891011[oracle@ora11g:/home/oracle]$ srvctl status database -d fung Instance fung1 is running on node ora11g [oracle@ora11g:/home/oracle]$ srvctl status instance -d fung -i fung1 Instance fung1 is running on node ora11g [oracle@ora11g:/home/oracle]$ srvctl stop database -h Stops the database. Usage: srvctl stop database -d &lt;db_unique_name&gt; [-o &lt;stop_options&gt;] [-f] -d &lt;db_unique_name&gt; Unique name for the database -o &lt;stop_options&gt; Options to shutdown command (e.g. NORMAL, TRANSACTIONAL, IMMEDIATE, or ABORT) -f Force stop, will stop database and any associated services and any dependent resources -h Print usage 12345678910111213[oracle@ora11g:/home/oracle]$ srvctl stop database -d fung -o immediate [oracle@ora11g:/home/oracle]$ srvctl status database -d fung Instance fung1 is not running on node ora11g [oracle@ora11g:/home/oracle]$ srvctl start database -h Starts the database. Usage: srvctl start database -d &lt;db_unique_name&gt; [-o &lt;start_options&gt;] [-n &lt;node&gt;] -d &lt;db_unique_name&gt; Unique name for the database -o &lt;start_options&gt; Options to startup command (e.g. OPEN, MOUNT, or &apos;READ ONLY&apos;) -n &lt;node&gt; Node on which to start the database (only for RAC One Node databases) -h Print usage[oracle@ora11g:/home/oracle]$ srvctl start database -d fung [oracle@ora11g:/home/oracle]$ srvctl status database -d fung Instance fung1 is running on node ora11g II．监听管理 123456789101112131415161718[oracle@ora11g:/home/oracle]$ srvctl status listener Listener LISTENER is enabled Listener LISTENER is running on node(s): ora11g[oracle@ora11g:/home/oracle]$ srvctl start listener -h Starts the listener. Usage: srvctl start listener [-l &lt;lsnr_name&gt;] [-n &lt;node_name&gt;] -l &lt;lsnr_name&gt; Listener name -n &lt;node_name&gt; Node name -h Print usage[oracle@ora11g:/home/oracle]$ srvctl stop listener -h Stops the listener. Usage: srvctl stop listener [-l &lt;lsnr_name&gt;] [-n &lt;node_name&gt;] [-f] -l &lt;lsnr_name&gt; Listener name -n &lt;node_name&gt; Node name -f Force stop -h Print usage III．ASM管理 12345678910111213141516[oracle@ora11g:/home/oracle]$ srvctl status asm ASM is running on ora11g[oracle@ora11g:/home/oracle]$ srvctl start asm -h Starts ASM instance. Usage: srvctl start asm [-n &lt;node_name&gt;] [-o &lt;start_options&gt;] -n &lt;node_name&gt; Node name -o &lt;start_options&gt; Options to startup command (e.g. OPEN, MOUNT, or NOMOUNT) -h Print usage [oracle@ora11g:/home/oracle]$ srvctl stop asm -h Stops ASM instance. Usage: srvctl stop asm [-n &lt;node_name&gt;] [-o &lt;stop_options&gt;] [-f] -n &lt;node_name&gt; Node name -o &lt;stop_options&gt; Options to shutdown command (e.g. NORMAL, TRANSACTIONAL, IMMEDIATE, or ABORT) -f Force stop -h Print usage IV．ASM磁盘组管理 1234567891011121314151617181920212223242526[oracle@ora11g:/home/oracle]$ srvctl status diskgroup -h Displays the current state of the diskgroup. Usage: srvctl status diskgroup -g &lt;dg_name&gt; [-n &quot;&lt;node_list&gt;&quot;] [-a] [-v] -g &lt;dg_name&gt; Disk Group name -n &quot;&lt;node_list&gt;&quot; Comma separated node names -a Print detailed status information -v Verbose output -h Print usage[oracle@ora11g:/home/oracle]$ srvctl status diskgroup -g OCR Disk Group OCR is running on ora11g [oracle@ora11g:/home/oracle]$ srvctl stop diskgroup -h Stops the diskgroup. Usage: srvctl stop diskgroup -g &lt;dg_name&gt; [-n &quot;&lt;node_list&gt;&quot;] [-f] -g &lt;dg_name&gt; Disk Group name -n &quot;&lt;node_list&gt;&quot; Comma separated node names -f Force stop -h Print usage[oracle@ora11g:/home/oracle]$ srvctl start diskgroup -h Starts the diskgroup, causing ASM to mount it. Usage: srvctl start diskgroup -g &lt;dg_name&gt; [-n &quot;&lt;node_list&gt;&quot;] -g &lt;dg_name&gt; Disk Group name -n &quot;&lt;node_list&gt;&quot; Comma separated node names -h Print usage V．其他命令 通过srvctl的enable、disable、remove、add等子命令，对各种资源进行激活、禁止、删除和添加，以监听管理为例： 123$srvctl enable/disable listener -l LISTENER -n node1 $srvctl remove listener -l LISTENER $srvctl add listener -l LISTENER -p 1521 -o $ORACLE_HOME VI.修改VIP 查看VIP配置情况： 12[grid@ora11g:/home/grid]$ srvctl config vip -n ora11g VIP exists: /fung-vip/192.168.137.111/192.168.137.0/255.255.255.0/eth0, hosting node ora11g 修改VIP，必须先停止数据库Service服务，如： 1[grid@ora11g:/home/grid]$ srvctl stop listener -n ora11g 接着，关闭这个节点的VIP资源 1$srvctl stop vip -n node1 以root用户修改VIP： 1[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl modify nodeapps -n ora11g -A 192.168.137.110/255.255.255.0/eth0 确认修改情况 12[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl config vip -n ora11g VIP exists: /192.168.137.110/192.168.137.110/192.168.137.0/255.255.255.0/eth0, hosting node ora11g 再次启动VIP服务： 12[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl start vip -n ora11g [root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl start listener -n ora11g VII．修改SCAN 先查询当前SCAN配置： 123[grid@ora11g:/home/grid]$ srvctl config scan SCAN name: scan-ip, Network: 1/192.168.137.0/255.255.255.0/eth0 SCAN VIP name: scan1, IP: /scan-ip/192.168.137.112 关闭当前SCAN资源： 12345[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl stop scan_listener [root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl stop scan [root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl status scan SCAN VIP scan1 is enabled SCAN VIP scan1 is not running 修改SCAN： 123456[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl modify scan -n fung-scan [root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl start scan [root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl start scan_listener [root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./srvctl config scan SCAN name: fung-scan, Network: 1/192.168.137.0/255.255.255.0/eth0 SCAN VIP name: scan1, IP: /fung-scan/192.168.137.111 VIII．修改Public IP 显示当前网卡配置： 123[grid@ora11g:/home/grid]$ oifcfg getif eth0 192.168.137.0 global public eth1 10.0.0.0 global cluster_interconnect 停止数据库及监听： 12[grid@ora11g:/home/grid]$ srvctl stop database -d fung -o immediate [grid@ora11g:/home/grid]$ srvctl stop listener -n ora11g 以root用户停止CRS： 1[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./crsctl stop crs 通过OS命令修改此节点Public IP。 启动CRS服务，并且用以下命令修改Public IP： 1[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./oifcfg setif -global eth0/192.168.137.13:public IX．修改private IP 保证CRS服务在线，使用以下命令修改： 1[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]# ./oifcfg setif -global eth1/192.76.31.0:cluster_interconnect 两边节点停止数据库及CRS： 12[root@ora11g:/u01/app/grid/product/11.2.0.4/bin]#./srvctl stop database -d gdcdc -o immedate [root@ora11g:/u01/app/grid/product/11.2.0.4/bin]#./crsctl stop crs 修改/etc/hosts，接着使用OS工具修改eth1网卡IP地址。启动crs并且检验修改结果。 RAC IP地址修改有风险，需谨慎！ EOF","link":"/manage-11gr2-rac-resource.html"},{"title":"Step by step install 11gr2 RAC in silent mode","text":"本文实验环境以vbox虚拟机，OEL5.8 X64下完成，ASM底层采取udev管理。以下为详细实验步骤，留给以后参考。OS安装及共享设备设置略过。非明确指出，即表明所做操作为两个节点。 1.安装前准备 1.1.关闭非必要进程 chkconfig acpid off chkconfig autofs off chkconfig avahi-daemon off chkconfig bluetooth off chkconfig hidd off chkconfig cups off chkconfig cpuspeed off chkconfig --level 245 gpm off chkconfig hplip off chkconfig ip6tables off chkconfig iptables off chkconfig irqbalance off chkconfig isdn off chkconfig lm_sensors off chkconfig mcstrans off chkconfig netfs off chkconfig nfslock off chkconfig pcscd off chkconfig portmap off chkconfig restorecond off chkconfig rpcgssd off chkconfig rpcidmapd off chkconfig sendmail off chkconfig smartd off chkconfig yum-updatesd off chkconfig xfs off chkconfig microcode_ctl off chkconfig iscsi off chkconfig iscsid off 1.2.安装oracle-validated Oracle-validated是OEL自带的oracle安装环境部署设置，包括内核参数、用户设置等。首先配置yum本地源，先将光盘mount至/mnt，再通过yum设置/mnt为本地源： 12345678910[root@node1 app]# cd /etc/yum.repos.d/ [root@node1 app]# vi rhel-debuginfo.repo [root@node1 app]# cat /etc/yum.repos.d/rhel-debuginfo.repo [Server] name=Server baseurl=file:///mnt/Server enabled=1 gpgcheck=0 [root@node1 app]# yum search oracle [root@node1 app]# yum install oracle-validated 1.3.创建用户环境 由于oracle-validated只是增加了oracle用户，GI拥有着gird用户需要我们自己创建， 1234567[root@node1 app]# id oracle uid=54321(oracle) gid=54321(oinstall) groups=54321(oinstall),54322(dba) [root@node1 app]# useradd -u 54322 -g oinstall grid [root@node1:/root]# groupadd -g 54323 asmdba [root@node1:/root]# groupadd -g 54324 asmadmin [root@node1:/root]# usermod -G oinstall,asmadmin,asmdba,dba grid [root@node1:/root]# usermod -G oinstall,asmdba,dba oracle 修改密码： 12#passwd oracle #passwd grid 添加环境变量： 123456789101112131415161718192021222324252627282930313233343536[root@node2 u01]# cat /home/grid/.bash_profile ... export TMP=/tmp export TMPDIR=$TMP export ORACLE_SID=+ASM2 export ORACLE_BASE=/u01/app/grid export ORACLE_HOME=/u01/app/11gr2/grid export JAVA_HOME=$ORACLE_HOME/jdk export ORACLE_TERM=xterm export NLS_DATE_FORMAT=&quot;yyyy-mm-dd HH24:MI:SS&quot; export ORA_NLS11=$ORACLE_HOME/nls/data export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib export CLASSPATH=$ORACLE_HOME/JRE:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlib export PATH=/usr/sbin:$ORACLE_HOME/bin:$JAVA_HOME:$PATH export PS1=&apos;[$LOGNAME@$HOSTNAME:$PWD]$ &apos; umask 022 export DISPLAY=192.168.56.1:0.0 [root@node2 u01]# cat /home/oracle/.bash_profile …export EDITOR=vi export TMP=/tmp export TMPDIR=$TMP export ORACLE_BASE=/u01/app/oracle export ORACLE_HOME=$ORACLE_BASE/product/11gr2/ export JAVA_HOME=$ORACLE_HOME/jdk export ORACLE_SID=racdb2 export ORACLE_TERM=xterm export PATH=/usr/sbin:$ORACLE_HOME/bin:$JAVA_HOME:$PATH export ORA_NLS11=$ORACLE_HOME/nls/data export LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/lib export CLASSPATH=$ORACLE_HOME/JRE:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlib export NLS_DATE_FORMAT=&quot;yyyy-mm-dd HH24:MI:SS&quot; export NLS_LANG=AMERICAN_AMERICA.ZHS16GBK export PS1=&apos;[$LOGNAME@$HOSTNAME:$PWD]$ &apos; umask 022 export DISPLAY=192.168.56.1:0.0 创建相关目录： 123456789[root@node1 app]# mkdir -p /u01/app/grid [root@node1 app]# mkdir -p /u01/app/11gr2/grid [root@node1 app]# chown -R grid:oinstall /u01/app/ [root@node1 app]# chmod -R 775 /u01/app [root@node1 app]# chown -R grid:oinstall /u01/app/grid [root@node1 app]# chmod -R 775 /u01/app/grid [root@node1 app]# mkdir -p /u01/app/oracle/product/11gr2 [root@node1 app]# chown -R oracle:oinstall /u01/app/oracle [root@node1 app]# chmod -R 775 /u01/app/oracle 移除ntp及dns设置： 12[root@node1 app]# mv /etc/ntp.conf /etc/ntp.conf_bk [root@node1 app]# mv /etc/resolv.conf /etc/resolv.conf_bk 最后需要在/etc/security/limits.conf将grid用户资源添加进去。 主机IP配置： #public IP 192.168.56.111 node1 192.168.56.112 node2 #priv 10.10.10.111 racdb1-priv 10.10.10.112 racdb2-priv #Virtual IP 192.168.56.113 racdb1-vip 192.168.56.114 #SCAN 192.168.56.100 racdb-scan 1.4.ssh等效性设置 两个节点oracle用户及grid用户的信任机制配置： 1234[grid@node1 app]$ mkdir -p ~/.ssh [grid@node1 app]$ chmod 700 ~/.ssh [grid@node1 app]$ ssh-keygen -t rsa [grid@node1 app]$ ssh-keygen -t dsa 以下操作只需其中一节点完成即可： 123456[grid@node1 app]$ cd .ssh [grid@node1 app]$ touch authorized_keys [grid@node1 app]$ cat ~/.ssh/*.pub &gt;&gt;authorized_keys [grid@node1 app]$ ssh node1 cat ~/.ssh/id_rsa.pub &gt;&gt;authorized_keys [grid@node1 app]$ ssh node2 cat ~/.ssh/id_dsa.pub &gt;&gt;authorized_keys [grid@node1 app]$ scp authorized_keys node2:.ssh/authorized_keys 1.5.udev共享存储设置 创建规则文件： 1[root@node1 app]# touch /etc/udev/rules.d/ 99-oracle-asmdevices.rules 使用fdisk -l扫描磁盘，并将识别出来的路径取代以下代码中的变量： 1234[root@node1 app]# for i in b c d e; &gt; do &gt; echo &quot;KERNEL==\\&quot;sd*\\&quot;, BUS==\\&quot;scsi\\&quot;, PROGRAM==\\&quot;/sbin/scsi_id -g -u -s %p\\&quot;, RESULT==\\&quot;`scsi_id -g -u -s /block/sd$i`\\&quot;, NAME=\\&quot;asm-disk$i\\&quot;, OWNER=\\&quot;grid\\&quot;, GROUP=\\&quot;asmadmin\\&quot;, MODE=\\&quot;0660\\&quot;&quot; &gt; done 将以上输出内容添加进规则文件中，重启udev，并且验证： 1234567[root@node1 app]# start_udev Starting udev: [ OK ] [root@node1 app]# ll /dev/asm* brw-rw---- 1 grid dba 8, 16 Sep 12 11:02 /dev/asm-diskb brw-rw---- 1 grid dba 8, 32 Sep 12 11:02 /dev/asm-diskc brw-rw---- 1 grid dba 8, 48 Sep 12 11:02 /dev/asm-diskd brw-rw---- 1 grid dba 8, 64 Sep 12 11:02 /dev/asm-diske 2.安装GI 安装前检查： 12345678910[grid@node1:/worktmp/11g/grid]$ ./runcluvfy.sh stage -pre crsinst -n node1,node2 -verbose Performing pre-checks for cluster services setupChecking node reachability... ...省略部分输出 Check: Time zone consistency Result: Time zone consistency check passed Pre-check for cluster services setup was successful. 有不通过的地方要先fixup完才能继续安装。 修改默认响应文件，可以用以下命令提取必要的东西出来，需要了解各项参数含义，请详细阅读默认响应文件： 1234[grid@node1:/worktmp/11g/grid/response]$ ll total 28 -rw-r--r-- 1 root root 24632 Aug 26 22:01 grid_install.rsp [grid@node1:/worktmp/11g/grid/response]$ cat grid_install.rsp | grep -v ^# | grep -v ^$ &gt; ~/gi.rsp 修改后的响应文件如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[grid@node1:/worktmp/11g/grid/response]$ cat ~/gi.rsp oracle.install.responseFileVersion=/oracle/install/rspfmt_crsinstall_response_schema_v11_2_0 ORACLE_HOSTNAME=node1 INVENTORY_LOCATION=/u01/app/oraInventory SELECTED_LANGUAGES=en,zh_CN oracle.install.option=CRS_CONFIG ORACLE_BASE=/u01/app/grid ORACLE_HOME=/u01/app/11gr2/grid oracle.install.asm.OSDBA=asmdba oracle.install.asm.OSOPER= oracle.install.asm.OSASM=asmadmin oracle.install.crs.config.gpnp.scanName=racdb-scan oracle.install.crs.config.gpnp.scanPort=1521 oracle.install.crs.config.clusterName=racdb oracle.install.crs.config.gpnp.configureGNS=false oracle.install.crs.config.gpnp.gnsSubDomain= oracle.install.crs.config.gpnp.gnsVIPAddress= oracle.install.crs.config.autoConfigureClusterNodeVIP=false oracle.install.crs.config.clusterNodes=node1:racdb1-vip,node2:racdb2-vip oracle.install.crs.config.networkInterfaceList=eth0:192.168.56.0:1,eth1:10.10.10.0:2 oracle.install.crs.config.storageOption=ASM_STORAGE oracle.install.crs.config.sharedFileSystemStorage.diskDriveMapping= oracle.install.crs.config.sharedFileSystemStorage.votingDiskLocations= oracle.install.crs.config.sharedFileSystemStorage.votingDiskRedundancy=NORMAL oracle.install.crs.config.sharedFileSystemStorage.ocrLocations= oracle.install.crs.config.sharedFileSystemStorage.ocrRedundancy=NORMAL oracle.install.crs.config.useIPMI=false oracle.install.crs.config.ipmi.bmcUsername= oracle.install.crs.config.ipmi.bmcPassword= oracle.install.asm.SYSASMPassword=Password123 oracle.install.asm.diskGroup.name=CRS oracle.install.asm.diskGroup.redundancy=NORMAL oracle.install.asm.diskGroup.AUSize=1 oracle.install.asm.diskGroup.disks=/dev/asm-diskb,/dev/asm-diskc,/dev/asm-diskd oracle.install.asm.diskGroup.diskDiscoveryString=/dev/asm* oracle.install.asm.monitorPassword=Password123 oracle.install.crs.upgrade.clusterNodes= oracle.install.asm.upgradeASM=false oracle.installer.autoupdates.option=SKIP_UPDATES oracle.installer.autoupdates.downloadUpdatesLoc= AUTOUPDATES_MYORACLESUPPORT_USERNAME= AUTOUPDATES_MYORACLESUPPORT_PASSWORD= PROXY_HOST= PROXY_PORT= PROXY_USER= PROXY_PWD= PROXY_REALM= 执行安装程序： 123456789101112131415161718192021222324252627282930[grid@node1:/worktmp/11g/grid]$ ./runInstaller -ignorePrereq -silent -force -responseFile ~/gi.rsp Starting Oracle Universal Installer... Checking Temp space: must be greater than 120 MB. Actual 16102 MB Passed Checking swap space: must be greater than 150 MB. Actual 4094 MB Passed Preparing to launch Oracle Universal Installer from /tmp/OraInstall2013-09-12_12-17-53PM. Please wait ... [grid@node1:/worktmp/11g/grid]$ You can find the log of this install session at: /u01/app/oraInventory/logs/installActions2013-09-12_12-17-53PM.log The installation of Oracle Grid Infrastructure 11g was successful. Please check &apos;/u01/app/oraInventory/logs/silentInstall2013-09-12_12-17-53PM.log&apos; for more details. As a root user, execute the following script(s): 1. /u01/app/oraInventory/orainstRoot.sh 2. /u01/app/11gr2/grid/root.sh Execute /u01/app/oraInventory/orainstRoot.sh on the following nodes: [node1, node2] Execute /u01/app/11gr2/grid/root.sh on the following nodes: [node1, node2] As install user, execute the following script to complete the configuration. 1. /u01/app/11gr2/grid/cfgtoollogs/configToolAllCommands RESPONSE_FILE=&lt;response_file /&gt; Note: 1. This script must be run on the same host from where installer was run. 2. This script needs a small password properties file for configuration assistants that require passwords (refer to install guide documentation). Successfully Setup Software. 按照提示，分别在两个节点执行以下脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687[root@node1:/home/grid]# /u01/app/oraInventory/orainstRoot.sh Changing permissions of /u01/app/oraInventory. Adding read,write permissions for group. Removing read,write,execute permissions for world. Changing groupname of /u01/app/oraInventory to oinstall. The execution of the script is complete.[root@node1:/home/grid]# /u01/app/11gr2/grid/root.sh Performing root user operation for Oracle 11g The following environment variables are set as: ORACLE_OWNER= grid ORACLE_HOME= /u01/app/11gr2/grid Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ... Creating /etc/oratab file... Entries will be added to the /etc/oratab file as needed by Database Configuration Assistant when a database is created Finished running generic part of root script. Now product-specific root actions will be performed. Using configuration parameter file: /u01/app/11gr2/grid/crs/install/crsconfig_params Creating trace directory User ignored Prerequisites during installation Installing Trace File Analyzer OLR initialization - successful root wallet root wallet cert root cert export peer wallet profile reader wallet pa wallet peer wallet keys pa wallet keys peer cert request pa cert request peer cert pa cert peer root cert TP profile reader root cert TP pa root cert TP peer pa cert TP pa peer cert TP profile reader pa cert TP profile reader peer cert TP peer user cert pa user cert Adding Clusterware entries to inittab CRS-2672: Attempting to start &apos;ora.mdnsd&apos; on &apos;node1&apos; CRS-2676: Start of &apos;ora.mdnsd&apos; on &apos;node1&apos; succeeded CRS-2672: Attempting to start &apos;ora.gpnpd&apos; on &apos;node1&apos; CRS-2676: Start of &apos;ora.gpnpd&apos; on &apos;node1&apos; succeeded CRS-2672: Attempting to start &apos;ora.cssdmonitor&apos; on &apos;node1&apos; CRS-2672: Attempting to start &apos;ora.gipcd&apos; on &apos;node1&apos; CRS-2676: Start of &apos;ora.gipcd&apos; on &apos;node1&apos; succeeded CRS-2676: Start of &apos;ora.cssdmonitor&apos; on &apos;node1&apos; succeeded CRS-2672: Attempting to start &apos;ora.cssd&apos; on &apos;node1&apos; CRS-2672: Attempting to start &apos;ora.diskmon&apos; on &apos;node1&apos; CRS-2676: Start of &apos;ora.diskmon&apos; on &apos;node1&apos; succeeded CRS-2676: Start of &apos;ora.cssd&apos; on &apos;node1&apos; succeeded ASM created and started successfully. Disk Group CRS created successfully. clscfg: -install mode specified Successfully accumulated necessary OCR keys. Creating OCR keys for user &apos;root&apos;, privgrp &apos;root&apos;.. Operation successful. CRS-4256: Updating the profile Successful addition of voting disk 013aab2ab1bf4f2ebf1b13f7237c2ecc. Successful addition of voting disk 5c947e9d03514f3ebf7a7486ab10a8f3. Successful addition of voting disk 5190c7747b184f64bf2ef35e520ea52c. Successfully replaced voting disk group with +CRS. CRS-4256: Updating the profile CRS-4266: Voting file(s) successfully replaced ## STATE File Universal Id File Name Disk group -- ----- ----------------- --------- --------- 1. ONLINE 013aab2ab1bf4f2ebf1b13f7237c2ecc (/dev/asm-diskb) [CRS] 2. ONLINE 5c947e9d03514f3ebf7a7486ab10a8f3 (/dev/asm-diskc) [CRS] 3. ONLINE 5190c7747b184f64bf2ef35e520ea52c (/dev/asm-diskd) [CRS] Located 3 voting disk(s). CRS-2672: Attempting to start &apos;ora.CRS.dg&apos; on &apos;node1&apos; CRS-2676: Start of &apos;ora.CRS.dg&apos; on &apos;node1&apos; succeeded Configure Oracle Grid Infrastructure for a Cluster ... succeeded 123456789101112131415161718192021222324[root@node2 11gr2]# /u01/app/11gr2/grid/root.sh Performing root user operation for Oracle 11g The following environment variables are set as: ORACLE_OWNER= grid ORACLE_HOME= /u01/app/11gr2/grid Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ... Creating /etc/oratab file... Entries will be added to the /etc/oratab file as needed by Database Configuration Assistant when a database is created Finished running generic part of root script. Now product-specific root actions will be performed. Using configuration parameter file: /u01/app/11gr2/grid/crs/install/crsconfig_params Creating trace directory User ignored Prerequisites during installation Installing Trace File Analyzer OLR initialization - successful Adding Clusterware entries to inittab CRS-4402: The CSS daemon was started in exclusive mode but found an active CSS daemon on node node1, number 1, and is terminating An active cluster was found during exclusive startup, restarting to join the cluster Configure Oracle Grid Infrastructure for a Cluster ... succeeded 最后，在安装节点node1以grid用户执行configToolAllCommands命令，此命令是为了创建密码（此命令propetites文件属性请参照Grid Infrastructure Installation Guide 11g Release 2 (11.2) for Linux-- B Installing and Configuring Oracle Database Using Response Files）。 12345678[root@node1:/home/grid]# su - grid [grid@node1:/home/grid]$ cd $ORACLE_HOME/cfgtoollogs [grid@node1:/u01/app/11gr2/grid/cfgtoollogs]$ touch cfgrsp.properties [grid@node1:/u01/app/11gr2/grid/cfgtoollogs]$ cat cfgrsp.properties oracle.assistants.asm|S_ASMPASSWORD=Password123 oracle.assistants.asm|S_ASMMONITORPASSWORD=Password123 [grid@node1:/u01/app/11gr2/grid/cfgtoollogs]$ chmod 600 cfgrsp.properties [grid@node1:/u01/app/11gr2/grid/cfgtoollogs]$ ./configToolAllCommands RESPONSE_FILE=./cfgrsp.properties 执行完后检测GI状态： 123456789101112131415161718192021222324252627282930313233343536373839404142434445[grid@node1:/u01/app/11gr2/grid/cfgtoollogs]$ olsnodes -s -t node1 Active Unpinned node2 Active Unpinned [grid@node1:/u01/app/11gr2/grid/cfgtoollogs]$ crsctl stat res -t -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.CRS.dg ONLINE ONLINE node1 ONLINE ONLINE node2 ora.LISTENER.lsnr ONLINE ONLINE node1 ONLINE ONLINE node2 ora.asm ONLINE ONLINE node1 Started ONLINE ONLINE node2 Started ora.gsd OFFLINE OFFLINE node1 OFFLINE OFFLINE node2 ora.net1.network ONLINE ONLINE node1 ONLINE ONLINE node2 ora.ons ONLINE ONLINE node1 ONLINE ONLINE node2 ora.registry.acfs ONLINE ONLINE node1 ONLINE ONLINE node2 -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE node1 ora.cvu 1 ONLINE ONLINE node1 ora.node1.vip 1 ONLINE ONLINE node1 ora.node2.vip 1 ONLINE ONLINE node2 ora.oc4j 1 ONLINE ONLINE node1 ora.scan1.vip 1 ONLINE ONLINE node1 3.创建ASM磁盘组 12345678#[grid@node1:/worktmp/11g/grid]$ asmca -silent -configureASM -sysAsmPassword Password123 \\ #-asmsnmpPassword Password123 -diskString &apos;/dev/asm*&apos; -diskGroupName DATA1 \\ #-disk &apos;/dev/asm-diske&apos; -redundancy EXTERNAL#Correct asmca -silent -createDiskGroup -diskString &apos;/dev/asm-disk*&apos; \\-diskGroupName DATA -disk &apos;/dev/asm-diske&apos; -redundancy EXTERNAL \\-sysAsmPassword Password123 -compatible.asm 11.2 \\-compatible.rdbms 11.2 检测安装结果： 12345678SQL&gt; select name,type,state,total_mb,free_mb,COMPATIBILITY, DATABASE_COMPATIBILITY from gv$asm_diskgroup; NAME TYPE STATE TOTAL_MB FREE_MB COMPATIBILITY DATABASE_COMPAT---------- ------ ----------- ---------- ---------- --------------- ---------------CRS NORMAL MOUNTED 24576 23650 11.2.0.0.0 10.1.0.0.0DATA EXTERN MOUNTED 30720 30625 11.2.0.0.0 10.1.0.0.0CRS NORMAL MOUNTED 24576 23650 11.2.0.0.0 10.1.0.0.0DATA EXTERN MOUNTED 30720 30625 11.2.0.0.0 10.1.0.0.0 4.安装RDBMS软件 安装前检测： 1[grid@node1:/worktmp/11g/grid]$ ./runcluvfy.sh stage -pre dbinst -n node1,node2 -verbose 只安装软件，不创建DB，修改database下默认响应文件： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[oracle@node1:/home/oracle]$ cd /worktmp/11g/database/response/ [oracle@node1:/worktmp/11g/database/response]$ cat db_install.rsp | grep -v ^# | grep -v ^$ &gt; ~/db_install.rsp [oracle@node1:/worktmp/11g/database/response]$ cat ~/db_install.rsp oracle.install.responseFileVersion=/oracle/install/rspfmt_dbinstall_response_schema_v11_2_0 oracle.install.option=INSTALL_DB_SWONLY ORACLE_HOSTNAME=node1 UNIX_GROUP_NAME=oinstall INVENTORY_LOCATION=/u01/app/oraInvertory SELECTED_LANGUAGES=en,zh_CN ORACLE_HOME=/u01/app/oracle/product/11gr2 ORACLE_BASE=/u01/app/oracle oracle.install.db.InstallEdition=EE oracle.install.db.EEOptionsSelection=false oracle.install.db.optionalComponents=oracle.rdbms.partitioning:11.2.0.4.0,oracle.oraolap:11.2.0.4.0, oracle.rdbms.dm:11.2.0.4.0,oracle.rdbms.dv:11.2.0.4.0, oracle.rdbms.lbac:11.2.0.4.0,oracle.rdbms.rat:11.2.0.4.0 oracle.install.db.DBA_GROUP=dba oracle.install.db.OPER_GROUP= oracle.install.db.CLUSTER_NODES=node1,node2 oracle.install.db.isRACOneInstall=false oracle.install.db.racOneServiceName= oracle.install.db.config.starterdb.type= oracle.install.db.config.starterdb.globalDBName= oracle.install.db.config.starterdb.SID= oracle.install.db.config.starterdb.characterSet=AL32UTF8 oracle.install.db.config.starterdb.memoryOption=false oracle.install.db.config.starterdb.memoryLimit= oracle.install.db.config.starterdb.installExampleSchemas=false oracle.install.db.config.starterdb.enableSecuritySettings=true oracle.install.db.config.starterdb.password.ALL= oracle.install.db.config.starterdb.password.SYS= oracle.install.db.config.starterdb.password.SYSTEM= oracle.install.db.config.starterdb.password.SYSMAN= oracle.install.db.config.starterdb.password.DBSNMP= oracle.install.db.config.starterdb.control=DB_CONTROL oracle.install.db.config.starterdb.gridcontrol.gridControlServiceURL= oracle.install.db.config.starterdb.automatedBackup.enable=false oracle.install.db.config.starterdb.automatedBackup.osuid= oracle.install.db.config.starterdb.automatedBackup.ospwd= oracle.install.db.config.starterdb.storageType= oracle.install.db.config.starterdb.fileSystemStorage.dataLocation= oracle.install.db.config.starterdb.fileSystemStorage.recoveryLocation= oracle.install.db.config.asm.diskGroup= oracle.install.db.config.asm.ASMSNMPPassword= MYORACLESUPPORT_USERNAME= MYORACLESUPPORT_PASSWORD= SECURITY_UPDATES_VIA_MYORACLESUPPORT=false DECLINE_SECURITY_UPDATES=true PROXY_HOST= PROXY_PORT= PROXY_USER= PROXY_PWD= PROXY_REALM= COLLECTOR_SUPPORTHUB_URL= oracle.installer.autoupdates.option=SKIP_UPDATES oracle.installer.autoupdates.downloadUpdatesLoc= AUTOUPDATES_MYORACLESUPPORT_USERNAME= AUTOUPDATES_MYORACLESUPPORT_PASSWORD= 执行安装程序： 123[oracle@node1:/worktmp/11g/database]$./runInstaller -silent \\ -responseFile /home/oracle/db_install.rsp \\ -ignorePrereq -ignoreSysPreReqs -ignoreDiskWarning 安装完成，执行脚本： 1234567891011121314151617[root@node1:/root]# /u01/app/oracle/product/11gr2/root.sh [root@node2:/root]# /u01/app/oracle/product/11gr2/root.sh Performing root user operation for Oracle 11g The following environment variables are set as: ORACLE_OWNER= oracle ORACLE_HOME= /u01/app/oracle/product/11gr2 Copying dbhome to /usr/local/bin ... Copying oraenv to /usr/local/bin ... Copying coraenv to /usr/local/bin ... Entries will be added to the /etc/oratab file as needed by Database Configuration Assistant when a database is created Finished running generic part of root script. Now product-specific root actions will be performed. Finished product-specific root actions. Finished product-specific root actions. 5.DBCA建库 1234567891011121314151617181920212223242526272829303132[oracle@node1:/home/oracle]$ $ORACLE_HOME/bin/dbca -silent -createDatabase \\ -templateName General_Purpose.dbc -gdbName racdb -sid racdb \\ -sysPassword Password123 -systemPassword Password123 -recoveryAreaDestination FRA -storageType ASM \\ -diskGroupName DATA1 -datafileJarLocation $ORACLE_HOME/assistants/dbca/templates \\ -nodeinfo node1,node2 -characterset AL32UTF8 -obfuscatedPasswords false \\ -sampleSchema false -asmSysPassword Password123 Copying database files 1% complete 3% complete 9% complete 15% complete 21% complete 27% complete 30% complete Creating and starting Oracle instance 32% complete 36% complete 40% complete 44% complete 45% complete 48% complete 50% complete Creating cluster database views 52% complete 70% complete Completing Database Creation 73% complete 76% complete 85% complete 94% complete 100% complete Look at the log file &quot;/u01/app/oracle/cfgtoollogs/dbca/racdb/racdb.log&quot; for further details. 利用Oracle提供的General_Purpose模版创建，也可以自己录制数据库模版，在dbca.rsp中添加自己的模版创建数据库，本文采用的是第一种方式。 利用自己的模版创建： a) 利用OUI图形界面创建create database的template。 b) 选择custom database c) 其他按照需求自定义 d) 最后一步取消create database选项，改为选择create template e) 创建后模版文件位置：$ORACLE_HOME/assistants/dbca/templates 修改安装文件内response文件dbca.rsp，主要修改GDBNAME、SID及TEMPLATENAME三个选项。再使用以下命令安装： dbca -silent -createdatabase -responseFile ./dbca.rsp 6.完善安装 修改归档模式： 1234567891011121314SQL&gt; select inst_id,instance_name,version,archiver,status from gv$instance; INST_ID INSTANCE_NAME VERSION ARCHIVER STATUS ---------- -------------------------------- ---------------------------------- -------------- ------------------------ 1 racdb1 11.2.0.4.0 STOPPED OPEN 2 racdb2 11.2.0.4.0 STOPPED OPEN SQL&gt; alter system set log_archive_dest_1=&apos;location=+DATA1/arch/racdb1&apos; sid=&apos;racdb1&apos; scope=spfile; System altered. SQL&gt; alter system set log_archive_dest_1=&apos;location=+DATA1/arch/racdb2&apos; sid=&apos;racdb2&apos; scope=spfile; System altered. 12[grid@node2:/home/grid]$ srvctl stop database -d racdb -o immediate [grid@node2:/home/grid]$ srvctl start database -d racdb -o mount 1234567891011SQL&gt; alter database archivelog; Database altered. SQL&gt; archive log list; Database log mode Archive Mode Automatic archival Enabled Archive destination +DATA1/arch/racdb1 Oldest online log sequence 4 Next log sequence to archive 5 Current log sequence 5 12[grid@node2:/home/grid]$ srvctl stop database -d racdb -o immediate [grid@node2:/home/grid]$ srvctl start database -d racdb -o open 1234567SQL&gt; set linesize 200 SQL&gt; select inst_id,instance_name,version,archiver,status from gv$instance; INST_ID INSTANCE_NAME VERSION ARCHIVER STATUS ---------- -------------------------------- ---------------------------------- -------------- ------------------------ 1 racdb1 11.2.0.4.0 STARTED OPEN 2 racdb2 11.2.0.4.0 STARTED OPEN 检查资源状况： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[root@node1:/root]# /u01/app/11gr2/grid/bin/crsctl stat res -t -------------------------------------------------------------------------------- NAME TARGET STATE SERVER STATE_DETAILS -------------------------------------------------------------------------------- Local Resources -------------------------------------------------------------------------------- ora.CRS.dg ONLINE ONLINE node1 ONLINE ONLINE node2 ora.DATA1.dg ONLINE ONLINE node1 ONLINE ONLINE node2 ora.LISTENER.lsnr ONLINE ONLINE node1 ONLINE ONLINE node2 ora.asm ONLINE ONLINE node1 Started ONLINE ONLINE node2 Started ora.gsd OFFLINE OFFLINE node1 OFFLINE OFFLINE node2 ora.net1.network ONLINE ONLINE node1 ONLINE ONLINE node2 ora.ons ONLINE ONLINE node1 ONLINE ONLINE node2 ora.registry.acfs ONLINE ONLINE node1 ONLINE ONLINE node2 -------------------------------------------------------------------------------- Cluster Resources -------------------------------------------------------------------------------- ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE node2 ora.cvu 1 ONLINE ONLINE node2 ora.node1.vip 1 ONLINE ONLINE node1 ora.node2.vip 1 ONLINE ONLINE node2 ora.oc4j 1 ONLINE ONLINE node2 ora.racdb.db 1 ONLINE ONLINE node1 Open 2 ONLINE ONLINE node2 Open ora.scan1.vip 1 ONLINE ONLINE node2 Reference： Oracle® Real Application Clusters Installation Guide 11g Release 2 (11.2) for Linux and UNIX Oracle® Grid Infrastructure Installation Guide 11g Release 2 (11.2) for Linux EOF","link":"/install-11gr2-rac-in-silent-mode.html"},{"title":"12C之PDB管理","text":"在上一篇文章12c Silent Installation创建的一个空的CDB，本文介绍如何使用sqlplus工具对PDB进行维护(EM Express更简单，以下所有操作均可从EM生成对应的SQL)。 1. 添加PDB添加PDB前需要满足以下几个条件： 数据库必须是CDB CDB处于READ/WRITE模式 创建PDB的用户必须是common user 创建PDB的用户要有CREATE PLUGGABLE DATABASE的系统权限 每个PDB须有不同的名称在12.1中，一个CDB最多支持253个PDB，其中包括一个PDB$SEED。新增pdb的方法有以下几种： 1.1 使用seed创建新的pdb这种方法复制seed中的文件到新的PDB。123456CREATE PLUGGABLE DATABASE salespdb ADMIN USER salesadm IDENTIFIED BY oracle roles=(DBA) STORAGE (MAXSIZE 2G MAX_SHARED_TEMP_SIZE 100M) DEFAULT TABLESPACE sales DATAFILE &apos;/u02/oradata/ora12c/salespdb/sales01.dbf&apos; SIZE 250M AUTOEXTEND ON PATH_PREFIX = &apos;/u02/oradata/ora12c/salespdb/&apos; FILE_NAME_CONVERT = (&apos;/u02/oradata/ora12c/pdbseed/&apos;, &apos;/u02/oradata/ora12c/salespdb/&apos;); StorageMAXSIZE定义一个属于这个PDB的表空间总容量；MAX_SHARED_TEMP_SIZE定义一个属于这个PDB的临时表空间总容量。如果设定为storage unlimited，或者没有设定此参数，均表示此PDB的没有存储限制。存储限制可于创建完PDB后修改：12sqlplus sys/oracle@linora:1522/salespdb as sydsbaSQL&gt; alter pluggable database salespdb storage(maxsize 20G); File Location of the New PDB在新的PDB中，有两个子句可以在创建PDB的时候指定文件路径：FILE_NAME_CONVERT和CREATE_FILE_DEST，后一个子句是用于OMF管理。而PATH_PREFIX所有跟此PDB相关的文件路径都会被存在在此参数指定的路径下。 ROLES给定管理者salsadm权限，这个用户是PDB local user，本例中预授的是PDB_DBA权限。创建完后可以看到PDB的状态：123456SYS@ora12c&gt; select con_id, name,open_mode from v$containers; CON_ID NAME OPEN_MODE---------- ---------- -------------------- 1 CDB$ROOT READ WRITE 2 PDB$SEED READ ONLY 3 SALESPDB MOUNTED 开启PDB至OPEN状态：123456789SYS@ora12c&gt; ALTER PLUGGABLE DATABASE salespdb open;Pluggable database altered.SYS@ora12c&gt; col name for a15SYS@ora12c&gt; select con_id, name,open_mode from v$containers; CON_ID NAME OPEN_MODE---------- --------------- -------------------- 1 CDB$ROOT READ WRITE 2 PDB$SEED READ ONLY 3 SALESPDB READ WRITE 1.2 从本地PDB Clone1234567891011121314151617--clone时，source PDB必须处于read only状态SYS@ora12c&gt; alter pluggable database salespdb close;Pluggable database altered.SYS@ora12c&gt; alter pluggable database salespdb open read only;Pluggable database altered.SYS@ora12c&gt; CREATE PLUGGABLE DATABASE hrpdb FROM salespdb no data 2 FILE_NAME_CONVERT = (&apos;/u02/oradata/ora12c/salespdb/&apos;, &apos;/u02/oradata/ora12c/hrpdb/&apos;) 3 STORAGE unlimited;Pluggable database created.SYS@ora12c&gt; col name for a15SYS@ora12c&gt; select con_id, name,open_mode from v$containers; CON_ID NAME OPEN_MODE---------- --------------- -------------------- 1 CDB$ROOT READ WRITE 2 PDB$SEED READ ONLY 3 SALESPDB READ ONLY 4 HRPDB MOUNTED NO DATA表示不从source PDB克隆数据，只Clone源数据。这个参数从12.1.0.2开始支持。 1.3 从远程PDB Clone本例中，远程PDB名称为SALESPDB，通过DBLINK远程连接至SALESPDB进行Clone。1234567891011#首先创建DBLINKcreate database link salespdbconnect to system identified by oracleusing &apos;linora:1522/salespdb&apos;;#将远程PDB处于read only状态SQL&gt; alter pluggable database salespdb close;SQL&gt; alter pluggable database salespdb open read only;#在目标端执行Clone动作CREATE PLUGGABLE DATABASE hrpdb FROM salespdb@salespdb no dataFILE_NAME_CONVERT = (&apos;/u02/oradata/ora12c/salespdb/&apos;, &apos;/u02/oradata/ora12c/hrpdb/&apos;)STORAGE unlimited; 1.4 从远程non-CDB CloneOracle有三种方法可以将non-CDB转换成PDB，包括data pump、OGG和DBMS_PDB包，这里简要说明下DBMS_PDB包的使用。这种方法只适合DB版本在12C以上。因为12C以下没有DBMS_PDB包。123456789101112131415161718192021222324252627282930#首先将non-CDB切换成read only状态SYS&gt; startup mount;SYS&gt; alter database open read only;#生成XMLSQL&gt; BEGINDBMS_PDB.DESCRIBE(pdb_descr_file =&gt; &apos;/home/oracle/ncdb.xml&apos;);END;/#检测生成的XML文件是否支持插拔SQL&gt; SET SERVEROUTPUT ONDECLAREhold_var boolean;beginhold_var := DBMS_PDB.CHECK_PLUG_COMPATIBILITY(pdb_descr_file=&gt;&apos;/home/oracle/ncdb.xml&apos;);if hold_var thendbms_output.put_line(&apos;YES&apos;);elsedbms_output.put_line(&apos;NO&apos;);end if;end;/#在CDB中创建PDBSQL&gt; CREATE PLUGGABLE DATABASE dkpdbUSING &apos;/home/oracle/ncdb.xml&apos;COPYFILE_NAME_CONVERT = (&apos;/u01/dbfile/dk/&apos;,&apos;/u01/dbfile/CDB/dkpdb/&apos;);#最后连接到新建的PDB，执行后续脚本$ sqlplus sys/oralce@&apos;linora:1522/dkpdb&apos; as sysdbaSQL&gt; @?/rdbms/admin/noncdb_to_pdb.sql 1.5 插入已拔除的PDB拔除指令：1234SYS@ora12c&gt; ALTER PLUGGABLE DATABASE hrpdb CLOSE IMMEDIATE;Pluggable database altered.SYS@ora12c&gt; ALTER PLUGGABLE DATABASE hrpdb UNPLUG INTO &apos;/home/ora12c/hrpdb.xml&apos;;Pluggable database altered. 当某个PDB被拔除后，会保留在Mount状态，在原来的CDB中除了可以通过RMAN进行备份外，就只能drop，其他操作都会出现异常。如果要将拔除的PDB插回原CDB，需要将该PDB DROP，然后再插入。123456789101112131415161718192021#检测COMPATIBILITYSQL&gt; SET SERVEROUTPUT ONDECLAREhold_var boolean;beginhold_var := DBMS_PDB.CHECK_PLUG_COMPATIBILITY(pdb_descr_file=&gt;&apos;/home/ora12c/hrpdb.xml&apos;);if hold_var thendbms_output.put_line(&apos;YES&apos;);elsedbms_output.put_line(&apos;NO&apos;);end if;end;/YESSYS@ora12c&gt; drop pluggable database hrpdb;Pluggable database dropped.#在新CDB中插入拔除的CDBCREATE PLUGGABLE DATABASE pdb2 using &apos;/home/ora12c/hrpdb.xml&apos;move|copyfile_name_convert=(&apos;/u02/oradata/ora12c/hrpdb/&apos;,&apos;/u02/oradata/ora12c/pdb2/&apos;);--source_file_name_convert=(&apos;/u02/oradata/ora12c/hrpdb/&apos;,&apos;/u02/oradata/ora12c/pdb2/&apos;) nocopy; 其中，move表示数据文件从原有位置mv至新位置，COPY则表示复制，NOCOPY表示重新生成。对于plug-in PDB有如下限制： 源端和目标端CDB endianness必须一样 源端和目标端数据库选件必须一样 目标端必须存在原来PDB的数据文件 两端字符集和compatible 必须一样 2. 连接PDBPDB创建后会自动创建和PDB名称一致的Service，在TNSNAMES中添加此Service，即可通过tns方式连接：123456789101112131415161718192021222324252627282930313233343536373839404142434445[ora12c@linora:/u01/app/ora12c/product/12.1.0/db1/network/admin]$ cat listener.ora LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = linora)(PORT = 1522)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1522)) ) )ADR_BASE_LISTENER = /u01/app/ora12cSID_LIST_LISTENER =(SID_LIST = (SID_DESC = (GLOBAL_DBNAME = ora12c) (ORACLE_HOME = /u01/app/ora12c/product/12.1.0/db1) (SID_NAME = ora12c) ) (SID_DESC = (GLOBAL_DBNAME = pdb12c) #PDB service, the same as PDB database name (ORACLE_HOME = /u01/app/ora12c/product/12.1.0/db1) (SID_NAME = ora12c) #CDB sid or the cdb database name ))salespdb = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.56.188)(PORT = 1522)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = salespdb) ) )[ora12c@linora:/home/ora12c]$ sqlplus sys/oracle@salespdb as sysdbaSYS@ora12c&gt; col name for a20SYS@ora12c&gt; col NETWORK_NAME for a10SYS@ora12c&gt; col pdb for a20SYS@ora12c&gt; select name,NETWORK_NAME,PDB from cdb_services;NAME NETWORK_NA PDB-------------------- ---------- --------------------SYS$BACKGROUND CDB$ROOTSYS$USERS CDB$ROOTora12c ora12c CDB$ROOThrpdb hrpdb HRPDBsalespdb salespdb SALESPDB 或者使用简易连接方式，但是在sqlnet.ora需添加ezconnect：12345678[ora12c@linora:/home/ora12c]$ sqlplus salesadm/oracle@linora:1522/salespdbSQL*Plus: Release 12.1.0.2.0 Production on Wed Aug 13 17:19:31 2014Copyright (c) 1982, 2014, Oracle. All rights reserved.Last Successful login time: Wed Aug 13 2014 17:19:22 +08:00Connected to:Oracle Database 12c Enterprise Edition Release 12.1.0.2.0 - 64bit ProductionWith the Partitioning, OLAP, Advanced Analytics and Real Application Testing optionsSALESADM@linora:1522/salespdb&gt; 或者使用以前的连接方式，通过alter session命令登入PDB：123456789101112SYS@ora12c&gt; alter session set container=salespdb;Session alteredSYS@ora12c&gt; col CON_ID for a15SYS@ora12c&gt; col CUR_CONTAINER for a20SYS@ora12c&gt; col CUR_USER for a10SYS@ora12c&gt; SELECT SYS_CONTEXT(&apos;USERENV&apos;, &apos;CON_ID&apos;) AS con_id, 2 SYS_CONTEXT(&apos;USERENV&apos;, &apos;CON_NAME&apos;) AS cur_container, 3 SYS_CONTEXT(&apos;USERENV&apos;, &apos;SESSION_USER&apos;) AS cur_user 4 FROM DUAL;CON_ID CUR_CONTAINER CUR_USER--------------- -------------------- ----------3 SALESPDB SYS 3. Start or shutdown PDB12345678910111213141516171819#从root容器执行SYS@ora12c&gt; SELECT SYS_CONTEXT (&apos;USERENV&apos;, &apos;CON_NAME&apos;) FROM DUAL;SYS_CONTEX----------CDB$ROOTSQL&gt; alter pluggable database salespdb open;SQL&gt; startup pluggable database salespdb open read only;SQL&gt; alter pluggable database salespdb close immediate;SQL&gt; alter pluggable database all open;SQL&gt; alter pluggable database all close immediate;#从PDB执行SYS@ora12c&gt; alter session set container=salespdb;Session altered.SYS@ora12c&gt; SELECT SYS_CONTEXT (&apos;USERENV&apos;, &apos;CON_NAME&apos;) FROM DUAL;SYS_CONTEX----------SALESPDBSQL&gt; startup;SQL&gt; shutdown immediate; Reference:Creating and Removing PDBs with SQL*Plus","link":"/manage-pdbs.html"},{"title":"MHVTL and NBU","text":"MHVTL 为开源虚拟带库软件，下载地址为：MHVTL，搭配上gui可模拟多款厂商带库，我唯一管理过的带库为HP MSL6000，而备份软件则为Netbackup。本文以这两种产品为例，对一些简单的配置进行说明。 1、安装MHVTLOS版本为RHEL6.5，以最小安装，通过配置yum本地源安装其他所需的包，其中，有三个rpm包需要自行下载，可从http://rpmfind.net/linux/rpm2html/search.php?query=lzo这里搜索对应版本或者在本站下载：lzo-2.03-3.1.el6_5.1.x86_64.rpm,lzo-devel-2.03-3.1.el6_5.1.x86_64.rpm,lzo-minilzo-2.03-3.1.el6_5.1.x86_64.rpm 1.1关闭firewall和selinux12345678910111213141516171819202122232425#关闭防火墙[root@mhvtl ~]# /etc/init.d/iptables stopiptables: Setting chains to policy ACCEPT: filter [ OK ]iptables: Flushing firewall rules: [ OK ]iptables: Unloading modules: [ OK ][root@mhvtl ~]# /etc/init.d/ip6tables stopip6tables: Setting chains to policy ACCEPT: filter [ OK ]ip6tables: Flushing firewall rules: [ OK ]ip6tables: Unloading modules: [ OK ][root@mhvtl ~]# chkconfig iptables off[root@mhvtl ~]# chkconfig ip6tables off#关闭selinux[root@mhvtl ~]# sed -i &apos;/^SELINUX/s/enforcing/disabled/g&apos; /etc/selinux/config[root@mhvtl ~]# cat /etc/selinux/config # This file controls the state of SELinux on the system.# SELINUX= can take one of these three values:# enforcing - SELinux security policy is enforced.# permissive - SELinux prints warnings instead of enforcing.# disabled - No SELinux policy is loaded.SELINUX=disabled# SELINUXTYPE= can take one of these two values:# targeted - Targeted processes are protected,# mls - Multi Level Security protection.SELINUXTYPE=targeted [root@mhvtl ~]# shutdown -ry 0 1.2配置yum本地源12345[Server] name=Server baseurl=file:///mnt/Server enabled=1 gpgcheck=0 挂载光盘，安装所需软件包1234567891011121314151617[root@mhvtl ~]# mount /dev/sr1 /mntmount: block device /dev/sr1 is write-protected, mounting read-only[root@mhvtl ~]# yum -y install zlib-devel mtx mt-st lsscsi kernel-devel kernel-headers sg3_utils gcc perl unzip[root@mhvtl worktmp]# ls -ltrtotal 708-rw-r--r--. 1 root root 283656 Jul 16 14:12 mhvtl-2015-04-14.tgz-rw-r--r--. 1 root root 12876 Jul 16 15:14 lzo-minilzo-2.03-3.1.el6_5.1.x86_64.rpm-rw-r--r--. 1 root root 31784 Jul 16 15:17 lzo-devel-2.03-3.1.el6_5.1.x86_64.rpm-rw-r--r--. 1 root root 56308 Jul 16 15:20 lzo-2.03-3.1.el6_5.1.x86_64.rpm-rw-r--r--. 1 root root 329355 Jul 16 15:54 mhvtl-gui-master.zip[root@mhvtl worktmp]# rpm -ivh *.rpmwarning: lzo-2.03-3.1.el6_5.1.x86_64.rpm: Header V3 RSA/SHA1 Signature, key ID c105b9de: NOKEYPreparing... ########################################### [100%] 1:lzo-minilzo ########################################### [ 33%] 2:lzo ########################################### [ 67%] 3:lzo-devel ########################################### [100%][root@mhvtl worktmp]# 1.3编译安装MHVTL创建vtl相关用户：123[root@mhvtl mhvtl-1.5]# groupadd vtl -g 600[root@mhvtl mhvtl-1.5]# useradd -g vtl -u 600 vtl[root@mhvtl mhvtl-1.5]# echo &quot;oracle&quot; | passwd vtl --stdin &gt; /dev/null 2&gt;&amp;1 编译安装vtl123456789[root@mhvtl mhvtl-1.5]# pwd/worktmp/mhvtl-1.5[root@mhvtl mhvtl-1.5]# cd kernel/[root@mhvtl kernel]# make[root@mhvtl kernel]# make install[root@mhvtl kernel]#[root@mhvtl kernel]# cd ../[root@mhvtl mhvtl-1.5]# make [root@mhvtl mhvtl-1.5]# make install 启动服务，并且查看虚拟磁带：1234567891011121314151617181920212223242526272829[root@mhvtl mhvtl-1.5]# mkdir -p /opt/mhvtl[root@mhvtl mhvtl-1.5]# chown vtl:vtl /opt/mhvtl/[root@mhvtl mhvtl-1.5]# /etc/init.d/mhvtl startvtllibrary process PID is 3722vtllibrary process PID is 3725[root@mhvtl mhvtl-1.5]# ll /opt/mhvtl/total 288drwxrwx--- 2 vtl vtl 4096 Jul 20 12:39 CLN101L4drwxrwx--- 2 vtl vtl 4096 Jul 20 12:39 CLN102L5drwxrwx--- 2 vtl vtl 4096 Jul 20 12:39 CLN303TAdrwxrwx--- 2 vtl vtl 4096 Jul 20 12:39 E01001L4drwxrwx--- 2 vtl vtl 4096 Jul 20 12:39 E01002L4drwxrwx--- 2 vtl vtl 4096 Jul 20 12:39 E01003L4drwxrwx--- 2 vtl vtl 4096 Jul 20 12:39 E01004L4[root@mhvtl mhvtl-1.5]# lsscsi -g[0:0:0:0] cd/dvd VBOX CD-ROM 1.0 /dev/sr0 /dev/sg0[0:0:1:0] cd/dvd VBOX CD-ROM 1.0 /dev/sr1 /dev/sg1[1:0:0:0] cd/dvd VBOX CD-ROM 1.0 /dev/sr2 /dev/sg2[2:0:0:0] disk ATA VBOX HARDDISK 1.0 /dev/sda /dev/sg3[3:0:0:0] mediumx STK L700 0105 /dev/sch0 /dev/sg12[3:0:1:0] tape IBM ULT3580-TD5 0105 /dev/st0 /dev/sg4[3:0:2:0] tape IBM ULT3580-TD5 0105 /dev/st1 /dev/sg5[3:0:3:0] tape IBM ULT3580-TD4 0105 /dev/st2 /dev/sg6[3:0:4:0] tape IBM ULT3580-TD4 0105 /dev/st3 /dev/sg7[3:0:8:0] mediumx STK L80 0105 /dev/sch1 /dev/sg13[3:0:9:0] tape STK T10000B 0105 /dev/st4 /dev/sg8[3:0:10:0] tape STK T10000B 0105 /dev/st5 /dev/sg9[3:0:11:0] tape STK T10000B 0105 /dev/st6 /dev/sg10[3:0:12:0] tape STK T10000B 0105 /dev/st7 /dev/sg11 从lssci可以看到，默认配置是两台带库，STK的L700和STK的L80。我们能够通过gui进行添加和删除带库，但最后一个带库不能被删除。 2、GUI配置GUI下载及安装说明：https://github.com/walterfrs/mhvtl-gui，也可以从本站下载：MHVL-GUI。 2.1. 设置http1234567891011121314151617[root@mhvtl mhvtl-gui-master]# pwd/worktmp/mhvtl-gui-master[root@mhvtl mhvtl-gui-master]# ls -ltotal 64-rw-r--r-- 1 root root 1150 Nov 28 2012 favicon.ico-rwxr-xr-x 1 root root 750 Nov 28 2012 go.phpdrwxr-xr-x 3 root root 12288 Nov 28 2012 html-rw-r--r-- 1 root root 343 Nov 28 2012 index.php-rw-r--r-- 1 root root 18006 Nov 28 2012 LICENSE-rw-r--r-- 1 root root 2961 Nov 28 2012 login.php-rw-r--r-- 1 root root 2379 Nov 28 2012 mhvtl.cfg.db-rw-r--r-- 1 root root 2931 Nov 28 2012 READMEdrwxr-xr-x 2 root root 4096 Nov 28 2012 scripts-rw-r--r-- 1 root root 14 Nov 28 2012 version[root@mhvtl mhvtl-gui-master]# yum install httpd -y[root@mhvtl mhvtl-gui-master]# chkconfig httpd on[root@mhvtl mhvtl-gui-master]# cp -r * /var/www/html/ 2.2.设置GUI1[root@mhvtl mhvtl-gui-master]# echo &quot;apache ALL=(ALL) NOPASSWD: ALL&quot; &gt;&gt;/etc/sudoers 屏蔽掉/et/sudoers中的&quot;Defaults requiretty&quot;12345[root@mhvtl mhvtl-gui-master]# grep &apos;Defaults requiretty&apos; /etc/sudoersDefaults requiretty[root@mhvtl mhvtl-gui-master]# sed -i &apos;/^Defaults requiretty/s/^/#/g&apos; /etc/sudoers[root@mhvtl mhvtl-gui-master]# grep &apos;Defaults requiretty&apos; /etc/sudoers#Defaults requiretty 安装所需rpm包：12[root@mhvtl mhvtl-gui-master]# yum install php sysstat git iscsi-initiator-utils* scsi-target-utils -y[root@mhvtl mhvtl-gui-master]# yum groupinstall &quot;Desktop&quot; -y 配置html网站的alias,将如下内容添加到/etc/httpd/conf/httpd.conf1234567Alias /mhvtl &quot;/var/www/html/mhvtl&quot;&lt;Directory &quot;/var/www/html/mhvtl&quot;&gt; Options None AllowOverride None Order allow,deny Allow from all&lt;/Directory&gt; 创建所需目录1[root@mhvtl mhvtl-gui-master]# mkdir -p /var/www/html/mhvtl OK，httpd服务，并测试连接：12345[root@mhvtl mhvtl-gui-master]# /etc/init.d/httpd restartStopping httpd: [FAILED]Starting httpd: httpd: apr_sockaddr_info_get() failed for mhvtlhttpd: Could not reliably determine the server&apos;s fully qualified domain name, using 127.0.0.1 for ServerName [ OK ] 上述报错是忘记在/etc/hosts添加主机名及IP了，添加后重启httpd服务正常。默认密码为mhvtl图中红框处为默认两台带库，下面开始配置自己的带库。 3、配置带库及iscsi target点击setup=&gt;Remove,选中要删除的带库，同时删除磁带：完成后，因为最后一个带库不能被删除，因此，添加一个我们所需的带库，然后再删除默认带库。点击setup=&gt;Add=&gt;Standard=&gt;Next，在brand选中HP，最后我的配置如下，只选了LTO3的磁带然后可以将默认磁带库删除了。同时，在vtl主机端可以看到设备类型：123456789101112131415161718192021222324252627282930313233343536373839404142[root@mhvtl html]# cat /etc/mhvtl/device.confVERSION: 5# VPD page format:# &lt;page #&gt; &lt;Length&gt; &lt;x&gt; &lt;x+1&gt;... &lt;x+n&gt;# NAA format is an 8 hex byte value seperated by &apos;:&apos;# Note: NAA is part of inquiry VPD 0x83## Each &apos;record&apos; is separated by one (or more) blank lines.# Each &apos;record&apos; starts at column 1# Serial num max len is 10.# Compression: factor X enabled 0|1# Where X is zlib compression factor 1 = Fastest compression# 9 = Best compression# enabled 0 == off, 1 == on## fifo: /var/tmp/mhvtl# If enabled, data must be read from fifo, otherwise daemon will block# trying to write.# e.g. cat /var/tmp/mhvtl (in another terminal)Library: 50 CHANNEL: 1 TARGET: 00 LUN: 00 Vendor identification: HP Product identification: MSL6000 Series --带库型号 Product revision level: 2.00 Unit serial number: 80000050 NAA: 50:11:22:33:ab:1:00:00 Home directory: /opt/mhvtl Backoff: 400Drive: 51 CHANNEL: 1 TARGET: 00 LUN: 01 Library ID: 50 Slot: 01 Vendor identification: HP Product identification: Ultrium 3-SCSI --driver型号 Product revision level: N11G Unit serial number: 80000051 NAA: 50:11:22:33:ab:1:00:01 Compression: factor 1 enabled 1 Compression type: lzo Backoff: 400... 最后状态如图：可以看到，iscsi target是offline的状态，下面开始配置iscsi target:点击iscsi，将打叉的服务全部安装或enable最后状态如图：配置iscsi target，点击new，然后点击create，名字可以自己取，如下图：至此，gui界面配置完毕，在vtl主机端，可以看到iscsi target：123456789101112131415161718192021[root@mhvtl html]# tgtadm --lld iscsi --op show --mode targetTarget 1: iqn.1994-05.com.redhat:mhvtl:mhvtl:tgt:1 System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: null Backing store path: None Backing store flags: Account information: ACL information: 最后，尚须手动添加磁带机及drivers信息到iscsi target中：12345678910[root@mhvtl html]# lsscsi -g[0:0:0:0] cd/dvd VBOX CD-ROM 1.0 /dev/sr0 /dev/sg0[0:0:1:0] cd/dvd VBOX CD-ROM 1.0 /dev/sr1 /dev/sg1[1:0:0:0] cd/dvd VBOX CD-ROM 1.0 /dev/sr2 /dev/sg2[2:0:0:0] disk ATA VBOX HARDDISK 1.0 /dev/sda /dev/sg3[3:1:0:0] mediumx HP MSL6000 Series 2.00 /dev/sch0 /dev/sg8[3:1:0:1] tape HP Ultrium 3-SCSI N11G /dev/st0 /dev/sg4[3:1:0:2] tape HP Ultrium 3-SCSI N11G /dev/st1 /dev/sg5[3:1:0:3] tape HP Ultrium 3-SCSI N11G /dev/st2 /dev/sg6[3:1:0:4] tape HP Ultrium 3-SCSI N11G /dev/st3 /dev/sg7 将标记有HP的设备信息写入/etc/tgt/targets.conf，如下：12345678910&lt;target iqn.1994-05.com.redhat:mhvtl:mhvtl:tgt:1&gt;backing-store /dev/sg8backing-store /dev/sg4backing-store /dev/sg5backing-store /dev/sg6backing-store /dev/sg7device-type ptbs-type sg&lt;/target&gt;initiator-address ALL 重启iscsi target服务，并且验证1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586[root@mhvtl html]# /etc/init.d/tgtd restartStopping SCSI target daemon: [ OK ]Starting SCSI target daemon: [ OK ][root@mhvtl html]# chkconfig tgtd on[root@mhvtl html]# tgtadm --lld iscsi --op show --mode targetTarget 1: iqn.1994-05.com.redhat:mhvtl:mhvtl:tgt:1 System information: Driver: iscsi State: ready I_T nexus information: LUN information: LUN: 0 Type: controller SCSI ID: IET 00010000 SCSI SN: beaf10 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: null Backing store path: None Backing store flags: LUN: 1 Type: passthrough SCSI ID: IET 00010001 SCSI SN: beaf11 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: sg Backing store path: /dev/sg4 Backing store flags: LUN: 2 Type: passthrough SCSI ID: IET 00010002 SCSI SN: beaf12 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: sg Backing store path: /dev/sg5 Backing store flags: LUN: 3 Type: passthrough SCSI ID: IET 00010003 SCSI SN: beaf13 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: sg Backing store path: /dev/sg6 Backing store flags: LUN: 4 Type: passthrough SCSI ID: IET 00010004 SCSI SN: beaf14 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: sg Backing store path: /dev/sg7 Backing store flags: LUN: 5 Type: passthrough SCSI ID: IET 00010005 SCSI SN: beaf15 Size: 0 MB, Block size: 1 Online: Yes Removable media: No Prevent removal: No Readonly: No Backing store type: sg Backing store path: /dev/sg8 Backing store flags: Account information: ACL information: ALL 4、windows server端配置iscsi本例中，NBU服务器为windows2008r2，配置好主机名及etc/hosts后，设置发现iscsi，如下图，在发现门户中输入虚拟带库IP地址然后在目标中连接目标iscsi target。此时，在设备管理器中能够发现磁带库驱动及磁带： 5、安装NBU Master Server点击安装文件中的Browser，有安装前预览及其他任务，针对于7.5以上版本的NBU，建议内存大于等于8GB，且安装的时候不要用terminal登陆。下面几步可以一直下一步，在选择安装类型的时候可以选择typical或者custom，这里选择typical即可，custom可以指定各个进程的端口号及安装路径。输入license，点击master server安装等待NBU安装完成。 6、配置NBU机械臂及driver等设备启动NBU Admin console，点击getting start开始配置drivers和robots：直接下一步，扫描完会发现VTL中配置的4个drivers和一个robot在driver的配置中，有可能会发生drivers出现在standalone里面，需要我们手动将四个drivers拖拽到robot 0里面：完成后，如图：配置完storage devices后，开始配置volume：在下面这个页面中，选中TLD，NBU会扫描带库中所有磁带，并添加到NBU的inventory中：catalog的policy及backup policy在后面手动配置。至此，NBU基于磁带的主要配置已经完成。 7、本地磁盘配置在某些环境下，有些master server挂载了一些存储，我们可以直接配置NBU，将数据备份在local disk：配置完成后，在policy中，可以选择基于disk的storage units，将备份放在本地硬盘。 EOF","link":"/mhvtl-and-nbu.html"},{"title":"Migrate ASM to different host","text":"客户搬迁机房，同时更换存储和主机，这是一台单实例的11g ASM数据库，通过底层存储镜像进行数据的迁移，在迁移过程中，还是遇到了一些小问题，在此记录一下。接手时的环境是客户已经自行安装好GI及数据库软件，ASM的diskgroup只有一个DATA盘，因此，只需要将部分资源添加进GI管理即可，初始GI状态如下：1234567891011121314151617[grid@orl6:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------NAME TARGET STATE SERVER STATE_DETAILS --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.ons OFFLINE OFFLINE orl6 --------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.cssd 1 OFFLINE OFFLINE ora.diskmon 1 OFFLINE OFFLINE ora.evmd 1 ONLINE ONLINE orl6 1、修改cssd资源为自启动：1234567891011121314151617181920[grid@orl6:/home/grid]$ crs_stat -p ora.cssdNAME=ora.cssdTYPE=ora.cssd.typeACTION_SCRIPT=ACTIVE_PLACEMENT=0AUTO_START=neverCHECK_INTERVAL=30DESCRIPTION=&quot;Resource type for CSSD&quot;FAILOVER_DELAY=0FAILURE_INTERVAL=3FAILURE_THRESHOLD=5HOSTING_MEMBERS=PLACEMENT=balancedRESTART_ATTEMPTS=5SCRIPT_TIMEOUT=600START_TIMEOUT=600STOP_TIMEOUT=900UPTIME_THRESHOLD=1m[grid@orl6:/home/grid]$ crsctl modify resource &quot;ora.cssd&quot; -attr &quot;AUTO_START=1&quot; 2、使用netca创建监听重启HA，修改后GI状态如下：1234567891011121314151617181920[grid@orl6:/home/grid]$ crsctl stop has &amp;&amp; crsctl start has[grid@orl6:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------NAME TARGET STATE SERVER STATE_DETAILS --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.LISTENER.lsnr ONLINE ONLINE orl6 ora.ons OFFLINE OFFLINE orl6 --------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.cssd 1 ONLINE ONLINE orl6 ora.diskmon 1 OFFLINE OFFLINE ora.evmd 1 ONLINE ONLINE orl6 3、添加ASM资源到GI123456789101112131415161718192021222324252627282930313233[grid@orl6:/home/grid]$ srvctl add asm -d /dev/asm*[grid@orl6:/home/grid]$ crsctl modify resource &quot;ora.asm&quot; -attr &quot;AUTO_START=1&quot;[grid@orl6:/home/grid]$ crsctl start res ora.asmCRS-2672: Attempting to start &apos;ora.asm&apos; on &apos;orl6&apos;CRS-2676: Start of &apos;ora.asm&apos; on &apos;orl6&apos; succeeded[grid@orl6:/home/grid]$ [grid@orl6:/home/grid]$ sqlplus / as sysasmSQL&gt; alter diskgroup DATA1 mount;Diskgroup altered.[grid@orl6:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------NAME TARGET STATE SERVER STATE_DETAILS --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.DATA1.dg ONLINE ONLINE orl6 ora.LISTENER.lsnr ONLINE ONLINE orl6 ora.asm ONLINE ONLINE orl6 Started ora.ons OFFLINE OFFLINE orl6 --------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.cssd 1 ONLINE ONLINE orl6 ora.diskmon 1 OFFLINE OFFLINE ora.evmd 1 ONLINE ONLINE orl6 4、添加database资源到GI添加前，先把旧机器上listener.ora等文件copy过来，同时要保证相关目录存在，添加spfile位置等，在客户现场遇到的问题就是GI在起的过程中，local_listener报错，其设置为tnsnames解析，将旧设备上tnsnames.ora复制过来即可。12345678910111213141516171819202122232425262728293031[oracle@orl6:/home/oracle]$ vi $ORACLE_HOME/dbs/initkyun.oraSPFILE=&apos;+DATA1/kyun/spfilekyun.ora&apos;[oracle@orl6:/home/oracle]$ mkdir -p $ORACLE_BASE/admin/$ORACLE_SID/adump[oracle@orl6:/home/oracle]$ srvctl add database -d kyun -o /u01/app/oracle/product/11gr2[oracle@orl6:/home/oracle]$ [grid@orl6:/home/grid]$ srvctl start database -d kyun[grid@orl6:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------NAME TARGET STATE SERVER STATE_DETAILS --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.DATA1.dg ONLINE ONLINE orl6 ora.LISTENER.lsnr ONLINE ONLINE orl6 ora.asm ONLINE ONLINE orl6 Started ora.ons OFFLINE OFFLINE orl6 --------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.cssd 1 ONLINE ONLINE orl6 ora.diskmon 1 OFFLINE OFFLINE ora.evmd 1 ONLINE ONLINE orl6 ora.kyun.db 1 ONLINE ONLINE orl6 Open 最后，重启集群和主机，看看数据库是否会随HA启动 EOF","link":"/migrate-asm-to-different-host.html"},{"title":"Migrate non-ASM to ASM in 12c","text":"There are many approaches can convert file system to ASM, such as RMAn copy database image, as of 12c, you can move datafiles online, that feature enables you minimize the downtime. 1. AbstractMy CDB named ora12c contain one PDB named pdb1 with local file system datafiles. I have my GI standalone installed with diffenert owner GRID contains two asm disk groups, I need to migrate the whole CDB to ASM. Below is the current environment before migration. 123456789101112131415161718192021222324252627282930#GI already installed with 2 disk groups [grid@linora:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------Name Target State Server State details --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.DATA.dg ONLINE ONLINE linora STABLEora.LISTENER.lsnr ONLINE ONLINE linora STABLEora.asm ONLINE ONLINE linora Started,STABLEora.ons OFFLINE OFFLINE linora STABLE--------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.cssd 1 ONLINE ONLINE linora STABLEora.diskmon 1 OFFLINE OFFLINE STABLEora.evmd 1 ONLINE ONLINE linora STABLE--------------------------------------------------------------------------------SQL&gt; select NAME,STATE from v$asm_diskgroup;NAME STATE------------------------------ -----------FRA MOUNTEDDATA MOUNTED 2. Find out the datafiles to be convertedConnect to CDB ROOT container via RMAN, use report schema which can show you all the datafiles and tempfiles that inlcuding PDBs and CDB.123456789101112131415161718192021222324RMAN&gt; report schema;using target database control file instead of recovery catalogReport of database schema for database with db_unique_name ORA12CList of Permanent Datafiles===========================File Size(MB) Tablespace RB segs Datafile Name---- -------- -------------------- ------- ------------------------1 790 SYSTEM YES /oradata/ora12c/system01.dbf2 260 PDB$SEED:SYSTEM NO /oradata/ora12c/pdbseed/system01.dbf3 690 SYSAUX NO /oradata/ora12c/sysaux01.dbf4 595 PDB$SEED:SYSAUX NO /oradata/ora12c/pdbseed/sysaux01.dbf5 1480 UNDOTBS1 YES /oradata/ora12c/undotbs01.dbf6 5 USERS NO /oradata/ora12c/users01.dbf7 260 PDB1:SYSTEM NO /oradata/ora12c/pdb1/system01.dbf8 605 PDB1:SYSAUX NO /oradata/ora12c/pdb1/sysaux01.dbf9 5 PDB1:USERS NO /oradata/ora12c/pdb1/pdb1_users01.dbf10 100 PDB1:FUNG NO /oradata/ora12c/pdb1/fung01.dbfList of Temporary Files=======================File Size(MB) Tablespace Maxsize(MB) Tempfile Name---- -------- -------------------- ----------- --------------------1 67 TEMP 32767 /oradata/ora12c/temp01.dbf2 62 PDB$SEED:TEMP 32767 /oradata/ora12c/pdbseed/temp01.dbf3 20 PDB1:TEMP 32767 /oradata/ora12c/pdb1/temp01.dbf 3. Moving the datafiles online to ASM disk group1234567SQL&gt; set lines 200set pages 50set feed offset head offspool /home/oracle/move_dbfiles.sqlselect &apos;ALTER DATABASE MOVE DATAFILE &apos;&apos;&apos;||name||&apos;&apos;&apos; TO &apos;&apos;+DATA&apos;&apos;;&apos; from v$datafile order by con_id;spool off Because there are multiple PDBs in the CDB, I need to change the session to the PDB container. I adjust the spooled file like below:12345678910111213[oracle@linora:/home/oracle]$ cat move_dbfiles.sql ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/system01.dbf&apos; TO &apos;+DATA&apos;;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/undotbs01.dbf&apos; TO &apos;+DATA&apos;;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/users01.dbf&apos; TO &apos;+DATA&apos;;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/sysaux01.dbf&apos; TO &apos;+DATA&apos;;ALTER SESSION SET CONTAINER=pdb$seed;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/pdbseed/sysaux01.dbf&apos; TO &apos;+DATA&apos;;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/pdbseed/system01.dbf&apos; TO &apos;+DATA&apos;;ALTER SESSION SET CONTAINER=pdb1;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/pdb1/fung01.dbf&apos; TO &apos;+DATA&apos;;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/pdb1/pdb1_users01.dbf&apos; TO &apos;+DATA&apos;;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/pdb1/system01.dbf&apos; TO &apos;+DATA&apos;;ALTER DATABASE MOVE DATAFILE &apos;/oradata/ora12c/pdb1/sysaux01.dbf&apos; TO &apos;+DATA&apos;; 4. Moving the tempfile to ASM disk groupWe can add the new tempfile and drop the old one to migrate the tempfile.123456789101112131415161718#Moving CDB tempfilesSQL&gt; alter tablespace TEMP add tempfile &apos;+DATA&apos;;SQL&gt; alter tablespace TEMP drop tempfile &apos;/oradata/ora12c/temp01.dbf&apos;;#Moving PDB tempfilesSQL&gt; alter session set container=pdb1;SQL&gt; alter tablespace TEMP add tempfile &apos;+DATA&apos;;SQL&gt; alter tablespace TEMP drop tempfile &apos;/oradata/ora12c/pdb1/temp01.dbf&apos;;#Moving PDB$SEED tempfiles SQL&gt; alter session set container=CDB$ROOT;SQL&gt; alter session set &quot;_oracle_script&quot;=TRUE;SQL&gt; alter pluggable database pdb$seed close;SQL&gt; alter pluggable database pdb$seed open read write;SQL&gt; alter session set container=pdb$seed;SQL&gt; alter tablespace temp add tempfile &apos;+DATA&apos;;SQL&gt; alter tablespace temp drop tempfile &apos;/oradata/ora12c/pdbseed/temp01.dbf&apos;;SQL&gt; alter session set container=CDB$ROOT;SQL&gt; alter pluggable database pdb$seed close;SQL&gt; alter pluggable database pdb$seed open read only; Query the modified result in RMAN:123456789101112131415161718192021222324RMAN&gt; report schema;using target database control file instead of recovery catalogReport of database schema for database with db_unique_name ORA12CList of Permanent Datafiles===========================File Size(MB) Tablespace RB segs Datafile Name---- -------- -------------------- ------- ------------------------1 790 SYSTEM YES +DATA/ORA12C/DATAFILE/system.257.9080426292 260 PDB$SEED:SYSTEM NO +DATA/ORA12C/2F64B9185F472450E0534638A8C061D3/DATAFILE/system.262.9080428853 690 SYSAUX NO +DATA/ORA12C/DATAFILE/sysaux.260.9080428114 595 PDB$SEED:SYSAUX NO +DATA/ORA12C/2F64B9185F472450E0534638A8C061D3/DATAFILE/sysaux.261.9080428495 1480 UNDOTBS1 YES +DATA/ORA12C/DATAFILE/undotbs1.258.9080427216 5 USERS NO +DATA/ORA12C/DATAFILE/users.259.9080428097 260 PDB1:SYSTEM NO +DATA/ORA12C/2F659BBCFD612D6DE0534638A8C0AEF9/DATAFILE/system.265.9080429098 605 PDB1:SYSAUX NO +DATA/ORA12C/2F659BBCFD612D6DE0534638A8C0AEF9/DATAFILE/sysaux.266.9080429259 5 PDB1:USERS NO +DATA/ORA12C/2F659BBCFD612D6DE0534638A8C0AEF9/DATAFILE/users.264.90804290710 100 PDB1:FUNG NO +DATA/ORA12C/2F659BBCFD612D6DE0534638A8C0AEF9/DATAFILE/fung.263.908042901List of Temporary Files=======================File Size(MB) Tablespace Maxsize(MB) Tempfile Name---- -------- -------------------- ----------- --------------------4 100 TEMP 32767 +DATA/ORA12C/TEMPFILE/temp.267.9080476655 100 PDB1:TEMP 32767 +DATA/ORA12C/2F659BBCFD612D6DE0534638A8C0AEF9/TEMPFILE/temp.268.9080477596 100 PDB$SEED:TEMP 32767 +DATA/ORA12C/2F64B9185F472450E0534638A8C061D3/TEMPFILE/temp.269.908047875 5. Moving redo log filesRedo log files only exisit in CDB, because all PDBs share the same redo, so when crash recovery needed, only can CDB do it.12345678910111213SQL&gt; select member from v$logfile;MEMBER--------------------------------------------------------------------------------/oradata/ora12c/redo01.log/oradata/ora12c/redo02.log/oradata/ora12c/redo03.logSQL&gt; select group#, status from v$log; GROUP# STATUS---------- -------------------------------- 1 INACTIVE 2 INACTIVE 3 CURRENT I dropped a group member and re-create it in ASM disk group to migrate the redo log files.123456789SQL&gt; alter database drop logfile group 1;SQL&gt; alter database add logfile group 1 &apos;+DATA&apos;;SQL&gt; alter database drop logfile group 2;SQL&gt; alter database add logfile group 2 &apos;+DATA&apos;;#Log group 3 is current log, switch it first SQL&gt; alter system switch logfile;SQL&gt; alter system checkpoint;SQL&gt; alter database drop logfile group 3;SQL&gt; alter database add logfile group 3 &apos;+DATA&apos;; Query the result from the dynamic view:123456789101112SQL&gt; select member from v$logfile;MEMBER--------------------------------------------------------------------------------+DATA/ORA12C/ONLINELOG/group_1.270.908048777+DATA/ORA12C/ONLINELOG/group_2.271.908048801+DATA/ORA12C/ONLINELOG/group_3.272.908048857SQL&gt; select group#, status from v$log; GROUP# STATUS---------- -------------------------------- 1 CURRENT 2 UNUSED 3 UNUSED 6. Moving control files and spfile to ASM disk groupActivate the control files new location needs to bring down the database, this is the only step which need to downtime in non-ASM to ASM migration in 12c.12345SQL&gt; show parameter control_filesNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------control_files string /oradata/ora12c/control01.ctl, /FRA/ora12c/control02.ctl Shutdown the instance, bring the database in nomount mode, restore current controfiles to ASM, and modify the location of controlfiles in spfile/initial file.123456789101112131415161718SQL&gt; shutdown immediateSQL&gt; startup nomount;#Restoring the current control files to ASM via RMANRMAN&gt; restore controlfile to &apos;+DATA&apos; from &apos;/oradata/ora12c/control01.ctl&apos;;RMAN&gt; restore controlfile to &apos;+FRA&apos; from &apos;/FRA/ora12c/control02.ctl&apos;;#Query the control files restored to ASM via asmcmdASMCMD [+] &gt; find --type CONTROLFILE +DATA *+DATA/ORA12C/CONTROLFILE/current.273.908049269ASMCMD [+] &gt; find --type CONTROLFILE +FRA *+FRA/ORA12C/CONTROLFILE/current.256.908049303#Modify the controlfiles location in spfileSQL&gt; alter system set control_files=&apos;+DATA/ORA12C/CONTROLFILE/current.273.908049269&apos;,&apos;+FRA/ORA12C/CONTROLFILE/current.256.908049303&apos; scope=spfile;#Change the FRA to ASMSQL&gt; alter system set db_recovery_file_dest=&apos;+FRA&apos; scope=spfile;#Modify archive log destination to FRA SQL&gt; alter system reset log_archive_dest_1;#Modify local listenerSQL&gt; alter system set local_listener=&apos;(ADDRESS=(PROTOCOL=TCP)(HOST=LINORA)(PORT=1522))&apos; scope=spfile; Now, the spfile still in file system, I need to move it to ASM, and create a legacy initial file point to the spfile location in ASM.1234567#Restoring the spfile to ASM via RMANRMAN&gt; alter database mount ;RMAN&gt; run&#123;BACKUP AS BACKUPSET SPFILE;RESTORE SPFILE TO &quot;+DATA/ORA12C/spfileora12c.ora&quot;;&#125; Rename or remove the old initial file or spfile in $ORACLE_HOME/dbs, edit a new initial file with below contents:12345678#delete the old spfile/initial file [oracle@linora:/u01/app/oracle/product/12.0.1/db1/dbs]$ rm -rf initora12c.ora [oracle@linora:/u01/app/oracle/product/12.0.1/db1/dbs]$ rm -rf spfileora12c.ora[oracle@linora:/u01/app/oracle/product/12.0.1/db1/dbs]$ cat &gt;&gt;initora12c.ora&lt;&lt;EOF&gt; SPFILE=&apos;+DATA/ORA12C/spfileora12c.ora&apos;&gt; EOF[oracle@linora:/u01/app/oracle/product/12.0.1/db1/dbs]$ cat initora12c.ora SPFILE=&apos;+DATA/ORA12C/spfileora12c.ora&apos; Start the database with the new spfile in ASM:12345678910111213SQL&gt; shutdown immediateSQL&gt; startupSQL&gt; show parameter pfile NAME TYPE VALUE------------------------------------ ---------------------- ------------------------------spfile string +DATA/ORA12C/spfileora12c.oraSQL&gt; show parameter control_filesNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------control_files string +DATA/ORA12C/CONTROLFILE/curre nt.273.908049269, +FRA/ORA12C/ CONTROLFILE/current.256.908049 303 7. Post-migration tasksThe rest tasks will be add the service to the standalone grid infrastructure, including the database, the listener. 7.1 Adding the database resource to GI1234#Add the database resource[oracle@linora:/home/oracle]$ srvctl add database -d ora12c -o $ORACLE_HOME -startoption OPEN -policy AUTOMATIC -v#Add the spfile to new location [oracle@linora:/home/oracle]$ srvctl modify database -db ora12c -o $ORACLE_HOME -spfile &apos;+DATA/ORA12C/spfileora12c.ora&apos; -diskgroup &quot;DATA,FRA&quot; 7.2 Adding the database listener resource to GIAfter you installed and created GI instance, the listener will create automatically, but it cannot listen the database. The database listener cannot manage by the GI too. This step is listener migration from database to GI. Remove the GI listener resource 123456789101112131415161718192021222324252627282930313233[grid@linora:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------Name Target State Server State details --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.DATA.dg ONLINE ONLINE linora STABLEora.FRA.dg ONLINE ONLINE linora STABLEora.LISTENER.lsnr ONLINE ONLINE linora STABLEora.asm ONLINE ONLINE linora Started,STABLEora.ons OFFLINE OFFLINE linora STABLE--------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.cssd 1 ONLINE ONLINE linora STABLEora.diskmon 1 OFFLINE OFFLINE STABLEora.evmd 1 ONLINE ONLINE linora STABLEora.ora12c.db 1 ONLINE ONLINE linora Open,STABLE--------------------------------------------------------------------------------[grid@linora:/home/grid]$ srvctl stop listener -listener listener[grid@linora:/home/grid]$ srvctl remove listener -all[grid@linora:/home/grid]$ pgrep -lf tns15 netns2442 /u01/app/oracle/product/12.0.1/db1/bin/tnslsnr LISTENER -inherit Copy the database listener configuration to GI HOME 123456789[oracle@linora:/home/oracle]$ lsnrctl stop[grid@linora:/home/grid]$ cd $ORACLE_HOME/network/admin/[grid@linora:/u02/app/grid/12.1.0/grid/network/admin]$ cp /u01/app/oracle/product/12.0.1/db1/network/admin/listener.ora ./[grid@linora:/u02/app/grid/12.1.0/grid/network/admin]$ cp /u01/app/oracle/product/12.0.1/db1/network/admin/tnsnames.ora ./[grid@linora:/u02/app/grid/12.1.0/grid/network/admin]$ cp /u01/app/oracle/product/12.0.1/db1/network/admin/sqlnet.ora ./[grid@linora:/u02/app/grid/12.1.0/grid/network/admin]$ cat &gt;&gt; listener.ora &lt;&lt;EOF ENABLE_GLOBAL_DYNAMIC_ENDPOINT_LISTENER=ONEOF[grid@linora:/u02/app/grid/12.1.0/grid/network/admin]$ sed -i &apos;/ADR_BASE_LISTENER/s/\\/u01\\/app\\/oracle/\\/u02\\/app\\/grid/g&apos; listener.ora Add the new listener to GI 1234567891011121314151617181920212223242526272829303132[grid@linora:/home/grid]$ srvctl add listener -l LISTENER -p &quot;TCP:1522&quot; -o $ORACLE_HOME[grid@linora:/home/grid]$ srvctl start listener -listener LISTENER[grid@linora:/home/grid]$ pgrep -lf tns15 netns7429 /u02/app/grid/12.1.0/grid/bin/tnslsnr LISTENER -no_crs_notify -inherit[grid@linora:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------Name Target State Server State details --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.DATA.dg ONLINE ONLINE linora STABLEora.FRA.dg ONLINE ONLINE linora STABLEora.LISTENER.lsnr ONLINE ONLINE linora STABLEora.asm ONLINE ONLINE linora Started,STABLEora.ons OFFLINE OFFLINE linora STABLE--------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.cssd 1 ONLINE ONLINE linora STABLEora.diskmon 1 OFFLINE OFFLINE STABLEora.evmd 1 ONLINE ONLINE linora STABLEora.ora12c.db 1 ONLINE ONLINE linora Open,STABLE Connect to the database via TCP/IP, if possible, reboot the OS to see if the database can autostart with the GI or not. 8. Trouble shootingWhen I tried to start the database, encountered the below errors:1234ORA-15025: could not open disk &quot;/dev/asm-diskb&quot;ORA-27041: unable to open fileLinux-x86_64 Error: 13: Permission deniedAdditional information: 3 Solutions:123[root@linora ~]# su - grid[grid@linora:/home/grid]$ cd $ORACLE_HOME/bin[grid@linora:/u02/app/grid/12.1.0/grid/bin]$ ./setasmgidwrap o=/u01/app/oracle/product/12.0.1/db1/bin/oracle If you need the database autostart with the GI, don&#39;t forget to add dba group to grid user:12[grid@linora:/home/grid]$ iduid=501(grid) gid=500(oinstall) groups=500(oinstall),501(dba),502(asmadmin),503(asmdba) EOF","link":"/migrate-non-asm-to-asm-in-12c.html"},{"title":"Migrating SMS to DMS in DB2","text":"Some DBA would be required to convert the SMS tablespace to DMS tablespace. But seems DB2 do not have such utilities to convert SMS to DMS directly. We cannot use backup/restore for restoring the SMS to DMS, the traditional way to convert SMS to DMS is to use db2look and db2move. Also hope some people can tell me a better option.To convert the SMS to DMS( in my production environment, there are over 300 tables belong to multiple schemas), following steps would be required(Outage required): 12345671. Extract tables&apos; DDL in the tablespace 2. Export all the data belong to the tablespace 3. Create a new DMS tablespace 4. Drop the old SMS tablespace 5. Modify the DDL script and create the tables from the DDL script 6. Load the data back into the new DMS tablespace 7. Set integrity for the tables 1. Extracting the DDL of the tablesBefore migration: 1234567891011121314151617181920212223242526272829303132333435[db2inst1@db2srv ~]$ db2 \"select substr(TABLE_SCHEMA,1,10) as schema,substr(TABLE_NAME,1,15) as tabname, \\substr(TABLESPACE_NAME,1,15) as tbsname from sysibmadm.dba_all_tables where TABLESPACE_NAME='CONVERT1'\"SCHEMA TABNAME TBSNAME ---------- --------------- ---------------FUNG CL_SCHED CONVERT1 FUNG EMPLOYEE CONVERT1 FUNG DEPARTMENT CONVERT1 FUNG EMP_PHOTO CONVERT1 FUNG EMP_RESUME CONVERT1 FUNG PROJECT CONVERT1 FUNG PROJACT CONVERT1 FUNG EMPPROJACT CONVERT1 FUNG ACT CONVERT1 FUNG IN_TRAY CONVERT1 FUNG ORG CONVERT1 FUNG STAFF CONVERT1 FUNG SALES CONVERT1 FUNG STAFFG CONVERT1 FUNG ADEFUSR CONVERT1 DB2INST1 EMPLOYEE CONVERT1 DB2INST1 CL_SCHED CONVERT1 DB2INST1 DEPARTMENT CONVERT1 DB2INST1 PROJACT CONVERT1 DB2INST1 EMPPROJACT CONVERT1 DB2INST1 ACT CONVERT1 DB2INST1 EMP_PHOTO CONVERT1 DB2INST1 EMP_RESUME CONVERT1 DB2INST1 PROJECT CONVERT1 DB2INST1 IN_TRAY CONVERT1 DB2INST1 ORG CONVERT1 DB2INST1 STAFF CONVERT1 DB2INST1 SALES CONVERT1 DB2INST1 STAFFG CONVERT1 DB2INST1 ADEFUSR CONVERT1 There&#39;re two options which can let you extract the table structure. Option A: Extracting the whole schema&#39;s table DDlFrom the output, there are only two schemas in my SMS table space, if we have fewer related schemas, this option can be considered. 12345678910111213141516[db2inst1@db2srv ~]$ db2look -d testdb -z FUNG -e -o fung_schema.sql-- No userid was specified, db2look tries to use Environment variable USER-- USER is: DB2INST1-- Specified SCHEMA is: FUNG-- Creating DDL for table(s)-- Schema name is ignored for the Federated Section-- Output is sent to file: fung_schema.sql[db2inst1@db2srv ~]$ db2look -d testdb -z DB2INST1 -e -o db2inst1_schema.sql-- No userid was specified, db2look tries to use Environment variable USER-- USER is: DB2INST1-- Specified SCHEMA is: DB2INST1-- Creating DDL for table(s)-- Schema name is ignored for the Federated Section-- Output is sent to file: db2inst1_schema.sql Now the table definition are saved to the output files. Option B: Extracting the table DDL only in the tablespaceThis method would be recommended if we have many schemas reside in the SMS tablespace. 123456789#Generating extract DDL statementdb2 \"select 'db2look -d testdb -t '|| rtrim(TABSCHEMA) ||'.'||'\\\"' \\||TABNAME||'\\\"'|| ' -e' from syscat.tables where TBSPACEID='2'\" &gt; db2look.sql#Generating the DDL script./db2look.sql &gt;o.txt#Remove the commit state, otherwise, only the first DDL would be executedsed -i '/^COMMIT\\ WORK/d' o.txtsed -i '/^CONNECT\\ RESET/d' o.txtsed -i '/^TERMINATE/d' o.txt 2. Exporting all the tables reside in the tablespaceExport the table data into a directory by using db2move, db move will generate two files for each table, so it&#39;s a good idea to put all the files into a separate directory. 12[db2inst1@db2srv ~]$ mkdir -p /db2backup/db2move; cd /db2backup/db2move/[db2inst1@db2srv db2move]$ db2move testdb export -ts convert1 3. Dropping the old tablespace and creating a new tablespace1234[db2inst1@db2srv db2move]$ db2 drop tablespace convert1[db2inst1@db2srv db2move]$ db2 \"create tablespace DMSTBS1 managed by database using \\(file '/db/db2inst1/testdb/db2inst1/NODE0000/TESTDB/T0000005/myfile' 2048, \\file '/db/db2inst1/testdb/db2inst1/NODE0000/TESTDB/T0000005/myfile2' 2048) extentsize 4\" 4. Modifying the DDL script and creating the tables from the DDL script12[db2inst1@db2srv ~]$ sed -i 's/CONVERT1/DMSTBS1/g' fung_schema.sql[db2inst1@db2srv ~]$ sed -i 's/CONVERT1/DMSTBS1/g' db2inst1_schema.sql Double check the script to ensure there&#39;s no missing anything. If everything is OK, then creating the table into the new tablespace: 123[db2inst1@db2srv ~]$ db2 connect to testdb[db2inst1@db2srv ~]$ db2 -tvf fung_schema.sql[db2inst1@db2srv ~]$ db2 -tvf db2inst1_schema.sql Double check to ensure everything is fine, then we can proceed. 5. Loading the data back into the new tablespace12[db2inst1@db2srv ~]$ cd /db2backup/db2move/[db2inst1@db2srv db2move]$ db2move testdb load -l ./ Compare the output of LOAD.out and EXPORT.out, if the committed rows are exactly equal, then everything is okay. 6. Setting the integrity for the tablesFirst, using following SQL to query the table status:12345678910111213141516171819202122232425Select substr(tabschema,1,8) as \"Qualified Name\",substr(tabname,1,50) as \"Table name\",CASE typeWHEN 'A' THEN 'Alias'WHEN 'H' THEN 'Hierarchy Table'WHEN 'N' THEN 'Nickname'WHEN 'S' THEN 'Summary Table'WHEN 'T' THEN 'Table'WHEN 'U' THEN 'Typed Table'WHEN 'V' THEN 'View'WHEN 'W' THEN 'Typed View'END as \"Table Type\",CASE statusWHEN 'N' THEN 'Normal'WHEN 'C' THEN 'Check Pending'WHEN 'X' THEN 'Inoperative'END as \"Table Status\"from syscat.tables;[db2inst1@db2srv ~]$ db2 -tvf finding_all_table_status.sql |grep -v NormalQualified Name Table name Table Type Table Status -------------- -------------------------------------------------- --------------- -------------FUNG DEPARTMENT Table Check PendingFUNG EMPLOYEE Table Check PendingFUNG EMP_PHOTO Table Check Pending Generating the set integrity command:123[db2inst1@db2srv ~]$ db2 \"select 'set integrity for '|| rtrim(tabschema)||'.'||tabname|| ' \\IMMEDIATE CHECKED;' from syscat.tables where status !='N'\"&gt;setint. sql[db2inst1@db2srv ~]$ db2 -tvf setint.sql Some errors are expected, because we separated co-dependency tables to set integrity, which they should be together. 12345678set integrity for FUNG.EMPLOYEE IMMEDIATE CHECKEDDB21034E The command was processed as an SQL statement because it was not a valid Command Line Processor command. During SQL processing it returned:SQL3608N Cannot check a dependent table \"FUNG.EMPLOYEE\" using the SET INTEGRITY statement while the parent table or underlying table \"FUNG.DEPARTMENT\" is in the Set Integrity Pending state or if it will be put into the Set Integrity Pending state by the SET INTEGRITY statement. SQLSTATE=428A8 Execute the set integrity together for the co-dependency tables:123456SET INTEGRITY FOR &lt;table1&gt;, &lt;table2&gt; IMMEDIATE CHECKED[db2inst1@db2srv ~]$ db2 set schema fungDB20000I The SQL command completed successfully.[db2inst1@db2srv ~]$ db2 set integrity for EMPLOYEE,EMP_PHOTO,EMP_RESUME, \\PROJECT,PROJACT,EMPPROJACT,ADEFUSR IMMEDIATE CHECKEDDB20000I The SQL command completed successfully. Finally, we&#39;re here, converted the SMS to DMS succefully. EOF","link":"/migrating-sms-to-dms-in-db2.html"},{"title":"Moving Files in database","text":"As a production DBA, we may meet some file movement requirements, such as move a data file from a filesystem to another filesystem, move redo log files, move control files, even move standard file system to ASM. This topic discuss how to relocate those files in Oracle database and how to migrate the whole tablespace in DB2 database. 1. Relocating files in Oracle databaseThe most important file types in Oracle database are: data file, control file and redo log file, I&#39;ll show the most common approach to relocate these types of file. 1.1 Moving datafilesIn oracle database 11g and earlier, moving datafiles will affect relevant applications or the whole database. As of Oracle database 12c, a new feature can let you moving the datafiles while the tablespace and the database keeping online. Moving datafiles in 12c With 12c new feature, you can move any datafiles without any downtime, and can move all dafafiles in all tablespaces, including SYSTEM AND SYSAUX. It&#39;s also works with ASM diskgroup.1234567891011121314151617SQL&gt; select INSTANCE_NAME,VERSION,STATUS from v$instance;INSTANCE_NAME VERSION STATUS-------------------------------- ---------------------------------- ------------------------linora 12.1.0.2.0 OPENSQL&gt; select * from v$dbfile where file#=5; FILE# NAME CON_ID---------- -------------------------------------------------- ---------- 5 /oradata/linora/fung01.dbf 0SQL&gt; alter database move datafile &apos;/oradata/linora/fung01.dbf&apos; to &apos;/data/linora/fung01.dbf&apos;;--to ASM DGSQL&gt; alter database move datafile &apos;/oradata/linora/fung01.dbf&apos; to &apos;+DATA&apos;;SQL&gt; select * from v$dbfile where file#=5; FILE# NAME CON_ID---------- -------------------------------------------------- ---------- 5 /data/linora/fung01.dbf 0 Previous post also can be referred in RAC or ASM environments: RAC Datafile in Local Node . Moving datafiles in 11g or earlier There are two approaches can accomplish this task: with ALTER DATABASE command or with ALTER TABLESPACE command. The difference between the two methods is that ALTER DATABASE need to bring the whole database down, and ALTER TABLESPACE only need to offline the relevant tablespaces.12345678910111213SQL&gt; select INSTANCE_NAME,VERSION,STATUS from v$instance;INSTANCE_NAME VERSION STATUS-------------------------------- ---------------------------------- ------------------------ora11g 11.2.0.4.0 OPENSQL&gt; select * from v$dbfile; FILE# NAME---------- -------------------------------------------------- 1 /oradata/ora11g/ora11g/system01.dbf 2 /oradata/ora11g/ora11g/sysaux01.dbf 3 /oradata/ora11g/ora11g/undotbs01.dbf 4 /oradata/ora11g/ora11g/fung01.dbf 5 /oradata/ora11g/ora11g/users01.dbf Moving datafiles with ALTER DATABASE This approach needs to shutdown the instance, because it needs to shutdown the instance, this method can move all the datafiles in all tablespaces including SYSTEM,SYSAUX etc., the general steps as below:1234567891011--moving fung01.dbf to /data/ora11g/ora11gSQL&gt; shutdown immediateSQL&gt; ! mv /oradata/ora11g/ora11g/fung01.dbf /data/ora11g/ora11g/ SQL&gt; startup mountSQL&gt; alter database rename file &apos;/oradata/ora11g/ora11g/fung01.dbf&apos; to &apos;/data/ora11g/ora11g/fung01.dbf&apos;;SQL&gt; alter database open;SQL&gt; select * from v$dbfile where file#=4; FILE# NAME---------- -------------------------------------------------- 4 /data/ora11g/ora11g/fung01.dbf--perform an full backup includes controlfiles Moving datafiles with ALTER TABLESPACE This approach cannot move SYSTEM,SYSAUX,active undo tablespace and temporary tablespace. With this method, you can keep your database online except the tablespace which datafiles will be moved. The general steps are as follow:12345678SQL&gt; alter tablespace fung offline;SQL&gt; !mv /data/ora11g/ora11g/fung01.dbf /oradata/ora11g/ora11g/fung01.dbf SQL&gt; alter tablespace fung rename datafile &apos;/data/ora11g/ora11g/fung01.dbf&apos; to &apos;/oradata/ora11g/ora11g/fung01.dbf&apos;;SQL&gt; alter tablespace fung online;SQL&gt; select * from v$dbfile where file#=4; FILE# NAME---------- -------------------------------------------------- 4 /oradata/ora11g/ora11g/fung01.dbf 1.2 Moving the redo log filesActually, you can just simply delete an entire redo log group and add a new redo log group in a different location Manage Redo .This approach can be used if database needs to be kept open. Below approach is how to do it when the database shut down.123456789101112131415161718SQL&gt; select * from v$logfile; GROUP# STATUS TYPE MEMBER IS_REC---------- -------------- -------------- -------------------------------------------------- ------ 1 ONLINE /oradata/ora11g/ora11g/redo01.log NO 2 ONLINE /oradata/ora11g/ora11g/redo02.log NO 3 ONLINE /oradata/ora11g/ora11g/redo03.log NOSQL&gt; shutdown immediateSQL&gt; !mv /oradata/ora11g/ora11g/redo03.log /data/ora11g/ora11g/SQL&gt; startup mountSQL&gt; alter database rename file &apos;/oradata/ora11g/ora11g/redo03.log&apos; to &apos;/data/ora11g/ora11g/redo03.log&apos;;SQL&gt; alter database open;SQL&gt; select * from v$logfile; GROUP# STATUS TYPE MEMBER IS_REC---------- -------------- -------------- -------------------------------------------------- ------ 1 ONLINE /oradata/ora11g/ora11g/redo01.log NO 2 ONLINE /oradata/ora11g/ora11g/redo02.log NO 3 ONLINE /data/ora11g/ora11g/redo03.log NO 1.3 Moving control filesThere are two approaches when moving control files depend on what initial files are you using. When using legacy init file instead of spfile, you need to shutdown the database, move the control file physically, and restart the database.Below method is about how to move the control file when using spfile.12345678910111213141516171819202122232425262728SQL&gt; select status,name from v$controlfile;STATUS NAME-------------- -------------------------------------------------- /oradata/ora11g/ora11g/control01.ctl /oradata/ora11g/ora11g/control02.ctlSQL&gt; show parameter control_files NAME TYPE VALUE------------------------- ---------------------- ------------------------------control_files string /oradata/ora11g/ora11g/control01.ctl, /oradata/ora11g/ora11g/control02.ctlSQL&gt; alter system set control_files = &apos;/data/ora11g/ora11g/control01.ctl&apos;, &apos;/data/ora11g/ora11g/control02.ctl&apos; scope=spfile;SQL&gt; shutdown immediateSQL&gt; !mv /oradata/ora11g/ora11g/control01.ctl /data/ora11g/ora11g/control01.ctlSQL&gt; !mv /oradata/ora11g/ora11g/control02.ctl /data/ora11g/ora11g/control02.ctlSQL&gt; startupSQL&gt; show parameter control_files NAME TYPE VALUE------------------------------------ ---------------------- ------------------------------control_files string /data/ora11g/ora11g/control01. ctl, /data/ora11g/ora11g/contr ol02.ctlSQL&gt; select name from v$controlfile;NAME--------------------------------------------------/data/ora11g/ora11g/control01.ctl/data/ora11g/ora11g/control02.ctl 2. Migrate the whole tablespace in DB2 databaseDepending on your storage configuration, there are different ways can let you move the tablespace to another location. As you know, DB2 V10.1 provide ALTER TABLESPACE... USING STOGROUP can relocate the whole tablespace to another storage group when using AUTOMATIC STORAGE MANAGEMENT. Following examples shows how to migrate the tablespace with different methods in different circumstance. 2.1 Migrate tablespace in non-automatic storageThere are three methods about moving tablespace in non-automatic storage. Below is the original testing environment.1234567891011121314[db2inst1@node1 ~]$ db2pd -d testdb -tablespacesTablespace Configuration:Address Id Type Content PageSz ExtentSz Auto Prefetch BufID BufIDDisk FSC NumCntrs MaxStripe LastConsecPg RSE Name0x00007FBAE70EE560 4 DMS Large 4096 32 Yes 64 1 1 Off 2 0 31 Yes FUNGTablespace Autoresize Statistics:Address Id AS AR InitSize IncSize IIP MaxSize LastResize LRF0x00007FBAE70EE560 4 No No -4096 0 No 0 None No #The AS field is No, mean non-automatic storageContainers:Address TspId ContainNum Type TotalPgs UseablePgs PathID StripeSet Container Containers:Address TspId ContainNum Type TotalPgs UseablePgs PathID StripeSet Container 0x00007FBAE70BE240 4 0 File 2560 2528 - 0 /data/db2inst1/NODE0000/SQL00001/fung01.LRG0x00007FBAE70BE470 4 1 File 2560 2528 - 0 /data/db2inst1/NODE0000/SQL00001/fung02.LRG I&#39;d like to move the tablespace &quot;FUNG&quot; from /data/ to /data2/ file system by using different ways showing as below. Adding the new containers without rebalance and delete the old containers First, add new containers to the target file system, I use begin new stripe set, this means no rebalancing occur when adding new containers, if you want to add containers to an exist stripe set, use ADD TO STRIPE SET clause.12345678910[db2inst1@node1 ~]$ db2 &quot;alter tablespace fung begin new stripe set(file &apos;/data2/db2inst1/NODE0000/SQL00001/fung01.LRG&apos; 10M,file &apos;/data2/db2inst1/NODE0000/SQL00001/fung02.LRG&apos; 10M)&quot;[db2inst1@node1 ~]$ db2pd -d testdb -tablespacesContainers:Address TspId ContainNum Type TotalPgs UseablePgs PathID StripeSet Container 0x00007FBAE70C3780 4 0 File 2560 2528 - 0 /data/db2inst1/NODE0000/SQL00001/fung01.LRG0x00007FBAE70C39B0 4 1 File 2560 2528 - 0 /data/db2inst1/NODE0000/SQL00001/fung02.LRG0x00007FBAE70C3BE0 4 2 File 2560 2528 - 1 /data2/db2inst1/NODE0000/SQL00001/fung01.LRG0x00007FBAE70C3E10 4 3 File 2560 2528 - 1 /data2/db2inst1/NODE0000/SQL00001/fung02.LRG Then, drop old containers, rebalancing will occur automatically in background.12[db2inst1@node1 ~]$ db2 &quot;alter tablespace fung drop ( file &apos;/data/db2inst1/NODE0000/SQL00001/fung01.LRG&apos;, file &apos;/data/db2inst1/NODE0000/SQL00001/fung02.LRG&apos;)&quot; We can use table function to monitor the rebalance status.123456789101112131415161718192021222324--As of V10.1db2 &quot;select varchar(tbsp_name, 30) as tbsp_name, dbpartitionnum, member, rebalancer_mode, rebalancer_status, rebalancer_extents_remaining, rebalancer_extents_processed, rebalancer_start_time from table(mon_get_rebalance_status(NULL,-2)) as t&quot;--V9.7 and earlierdb2 &quot;select varchar(tbsp_name, 30) as tbsp_name, dbpartitionnum, rebalancer_mode, rebalancer_extents_remaining, rebalancer_extents_processed, rebalancer_start_time from table(snap_get_tbsp_part_v91(NULL,-2)) as t&quot; Performing a db2relocatedb utility This is a much quickly way than adding new containers, if you have large data in this tablespace, the rebalancing will last very long time. But relocatedb can minimal the downtime via move physical file directly, this method need to restart the database. 12345678910111213141516171819202122--configure the relocatedb parameter file as below[db2inst1@node1 ~]$ cat relocatedb.cfgDB_NAME=testdbDB_PATH=/data/INSTANCE=db2inst1NODENUM=0CONT_PATH=/data/db2inst1/NODE0000/SQL00001/fung01.LRG,/data2/db2inst1/NODE0000/SQL00001/fung01.LRGCONT_PATH=/data/db2inst1/NODE0000/SQL00001/fung02.LRG,/data2/db2inst1/NODE0000/SQL00001/fung02.LRG--deactivate the database, move the containers physically via OS command [db2inst1@node1 ~]$ db2 deactivate db testdb[db2inst1@node1 ~]$ mv /data/db2inst1/NODE0000/SQL00001/fung01.LRG /data2/db2inst1/NODE0000/SQL00001/fung01.LRG[db2inst1@node1 ~]$ mv /data/db2inst1/NODE0000/SQL00001/fung02.LRG /data2/db2inst1/NODE0000/SQL00001/fung02.LRG--relocate the database [db2inst1@node1 ~]$ db2relocatedb -f relocatedb.cfg Files and control structures were changed successfully.--activate the database, and verify the result[db2inst1@node1 ~]$ db2pd -d testdb -tablespaces...Containers:Address TspId ContainNum Type TotalPgs UseablePgs PathID StripeSet Container 0x00007FBADFA9A120 4 0 File 2560 2528 - 0 /data2/db2inst1/NODE0000/SQL00001/fung01.LRG0x00007FBADFA9A350 4 1 File 2560 2528 - 0 /data2/db2inst1/NODE0000/SQL00001/fung02.LRG Redirect restoring the tablespace This is another optional way, backup images and the downtime are required.1234567891011121314--generate redirect script[db2inst1@node1 ~]$ db2 &quot;restore db testdb REBUILD WITH all tablespaces in database from /data \\taken at 20160324193845 redirect generate script redirect.clp&quot;--modify the script of container 4 toSET TABLESPACE CONTAINERS FOR 4-- IGNORE ROLLFORWARD CONTAINER OPERATIONSUSING ( FILE &apos;/data2/db2inst1/NODE0000/SQL00001/fung01.LRG&apos; 2560, FILE &apos;/data2/db2inst1/NODE0000/SQL00001/fung02.LRG&apos; 2560);--executing redirect script[db2inst1@node1 ~]$ db2 -tvf redirect.clp--rollforward the db to end of logs [db2inst1@node1 ~]$ db2 rollforward db testdb to end of logs and complete By verifying the result, you can find out the container path already changed. 2.2 Migrate tablespace in automatic storageIt&#39;s very simple while relocating the tablespace to another location when using automatic storage, via ALTER TABLESPACE...USING STOGROUP you can simply specify the storage path which you want to move to. You can also use db2relocatedb, but f you via db2relocatedb tool to relocate the containers, it&#39;s not support CONT_PATH, you need to reloate the whole storage group together.1234567891011[db2inst1@node1 ~]$ db2pd -d source -storagepath|grep -i &quot;Group Paths&quot; -A 5Storage Group Paths: Address SGID PathID PathState PathName0x00007FBB1B348000 0 0 InUse /db2/data/newstorage[db2inst1@node1 ~]$ db2pd -d source -tablespacesTablespace Configuration:Address Id Type Content PageSz ExtentSz Auto Prefetch BufID BufIDDisk FSC NumCntrs MaxStripe LastConsecPg RSE Name0x00007FBB1E230080 2 DMS Large 8192 32 Yes 64 1 1 Off 2 0 31 Yes USERSPACE1Containers:Address TspId ContainNum Type TotalPgs UseablePgs PathID StripeSet Container 0x00007FBB226F9200 2 0 File 1920 1888 0 0 /db2/data/newstorage/db2inst1/NODE0000/SOURCE/T0000002/C0000002.LRG Assumed my file system &quot;/db2/data/newstorage&quot; is encountered file system full issue, I&#39;d like to move the whole tablespace &quot;USERSPACE1&quot; to another file system &quot;/db2/data/db2inst1&quot;, only 2 steps can accomplish that, and with this method, no need to bring down database, the rebalance will start automatically and will move all tablespace data to the new path in the background.123456789101112131415161718--create a storage path in /db2/data/db2inst1[db2inst1@node1 ~]$ db2 &quot;create stogroup sg2 on &apos;/db2/data/db2inst1&apos;&quot;--find out the create result[db2inst1@node1 ~]$ db2 &quot;select substr(SGNAME,1,20) as SGNAME,substr(OWNER,1,10) as owner, \\CREATE_TIME,DEFAULTSG from syscat.stogroups&quot;SGNAME OWNER CREATE_TIME DEFAULTSG-------------------- ---------- -------------------------- ---------IBMSTOGROUP SYSIBM 2016-03-22-14.03.00.472669 Y SG2 DB2INST1 2016-03-24-17.38.22.583351 N --move the tablespace to new storage group[db2inst1@node1 ~]$ db2 &quot;alter tablespace USERSPACE1 using stogroup sg2&quot;[db2inst1@node1 ~]$ db2pd -d source -tablespacesTablespace Configuration:Address Id Type Content PageSz ExtentSz Auto Prefetch BufID BufIDDisk FSC NumCntrs MaxStripe LastConsecPg RSE Name0x00007FBB1E230080 2 DMS Large 8192 32 Yes 32 1 1 Off 1 0 31 Yes USERSPACE1Containers:Address TspId ContainNum Type TotalPgs UseablePgs PathID StripeSet Container 0x00007FBB226FBCE0 2 0 File 3776 3744 1024 0 /db2/data/db2inst1/db2inst1/NODE0000/SOURCE/T0000002/C0000004.LRG 2.3. How to find out whether the tablespace is automatic storage or notMany ways can find out whether the databaspace is AS or not.12345db2 &quot;select TBSP_USING_AUTO_STORAGE,tbsp_name from SYSIBMADM.SNAPTBSP&quot;db2 &quot;select TBSP_USING_AUTO_STORAGE,tbsp_name from SYSIBMADM.TBSP_UTILIZATION&quot;db2 &quot;select TBSP_USING_AUTO_STORAGE,tbsp_name from SYSIBMADM.MON_TBSP_UTILIZATION&quot;db2pd -db source -tablespaces #Tablespace Autoresize Statistics field &quot;AS&quot; value &quot;YES&quot;db2 get snapshot for tablespaces on DB_NAME #Using automatic storage field value &quot;YES&quot; EOF","link":"/moving-files-in-database.html"},{"title":"Multipath with udev in RHEL6","text":"Multipath为linux自带多路径聚合软件，用于磁盘路径设备名称绑定，在6.x后期版本中，已经不支持multipath直接修改磁盘权限，需要通过udev进行设定。 1.multipath安装1234567891011121314[root@orl6 ~]# yum install device-mapper-multipath -y[root@orl6 ~]# /etc/init.d/multipathd startStarting multipathd daemon: [ OK ][root@orl6 ~]# chkconfig multipathd on[root@orl6 ~]# multipath enableJun 15 22:09:36 | /etc/multipath.conf does not exist, blacklisting all devices.Jun 15 22:09:36 | A sample multipath.conf file is located atJun 15 22:09:36 | /usr/share/doc/device-mapper-multipath-0.4.9/multipath.confJun 15 22:09:36 | You can run /sbin/mpathconf to create or modify /etc/multipath.conf[root@orl6 ~]# cp /usr/share/doc/device-mapper-multipath-0.4.9/multipath.conf /etc/multipath.conf[root@orl6 ~]# grep -v ^# /etc/multipath.confdefaults &#123; user_friendly_names yes&#125; 2.配置multipath.conf通过scsi_id命令找出磁盘wwid，并按照模板写入multipath.confRHEL 7 scsi_id为/lib/udev/scsi_id.12345678[root@orl6 ~]# for i in a b c d;&gt; do &gt; /sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i&gt; done1ATA_VBOX_HARDDISK_VBfe43d230-3b43fe421ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b14f504e46494c45526354355179652d663752632d6d75574114f504e46494c45526354355179652d663752632d6d755741 可以看到，/dev/sdc和/dev/sdd是同一块磁盘，通过多路径聚合成一块，最后的配置文件如下：12345678910111213141516171819202122[root@orl6 ~]# grep -v ^# /etc/multipath.confblacklist &#123; #devnode &quot;^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*&quot; #devnode &quot;^hd[a-z]&quot; devnode &quot;sda&quot; #排除本地硬盘 #wwid 1ATA_VBOX_HARDDISK_VB2314099c-4ddf514a #wwid 1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b&#125;defaults &#123; user_friendly_names no getuid_callout &quot;/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/%n&quot;&#125;multipaths &#123; multipath &#123; wwid 1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b #原有ASM磁盘 alias mpath1 &#125; multipath &#123; wwid 14f504e46494c45526354355179652d663752632d6d755741 alias data_mpath2 &#125;&#125; 通过multipath路径即可发现聚合后的路径123456789101112[root@orl6 ~]# multipath -F[root@orl6 ~]# multipath -v2create: mpath1 (1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b) undef ATA,VBOX HARDDISKsize=20G features=&apos;0&apos; hwhandler=&apos;0&apos; wp=undef`-+- policy=&apos;round-robin 0&apos; prio=1 status=undef `- 3:0:0:0 sdb 8:16 undef ready runningcreate: data_mpath2 (14f504e46494c45526354355179652d663752632d6d755741) undef OPNFILER,VIRTUAL-DISKsize=15G features=&apos;0&apos; hwhandler=&apos;0&apos; wp=undef|-+- policy=&apos;round-robin 0&apos; prio=1 status=undef| `- 5:0:0:0 sdc 8:32 undef ready running`-+- policy=&apos;round-robin 0&apos; prio=1 status=undef `- 4:0:0:0 sdd 8:48 undef ready running Liunx自带device mapper的命令dmsetup:1234567891011121314151617181920212223[root@orl6 ~]# dmsetup lsmpath1 (252:0)data_mpath2 (252:1)[root@orl6 ~]# dmsetup infoName: mpath1State: ACTIVERead Ahead: 256Tables present: LIVEOpen count: 22Event number: 1Major, minor: 252, 0Number of targets: 1UUID: mpath-1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71bName: data_mpath2State: ACTIVERead Ahead: 256Tables present: LIVEOpen count: 0Event number: 0Major, minor: 252, 1Number of targets: 1UUID: mpath-14f504e46494c45526354355179652d663752632d6d755741 3.通过udev设置磁盘权限磁盘权限的设定在6后期版本中，multipath有自带的模板文件，如下：12345678910111213141516171819202122232425262728293031323334353637[root@orl6 ~]# find / -name &quot;12-dm-permissions.rules&quot;/usr/share/doc/device-mapper-1.02.79/12-dm-permissions.rules[root@orl6 ~]# cat /usr/share/doc/device-mapper-1.02.79/12-dm-permissions.rules--部分关于multipath的权限设定如下# Copyright (C) 2009 Red Hat, Inc. All rights reserved.## This file is part of LVM2.# Udev rules for device-mapper devices.## These rules set permissions for DM devices.## This file is considered to be a template where users can put their# own entries and then put a copy of it manually to a usual place with# user-edited udev rules (usually /etc/udev/rules.d).## There are some environment variables set that can be used:# DM_UDEV_RULES_VSN - DM udev rules version# DM_NAME - actual DM device&apos;s name# DM_UUID - UUID set for DM device (blank if not specified)# DM_SUSPENDED - suspended state of DM device (0 or 1)# DM_LV_NAME - logical volume name (not set if LVM device not present)# DM_VG_NAME - volume group name (not set if LVM device not present)# DM_LV_LAYER - logical volume layer (not set if LVM device not present)# PLAIN DM DEVICES## Set permissions for a DM device named &apos;my_device&apos; exactly# ENV&#123;DM_NAME&#125;==&quot;my_device&quot;, OWNER:=&quot;root&quot;, GROUP:=&quot;root&quot;, MODE:=&quot;660&quot;# Set permissions for all DM devices having &apos;MY_UUID-&apos; UUID prefix# ENV&#123;DM_UUID&#125;==&quot;MY_UUID-?*&quot;, OWNER:=&quot;root&quot;, GROUP:=&quot;root&quot;, MODE:=&quot;660&quot;# MULTIPATH DEVICES## Set permissions for all multipath devices# ENV&#123;DM_UUID&#125;==&quot;mpath-?*&quot;, OWNER:=&quot;root&quot;, GROUP:=&quot;root&quot;, MODE:=&quot;660&quot;# Set permissions for first two partitions created on a multipath device (and detected by kpartx)# ENV&#123;DM_UUID&#125;==&quot;part[1-2]-mpath-?*&quot;, OWNER:=&quot;root&quot;, GROUP:=&quot;root&quot;, MODE:=&quot;660&quot; 按照模板文件修改属主权限即可。12345678910111213[root@orl6 ~]# cat /etc/udev/rules.d/12-asm-perssion.rules ENV&#123;DM_NAME&#125;==&quot;mpath1&quot;,NAME=&quot;asmdisk1&quot;, OWNER:=&quot;grid&quot;, GROUP:=&quot;oinstall&quot;, MODE:=&quot;660&quot;ENV&#123;DM_NAME&#125;==&quot;data_mpath2&quot;,NAME=&quot;asmdisk2&quot;, OWNER:=&quot;grid&quot;, GROUP:=&quot;oinstall&quot;, MODE:=&quot;660&quot;下面一段可以不加：#[root@orl6 ~]# cat /etc/udev/rules.d/99-asm-rules.rules #KERNEL==&quot;sd*&quot;, SUBSYSTEM==&quot;block&quot;, ENV&#123;DEVTYPE&#125;==&quot;disk&quot;, ENV&#123;ID_SERIAL&#125;==&quot;1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;oinstall&quot;, MODE=&quot;0660&quot;#KERNEL==&quot;sd*&quot;, SUBSYSTEM==&quot;block&quot;, ENV&#123;DEVTYPE&#125;==&quot;disk&quot;, ENV&#123;ID_SERIAL&#125;==&quot;14f504e46494c45526354355179652d663752632d6d755741&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;oinstall&quot;, MODE=&quot;0660&quot;#重启udev[root@orl6 ~]# start_udevStarting udev: [ OK ][root@orl6 ~]# ll /dev/asm*brw-rw----. 1 grid oinstall 252, 0 Jun 15 22:17 /dev/asmdisk1brw-rw----. 1 grid oinstall 252, 1 Jun 15 22:17 /dev/asmdisk2 此时，grid用户通过asmca可发现可用磁盘。另外，udev自带的模板在[root@orl6 ~]# more /lib/udev/rules.d/50-udev-default.rules下。 4.EMC PowerPath使用udev1234567891011121314151617181920212223242526272829[root@db01 ~]# ls -l /dev/emc*crw-r--r--. 1 root root 10, 56 Jun 10 14:56 /dev/emcpowerbrw-rw----. 1 root disk 120, 0 Jun 10 14:56 /dev/emcpowerabrw-rw----. 1 root disk 120, 16 Jun 10 14:56 /dev/emcpowerbbrw-rw----. 1 root disk 120, 32 Jun 10 14:56 /dev/emcpowercbrw-rw----. 1 root disk 120, 48 Jun 10 14:56 /dev/emcpowerdbrw-rw----. 1 root disk 120, 64 Jun 10 14:56 /dev/emcpowerebrw-rw----. 1 root disk 120, 80 Jun 10 14:56 /dev/emcpowerfbrw-rw----. 1 root disk 120, 96 Jun 10 14:56 /dev/emcpowergbrw-rw----. 1 root disk 120, 112 Jun 10 14:56 /dev/emcpowerhbrw-rw----. 1 root disk 120, 128 Jun 10 14:56 /dev/emcpoweri[root@db01 rules.d]# cat 99-oracle-asmdevices.rulesSUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowera&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerb&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerc&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerd&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;...[root@db01 rules.d]# start_udev[root@db01 app]# ll /dev/emc*crw-rw---- 1 root root 10, 56 6月 10 15:30 /dev/emcpowerbrw-rw---- 1 grid dba 120, 0 6月 10 15:34 /dev/emcpowerabrw-rw---- 1 grid dba 120, 16 6月 10 15:34 /dev/emcpowerbbrw-rw---- 1 grid dba 120, 32 6月 10 15:34 /dev/emcpowercbrw-rw---- 1 grid dba 120, 48 6月 10 15:34 /dev/emcpowerdbrw-rw---- 1 grid dba 120, 64 6月 10 15:34 /dev/emcpowerebrw-rw---- 1 grid dba 120, 80 6月 10 15:34 /dev/emcpowerfbrw-rw---- 1 grid dba 120, 96 6月 10 15:34 /dev/emcpowergbrw-rw---- 1 grid dba 120, 112 6月 10 15:34 /dev/emcpowerhbrw-rw---- 1 grid dba 120, 128 6月 10 15:34 /dev/emcpoweri 5.Multipathd指令12345678910111213141516171819202122232425262728--检查设备[root@orl6 ~]# multipathd show devicesavailable block devices: sda devnode blacklisted, unmonitored sdb devnode whitelisted, monitored sdc devnode whitelisted, monitored sdd devnode whitelisted, monitored sr0 devnode blacklisted, unmonitored sr1 devnode blacklisted, unmonitored dm-0 devnode blacklisted, unmonitored...--检查映射情况[root@orl6 ~]# multipathd show mapsname sysfs uuid mpath1 dm-0 1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b data_mpath2 dm-1 14f504e46494c45526354355179652d663752632d6d755741[root@orl6 ~]# multipathd show topology#此命令等同于&lt;code&gt;multipath -ll&lt;/code&gt;mpath1 (1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b) dm-0 ATA,VBOX HARDDISKsize=20G features=&apos;0&apos; hwhandler=&apos;0&apos; wp=rw`-+- policy=&apos;round-robin 0&apos; prio=1 status=active `- 3:0:0:0 sdb 8:16 active ready runningdata_mpath2 (14f504e46494c45526354355179652d663752632d6d755741) dm-1 OPNFILER,VIRTUAL-DISKsize=15G features=&apos;0&apos; hwhandler=&apos;0&apos; wp=rw|-+- policy=&apos;round-robin 0&apos; prio=1 status=enabled| `- 5:0:0:0 sdc 8:32 active ready running`-+- policy=&apos;round-robin 0&apos; prio=1 status=active `- 4:0:0:0 sdd 8:48 active ready running 更加详细的命令可以参照man，multipathd -k为交互模式。 6.Multipath相关配置文件1234567891011121314151617181920212223242526272829303132333435363738394041[root@orl6 ~]# cat /etc/multipath/bindings # Multipath bindings, Version : 1.0# NOTE: this file is automatically maintained by the multipath program.# You should not need to edit this file in normal circumstances.## Format:# alias wwid#mpatha 1ATA VBOX HARDDISK VBfe43d230-3b43fe42 mpathb 1ATA VBOX HARDDISK VB9b70e1bb-9ea5e71b mpathc 14f504e46494c45526354355179652d663752632d6d755741[root@orl6 ~]# cat /etc/multipath/wwids # Multipath wwids, Version : 1.0# NOTE: This file is automatically maintained by multipath and multipathd.# You should not need to edit this file in normal circumstances.## Valid WWIDs:/1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b//14f504e46494c45526354355179652d663752632d6d755741/[root@orl6 ~]# grep -v ^# /etc/multipath.conf |grep -v ^$blacklist &#123; #devnode &quot;^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*&quot; #devnode &quot;^hd[a-z]&quot; devnode &quot;sda&quot; #wwid 1ATA_VBOX_HARDDISK_VB2314099c-4ddf514a #wwid 1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b&#125;defaults &#123; user_friendly_names no getuid_callout &quot;/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/%n&quot;&#125;multipaths &#123; multipath &#123; wwid 1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b alias mpath1 &#125; multipath &#123; wwid 14f504e46494c45526354355179652d663752632d6d755741 alias data_mpath2 &#125;&#125; 7. RHEL7.4 ASM udev加盘12345/usr/bin/scsi-rescanmultipath -llvi /etc/udev/rule.d/99-oracle-asmdevices.rules--restart udev/sbin/udevadm trigger --type=devices --action=change Find the UUID of the disk 1udevadm info --query=all --name=/dev/mapper/mpathx | grep -i DM_UUID Create udev Rules 12345678vi /etc/udev/rules.d/96-asm.rulesACTION==&quot;add|change&quot;, ENV&#123;DM_UUID&#125;==&quot;mpath-[DM_UUID]&quot;, SYMLINK+=&quot;udev-asmdisk1&quot;, GROUP=&quot;oinstall&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;--orfor i in b c d edoecho &quot;KERNEL==\\&quot;sd*\\&quot;, SUBSYSTEM==\\&quot;block\\&quot;, PROGRAM==\\&quot;/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/\\$name\\&quot;, RESULT==\\&quot;`/usr/lib/udev/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`\\&quot;, SYMLINK+=\\&quot;asm-disk$i\\&quot;, OWNER=\\&quot;grid\\&quot;, GROUP=\\&quot;asmadmin\\&quot;, MODE=\\&quot;0660\\&quot;&quot; done Reload udev Rules 12udevadm control --reload-rulesudevadm trigger --type=devices --action=change Verify the disks with sg_inq command 123# su - grid$ sg_inq /dev/mapper/mpathx$ sg_inq /dev/dm-x Reference:ID 1538626.1ID 1521757.1 EOF","link":"/multipath-with-udev.html"},{"title":"Multiple Standbys in HADR","text":"Before DB2 V10.1, HADR only support one standby server. But from V10.1, multiple standby can be supported up to three standby databases. This feature truelly combine the HA and DR together. In this post, I&#39;d like to show you how to initialize a multiple standbys system and how to rolling update through multiple standbys. 1. IntroductionSome terminologies or parameters have been introduced for multiple standby. hadr_target_list Initializing a HADR with multiple standby is similar to single standby mode. The main difference between single and multiple standby is the parameter hadr_target_list, this parameter should be set on all participate databases. This parameter&#39;s value specified on the primary determines how many standbys does the primary has. Principle standby The first standby in multiple standby mode is called principle standby, it support most of the HADR features, RoS, delayed replay, takeover ect.. And additional, all of synchronization modes are supported in priciple standby. Auxiliary standby The other standbys except principle standby can be called auxiliary standby, both types of standbys support RoS, delayed replay, takeover. But auxiliary standbys only support supersync mode. 2. Initialize a mutilple standbyThere are 2 approaches to initialize multiple standbys. Initialize a totally new multiple standby HADR Convert a single standby HADR to a multiple standby HADR Actually, it&#39;s not so much difference between these 2 approaches, for a single standby, just need to add hadr_target_list value for it become a mutilple standbys. In this post, I&#39;ll introduce how to setup a totally new multiple standby HADR. Below is my testing environment. 1234HOSTNAME |INSTANCE |DBNAME |SVCENAME |ROLEnode1 db2inst1 sample 51000 Primarynode2 db2inst1 sample 51001 Principlenode3 db2inst1 sample 51002 Auxiliary To initialize multiple standby in HADR, complete the following steps. 2.1 Configure required database parameters in primaryConfigure archival log mode if archive not enable, configure LOGINDEXBUILD.1234567891011121314151617DBPATH=/db2/data/$INSTANCEACTLOG=/db2/log/$INSTANCEBKPATH=/db2/backup/$INSTANCEARCLOG=/db2/arch/$INSTANCEDBGROUP=db2admDBNAME=samplemkdir -p $ACTLOG/$DBNAMEmkdir -p $ARCLOG/$DBNAMEmkdir -p $BKPATH/$DBNAMEdb2 update db cfg for $DBNAME using NEWLOGPATH $ACTLOG/$DBNAMEdb2 update db cfg for $DBNAME using LOGARCHMETH1 disk:$ARCLOG/$DBNAMEdb2 update db cfg for $DBNAME using LOGINDEXBUILD ONdb2 terminatedb2 deactivate database $DBNAMEdb2 update db cfg for $DBNAME using trackmod ondb2 backup db $DBNAME to /dev/nulldb2 activate database $DBNAME 2.2 Backup primary databasePerform a full offline/online backup of primary, copy the backup images to all the standbys.1234[db2inst1@node1 ~]$ db2 backup db sample online to /db2/backup/db2inst1/ compressBackup successful. The timestamp for this backup image is : 20160321150828[db2inst1@node1 ~]$ scp /db2/backup/db2inst1/*20160321150828* node2:/db2/backup/db2inst1/[db2inst1@node1 ~]$ scp /db2/backup/db2inst1/*20160321150828* node3:/db2/backup/db2inst1/ 2.3 Restore the database on all standbys1234[db2inst1@node2 ~]$ db2 restore db sample from /db2/backup/db2inst1/ taken at 20160321150828 DBPATH ON &apos;/db2/data/db2inst1&apos; redirect[db2inst1@node2 ~]$ db2 restore db sample continue[db2inst1@node3 ~]$ db2 restore db sample from /db2/backup/db2inst1/ taken at 20160321150828 DBPATH ON &apos;/db2/data/db2inst1&apos; redirect[db2inst1@node3 ~]$ db2 restore db sample continue 2.4 Add the following entries in the service fileAdd the HADR service name to /etc/services for all of the servers to setup HADR communication. This service name is different from database service name.12345678Service name: hadr_node1_db1Port: 51000/tcpService name: hadr_node2_db1Port: 51001/tcpService name: hadr_node3_db1Port: 51002/tcp 2.5 Update database configuration on primary node1Update the HADR configuration parameter on priamry1234567891011121314[db2inst1@node1 ~]$ db2 &quot;update db cfg for sample usingHADR_LOCAL_HOST node1HADR_LOCAL_SVC hadr_node1_db1HADR_REMOTE_HOST node2HADR_REMOTE_SVC hadr_node2_db1HADR_REMOTE_INST db2inst1HADR_TARGET_LIST node2:51001|node3:51002HADR_SYNCMODE NEARSYNC&quot;db2 connect to SAMPLEdb2 quiesce database immediate force connectionsdb2 unquiesce databasedb2 connect reset 2.6 Update database configuration on principle node21234567891011[db2inst1@node2 ~]$ db2 &quot;update db cfg for sample usingHADR_LOCAL_HOST node2HADR_LOCAL_SVC hadr_node2_db1HADR_REMOTE_HOST node1HADR_REMOTE_SVC hadr_node1_db1HADR_REMOTE_INST db2inst1HADR_TARGET_LIST node1:51000|node3:51002HADR_SYNCMODE NEARSYNC&quot;DB20000I The UPDATE DATABASE CONFIGURATION command completed successfully. 2.7 Update database configuration on auxilary node31234567891011[db2inst1@node3 ~]$ db2 &quot;update db cfg for sample usingHADR_LOCAL_HOST node3HADR_LOCAL_SVC hadr_node3_db1HADR_REMOTE_HOST node1HADR_REMOTE_SVC hadr_node1_db1HADR_REMOTE_INST db2inst1HADR_TARGET_LIST node2:51001|node1:51000HADR_SYNCMODE superasync&quot;DB20000I The UPDATE DATABASE CONFIGURATION command completed successfully. 2.8 Start the HADRFirst, start HADR standby in node2 and node3.12345[db2inst1@node2 ~]$ db2 deactivate database SAMPLE[db2inst1@node2 ~]$ db2 start hadr on database SAMPLE as standby[db2inst1@node3 ~]$ db2 deactivate database SAMPLE[db2inst1@node3 ~]$ db2 start hadr on database SAMPLE as standby Second, start HADR on primary node1.12[db2inst1@node1 ~]$ db2 deactivate database SAMPLE[db2inst1@node1 ~]$ db2 start hadr on database SAMPLE as primary To verify the HADR is running, run the db2pd -d sample -hadr command to monitor the HADR status, or use mon_get_hadr table function to monitor HADR status:123456789[db2inst1@node1 ~]$ db2 &quot;select HADR_ROLE, STANDBY_ID, HADR_STATE, varchar(PRIMARY_MEMBER_HOST,20) as PRIMARY_HOST, varchar(STANDBY_MEMBER_HOST,20) as STANDBY_HOST from table (mon_get_hadr(NULL))&quot;HADR_ROLE STANDBY_ID HADR_STATE PRIMARY_HOST STANDBY_HOST------------- ---------- ----------------------- -------------------- --------------------PRIMARY 1 PEER node1 node2PRIMARY 2 REMOTE_CATCHUP node1 node3 3. Rolling update in multiple standbysHADR can provide High Avaliability while performing some maintenance tasks such as fix pack with minimal downtime or without any downtime. I have introduced how to rolling fix pack in single standby Rolling Update and Upgrade in HADR , and we can take a look at how to rolling update in multiple standbys.The generate steps of updating as follow: Deactivate node3, make any required changes, activate node3, and start node3 as standby Repeate above tasks in node2 Takeover from node2, node2 now should be the primary Deactivate node1, upgrade/update in node1, start node1 as standby Takeover from node1 as primary, post-installation tasks Below demo is how to update from V10.1 to V10.1_FP5 with minimal downtime. We can install DB2 V10.1_FP5 binary code in all three servers in a new directory beforehand to minimize downtime. So I assumed all the V10.1_FP5 code have been installed into /opt/ibm/db2/V10.1_FP5 directory beforehand.12345[db2inst1@node1 ~]$ db2lsInstall Path Level Fix Pack Special Install Number Install Date Installer UID---------------------------------------------------------------------------------------------------------------------/opt/ibm/db2/V10.1 10.1.0.0 0 Thu Mar 17 14:30:52 2016 CST 0/opt/ibm/db2/V10.1_FP5 10.1.0.5 5 Thu Mar 17 16:24:37 2016 CST 0 3.1 Rolling update (fix pack) in multiple standby Deactivate node3, make any required changes, activate node3, and start node3 as standby 1234567[db2inst1@node3 ~]$ db2 deactivate db sample[db2inst1@node3 ~]$ db2stop[root@node3 worktmp]# /opt/ibm/db2/V10.1_FP5/instance/db2iupdt db2inst1[root@node3 worktmp]# su - db2inst1[db2inst1@node3 ~]$ db2licm -a /worktmp/db2ese_c.lic[db2inst1@node3 ~]$ db2start[db2inst1@node3 ~]$ db2 activate db sample Repeate above tasks in node2 1234567[db2inst1@node2 ~]$ db2 deactivate db sample[db2inst1@node2 ~]$ db2stop[root@node2 worktmp]# /opt/ibm/db2/V10.1_FP5/instance/db2iupdt db2inst1[root@node2 worktmp]# su - db2inst1[db2inst1@node2 ~]$ db2licm -a /worktmp/db2ese_c.lic[db2inst1@node2 ~]$ db2start[db2inst1@node2 ~]$ db2 activate db sample Takeover from node2, node2 now should be the primary 1[db2inst1@node2 ~]$ db2 takeover hadr on db sample Deactivate node1, upgrade/update in node1, start node1 as standby 1234567[db2inst1@node1 ~]$ db2 deactivate db sample[db2inst1@node1 ~]$ db2stop[root@node1 worktmp]# /opt/ibm/db2/V10.1_FP5/instance/db2iupdt db2inst1[root@node1 worktmp]# su - db2inst1[db2inst1@node1 ~]$ db2licm -a /worktmp/db2ese_c.lic[db2inst1@node1 ~]$ db2start[db2inst1@node1 ~]$ db2 activate db sample Takeover from node1 as primary, post-installation tasks 12345678910[db2inst1@node1 ~]$ db2 takeover hadr on db sample[db2inst1@node1 ~]$ /opt/ibm/db2/V10.1_FP5/bin/db2updv10 -d sample[db2inst1@node1 ~]$ db2 connect to sample[db2inst1@node1 ~]$ db2 BIND /opt/ibm/db2/V10.1_FP5/bnd/db2schema.bnd BLOCKING ALL GRANT PUBLIC SQLERROR CONTINUE[db2inst1@node1 ~]$ db2 BIND /opt/ibm/db2/V10.1_FP5/bnd/@db2ubind.lst BLOCKING ALL GRANT PUBLIC ACTION ADD[db2inst1@node1 ~]$ db2 BIND /opt/ibm/db2/V10.1_FP5/bnd/@db2cli.lst BLOCKING ALL GRANT PUBLIC ACTION ADD[db2inst1@node1 ~]$ db2rbind sample -l ./rbind.log all[db2inst1@node1 ~]$ db2pd -vInstance db2inst1 uses 64 bits and DB2 code release SQL10015 with level identifier 0206010EInformational tokens are DB2 v10.1.0.5, s150624, IP23772, Fix Pack 5. EOF","link":"/multiple-standby-in-hadr.html"},{"title":"Multiple version Python on the same machine","text":"Python is a critical package on Linux system, if you removed the current version before you install the new version, the OS maybe crash. So the best practice of upgrade Python on RHEL is reserved previous one. Installing latest versionI want to install the latest version for Python2 and Python3, download the source code package from official site, and extract them one by one.Extract the source code 123yum install openssl-devel zlib-devel -ytar -xzvf Python-3.6.1.tgztar -xzvf Python-2.7.13.tgz Compile and install the python from source code 123456cd Python-2.7.13orcd Python-3.6.1./configure --enable-shared --prefix=/usr/local/makesudo make altinstall create the symbolic link for python2.7 or python3.6 library 12345#On 64 bit OS# ldd `python2.7` to check the dependencysudo ln -s /usr/local/lib/libpython2.7.so.1.0 /usr/lib64/libpython2.7.so.1.0#for python3.6sudo ln -s /usr/local/lib/libpython3.6m.so.1.0 /usr/lib64/libpython3.6m.so.1.0 Install pip for python2.7pip on Python3 will be automatically installed, for python2.7, install pip from get-pip.py is recommended. 12wget https://bootstrap.pypa.io/get-pip.pypython2.7 get-pip.py Now, we have two version of pip. Trouble shooting pip is configured with locations that require TLS/SSL, however the ssl module in Python is not available. Because we missed to install the openssl-devel package, install the package and re-compile/reinstall the source code will resolve this issue. 1yum install openssl-devel zlib-devel -y python2.7: error while loading shared libraries: libpython2.7.so.1.0: cannot open shared object file: No such file or directory Check the lib dependency and found that some libs are missing, create the symbolic link will resolve this issue. 123456789$ ldd /usr/local/bin/python2.7 linux-vdso.so.1 =&gt; (0x00007fffd91ff000) libpython2.7.so.1.0 =&gt; not found libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f46bf554000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f46bf350000) libutil.so.1 =&gt; /lib64/libutil.so.1 (0x00007f46bf14d000) libm.so.6 =&gt; /lib64/libm.so.6 (0x00007f46beec8000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f46beb34000) /lib64/ld-linux-x86-64.so.2 (0x00007f46bf77d000) Creating the symbolic link for python library 12345#On 64 bit OS# ldd `python2.7` to check the dependencysudo ln -s /usr/local/lib/libpython2.7.so.1.0 /usr/lib64/libpython2.7.so.1.0#for python3.6sudo ln -s /usr/local/lib/libpython3.6m.so.1.0 /usr/lib64/libpython3.6m.so.1.0 Hint for virtualenvwrappervirtualenvwrapper for python virtual environment management, install this package from any version of pip, virtualenvwrapper can cover any version of python, such as: Specified version of python to create virtual environment 12345678910111213# for python2mkvirtualenv py2 --python=/usr/local/bin/python2.7$ python -VPython 2.7.13$ pip -Vpip 9.0.1 from /home/kingsley/.virtualenvs/py2/lib/python2.7/site-packages (python 2.7)# for python3mkvirtualenv py2 --python=/usr/local/bin/python3.6$ python -VPython 3.6.1$ pip -Vpip 9.0.1 from /home/kingsley/.virtualenvs/py2/lib/python3.6/site-packages (python 3.6) Deactivating virtual environment 1$ deactivate Activating virtual environment 1$ workon py2 Removing virtual environment 12$ rmvirtualenv py2Removing py2... EOF","link":"/multiple-version-python-on-the-same-machine.html"},{"title":"nbu lanfree issue","text":"客户一个新系统，两台AIX组成HACMP集群，存储挂了一个EMC VNX5500，VNX5300为备份专用，目前挂载在nbu master server上。要求通过RMAN同时往磁带和磁盘里面写。由于lanfree架构，需要在备份客户端配置san media server，即这两台小机。在NBU备份策略中，如果选取多份备份，media server需为同一台。因此，这种方案无法实现，否则就只能通过lan备份。最后决定同一个实例配置两个policy，一个为磁带lanfree，一个为nbu master server本地磁盘。然后神奇的事情出现了，当第一个policy配置为lanfree时候，其他policy都申请lanfree资源，policy storage明明选择了disk资源，都会备份到磁带。而且其他policy调用子进程时候，显示的是第一个policy的名称。以下截图情况说明：djgisimg为第一个policy，配置的是oracle_unit的磁盘存储。djoracle配置的是lanfree资源，备份到磁带的。oracle_unit为磁盘资源：父进程名称为djoracle，子进程却变成了第一个policy名称：djgisimg。切父进程调用的是lanfree资源，但子进程却使用了oracle_unit资源：通过官方文档，找到一个解决办法，就是在rman中，加入运行时候环境，指定NBU master server及policy。如：1234567run &#123;allocate channel t1 type &apos;SBT_TAPE&apos;;allocate channel t2 type &apos;SBT_TAPE&apos;;send &apos;NB_ORA_POLICY=your_policy, NB_ORA_SERV=your_server&apos;;backup(database format &apos;bk_%U_%t&apos;);&#125; 或者：12345678910run &#123;allocate channel t1 type &apos;SBT_TAPE&apos;parms=&quot;ENV=(NB_ORA_POLICY=your_pol,NB_ORA_SERV=your_server)&quot;;allocate channel t2 type &apos;SBT_TAPE&apos;parms=&quot;ENV=(NB_ORA_POLICY=your_pol,NB_ORA_SERV=your_server)&quot;;backup(database format &apos;bk_%s_%p_%t&apos;);&#125; send 命令或 parms 操作数用于指定在备份或还原过程中要使用的 Netbackup for Oracle 环境变量。Netbackup for Oracle的环境变量有如下参数（部分）：NB_ORA_SERV:指定netbackup master server名称。NB_ORA_CLIENT:指定Oracle客户端名称。NB_ORA_POLICY:指定Oracle备份时所用到的备份策略。NB_ORA_SCHED:指定Oracle要用到的“应用程序备份”日程表的名称。而导致上述情况出现，是跟NBU中oracle备份策略自动产生的default-application-backup有关。按照官网的说法，指定NB_ORA_SCHED不走default-application-backup也可以达到目的，这种方法尚未测试。在网上找了许多文档，也没看到官方对这个default-application-backup有一个明确的说法。个人理解，它是允许用户在客户端通过其他工具对master server发起作业，如Oracle中的RMAN工具。此外，在NBU7.5自带的Windows脚本中，好像有点问题，执行的时候一闪而过，并没有执行备份。后面找了一个5.x的脚本，顺利通过。附上修改后的NBU for Linux/UNIX脚本及for Windows脚本：Linux/UNIX:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291#!/bin/sh# $Header: hot_database_backup.sh,v 1.3 2010/08/04 17:56:02 $##bcpyrght#***************************************************************************#* $VRTScprght: Copyright 1993 - 2012 Symantec Corporation, All Rights Reserved $ *#***************************************************************************#ecpyrght## ---------------------------------------------------------------------------# hot_database_backup.sh# ---------------------------------------------------------------------------# This script uses Recovery Manager to take a hot (inconsistent) database# backup. A hot backup is inconsistent because portions of the database are# being modified and written to the disk while the backup is progressing.# You must run your database in ARCHIVELOG mode to make hot backups. It is# assumed that this script will be executed by user root. In order for RMAN# to work properly we switch user (su -) to the oracle dba account before# execution. If this script runs under a user account that has Oracle dba# privilege, it will be executed using this user&apos;s account.# ---------------------------------------------------------------------------# ---------------------------------------------------------------------------# Determine the user which is executing this script.# ---------------------------------------------------------------------------CUSER=`id |cut -d&quot;(&quot; -f2 | cut -d &quot;)&quot; -f1`# ---------------------------------------------------------------------------# Put output in &lt;this file name&gt;.out. Change as desired.# Note: output directory requires write permission.# ---------------------------------------------------------------------------RMAN_LOG_FILE=$&#123;0&#125;_`date +%y%m%d`.out# ---------------------------------------------------------------------------# You may want to delete the output file so that backup information does# not accumulate. If not, delete the following lines.# ---------------------------------------------------------------------------if [ -f &quot;$RMAN_LOG_FILE&quot; ]then rm -f &quot;$RMAN_LOG_FILE&quot;fi# -----------------------------------------------------------------# Initialize the log file.# -----------------------------------------------------------------echo &gt;&gt; $RMAN_LOG_FILEchmod 666 $RMAN_LOG_FILE# ---------------------------------------------------------------------------# Log the start of this script.# ---------------------------------------------------------------------------echo Script $0 &gt;&gt; $RMAN_LOG_FILEecho ==== started on `date` ==== &gt;&gt; $RMAN_LOG_FILEecho &gt;&gt; $RMAN_LOG_FILE# ---------------------------------------------------------------------------# Replace /db/oracle/product/ora102, below, with the Oracle home path.# ---------------------------------------------------------------------------ORACLE_HOME=/u01/product/11.2.0/db_1export ORACLE_HOME# ---------------------------------------------------------------------------# Replace ora102, below, with the Oracle SID of the target database.# ---------------------------------------------------------------------------ORACLE_SID=your_sidexport ORACLE_SID# ---------------------------------------------------------------------------# Replace ora102, below, with the Oracle DBA user id (account).# ---------------------------------------------------------------------------ORACLE_USER=oracle# ---------------------------------------------------------------------------# Set the target connect string.# Replace &quot;sys/manager&quot;, below, with the target connect string.# ---------------------------------------------------------------------------TARGET_CONNECT_STR=/# ---------------------------------------------------------------------------# Set the Oracle Recovery Manager name.# ---------------------------------------------------------------------------RMAN=$ORACLE_HOME/bin/rman# ---------------------------------------------------------------------------# Print out the value of the variables set by this script.# ---------------------------------------------------------------------------echo &gt;&gt; $RMAN_LOG_FILEecho &quot;RMAN: $RMAN&quot; &gt;&gt; $RMAN_LOG_FILEecho &quot;ORACLE_SID: $ORACLE_SID&quot; &gt;&gt; $RMAN_LOG_FILEecho &quot;ORACLE_USER: $ORACLE_USER&quot; &gt;&gt; $RMAN_LOG_FILEecho &quot;ORACLE_HOME: $ORACLE_HOME&quot; &gt;&gt; $RMAN_LOG_FILE# ---------------------------------------------------------------------------# Print out the value of the variables set by bphdb.# ---------------------------------------------------------------------------echo &gt;&gt; $RMAN_LOG_FILEecho &quot;NB_ORA_FULL: $NB_ORA_FULL&quot; &gt;&gt; $RMAN_LOG_FILEecho &quot;NB_ORA_INCR: $NB_ORA_INCR&quot; &gt;&gt; $RMAN_LOG_FILEecho &quot;NB_ORA_CINC: $NB_ORA_CINC&quot; &gt;&gt; $RMAN_LOG_FILEecho &quot;NB_ORA_SERV: $NB_ORA_SERV&quot; &gt;&gt; $RMAN_LOG_FILEecho &quot;NB_ORA_POLICY: $NB_ORA_POLICY&quot; &gt;&gt; $RMAN_LOG_FILE# ---------------------------------------------------------------------------# NOTE: This script assumes that the database is properly opened. If desired,# this would be the place to verify that.# ---------------------------------------------------------------------------echo &gt;&gt; $RMAN_LOG_FILE# ---------------------------------------------------------------------------# If this script is executed from a NetBackup schedule, NetBackup# sets an NB_ORA environment variable based on the schedule type.# The NB_ORA variable is then used to dynamically set BACKUP_TYPE# For example, when:# schedule type is BACKUP_TYPE is# ---------------- --------------# Automatic Full INCREMENTAL LEVEL=0# Automatic Differential Incremental INCREMENTAL LEVEL=1# Automatic Cumulative Incremental INCREMENTAL LEVEL=1 CUMULATIVE## For user initiated backups, BACKUP_TYPE defaults to incremental# level 0 (full). To change the default for a user initiated# backup to incremental or incremental cumulative, uncomment# one of the following two lines.# BACKUP_TYPE=&quot;INCREMENTAL LEVEL=1&quot;# BACKUP_TYPE=&quot;INCREMENTAL LEVEL=1 CUMULATIVE&quot;## Note that we use incremental level 0 to specify full backups.# That is because, although they are identical in content, only# the incremental level 0 backup can have incremental backups of# level &gt; 0 applied to it.# ---------------------------------------------------------------------------if [ &quot;$NB_ORA_FULL&quot; = &quot;1&quot; ]then echo &quot;Full backup requested&quot; &gt;&gt; $RMAN_LOG_FILE BACKUP_TYPE=&quot;INCREMENTAL LEVEL=0&quot;elif [ &quot;$NB_ORA_INCR&quot; = &quot;1&quot; ]then echo &quot;Differential incremental backup requested&quot; &gt;&gt; $RMAN_LOG_FILE BACKUP_TYPE=&quot;INCREMENTAL LEVEL=1&quot;elif [ &quot;$NB_ORA_CINC&quot; = &quot;1&quot; ]then echo &quot;Cumulative incremental backup requested&quot; &gt;&gt; $RMAN_LOG_FILE BACKUP_TYPE=&quot;INCREMENTAL LEVEL=1 CUMULATIVE&quot;elif [ &quot;$BACKUP_TYPE&quot; = &quot;&quot; ]then echo &quot;Default - Full backup requested&quot; &gt;&gt; $RMAN_LOG_FILE BACKUP_TYPE=&quot;INCREMENTAL LEVEL=0&quot;fi# ---------------------------------------------------------------------------# Call Recovery Manager to initiate the backup. This example does not use a# Recovery Catalog. If you choose to use one, replace the option &apos;nocatalog&apos;# from the rman command line below with the# &apos;catalog &lt;userid&gt;/&lt;passwd&gt;@&lt;net service name&gt;&apos; statement.## Note: Any environment variables needed at run time by RMAN# must be set and exported within the switch user (su) command.# ---------------------------------------------------------------------------# Backs up the whole database. This backup is part of the incremental# strategy (this means it can have incremental backups of levels &gt; 0# applied to it).## We do not need to explicitly request the control file to be included# in this backup, as it is automatically included each time file 1 of# the system tablespace is backed up (the inference: as it is a whole# database backup, file 1 of the system tablespace will be backed up,# hence the controlfile will also be included automatically).## Typically, a level 0 backup would be done at least once a week.## The scenario assumes:# o you are backing your database up to two tape drives# o you want each backup set to include a maximum of 5 files# o you wish to include offline datafiles, and read-only tablespaces,# in the backup# o you want the backup to continue if any files are inaccessible.# o you are not using a Recovery Catalog# o you are explicitly backing up the control file. Since you are# specifying nocatalog, the controlfile backup that occurs# automatically as the result of backing up the system file is# not sufficient; it will not contain records for the backup that# is currently in progress.# o you want to archive the current log, back up all the# archive logs using two channels, putting a maximum of 20 logs# in a backup set, and deleting them once the backup is complete.## Note that the format string is constructed to guarantee uniqueness and# to enhance NetBackup for Oracle backup and restore performance.### NOTE WHEN USING NET SERVICE NAME: When connecting to a database# using a net service name, you must use a send command or a parms operand to# specify environment variables. In other words, when accessing a database# through a listener, the environment variables set at the system level are not# visible when RMAN is running. For more information on the environment# variables, please refer to the NetBackup for Oracle Admin. Guide.## ---------------------------------------------------------------------------CMD_STR=&quot;ORACLE_HOME=$ORACLE_HOMEexport ORACLE_HOMEORACLE_SID=$ORACLE_SIDexport ORACLE_SID$RMAN target $TARGET_CONNECT_STR nocatalog msglog $RMAN_LOG_FILE append &lt;&lt; EOFRUN &#123;ALLOCATE CHANNEL ch00 TYPE &apos;SBT_TAPE&apos;;ALLOCATE CHANNEL ch01 TYPE &apos;SBT_TAPE&apos;;send &apos;NB_ORA_POLICY=your_policy, NB_ORA_SERV=your_server’;BACKUP $BACKUP_TYPE SKIP INACCESSIBLE TAG hot_db_bk_level0 FILESPERSET 5 # recommended format FORMAT &apos;bk_%s_%p_%t&apos; DATABASE; sql &apos;alter system archive log current&apos;;RELEASE CHANNEL ch00;RELEASE CHANNEL ch01;# backup all archive logsALLOCATE CHANNEL ch00 TYPE &apos;SBT_TAPE&apos;;ALLOCATE CHANNEL ch01 TYPE &apos;SBT_TAPE&apos;;BACKUP filesperset 20 FORMAT &apos;al_%s_%p_%t&apos; ARCHIVELOG ALL DELETE INPUT;RELEASE CHANNEL ch00;RELEASE CHANNEL ch01;## Note: During the process of backing up the database, RMAN also backs up the# control file. This version of the control file does not contain the# information about the current backup because &quot;nocatalog&quot; has been specified.# To include the information about the current backup, the control file should# be backed up as the last step of the RMAN section. This step would not be# necessary if we were using a recovery catalog or auto control file backups.#ALLOCATE CHANNEL ch00 TYPE &apos;SBT_TAPE&apos;;BACKUP # recommended format FORMAT &apos;cntrl_%s_%p_%t&apos; CURRENT CONTROLFILE;RELEASE CHANNEL ch00;&#125;EOF&quot;# Initiate the command stringif [ &quot;$CUSER&quot; = &quot;root&quot; ]then su - $ORACLE_USER -c &quot;$CMD_STR&quot; &gt;&gt; $RMAN_LOG_FILE RSTAT=$?else /usr/bin/sh -c &quot;$CMD_STR&quot; &gt;&gt; $RMAN_LOG_FILE RSTAT=$?fi# ---------------------------------------------------------------------------# Log the completion of this script.# ---------------------------------------------------------------------------if [ &quot;$RSTAT&quot; = &quot;0&quot; ]then LOGMSG=&quot;ended successfully&quot;else LOGMSG=&quot;ended in error&quot;fiecho &gt;&gt; $RMAN_LOG_FILEecho Script $0 &gt;&gt; $RMAN_LOG_FILEecho ==== $LOGMSG on `date` ==== &gt;&gt; $RMAN_LOG_FILEecho &gt;&gt; $RMAN_LOG_FILEexit $RSTAT Windows NBU5.x:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258@REM $Header: hot_database_backup.cmd,v 1.3 from QaSanil 2005/11/28 19:01:53 $@REM bcpyrght@REM ***************************************************************************@REM * $VRTScprght: Copyright 1993 - 2009 Symantec Corporation, All Rights Reserved $ *@REM ***************************************************************************@REM ecpyrght@REM@REM ---------------------------------------------------------------------------@REM hot_database_backup.cmd@REM ---------------------------------------------------------------------------@REM This script uses Recovery Manager to take a hot (inconsistent) database@REM backup. A hot backup is inconsistent because portions of the database are@REM being modified and written to the disk while the backup is progressing.@REM You must run your database in ARCHIVELOG mode to make hot backups.@REM@REM NOTE information for running proxy backups has been included. These@REM information sections begin with a comment line of PROXY@REM ---------------------------------------------------------------------------@setlocal ENABLEEXTENSIONS@REM ---------------------------------------------------------------------------@REM No need to echo the commands.@REM ---------------------------------------------------------------------------@echo off@REM ---------------------------------------------------------------------------@REM Put output in the same filename, different extension.@REM ---------------------------------------------------------------------------@set RMAN_LOG_FILE=&quot;%~dpn0.out&quot;@REM ---------------------------------------------------------------------------@REM You may want to delete the output file so that backup information does@REM not accumulate. If not, delete the following command.@REM ---------------------------------------------------------------------------@if exist %RMAN_LOG_FILE% del %RMAN_LOG_FILE%@REM ---------------------------------------------------------------------------@REM Replace H:\\oracle\\ora81, below, with the Oracle home path.@REM ---------------------------------------------------------------------------@set ORACLE_HOME=D:\\oracle\\product\\10.2.0\\db_1@REM ---------------------------------------------------------------------------@REM Replace ora81, below, with the Oracle SID.@REM ---------------------------------------------------------------------------@set ORACLE_SID=your-sid@REM ---------------------------------------------------------------------------@REM Replace sys/manager, below, with the target connect string.@REM ---------------------------------------------------------------------------@set TARGET_CONNECT_STR=/@REM ---------------------------------------------------------------------------@REM Set the Oracle Recovery Manager.@REM ---------------------------------------------------------------------------@set RMAN=%ORACLE_HOME%\\bin\\rman.exe@REM ---------------------------------------------------------------------------@REM PROXY@REM For a PROXY backup, uncomment the line below and replace the value.@REM@REM NB_ORA_PC_STREAMS - specifies the number of parallel backup streams@REM to be started.@REM ---------------------------------------------------------------------------@REM @set NB_ORA_PC_STREAMS=3@REM ---------------------------------------------------------------------------@REM Log the start of this scripts.@REM ---------------------------------------------------------------------------@for /F &quot;tokens=1*&quot; %%p in (&apos;date /T&apos;) do @set DATE=%%p %%q@for /F %%p in (&apos;time /T&apos;) do @set DATE=%DATE% %%p@echo ==== started on %DATE% ==== &gt;&gt; %RMAN_LOG_FILE%@echo Script name: %0 &gt;&gt; %RMAN_LOG_FILE%@REM ---------------------------------------------------------------------------@REM Several RMAN commands use time parameters that require NLS_LANG and@REM NLS_DATE_FORMAT to be set. This example uses the standard date format.@REM Replace below with the desired language values.@REM ---------------------------------------------------------------------------@set NLS_LANG=american@set NLS_DATE_FORMAT=YYYY-MM-DD:hh24:mi:ss@REM ---------------------------------------------------------------------------@REM Print out environment variables set in this script.@REM ---------------------------------------------------------------------------@echo # &gt;&gt; %RMAN_LOG_FILE%@echo RMAN : %RMAN% &gt;&gt; %RMAN_LOG_FILE%@echo NLS_LANG : %NLS_LANG% &gt;&gt; %RMAN_LOG_FILE%@echo ORACLE_HOME : %ORACLE_HOME% &gt;&gt; %RMAN_LOG_FILE%@echo ORACLE_SID : %ORACLE_SID% &gt;&gt; %RMAN_LOG_FILE%@echo NLS_DATE_FORMAT : %NLS_DATE_FORMAT% &gt;&gt; %RMAN_LOG_FILE%@echo RMAN_LOG_FILE : %RMAN_LOG_FILE% &gt;&gt; %RMAN_LOG_FILE%@REM ---------------------------------------------------------------------------@REM PROXY@REM For a PROXY backup, uncomment the line below.@REM ---------------------------------------------------------------------------@REM @echo NB_ORA_PC_STREAMS : %NB_ORA_PC_STREAMS% &gt;&gt; %RMAN_LOG_FILE%@REM ---------------------------------------------------------------------------@REM Print out environment variables set in bphdb.@REM ---------------------------------------------------------------------------@echo NB_ORA_SERV : %NB_ORA_SERV% &gt;&gt; %RMAN_LOG_FILE%@echo NB_ORA_FULL : %NB_ORA_FULL% &gt;&gt; %RMAN_LOG_FILE%@echo NB_ORA_INCR : %NB_ORA_INCR% &gt;&gt; %RMAN_LOG_FILE%@echo NB_ORA_CINC : %NB_ORA_CINC% &gt;&gt; %RMAN_LOG_FILE%@echo NB_ORA_CLASS : %NB_ORA_CLASS% &gt;&gt; %RMAN_LOG_FILE%@REM ---------------------------------------------------------------------------@REM We assume that the database is properly opened. If desired, this would@REM be the place to verify that.@REM ---------------------------------------------------------------------------@REM ---------------------------------------------------------------------------@REM If this script is executed from a NetBackup schedule, NetBackup@REM sets an NB_ORA environment variable based on the schedule type.@REM For example, when:@REM schedule type is BACKUP_TYPE is@REM ---------------- --------------@REM Automatic Full INCREMENTAL LEVEL=0@REM Automatic Differential Incremental INCREMENTAL LEVEL=1@REM Automatic Cumulative Incremental INCREMENTAL LEVEL=1 CUMULATIVE@REM@REM For user initiated backups, BACKUP_TYPE defaults to incremental@REM level 0 (Full). To change the default for a user initiated@REM backup to incremental or incrementatl cumulative, uncomment@REM one of the following two lines.@REM @set BACKUP_TYPE=&quot;INCREMENTAL LEVEL=1&quot;@REM @set BACKUP_TYPE=&quot;INCREMENTAL LEVEL=1 CUMULATIVE&quot;@REM@REM Note that we use incremental level 0 to specify full backups.@REM That is because, although they are identical in content, only@REM the incremental level 0 backup can have incremental backups of@REM level &gt; 0 applied to it.@REM ---------------------------------------------------------------------------@REM ---------------------------------------------------------------------------@REM What kind of backup will we perform.@REM ---------------------------------------------------------------------------@if &quot;%NB_ORA_FULL%&quot; EQU &quot;1&quot; @set BACKUP_TYPE=INCREMENTAL Level=0@if &quot;%NB_ORA_INCR%&quot; EQU &quot;1&quot; @set BACKUP_TYPE=INCREMENTAL Level=1@if &quot;%NB_ORA_CINC%&quot; EQU &quot;1&quot; @set BACKUP_TYPE=INCREMENTAL Level=1 CUMULATIVE@if NOT DEFINED BACKUP_TYPE @set BACKUP_TYPE=INCREMENTAL Level=0@REM ---------------------------------------------------------------------------@REM Call Recovery Manager to initiate the backup. This example does not use a@REM Recovery Catalog. If you choose to use one, remove the option, nocatalog,@REM from the rman command line below and add a@REM &apos;rcvcat &lt;userid&gt;/&lt;passwd&gt;@&lt;tns alias&gt;&apos; statement.@REM@REM NOTE WHEN USING TNS ALIAS: When connecting to a database@REM using a TNS alias, you must use a send command or a parms operand to@REM specify environment variables. In other words, when accessing a database@REM through a listener, the environment variables set at the system level are not@REM visible when RMAN is running. For more information on the environment@REM variables, please refer to the NetBackup for Oracle Admin. Guide.@REM@REM If you are getting an error that the input line is too long, you will need@REM to put the RMAN run block in a separate file. Then use the &quot;cmdfile&quot;@REM option of RMAN. For more information on the &quot;cmdfile&quot; options please@REM refer to the RMAN documentation.@REM ---------------------------------------------------------------------------@REM ---------------------------------------------------------------------------@REM PROXY@REM For a PROXY backup, you must use a send command to specify@REM the NB_ORA_PC_STREAMS environment variable. For example,@REM echo ALLOCATE CHANNEL ch01 TYPE &apos;SBT_TAPE&apos;;@REM echo SEND &apos;NB_ORA_PC_STREAMS=%%NB_ORA_PC_STREAMS%%&apos;;@REM@REM %BACKUP_TYPE% must also be removed and replaced with the PROXY parameter@REM in the RMAN section associated with the data files. For example,@REM echo BACKUP@REM echo PROXY@REM echo FORMAT &apos;bk_u%%u_s%%s_p%%p_t%%t&apos;@REM echo DATABASE;@REM .@REM .@REM Note that the controlfiles and archivelogs are not backed up using proxy@REM copy method. Rman will initiate non-proxy copy sessions to backup the@REM controlfile and archivelogs.@REM ---------------------------------------------------------------------------@(echo RUN &#123;echo ALLOCATE CHANNEL ch00 TYPE &apos;SBT_TAPE&apos;;echo ALLOCATE CHANNEL ch01 TYPE &apos;SBT_TAPE&apos;;echo send &apos;NB_ORA_SERV=your_bk_server,NB_ORA_POLICY=your_policy&apos;;echo BACKUPecho %BACKUP_TYPE%echo FORMAT &apos;bk_u%%u_s%%s_p%%p_t%%t&apos;echo DATABASE;echo sql &apos;alter system archive log current&apos;;echo RELEASE CHANNEL ch00;echo RELEASE CHANNEL ch01;echo # Backup all archive logsecho ALLOCATE CHANNEL ch00 TYPE &apos;SBT_TAPE&apos;;echo BACKUPecho FILESPERSET 20echo FORMAT &apos;arch-s%%s-p%%p&apos;echo ARCHIVELOG ALL;echo RELEASE CHANNEL ch00;echo ALLOCATE CHANNEL ch00 TYPE &apos;SBT_TAPE&apos;;echo BACKUPecho FORMAT &apos;cntrl_%s_%p_%t&apos;echo CURRENT CONTROLFILE;echo RELEASE CHANNEL ch00;echo &#125;) | %RMAN% target %TARGET_CONNECT_STR% nocatalog msglog &apos;%RMAN_LOG_FILE%&apos; append@set ERRLEVEL=%ERRORLEVEL%@REM ---------------------------------------------------------------------------@REM NetBackup (bphdb) stores the name of a file in an environment variable,@REM called STATUS_FILE. This file is used by an automatic schedule to@REM communicate status information with NetBackup&apos;s job monitor. It is up to@REM the script to write a 0 (passed) or 1 (failure) to the status file.@REM ---------------------------------------------------------------------------@if %ERRLEVEL% NEQ 0 @goto err@set LOGMSG=ended successfully@if &quot;%STATUS_FILE%&quot; EQU &quot;&quot; goto end@echo 0 &gt; &quot;%STATUS_FILE%&quot;@goto end:err@set LOGMSG=ended in error@if &quot;%STATUS_FILE%&quot; EQU &quot;&quot; @goto end@echo 1 &gt; &quot;%STATUS_FILE%&quot;:end@REM ---------------------------------------------------------------------------@REM Log the completion of this script.@REM ---------------------------------------------------------------------------@for /F &quot;tokens=1*&quot; %%p in (&apos;date /T&apos;) do @set DATE=%%p %%q@for /F %%p in (&apos;time /T&apos;) do @set DATE=%DATE% %%p@echo # &gt;&gt; %RMAN_LOG_FILE%@echo %==== %LOGMSG% on %DATE% ==== &gt;&gt; %RMAN_LOG_FILE%@endlocal@REM End of Main Program -----------------------------------------------------","link":"/nbu-lanfree-issue.html"},{"title":"OGG RMAN Initial Load sample","text":"My first experience of deploying OGG was in 2010, we were synchronizing the data from prod server to a report server. Before using OGG, we were using MV table to achieve that. But I didn&#39;t maintain OGG since 2013, so I almost forgot everything about the OGG. It&#39;s necessary to write down some fundamental steps about how to build an OGG environment. Terminology MGR process The first process you should start before Extract/Replicat, it&#39;s the control process of OGG, need to be ran on both source and target. It performs monitoring, starting other OGG process,managing the trail files and so on. Extract process This process is performing capturing changed committed data on the source, also can be configured for initialing load. Trail files Trail files can exist on both source and target. It stores changed data of database continuously to disk files, these files are called trails. Without the Data pump configured, there will be no trail files on the source. The source trail file also known as local trail, the target trail also known as remote trail. Data pump process The main purpose using pump is protecting Extract process abend or abort from network failure between source and target. This process only reside on the source. Without the pump process, the trail file only exist on the target, from the source end, the changed committed data which Extract process would be stored in the memory, in case of network connectivity broken, the Extract maybe run out of memory and abort. With the pump process, the data that Extract process will be storing into a source trail file, if the network failure, since the captured data moved to the disk, there&#39;s no risks for running out of memory, once the connectivity restored, the pump process will read the data from the source trail and send to the target trail. Replicat process The Replicat process runs on the target system. It read the trail on the target, re-apply the DML or DDL operation to the target system. Configuring the OGG on the source system Creating GoldenGate users 123SQL&gt; create tablespace goldengate datafile '/u01/linora/goldengate01.dbf' size 100M;SQL&gt; create user ggsusr identified by oracle default tablespace goldengate account unlock;SQL&gt; grant resource,connect,dba to ggsusr; Enabling the archive log mode 12345SQL&gt; alter system set LOG_ARCHIVE_DEST_1 = 'LOCATION=/u01/arch' scope=both;SQL&gt; shutdown immediateSQL&gt; alter database archivelog;SQL&gt; alter database open;SQL&gt; alter system switch logfile; Enabling the supplemental log 123456789SQL&gt; select SUPPLEMENTAL_LOG_DATA_MIN,SUPPLEMENTAL_LOG_DATA_PK,SUPPLEMENTAL_LOG_DATA_UI,SUPPLEMENTAL_LOG_DATA_FK,SUPPLEMENTAL_LOG_DATA_ALL from v$database;SQL&gt; alter database add supplemental log data ;SQL&gt; alter database add supplemental log data (primary key, unique,foreign key) columns;SQL&gt; alter system switch logfile; Ensure supplemental log PK,UI,FK are enabled, the ALL Columns are disabled, if the ALL Columns are enabled, use following sql to close it:1SQL&gt; alter database drop supplemental log data (ALL) columns; Enabling the force logging 12SQL&gt; select FORCE_LOGGING from v$database;SQL&gt; alter database force logging; Installing the GoldenGate software Before install the software, we need to add some variables to the profile, add the following line to oracle user&#39;s profile:123456export GG_HOME=/gghomeexport LD_LIBRARY_PATH=$GG_HOME:$ORACLE_HOME/lib:/lib:/usr/lib#Unzip the package with oracle usercd /gghome/unzip V34339-01.ziptar -xvf fbo_ggs_Linux_x64_ora11g_64bit.tar Create subdirs for OGG123456789101112[oracle@node1:/gghome]$ ./ggsciGGSCI (node1) 1&gt; create subdirsCreating subdirectories under current directory /gghomeParameter files /gghome/dirprm: already existsReport files /gghome/dirrpt: createdCheckpoint files /gghome/dirchk: createdProcess status files /gghome/dirpcs: createdSQL script files /gghome/dirsql: createdDatabase definitions files /gghome/dirdef: createdExtract data files /gghome/dirdat: createdTemporary files /gghome/dirtmp: createdStdout files /gghome/dirout: created Enabling sequence support 12345[oracle@node1:/gghome]$ cd /gghome/[oracle@node1:/gghome]$ sqlplus \"/as sysdba\"SQL&gt; @sequence.sqlSQL&gt; GRANT EXECUTE on ggsusr.updateSequence to ggsusr;SQL&gt; ALTER TABLE sys.seq$ ADD SUPPLEMENTAL LOG DATA (PRIMARY KEY) COLUMNS; Adding trandata to source tables 123456789101112131415161718SQL&gt; set head offSQL&gt; set feedback offSQL&gt; spool /gghome/dirprm/addtrandata.txtSQL&gt; select 'add trandata '|| owner ||'.'|| table_name from dba_tables where owner='SCOTT';add trandata SCOTT.DEPTadd trandata SCOTT.EMPadd trandata SCOTT.BONUSadd trandata SCOTT.SALGRADESQL&gt; spool off[oracle@node1:/home/oracle]$ cd /gghome/[oracle@node1:/gghome]$ ./ggsciGGSCI (node1) 1&gt; dblogin userid ggsusr, password oracleSuccessfully logged into database.GGSCI (node1) 3&gt; obey /gghome/dirprm/addtrandata.txt#find the result of adding trandataGGSCI (node1) 11&gt; info trandata scott.dept Configuring manager process 123456789101112131415161718#Encrept the passowrdGGSCI (node1) 2&gt; ENCRYPT PASSWORD oracle BLOWFISH ENCRYPTKEY DEFAULTUsing default key...Encrypted password: AACAAAAAAAAAAAGAIFAAUDVHCFUGFIYFAlgorithm used: BLOWFISHGGSCI (node1) 3&gt; edit params mgrPORT 7809DYNAMICPORTLIST 7810-7880USERID ggsusr, PASSWORD AAACAAAAAAAAAAAGAIFAAUDVHCFUGFIYF, ENCRYPTKEY defaultAUTORESTART EXTRACT *, RETRIES 5, WAITMINUTES 3PURGEOLDEXTRACTS ./dirdat/*, USECHECKPOINTS, MINKEEPDAYS 3--PURGEOLDEXTRACTS parameter is determinating how long the extract trail file is keeping--Disable this parameter during initail load, and enable it when sychronizateLAGREPORTHOURS 1LAGINFOMINUTES 30LAGCRITICALMINUTES 45 Configuring Extract process 1234567891011121314151617181920212223#We need to confirm we don't have any transactions running, otherwise, rollback it or waiting for completing.SQL&gt; select count(*) from gv$transaction;GGSCI (node1) 5&gt; dblogin userid ggsusr, password oracleSuccessfully logged into database.GGSCI (node1) 6&gt; edit params ext1GGSCI (node1) 7&gt; view params ext1EXTRACT ext1--SETENV (NLS_LANG=\"AMERICAN_AMERICA.ZHS16GBK\")USERID ggsusr, PASSWORD AAACAAAAAAAAAAAGAIFAAUDVHCFUGFIYF, ENCRYPTKEY defaultGETTRUNCATESREPORTCOUNT EVERY 1 MINUTES, RATEDISCARDFILE ./dirrpt/ext1.dsc, APPEND, MEGABYTES 1024WARNLONGTRANS 2h, CHECKINTERVAL 3mEXTTRAIL ./dirdat/laDYNAMICRESOLUTIONDBOPTIONS ALLOWUNUSEDCOLUMNFETCHOPTIONS NOUSESNAPSHOT--TRANLOGOPTIONS altarchivelogdest primary instance RACDB1 /RAC1_arch1, altarchivelogdest instance RACDB2 /RAC2_arch1--THREADOPTIONS MAXCOMMITPROPAGATIONDELAY 60000 IOLATENCY 60000--TRANLOGOPTIONS is for RAC, tell OGG where the location to extract data from archive log desc--table----obey ./dirprm/source_tables.txt Generate tables using following SQLs:1234567891011SQL&gt; set termout offset feedback offset verify offset pagesize 0spool /gghome/dirprm/source_tables.txtSQL&gt; select 'table '||owner||'.'||table_name||';' from dba_tables where owner='SCOTT';table SCOTT.DEPT;table SCOTT.EMP;table SCOTT.BONUS;table SCOTT.SALGRADE;SQL&gt; spool off Configuring Data pump process 123456789GGSCI (node1) 12&gt; edit params dpe1GGSCI (node1) 13&gt; view params dpe1EXTRACT dpe1PASSTHRURMTHOST 192.168.56.102, MGRPORT 7809, compressDYNAMICRESOLUTIONRMTTRAIL ./dirdat/ra--table----obey ./dirprm/source_tables.txt Adding Extract and Data pump trail file 123456789101112GGSCI (node1) 14&gt; add extract ext1, tranlog, begin nowEXTRACT added.--RAC use: add extract ext1, tranlog, begin now threads 2--threads means how much nodes of this RACGGSCI (node1) 16&gt; add exttrail ./dirdat/la, extract ext1, megabytes 200EXTTRAIL added.GGSCI (node1) 18&gt; add extract dpe1, exttrailsource ./dirdat/laEXTRACT added.GGSCI (node1) 19&gt; add rmttrail ./dirdat/ra, extract dpe1, megabytes 200RMTTRAIL added.GGSCI (node1) 20&gt; start mgrGGSCI (node1) 21&gt; start ext1 Performing full online backup of the source database Pre-backup actions 123456789101112131415161718192021222324252627SQL&gt; select count(*) from gv$transaction;#If no transactions running, do the full backupSQL&gt; select dbid from v$database; DBID ---------- 3461558107SQL&gt; select 'set newname for datafile '||file_id||' to '''||'/u01/linora/temp01.dbf'||''';' from dba_temp_files;set newname for datafile 1 to '/u01/linora/temp01.dbf';SQL&gt; select 'set newname for datafile '||file# ||' to '''||'/u01/linora'||''';' from v$datafile;set newname for datafile 1 to '/u01/linora/system01.dbf';set newname for datafile 2 to '/u01/linora/sysaux01.dbf';set newname for datafile 3 to '/u01/linora/undotbs01.dbf';set newname for datafile 4 to '/u01/linora/users01.dbf';set newname for datafile 5 to '/u01/linora/goldengate01.dbf';#Copy the password from source to targetscp $ORACLE_HOME/dbs/orapwlinora node2:$ORACLE_HOME/dbs/#Record source redo log locationSQL&gt; SELECT member FROM gv$logfile;MEMBER--------------------------------------------------------------------------------/u01/linora/redo03.log/u01/linora/redo02.log/u01/linora/redo01.log Performing full backup 123456789101112131415161718192021222324252627282930#!/bin/bash. ~/.bash_profileexport DB_NAME=linoraRMAN=$ORACLE_HOME/bin/rmanSQLPLUS=$ORACLE_HOME/bin/sqlplusTEE=/usr/bin/teeDBDEST=/backupLOGFILE=/backup/log/backup_db_`date +'%Y%m%d%H%M%S'`.logmkdir -p $&#123;DBDEST&#125;/logecho \"--------------------backup start `date +'%Y-%m-%d %H:%M:%S'`--------------------\" &gt; $LOGFILE$RMAN &lt;&lt;EOF | $TEE -a $LOGFILEconnect targetrun &#123;ALLOCATE CHANNEL ch00 TYPE DISK MAXPIECESIZE 200G;ALLOCATE CHANNEL ch01 TYPE DISK MAXPIECESIZE 200G;CROSSCHECK BACKUPSET;DELETE NOPROMPT EXPIRED BACKUPSET;sql 'alter system archive log current';BACKUP AS BACKUPSET SKIP INACCESSIBLETAG hot_db_bk_level0 FORMAT '/backup/bk_%s_%p_%U_%T_%d'FULL DATABASE;backup current controlfile tag 'ctl' format '/backup/ctl_%U_%T_%d';RELEASE CHANNEL ch00;RELEASE CHANNEL ch01;&#125;exit;EOFecho \"--------------------backup end `date +'%Y-%m-%d %H:%M:%S'`--------------------\" &gt;&gt; $LOGFILEexit 0 Performing redo and archive log backup plus control file 1234567891011121314151617181920212223242526272829#!/bin/bash. ~/.bash_profileexport DB_NAME=linoraRMAN=$ORACLE_HOME/bin/rmanSQLPLUS=$ORACLE_HOME/bin/sqlplusTEE=/usr/bin/teeDBDEST=/backupLOGFILE=/backup/log/backup_archivelog_`date +'%Y%m%d%H%M%S'`.logmkdir -p $&#123;DBDEST&#125;echo \"--------------------backup start `date +'%Y-%m-%d %H:%M:%S'`--------------------\" &gt; $LOGFILE$RMAN &lt;&lt;EOF | $TEE -a $LOGFILEconnect targetrun &#123;ALLOCATE CHANNEL ch00 TYPE DISK MAXPIECESIZE 200G;ALLOCATE CHANNEL ch01 TYPE DISK MAXPIECESIZE 200G;sql 'alter system switch logfile';sql 'alter system switch logfile';sql 'alter system switch logfile';sql 'alter system archive log current';BACKUP ARCHIVELOG FROM TIME 'sysdate-3' FORMAT '/backup/ARCH_%U_T_%d';RELEASE CHANNEL ch00;RELEASE CHANNEL ch01;&#125;exit;EOFecho \"--------------------backup end `date +'%Y-%m-%d %H:%M:%S'`--------------------\" &gt;&gt; $LOGFILEexit 0 Retrieving the SCN after backing up the database and scp the backup images to node2 1234567SQL&gt; select inst_id,group#,thread#,sequence#,members,status,first_change#,next_change# from gv$log;INST_ID GROUP# THREAD# SEQUENCE# MEMBERS STATUS FIRST_CHANGE# NEXT_CHANGE#---------- ---------- ---------- ---------- ---------- -------------------------------- ------------- ------------1 1 1 13 1 INACTIVE 1007503 10075121 2 1 14 1 INACTIVE 1007512 10075211 3 1 15 1 CURRENT 1007521 2.8147E+14 We use the largest SCN of the inactive member. Here&#39;s 1007512. Restoring the database to target system Modifying the initial parameter file 12345mkdir -p /u01/app/oracle/admin/linora/adumpmkdir -p /u01/linora/mkdir -p /u01/app/oracle/fast_recovery_area/linora/mkdir -p /u01/archmkdir -p /u01/app/oracle Starting up the instance to nomount mode 1SQL&gt; startup nomount Restoring the control file and mount the database 1234567891011121314RMAN&gt; restore controlfile from '/backup/ctl_0cr9c7na_1_1_20160629_LINORA';Starting restore at 2016-06-29 16:02:25using target database control file instead of recovery catalogallocated channel: ORA_DISK_1channel ORA_DISK_1: SID=18 device type=DISKchannel ORA_DISK_1: restoring control filechannel ORA_DISK_1: restore complete, elapsed time: 00:00:01output file name=/u01/linora/control01.ctloutput file name=/u01/app/oracle/fast_recovery_area/linora/control02.ctlFinished restore at 2016-06-29 16:02:27RMAN&gt; sql 'alter database mount';sql statement: alter database mountreleased channel: ORA_DISK_1 Cataloging the backup images 1RMAN&gt; catalog start with '/backup'; Restoring and recovering the database 123456789101112131415161718192021222324252627282930313233#!/bin/bash. ~/.bash_profileexport DB_NAME=linoraRMAN=$ORACLE_HOME/bin/rmanSQLPLUS=$ORACLE_HOME/bin/sqlplusTEE=/usr/bin/teeDBDEST=/backupLOGFILE=/backup/log/restore_db_`date +'%Y%m%d%H%M%S'`.logmkdir -p $&#123;DBDEST&#125;/logecho \"--------------------restore start `date +'%Y-%m-%d %H:%M:%S'`--------------------\" &gt; $LOGFILE$RMAN &lt;&lt;EOF | $TEE -a $LOGFILEconnect targetrun&#123;allocate channel c0 type disk;allocate channel c1 type disk;set newname for datafile 1 to '/u01/linora/system01.dbf';set newname for datafile 2 to '/u01/linora/sysaux01.dbf';set newname for datafile 3 to '/u01/linora/undotbs01.dbf';set newname for datafile 4 to '/u01/linora/users01.dbf';set newname for datafile 5 to '/u01/linora/goldengate01.dbf';set newname for tempfile 1 to '/u01/linora/temp01.dbf';restore database; switch datafile all;switch tempfile all;release channel c0;release channel c1;&#125;exit;EOFecho \"--------------------restore end `date +'%Y-%m-%d %H:%M:%S'`--------------------\" &gt;&gt; $LOGFILEexit 0 If needed, rename the redo log file:12SQL&gt; SELECT member FROM gv$logfile;SQL&gt; alter database rename file '/u01/.../redo01.log' to '/u02/.../redo01.log'; Recover the database from specify SCN 1007512.1RMAN&gt; recover database until scn 1007512; Check the file header and the control file SCN1234567891011121314151617SQL&gt; select checkpoint_change# from v$datafile;CHECKPOINT_CHANGE#------------------10075121007512100751210075121007512SQL&gt; select checkpoint_change# from v$datafile_header;CHECKPOINT_CHANGE#------------------10075121007512100751210075121007512 If we don&#39;t have temp tablespace, we need to create the TBS:12345678SQL&gt; select name,bytes/1024/1024/1024 GB from v$tempfile;SQL&gt; create temporary tablespace TEMP tempfile '/u01/linora/temp01.dbf' size 32G;SQL&gt; alter database default temporary tablespace TEMP;SQL&gt; alter database open resetlogs;--using spfile instead pfileSQL&gt; create spfile from pfile;SQL&gt; shutdown immediateSQL&gt; startup Configuring the OGG on the target system Creating the Golden Gate user if we don&#39;t have one 123SQL&gt; create tablespace goldengate datafile '+DATA' size 5000M autoextend on next 64M maxsize unlimited;SQL&gt; create user goldengate identified by goldengate default tablespace goldengate temporary tablespace TEMP profile DEFAULT;SQL&gt; grant dba to goldengate; Disabling the trigger on the target database Disable trigger SP: 12345678910111213declarev_sql varchar2(2000);CURSOR c_trigger IS SELECT 'alter trigger '||owner||'.'||trigger_name||' disable' from dba_triggers where status='ENABLED' and owner in ('SCOTT');BEGINOPEN c_trigger;LOOPFETCH c_trigger INTO v_sql;EXIT WHEN c_trigger%NOTFOUND;execute immediate v_sql;end loop;close c_trigger;end;/ Enable trigger SP: 12345678910111213declarev_sql varchar2(2000);CURSOR c_trigger IS SELECT 'alter trigger '||owner||'.'||trigger_name||' enable' from dba_triggers where status='ENABLED' and owner in ('SCOTT');BEGINOPEN c_trigger;LOOPFETCH c_trigger INTO v_sql;EXIT WHEN c_trigger%NOTFOUND;execute immediate v_sql;end loop;close c_trigger;end;/ Disabling the foreign key Disable FK SP: 12345678910111213declarev_sql varchar2(2000);CURSOR c_trigger IS SELECT 'alter table '||owner||'.'||table_name||' disable constraint '||constraint_name from dba_constraints where constraint_type='R' and owner in ('SCOTT');BEGINOPEN c_trigger;LOOPFETCH c_trigger INTO v_sql;EXIT WHEN c_trigger%NOTFOUND;execute immediate v_sql;end loop;close c_trigger;end;/ Enable FK SP: 12345678910111213declarev_sql varchar2(2000);CURSOR c_trigger IS SELECT 'alter table '||owner||'.'||table_name||' enable constraint '||constraint_name from dba_constraints where constraint_type='R' and owner in ('SCOTT');BEGINOPEN c_trigger;LOOPFETCH c_trigger INTO v_sql;EXIT WHEN c_trigger%NOTFOUND;execute immediate v_sql;end loop;close c_trigger;end;/ Disabling the jobs When target start the replication, broken the DML job, but keep the MV job running. 12345678SQL&gt; set line 200SQL&gt; col what for a50SQL&gt; select job,log_user what from dba_jobs;SQL&gt; select log_user,job,what from dba_jobs where what like '%refresh%';conn /as sysdbaSQL&gt;exec dbms_ijob.broken(121,true);SQL&gt;exec dbms_ijob.broken(141,true);SQL&gt;exec dbms_ijob.broken(301,true); Configuring the listener on the target system 1234567891011121314151617181920212223SID_LIST_LISTENER = (SID_LIST = (SID_DESC = (SID_NAME = PLSExtProc) (ORACLE_HOME = /u01/app/oracle/product/11.2.0/db_1) (PROGRAM = extproc) ) (SID_DESC = (GLOBAL_DBNAME = linora) (ORACLE_HOME = u01/app/oracle/product/11.2.0/db_1) (SID_NAME = linora) ) )LISTENER = (DESCRIPTION_LIST = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = node2)(PORT = 1521)) (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC1521)) ) )ADR_BASE_LISTENER = /u01/app/oracle Other operations before installing the OGG Disable archival on target system1234SQL&gt; shutdown immediateSQL&gt; startup mountSQL&gt; alter database noarchivelog;SQL&gt; alter database open; If we have sequence support on OGG, we need to grant necessary privilege to target database. 12GRANT EXECUTE on ggsusr.replicateSequence TO ggsusr;exec dbms_streams_auth.grant_admin_privilege('ggsusr') Disable sys user capture DDL1Alter trigger sys.GGS_DDL_TRIGGER_BEFORE disable; Installing OGGUnzip and tar the OGG package. The same operation as the source. Configuring GLOBAL parameters 12345[oracle@node2:/u01/arch]$ cd /gghome/[oracle@node2:/gghome]$ ./ggsci GGSCI (node2) 2&gt; create subdirsGGSCI&gt; EDIT PARAMS ./GLOBALSCHECKPOINTTABLE ggsusr.checktable Enabling sequence support 1234[oracle@node2:/backup]$ cd /gghome/[oracle@node2:/gghome]$ sqlplus \"/as sysdba\"SQL&gt; @sequence.sqlSQL&gt; grant execute on ggsusr.replicateSequence to ggsusr; Configuring manager process 1234567891011GGSCI (node2) 4&gt; edit params mgrPORT 7809DYNAMICPORTLIST 7810-7880USERID ggsusr, PASSWORD AACAAAAAAAAAAAGAIFAAUDVHCFUGFIYF, ENCRYPTKEY defaultAUTORESTART EXTRACT *,RETRIES 5,WAITMINUTES 3PURGEOLDEXTRACTS ./dirdat/*,usecheckpoints,minkeepdays 3--PURGEOLDEXTRACTS parameter is determinating how long the extract trail file is keeping--Disable this parameter during initail load, and enable it when sychronizateLAGREPORTHOURS 1LAGINFOMINUTES 30LAGCRITICALMINUTES 45 Configuring Replicat process 123456789101112131415161718192021GGSCI (node2) 5&gt; dblogin userid ggsusr, password oracleGGSCI (node2) 6&gt; add checkpointtable ggsusr.checktableGGSCI (node2) 7&gt; ENCRYPT PASSWORD oracle BLOWFISH ENCRYPTKEY DEFAULTUsing default key...Encrypted password: AACAAAAAAAAAAAGAIFAAUDVHCFUGFIYFGGSCI (node2) 8&gt; edit params repyREPLICAT repy--setenv (NLS_LANG=AMERICAN_AMERICA.ZHS16GBK)USERID ggsusr, PASSWORD AACAAAAAAAAAAAGAIFAAUDVHCFUGFIYF, ENCRYPTKEY defaultREPORT AT 01:59REPORTCOUNT EVERY 30 MINUTES, RATEREPERROR DEFAULT, ABENDDBOPTIONS DEFERREFCONSTassumetargetdefsDISCARDFILE ./dirrpt/repy.dsc, APPEND, MEGABYTES 1024DISCARDROLLOVER AT 02:30GETTRUNCATES ALLOWNOOPUPDATES--table--obey ./dirprm/map_tables_repy.txt You can find the map_tables_repy.txt from below SQLs:1234567SQL&gt; select 'MAP '||owner||'.'||table_name||', TARGET '||owner||'.'||table_name||';' from dba_tables where owner='SCOTT';'MAP'||OWNER||'.'||TABLE_NAME||',TARGET'||OWNER||'.'||TABLE_NAME||';'----------------------------------------------------------------------------MAP SCOTT.DEPT, TARGET SCOTT.DEPT;MAP SCOTT.EMP, TARGET SCOTT.EMP;MAP SCOTT.SALGRADE, TARGET SCOTT.SALGRADE;MAP SCOTT.BONUS, TARGET SCOTT.BONUS; Add replicat process:12GGSCI (node2) 10&gt; ADD REPLICAT repy, EXTTRAIL ./dirdat/ra, checkpointtable ggsusr.checktableREPLICAT added. Starting the replication Start manager process on the target:1GGSCI (node2) 1&gt; start mgr Start the pump process on the source, and observe if any trail files are delivery to the target:1GGSCI (node1) 4&gt; start dpe1 Start the replicat process on the target:1GGSCI (node2) 7&gt; start repy aftercsn 1007521; Testing the replicationUpdate one of the recode of scott.emp table12345678SQL&gt; update scott.emp set SAL=1000 where empno = 7900;1 row updated.SQL&gt; commit;Commit complete.SQL&gt; select * from scott.emp where empno=7900;EMPNO ENAME JOB MGR HIREDATE SAL COMM DEPTNO---------- -------------------- ------------------ ---------- ------------------- ---------- ---------- ----------7900 JAMES CLERK 7698 1981-12-03 00:00:00 1000 30 After a few minutes, check the result from the target.1234SQL&gt; select * from scott.emp where empno=7900;EMPNO ENAME JOB MGR HIREDATE SAL COMM DEPTNO---------- -------------------- ------------------ ---------- ------------------- ---------- ---------- ----------7900 JAMES CLERK 7698 1981-12-03 00:00:00 1000 30 Enable DDL replicationBefore enable ddl replication, we must ensure: Recyclebin has been disabled(10g). The target and source schema must be identical. Enable DDL support12345678[oracle@node1:/home/oracle]$ cd /gghome/[oracle@node1:/gghome]$ sqlplus \"/as sysdba\"SQL&gt; grant execute on utl_file to ggsusr;SQL&gt; @marker_setup.sqlSQL&gt; @ddl_setup.sqlSQL&gt; @role_setup.sqlSQL&gt; GRANT GGS_GGSUSER_ROLE TO ggsusr;SQL&gt; @ddl_enable.sql Edit the OGG params:123456789101112--Both on source and targetGGSCI (node1) 12&gt; edit params GLOBALSGGSCHEMA ggsusr--add the folloing line to Extract and Replicat.GGSCI (node1) 14&gt; edit param ext1ddl include mappedddloptions addtrandata, report--Only on targetGGSCI (node2) 8&gt; edit params repyDDLERROR DEFAULT IGNORE Now, have a test:1234567891011121314151617181920--On the source, modify the columnSQL&gt; desc scott.empName Null? Type----------------------------------------------------------------- -------- ---------------------EMPNO NOT NULL NUMBER(4)ENAME VARCHAR2(10)JOB VARCHAR2(9)MGR NUMBER(4)HIREDATE DATESAL NUMBER(7,2)COMM NUMBER(7,2)DEPTNO NUMBER(2)SQL&gt; alter table scott.emp add ncol varchar2(10);SQL&gt; create table scott.test as select * from scott.emp;--On targetSQL&gt; select count(*) from scott.test; COUNT(*) ---------- 14 Trouble shooting When doing some DMLs to the table, encountered following errors: 12342016-06-29 21:43:43 WARNING OGG-00869 Oracle GoldenGate Delivery for Oracle, repy.prm: OCI Error ORA-26945: unsupported hint RESTRICT_ALL_REF_CONS (status = 26945). UPDATE /*+ RESTRICT_ALL_REF_CONS */ \"SCOTT\".\"EMP\" SET \"SAL\" = :a1 WHERE \"EMPNO\" = :b0.2016-06-29 21:43:43 WARNING OGG-01004 Oracle GoldenGate Delivery for Oracle, repy.prm: Aborted grouped transaction on 'SCOTT.EMP', Database error 26945 (OCI Error ORA-26945: unsupported hint RESTRICT_ALL_REF_CONS (status = 26945). UPDATE /*+ RESTRICT_ALL_REF_CONS */ \"SCOTT\".\"EMP\" SET \"SAL\" = :a1 WHERE \"EMPNO\" = :b0).2016-06-29 21:43:43 WARNING OGG-01003 Oracle GoldenGate Delivery for Oracle, repy.prm: Repositioning to rba 1479 in seqno 0.2016-06-29 21:43:43 WARNING OGG-01154 Oracle GoldenGate Delivery for Oracle, repy.prm: SQL error 26945 mapping SCOTT.EMP to SCOTT.EMP OCI Error ORA-26945: unsupported hint RESTRICT_ALL_REF_CONS (status = 26945). UPDATE /*+ RESTRICT_ALL_REF_CONS */ \"SCOTT\".\"EMP\" SET \"SAL\" = :a1 WHERE \"EMPNO\" = :b0. Solution:12SQL&gt; exec dbms_goldengate_auth.grant_admin_privilege('GGSUSR');SQL&gt; ALTER SYSTEM SET ENABLE_GOLDENGATE_REPLICATION = TRUE SCOPE = BOTH; If you want to skip current transaction, do the following:1GGSCI (node2) 33&gt; START REPLICAT repy SKIPTRANSACTION When enabling DDL support, encountered following errors: 123456789SQL&gt; @ddl_setup.sql[oracle@node1:/gghome]$ more ddl_setup_spool.txt...BEGIN \"GGSUSR\" .initial_setup; END;**ERROR at line 1:ORA-20782: Creating GGS_DDL_RULES table:ORA-01031: insufficient privileges:ORA-01031: insufficient privilegesORA-06512: at \"GGSUSR.INITIAL_SETUP\", line 477ORA-06512: at line 1 Solution:12345cd /gghome/sqlplus \"/as sysdba\"SQL&gt; @ddl_disable.sqlSQL&gt; grant create table,create sequence to ggsusr;SQL&gt; @ddl_setup.sql EOF","link":"/ogg-rman-initial-load-sample.html"},{"title":"Opatch","text":"Opatch主要是针对小补丁集管理的工具，不同于release，这些小补丁包含PSU(每季度发布)，one-off patch，CPU等。打补丁前先将opatch升级至最新版，同时先停止数据库及监听服务。 1.新版opatch下载地址https://updates.oracle.com/download/6880880.html 2.查看当前数据库opatch版本1234oracle@linux:~&gt; $ORACLE_HOME/OPatch/opatch versionInvoking OPatch 11.2.0.1.7OPatch Version: 11.2.0.1.7OPatch succeeded. 3.更新至最新版opatch123456789101112131415oracle@linux:/opt&gt; cd ~/opatch/oracle@linux:~/opatch&gt; lltotal 32668-rw-r--r-- 1 root root 33020933 Feb 10 15:47 p6880880_112000_Linux-x86-64.zip#修改属性linux:~ # chown -R oracle:oinstall /home/oracle/opatch/#解压zip包oracle@linux:~/opatch&gt; lltotal 32668-rw-r--r-- 1 oracle oinstall 33020933 Feb 10 15:47 p6880880_112000_Linux-x86-64.ziporacle@linux:~/opatch&gt; unzip p6880880_112000_Linux-x86-64.zip oracle@linux:~/opatch&gt; ls -ltrtotal 32672drwxr-xr-x 8 oracle oinstall 4096 Dec 14 2013 OPatch-rw-r--r-- 1 oracle oinstall 33020933 Feb 10 15:47 p6880880_112000_Linux-x86-64.zip 解压完直接替换即可：12345678oracle@linux:~/opatch&gt; cd /oracle/app/oracle/product/11.2.0/linoradboracle@linux:/oracle/app/oracle/product/11.2.0/linoradb&gt; mv OPatch OPatch_oldoracle@linux:/oracle/app/oracle/product/11.2.0/linoradb&gt; mv /home/oracle/opatch/OPatch/ \\/oracle/app/oracle/product/11.2.0/linoradb/#查看更新后版本oracle@linux:/oracle/app/oracle/product/11.2.0/linoradb&gt; OPatch/opatch versionOPatch Version: 11.2.0.3.6OPatch succeeded. 4.安装前准备--当前数据库PSU及补丁情况123456789101112131415161718192021222324252627282930313233343536[oracle@linora:/worktmp]$ $ORACLE_HOME/OPatch/opatch lsinvOracle Interim Patch Installer version 11.2.0.3.6Copyright (c) 2013, Oracle Corporation. All rights reserved.Oracle Home : /u01/app/oracle/product/11gr2Central Inventory : /u01/app/oraInventory from : /u01/app/oracle/product/11gr2/oraInst.locOPatch version : 11.2.0.3.6OUI version : 11.2.0.3.0Log file location : /u01/app/oracle/product/11gr2/cfgtoollogs/opatch/opatch2015-03-25_09-34-31AM_1.logLsinventory Output file location : /u01/app/oracle/product/11gr2/cfgtoollogs/opatch/lsinv/lsinventory2015-03-25_09-34-31AM.txt--------------------------------------------------------------------------------Installed Top-level Products (1): Oracle Database 11g 11.2.0.3.0There are 1 product(s) installed in this Oracle Home.Interim patches (1) :Patch 13696216 : applied on Wed Mar 25 09:25:43 CST 2015Unique Patch ID: 14596729Patch description: &quot;Database Patch Set Update : 11.2.0.3.2 (13696216)&quot; Created on 3 Apr 2012, 22:02:51 hrs PST8PDTSub-patch 13343438; &quot;Database Patch Set Update : 11.2.0.3.1 (13343438)&quot; Bugs fixed: 13070939, 13035804, 10350832, 13632717, 13041324, 12919564, 13420224 13742437, 12861463, 12834027, 13742438, 13332439, 13036331, 13499128 12998795, 12829021, 13492735, 9873405, 13742436, 13503598, 12960925 12718090, 13742433, 12662040, 9703627, 12905058, 12938841, 13742434 12849688, 12950644, 13362079, 13742435, 12620823, 12917230, 12845115 12656535, 12764337, 13354082, 12588744, 11877623, 12612118, 12847466 13742464, 13528551, 12894807, 13343438, 12582664, 12780983, 12748240 12797765, 12780098, 13696216, 12923168, 13466801, 13772618, 11063191, 13554409 以上列出了已经安装了的补丁集：13696216,13343438。1234567891011121314151617181920212223--解压11.2.0.3.4[oracle@linora:/worktmp]$ unzip p14275605_112030_Linux-x86-64.zip[oracle@linora:/worktmp]$ cd 14275605/--检查11.2.0.3.4是否与之前11.2.0.3.2有冲突[oracle@linora:/worktmp/14275605]$ $ORACLE_HOME/OPatch/opatch prereq \\CheckConflictAgainstOHWithDetail -ph ./Oracle Interim Patch Installer version 11.2.0.3.6Copyright (c) 2013, Oracle Corporation. All rights reserved.PREREQ sessionOracle Home : /u01/app/oracle/product/11gr2Central Inventory : /u01/app/oraInventory from : /u01/app/oracle/product/11gr2/oraInst.locOPatch version : 11.2.0.3.6OUI version : 11.2.0.3.0Log file location : /u01/app/oracle/product/11gr2/cfgtoollogs/opatch/opatch2015-03-25_09-37-00AM_1.logInvoking prereq &quot;checkconflictagainstohwithdetail&quot;Prereq &quot;checkConflictAgainstOHWithDetail&quot; passed.OPatch succeeded. 5.安装psu关闭数据库相关服务，如EM，OGG等，在此之前，要确保对数据库做了备份。进入patch 目录，直接进行apply：1[oracle@linora:/worktmp/14275605]$ $ORACLE_HOME/OPatch/opatch apply 6.确认补丁状况1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[oracle@linora:/worktmp/14275605]$ $ORACLE_HOME/OPatch/opatch lsinvOracle Interim Patch Installer version 11.2.0.3.6Copyright (c) 2013, Oracle Corporation. All rights reserved.Oracle Home : /u01/app/oracle/product/11gr2Central Inventory : /u01/app/oraInventory from : /u01/app/oracle/product/11gr2/oraInst.locOPatch version : 11.2.0.3.6OUI version : 11.2.0.3.0Log file location : /u01/app/oracle/product/11gr2/cfgtoollogs/opatch/opatch2015-03-25_10-12-01AM_1.logLsinventory Output file location : /u01/app/oracle/product/11gr2/cfgtoollogs/opatch/lsinv/lsinventory2015-03-25_10-12-01AM.txt--------------------------------------------------------------------------------Installed Top-level Products (1): Oracle Database 11g 11.2.0.3.0There are 1 product(s) installed in this Oracle Home.Interim patches (1) :Patch 14275605 : applied on Wed Mar 25 09:55:51 CST 2015Unique Patch ID: 15367368Patch description: &quot;Database Patch Set Update : 11.2.0.3.4 (14275605)&quot; Created on 3 Oct 2012, 18:38:19 hrs PST8PDTSub-patch 13923374; &quot;Database Patch Set Update : 11.2.0.3.3 (13923374)&quot;Sub-patch 13696216; &quot;Database Patch Set Update : 11.2.0.3.2 (13696216)&quot;Sub-patch 13343438; &quot;Database Patch Set Update : 11.2.0.3.1 (13343438)&quot; Bugs fixed: 14480676, 13566938, 13419660, 10350832, 13632717, 14063281, 12919564 13624984, 13430938, 13467683, 13588248, 13420224, 14548763, 13080778 12646784, 13804294, 12861463, 12834027, 13377816, 13036331, 12880299 14664355, 13499128, 14409183, 12998795, 12829021, 13492735, 12794305 13503598, 10133521, 12718090, 13742433, 12905058, 12401111, 13742434 13257247, 12849688, 13362079, 12950644, 13742435, 13464002, 12917230 13923374, 12879027, 14613900, 12585543, 12535346, 14480675, 12588744 11877623, 14480674, 13916709, 12847466, 13773133, 14076523, 13649031 13340388, 13366202, 13528551, 13981051, 12894807, 13343438, 12582664 12748240, 12797765, 13385346, 12923168, 13384182, 13612575, 13466801 13484963, 12971775, 11063191, 13772618, 13070939, 12797420, 13035804 13041324, 12976376, 11708510, 13742437, 13737746, 14062795, 13035360 12693626, 13742438, 13326736, 13332439, 14038787, 14062796, 12913474 13001379, 14390252, 13099577, 13370330, 13059165, 14062797, 14275605 9873405, 13742436, 9858539, 14062794, 13358781, 12960925, 13699124 12662040, 9703627, 12617123, 13338048, 12938841, 12658411, 12620823 12845115, 12656535, 14062793, 12678920, 12764337, 13354082, 13397104 14062792, 13250244, 12594032, 9761357, 12612118, 13742464, 13550185 13457582, 13527323, 12780983, 12583611, 13502183, 12780098, 13705338 13696216, 13476583, 11840910, 13903046, 13572659, 13718279, 13554409 13657605, 13103913, 14063280--------------------------------------------------------------------------------OPatch succeeded.[oracle@linora:/worktmp/14275605]$ $ORACLE_HOME/OPatch/opatch lsinventory -invPtrLoc \\/u01/app/oraInventory/oraInst.loc -bugs_fixed | egrep &apos;PSU|PATCH SET UPDATE&apos;14275605 14275605 Wed Mar 25 11:06:52 CST 2015 DATABASE PATCH SET UPDATE 11.2.0.3.4 (INCLUDES CPU13923374 13923374 Wed Mar 25 11:06:44 CST 2015 DATABASE PATCH SET UPDATE 11.2.0.3.3 (INCLUDES 13696216 13696216 Wed Mar 25 09:25:43 CST 2015 DATABASE PATCH SET UPDATE 11.2.0.3.2 (INCLUDES 13343438 13343438 Wed Mar 25 09:17:40 CST 2015 DATABASE PATCH SET UPDATE 11.2.0.3.1 7.开启数据库及监听，注册PSU信息至数据库12345678SQL&gt; alter system regeister;SQL&gt; @?/rdbms/admin/catbundle.sql psu applycol action_time for a28col version for a10col comments for a35col action for a25col namespace for a12select * from registry$history; 执行完catbundle.sql后，会在$ORACLE_HOME/rdbms/admin目录下生成catbundle_PSU__APPLY.sql，catbundle_PSU__ROLLBACK.sql两个脚本验证无误后开启其他数据库服务，如OGG、EM等。 8.回滚操作关闭数据库相关服务，如监听、OGG、EM等。1234567SQL&gt; shutdown immediateDatabase closed.Database dismounted.ORACLE instance shut down.SQL&gt; Disconnected from Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing options[oracle@linora:/worktmp/14275605]$ lsnrctl stop opatch回滚patch 142756051[oracle@linora:/worktmp/14275605]$ $ORACLE_HOME/OPatch/opatch rollback -id 14275605 执行完毕后，开启数据库，执行数据库级别的回滚操作：1234567891011121314151617181920SQL&gt; alter system register;SQL&gt; @?/rdbms/admin/catbundle_PSU_LINORA_ROLLBACK.sql;SQL&gt; set line 200SQL&gt; col action_time for a28SQL&gt; col version for a10SQL&gt; col comments for a35SQL&gt; col action for a25SQL&gt; col namespace for a12SQL&gt; select * from registry$history;ACTION_TIME ACTION NAMESPACE VERSION ID COMMENTS BUNDLE_SERIES---------------------------- -------------- ------------ ---------- ----- --------------------- --------17-SEP-11 10.21.11.595816 AM APPLY SERVER 11.2.0.3 0 Patchset 11.2.0.2.0 PSU24-MAR-15 02.33.46.001293 PM APPLY SERVER 11.2.0.3 0 Patchset 11.2.0.2.0 PSU25-MAR-15 09.20.32.232223 AM APPLY SERVER 11.2.0.3 1 PSU 11.2.0.3.1 PSU25-MAR-15 09.26.39.633258 AM APPLY SERVER 11.2.0.3 2 PSU 11.2.0.3.2 PSU25-MAR-15 10.14.32.978033 AM APPLY SERVER 11.2.0.3 4 PSU 11.2.0.3.4 PSU25-MAR-15 10.26.42.133461 AM ROLLBACK SERVER 11.2.0.3 4 PSU 11.2.0.3.4 PSU6 rows selected. Reference:Patching Oracle Software with OPatch EOF","link":"/opatch.html"},{"title":"ora-12514解决一例","text":"1.环境 11g RAC,重装时取消了REMOTE_LISTENER参数，导致在连接tns的时候报错。 123456789101112131415161718C:\\Users\\Administrator&gt;tnsping fungTNS Ping Utility for 32-bit Windows: Version 10.2.0.4.0 - Production on 02-9月 - 2013 15:52:32 Copyright (c) 1997, 2007, Oracle. All rights reserved. 已使用的参数文件: D:\\OraClient\\oracle\\product\\10.2.0\\client_1\\network\\admin\\sqlnet.ora已使用 TNSNAMES 适配器来解析别名 Attempting to contact (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168. 137.112)(PORT = 1521)) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = fung ))) OK (20 毫秒) C:\\Users\\Administrator&gt;sqlplus system@fung SQL*Plus: Release 10.2.0.4.0 - Production on 星期一 9月 2 15:52:39 2013 Copyright (c) 1982, 2007, Oracle. All Rights Reserved. 输入口令: ERROR: ORA-12514: TNS: 监听程序当前无法识别连接描述符中请求的服务 2.登录Server，查询该参数 1234567891011121314151617[oracle@ora11g:/home/oracle]$ sqlplus &quot;/as sysdba&quot;SQL*Plus: Release 11.2.0.4.0 Production on Mon Sep 2 16:04:36 2013 Copyright (c) 1982, 2013, Oracle. All rights reserved. Connected to: Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit Production With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP, Data Mining and Real Application Testing optionsSQL&gt; show parameter remote NAME TYPE VALUE ------------------------------------ ----------- ------------------------------ remote_dependencies_mode string TIMESTAMP remote_listener string remote_login_passwordfile string EXCLUSIVE remote_os_authent boolean FALSE remote_os_roles boolean FALSE result_cache_remote_expiration integer 0 在spfile中添加remote_listener： 1234567SQL&gt; alter system set remote_listener=&apos;scan-ip:1521&apos; scope=both sid=&apos;*&apos;; alter system set remote_listener=&apos;scan-ip:1521&apos; scope=both sid=&apos;*&apos; *ERROR at line 1: ORA-02097: parameter cannot be modified because specified value is invalid ORA-00119: invalid specification for system parameter REMOTE_LISTENER ORA-00132: syntax error or unresolved network name &apos;scan-ip:1521&apos; 再次报错，使用另一种方式解析： 123456789101112131415161718192021222324SQL&gt; alter system set remote_listener=&apos;(ADDRESS_LIST=(Address=(Protocol=tcp) (Host=scan-ip)(Port=1521)))&apos; scope=both sid=&apos;*&apos;; System altered. SQL&gt; show parameter remote NAME TYPE VALUE ------------------------------------ ----------- ------------------------------ remote_dependencies_mode string TIMESTAMP remote_listener string (ADDRESS_LIST=(Address=(Protoc ol=tcp) (Host=scan-ip)(Port=15 21))) remote_login_passwordfile string EXCLUSIVE remote_os_authent boolean FALSE remote_os_roles boolean FALSE result_cache_remote_expiration integer 0 C:\\Users\\Administrator&gt;sqlplus system@fungSQL*Plus: Release 10.2.0.4.0 - Production on 星期一 9月 2 16:02:01 2013 Copyright (c) 1982, 2007, Oracle. All Rights Reserved. 输入口令: 连接到: Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit Production With the Partitioning, Real Application Clusters, Automatic Storage Management, OLAP, Data Mining and Real Application Testing options SQL&gt;","link":"/ora-12514-rac.html"},{"title":"ORA-19511","text":"客户最近因升级主机，NBU客户端重新安装，最近说NBU备份Oracle老是报错。我过去现场一看，最早记录10月份，从那时开始一直在报错，这一个多月就从没备份成功过。很有可能NBU客户端安装后就一直备份不成功，但是客户一直没发现。 1.现象当时重现了一下错误过程，从RMAN后台日志发现第一个backup piece能成功备份，第二个开始报错，RMAN报错信息如下：1234567891011121314RMAN-03009: failure of backup command on ch01 channel at 11/17/2014 15:59:51ORA-19506: failed to create sequential file, name=&quot;al_37873_1_863883864&quot;, parms=&quot;&quot;ORA-27028: skgfqcre: sbtbackup returned errorORA-19511: Error received from media manager layer, error text: VxBSACreateObject: Failed with error: Server Status: Communication with the server has not been initiated or the server status has not been retrieved from the serveRMAN-03009: failure of backup command on ch00 channel at 11/17/2014 15:59:51ORA-19506: failed to create sequential file, name=&quot;al_37872_1_863883864&quot;, parms=&quot;&quot;ORA-27028: skgfqcre: sbtbackup returned errorORA-19511: Error received from media manager layer, error text: VxBSACreateObject: Failed with error: Server Status: Communication with the server has not been initiated or the server status has not been retrieved from the serve 2.可能的解决方法2.1 主机名解析及连通性首先我想到的是客户端和server端主机名/etc/hosts及bp.conf的解析，但是相互解析都是OK的。在client端执行：1/usr/openv/netbackup/bin/bptestnetconn -as -sc 进一步我想查看日志，没有相关日志目录，在客户端自己创建一个。12345678mkdir -p /usr/openv/netbackup/logs/bpdbmmkdir -p /usr/openv/netbackup/logs/bpdbmmkdir -p /usr/openv/netbackup/logs/bptmmkdir -p /usr/openv/netbackup/logs/bpcdmkdir -p /usr/openv/netbackup/logs/vnetdmkdir -p /usr/openv/netbackup/logs/bprdmkdir -p /usr/openv/netbackup/logs/dbclientchmod -R 777 /usr/openv/netbackup/logs 重新运行备份作业，并没有得到有用的日志信息。 2.2 在备份脚本中执行backup server、client及policy1SEND &apos;NB_ORA_SERV=Master,NB_ORA_CLIENT=Client,NB_ORA_POLICY=oracle_arch&apos;; 重新尝试备份，结果依旧一样。 3.问题的解决继续“盘问”客户，得知这是一套HACMP架构，而bp.conf里面使用的是虚拟IP地址，且有多网卡。在bp.conf中指定使用那张网卡，问题得到解决。123SERVER = backupserverCLIENT_NAME = oracleREQUIRED_INTERFACE = 192.168.11.155 其实这是一个很简单的问题，处理时间比较久是因为本身对NBU备份HA不熟悉。","link":"/ora-19511.html"},{"title":"数据文件权限导致DataGuard无法同步","text":"1. 现象 备库执行rman报以下错误： 12345678910111213Starting backup at 29-AUG-13 could not read file header for datafile 25 error reason 1 could not read file header for datafile 25 error reason 1 released channel: sbt1RMAN-00571: =========================================================== RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS =============== RMAN-00571: =========================================================== RMAN-03002: failure of backup command at 08/29/2013 00:00:08 RMAN-06056: could not access datafile 25 RMAN&gt; RMAN&gt; 2&gt; 3&gt; 4&gt; 5&gt; 6&gt; 7&gt; 8&gt; 2. 诊断 查询备库alert日志，发现六天前出现如下错误： 12345678910111213141516171819202122232425WARNING: File being created with same name as in Primary Existing file may be overwritten File #25 added to control file as &apos;UNNAMED00025&apos;. Originally created as: &apos;/dev/rLNT_TXNIDX_01&apos; Recovery was unable to create the file as: &apos;/dev/rLNT_TXNIDX_01&apos; Errors with log /oradata/szdb/archive/1_425944_652903983.arc MRP0: Background Media Recovery terminated with error 1119 Fri Aug 23 17:20:53 BEIST 2013 Errors in file /oracle/admin/szdb/bdump/stdszdb_mrp0_647254.trc: ORA-01119: error in creating database file &apos;/dev/rLNT_TXNIDX_01&apos; ORA-27041: unable to open file IBM AIX RISC System/6000 Error: 13: Permission denied Additional information: 11 Some recovered datafiles maybe left media fuzzy Media recovery may continue but open resetlogs may fail Fri Aug 23 17:20:55 BEIST 2013 Errors in file /oracle/admin/szdb/bdump/stdszdb_mrp0_647254.trc: ORA-01119: error in creating database file &apos;/dev/rLNT_TXNIDX_01&apos; ORA-27041: unable to open file IBM AIX RISC System/6000 Error: 13: Permission denied Additional information: 11 Fri Aug 23 17:20:55 BEIST 2013 MRP0: Background Media Recovery process shutdown (stdszdb) 跟客户沟通，发现在23号主库添加过数据文件，但是在备库端没有赋予相应权限，等后面改过来后，MRP进程已经被shutdown了。 3. 解决思路 日志传输仍然是正常的，尝试重启MRP进程： 12alter database recover managed standby database cancel; alter database recover managed standby database finish; 报错如下： 12345678910SQL&gt; alter database recover managed standby database finish; alter database recover managed standby database finish *ERROR at line 1: ORA-00283: recovery session canceled due to errors ORA-01111: name for data file 25 is unknown - rename to correct file ORA-01110: data file 25: &apos;/oracle/product/10.2.0/db_1/dbs/UNNAMED00025&apos; ORA-01157: cannot identify/lock data file 25 - see DBWR trace file ORA-01111: name for data file 25 is unknown - rename to correct file ORA-01110: data file 25: &apos;/oracle/product/10.2.0/db_1/dbs/UNNAMED00025&apos; 尝试在备机重建数据文件： 123456SQL&gt; select file#，name from v$datafile where file#=25; SQL&gt; alter database create datafile &apos;/oracle/product/10.2.0/db_1/dbs/UNNAMED00025&apos; as &apos;/dev/rLNT_TXNIDX_01&apos;; alter database create datafile &apos;/oracle/product/10.2.0/db_1/dbs/UNNAMED00025&apos; as &apos;/dev/rLNT_TXNIDX_01&apos; *ERROR at line 1: ORA-01275: Operation CREATE DATAFILE is not allowed if standby file management is automatic. 最后将Standby file management修改为manual，再重新创建数据文件即可。操作如下： 12345alter system set standby_file_management=manual; alter database create datafile &apos;/oracle/product/10.2.0/db_1/dbs/UNNAMED00025&apos; as &apos;/dev/rLNT_TXNIDX_01&apos;; alter database recover managed standby database cancel; alter database recover managed standby database disconnect from session; alter system set standby_file_management=&apos;auto&apos; scope=both; 4. 结果 查询Standby alert日志，发现已经开始同步： 123Thu Aug 29 14:29:53 BEIST 2013 Media Recovery Log /oradata/szdb/archive/1_426095_652903983.arc Media Recovery Log /oradata/szdb/archive/2_335064_652903983.arc 在主备端各自查询最大log sequence： 123456789select thread#,max(sequence#) from v$log_history group by thread#; THREAD# MAX(SEQUENCE#) 1 1 428326 2 2 336500 THREAD# MAX(SEQUENCE#) ---------- -------------- 1 426090 2 335062 日志已经在同步，但是因为相差时间太久，需要时间才能同步完。 EOF","link":"/ora01111-ora01119.html"},{"title":"Oracle Data Pump","text":"1. BasicOracle Data Pump是10g以后用于数据逻辑导入导出的加强工具，加强是相对于exp跟imp而言。经常用于逻辑备份及数据库迁移方面，本文就经常用到的方法做一个小的总结。不同于exp/imp，data pump使用的时候要先创建一个目录用于存放dump文件。12345[oracle@:/oracle]$ ls -lttotal 2580304drwxr-xr-x 3 oracle oinstall 256 May 20 14:08 oradatadrwxr-xr-x 2 oracle oinstall 256 May 20 14:07 archdrwxr-xr-x 2 oracle oinstall 256 May 20 14:07 expdir 10g默认的目录如下：123456789SQL&gt; col OWNER for a10SQL&gt; col DIRECTORY_NAME for a20SQL&gt; col DIRECTORY_PATH for a50SQL&gt; set linesize 200SQL&gt; select * from dba_directories;OWNER DIRECTORY_NAME DIRECTORY_PATH---------- -------------------- --------------------------------------------------SYS DATA_PUMP_DIR /oracle/app/oracle/product/10gr2/rdbms/log/ 创建一个新的目录，并赋予Public的权限，这样，凡是有exdpd权限的用户均可读写此目录。12345678910111213SQL&gt; create directory expdir as &apos;/oracle/expdir&apos;;Directory created.SQL&gt; grant read,write on directory expdir to public;Grant succeeded.SQL&gt; select * from dba_directories;OWNER DIRECTORY_NAME DIRECTORY_PATH---------- -------------------- --------------------------------------------------SYS DATA_PUMP_DIR /oracle/app/oracle/product/10gr2/rdbms/log/SYS EXPDIR /oracle/expdir Data Pump是基于server端的，因此，目录也只能是基于server端。目录创建好，就可以进行导入导出动作了。Data Pump可基于表、用户、数据库等方式的导入导出。 1.1 Tables12345678910111213141516171819202122232425262728293031323334[oracle@:/home/oracle]$ expdp fung/oracle@oratest tables=object directory=expdir dumpfile=fung.object.dmp logfile=fung.object.logExport: Release 10.2.0.1.0 - 64bit Production on Tuesday, 20 May, 2014 14:52:16Copyright (c) 2003, 2005, Oracle. All rights reserved.Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP and Data Mining optionsStarting &quot;FUNG&quot;.&quot;SYS_EXPORT_TABLE_01&quot;: fung/********@oratest tables=object directory=expdir dumpfile=fung.object.dmp logfile=fung.object.log Estimate in progress using BLOCKS method...Processing object type TABLE_EXPORT/TABLE/TABLE_DATATotal estimation using BLOCKS method: 32 MBProcessing object type TABLE_EXPORT/TABLE/TABLE. . exported &quot;FUNG&quot;.&quot;OBJECT&quot; 26.63 MB 315008 rowsMaster table &quot;FUNG&quot;.&quot;SYS_EXPORT_TABLE_01&quot; successfully loaded/unloaded******************************************************************************Dump file set for FUNG.SYS_EXPORT_TABLE_01 is: /oracle/expdir/fung.object.dmpJob &quot;FUNG&quot;.&quot;SYS_EXPORT_TABLE_01&quot; successfully completed at 14:52:26[oracle@:/home/oracle]$ impdp fung/oracle@oratest tables=object directory=expdir dumpfile=fung.object.dmp logfile=imp.object.logImport: Release 10.2.0.1.0 - 64bit Production on Tuesday, 20 May, 2014 14:54:35Copyright (c) 2003, 2005, Oracle. All rights reserved.Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP and Data Mining optionsMaster table &quot;FUNG&quot;.&quot;SYS_IMPORT_TABLE_01&quot; successfully loaded/unloadedStarting &quot;FUNG&quot;.&quot;SYS_IMPORT_TABLE_01&quot;: fung/********@oratest tables=object directory=expdir dumpfile=fung.object.dmp logfile=imp.object.log Processing object type TABLE_EXPORT/TABLE/TABLEProcessing object type TABLE_EXPORT/TABLE/TABLE_DATA. . imported &quot;FUNG&quot;.&quot;OBJECT&quot; 26.63 MB 315008 rowsJob &quot;FUNG&quot;.&quot;SYS_IMPORT_TABLE_01&quot; successfully completed at 14:54:40 1.2 Schemas12345678910111213141516171819202122232425262728293031323334353637383940414243444546[oracle@:/home/oracle]$ expdp system/oracle schemas=fung directory=expdir dumpfile=fung.dmp logfile=fung.exp.logExport: Release 10.2.0.1.0 - 64bit Production on Tuesday, 20 May, 2014 18:00:39Copyright (c) 2003, 2005, Oracle. All rights reserved.Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP and Data Mining optionsStarting &quot;SYSTEM&quot;.&quot;SYS_EXPORT_SCHEMA_01&quot;: system/******** schemas=fung directory=expdir dumpfile=fung.dmp logfile=fung.exp.log Estimate in progress using BLOCKS method...Processing object type SCHEMA_EXPORT/TABLE/TABLE_DATATotal estimation using BLOCKS method: 32 MBProcessing object type SCHEMA_EXPORT/USERProcessing object type SCHEMA_EXPORT/SYSTEM_GRANTProcessing object type SCHEMA_EXPORT/ROLE_GRANTProcessing object type SCHEMA_EXPORT/DEFAULT_ROLEProcessing object type SCHEMA_EXPORT/TABLESPACE_QUOTAProcessing object type SCHEMA_EXPORT/PRE_SCHEMA/PROCACT_SCHEMAProcessing object type SCHEMA_EXPORT/TABLE/TABLE. . exported &quot;FUNG&quot;.&quot;OBJECT&quot; 26.63 MB 315008 rowsMaster table &quot;SYSTEM&quot;.&quot;SYS_EXPORT_SCHEMA_01&quot; successfully loaded/unloaded******************************************************************************Dump file set for SYSTEM.SYS_EXPORT_SCHEMA_01 is: /oracle/expdir/fung.dmpJob &quot;SYSTEM&quot;.&quot;SYS_EXPORT_SCHEMA_01&quot; successfully completed at 18:00:49[oracle@:/home/oracle]$ impdp system/oracle@orcl schemas=fung directory=expdir dumpfile=oratest.dmpImport: Release 10.2.0.1.0 - 64bit Production on Tuesday, 20 May, 2014 17:49:57Copyright (c) 2003, 2005, Oracle. All rights reserved.Connected to: Oracle Database 11g Enterprise Edition Release 11.2.0.3.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsMaster table &quot;SYSTEM&quot;.&quot;SYS_IMPORT_SCHEMA_01&quot; successfully loaded/unloadedStarting &quot;SYSTEM&quot;.&quot;SYS_IMPORT_SCHEMA_01&quot;: system/********@orcl schemas=fung directory=expdir dumpfile=oratest.dmp Processing object type DATABASE_EXPORT/SCHEMA/USERProcessing object type DATABASE_EXPORT/SCHEMA/GRANT/SYSTEM_GRANTProcessing object type DATABASE_EXPORT/SCHEMA/ROLE_GRANTProcessing object type DATABASE_EXPORT/SCHEMA/DEFAULT_ROLEProcessing object type DATABASE_EXPORT/SCHEMA/TABLESPACE_QUOTAProcessing object type DATABASE_EXPORT/SCHEMA/PROCACT_SCHEMAProcessing object type DATABASE_EXPORT/SCHEMA/TABLE/TABLEProcessing object type DATABASE_EXPORT/SCHEMA/TABLE/TABLE_DATA. . imported &quot;FUNG&quot;.&quot;OBJECT&quot; 26.63 MB 315008 rowsJob &quot;SYSTEM&quot;.&quot;SYS_IMPORT_SCHEMA_01&quot; successfully completed at 04:46:29 1.3 Database12[oracle@:/home/oracle]$ expdp system/oracle full=y directory=expdir dumpfile=oratest01.dmp[oracle@:/home/oracle]$ impdp system/oracle@orcl full=y directory=expdir dumpfile=oratest.dmp 2. Advanced Options 2.1 exclude/include使用exclude及include参数排除/加入某些表、用户等。语法：12EXCLUDE = object_type[:name_clause] [, ...]INCLUDE = object_type[:name_clause] [, ...] #####示例11expdp hr/hr DIRECTORY=dpump_dir1 DUMPFILE=hr_exclude.dmp EXCLUDE=VIEW,PACKAGE, FUNCTION #####示例2全库导出，排除系统自带用户。12345678910111213[oracle@:/home/oracle]$ expdp system/oracle full=y directory=expdir \\&gt; EXCLUDE=SCHEMA:&quot;IN (&apos;OUTLN&apos;,&apos;DBSNMP&apos;,&apos;DIP&apos;)&quot; \\&gt; EXCLUDE=SCHEMA:&quot;LIKE &apos;%SYS%&apos;&quot; dumpfile=oratest.dmpExport: Release 10.2.0.1.0 - 64bit Production on Tuesday, 20 May, 2014 18:11:12Copyright (c) 2003, 2005, Oracle. All rights reserved.Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP and Data Mining optionsORA-39001: invalid argument valueORA-39071: Value for EXCLUDE is badly formed.ORA-00936: missing expression 出现这个错误，需要加上转义字符：123456789101112131415161718192021222324252627282930313233343536373839[oracle@:/home/oracle]$ expdp system/oracle full=y directory=expdir \\&gt; EXCLUDE=SCHEMA:\\&quot;IN \\(\\&apos;OUTLN\\&apos;,\\&apos;DBSNMP\\&apos;,\\&apos;DIP\\&apos;\\)\\&quot; \\&gt; EXCLUDE=SCHEMA:\\&quot;LIKE \\&apos;\\%SYS\\%\\&apos;\\&quot; dumpfile=oratest.dmpExport: Release 10.2.0.1.0 - 64bit Production on Tuesday, 20 May, 2014 18:12:35Copyright (c) 2003, 2005, Oracle. All rights reserved.Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP and Data Mining optionsStarting &quot;SYSTEM&quot;.&quot;SYS_EXPORT_FULL_01&quot;: system/******** full=y directory=expdir EXCLUDE=SCHEMA:&quot;IN (&apos;OUTLN&apos;,&apos;DBSNMP&apos;,&apos;DIP&apos;)&quot; EXCLUDE=SCHEMA:&quot;LIKE &apos;%SYS%&apos;&quot; dumpfile=oratest.dmp Estimate in progress using BLOCKS method...Processing object type DATABASE_EXPORT/SCHEMA/TABLE/TABLE_DATATotal estimation using BLOCKS method: 32 MBProcessing object type DATABASE_EXPORT/TABLESPACEProcessing object type DATABASE_EXPORT/SYS_USER/USERProcessing object type DATABASE_EXPORT/SCHEMA/USERProcessing object type DATABASE_EXPORT/ROLEProcessing object type DATABASE_EXPORT/GRANT/SYSTEM_GRANT/PROC_SYSTEM_GRANTProcessing object type DATABASE_EXPORT/SCHEMA/GRANT/SYSTEM_GRANTProcessing object type DATABASE_EXPORT/SCHEMA/ROLE_GRANTProcessing object type DATABASE_EXPORT/SCHEMA/DEFAULT_ROLEProcessing object type DATABASE_EXPORT/SCHEMA/TABLESPACE_QUOTAProcessing object type DATABASE_EXPORT/RESOURCE_COSTProcessing object type DATABASE_EXPORT/TRUSTED_DB_LINKProcessing object type DATABASE_EXPORT/DIRECTORY/DIRECTORYProcessing object type DATABASE_EXPORT/DIRECTORY/GRANT/OWNER_GRANT/OBJECT_GRANTProcessing object type DATABASE_EXPORT/CONTEXTProcessing object type DATABASE_EXPORT/SYSTEM_PROCOBJACT/PRE_SYSTEM_ACTIONS/PROCACT_SYSTEMProcessing object type DATABASE_EXPORT/SYSTEM_PROCOBJACT/POST_SYSTEM_ACTIONS/PROCACT_SYSTEMProcessing object type DATABASE_EXPORT/SCHEMA/PROCACT_SCHEMAProcessing object type DATABASE_EXPORT/SCHEMA/TABLE/TABLEProcessing object type DATABASE_EXPORT/SCHEMA/POST_SCHEMA/PROCACT_SCHEMA. . exported &quot;FUNG&quot;.&quot;OBJECT&quot; 26.63 MB 315008 rowsMaster table &quot;SYSTEM&quot;.&quot;SYS_EXPORT_FULL_01&quot; successfully loaded/unloaded******************************************************************************Dump file set for SYSTEM.SYS_EXPORT_FULL_01 is: /oracle/expdir/oratest.dmpJob &quot;SYSTEM&quot;.&quot;SYS_EXPORT_FULL_01&quot; successfully completed at 18:12:45 2.2 NETWORK_LINK由于data pump是基于server端的，因此，所有的导入导出都是存储在server上。如果需要将远程数据库dump到本地来，必须要使用network_link参数。使用network_link要先创建dblink。12345678SQL&gt; create public database link &quot;orcl&quot; 2 connect to system 3 identified by &quot;oracle&quot; 4 using &apos;orcl&apos;;Database link created.[oracle@:/home/oracle]$ expdp system/oracle directory=expdir network_link=orcl dumpfile=netdmp.dmp[oracle@:/home/oracle]$ impdp system/oracle directory=expdir schemas=fung network_link=orcl remap_schema=fung:kong 注意，使用network_link导入的时候，可以不产生dump文件，而直接导入目标数据库。 3. Miscellaneous 3.1 基于scn或者timestamp导入导出1234567891011121314151617181920212223#查询scn或者timestampSQL&gt; SELECT current_scn FROM v$database;CURRENT_SCN----------- 256822SQL&gt; SELECT DBMS_FLASHBACK.get_system_change_number FROM dual;GET_SYSTEM_CHANGE_NUMBER------------------------ 256824SQL&gt; SELECT TIMESTAMP_TO_SCN(SYSTIMESTAMP) FROM dual;TIMESTAMP_TO_SCN(SYSTIMESTAMP)------------------------------ 2SQL&gt; SELECT SCN_TO_TIMESTAMP(256826) FROM dual;SCN_TO_TIMESTAMP(256826)---------------------------------------------------------------------------20-MAY-14 06.56.14.000000000 PM 过段时间，删除某些行。执行导出。1234567891011121314151617181920SQL&gt; delete fung.object where rownum=1;1 row deleted.SQL&gt; commit;Commit complete.SQL&gt; select count(*) from object; COUNT(*)---------- 315007SQL&gt; SELECT TIMESTAMP_TO_SCN(SYSTIMESTAMP) FROM dual;TIMESTAMP_TO_SCN(SYSTIMESTAMP)------------------------------ 260057[oracle@:/oracle/expdir]$ expdp system/oracle full=y directory=expdir dumpfile=full.emp flashback_scn=256826 删除表，执行导入，发现数据回复到表删除一行前的状态。1234567891011121314151617181920212223242526272829SQL&gt; drop table fung.object;Table dropped.[oracle@:/oracle/expdir]$ impdp system/oracle directory=expdir dumpfile=full.emp schemas=fungImport: Release 10.2.0.1.0 - 64bit Production on Tuesday, 20 May, 2014 19:13:20Copyright (c) 2003, 2005, Oracle. All rights reserved.Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.1.0 - 64bit ProductionWith the Partitioning, OLAP and Data Mining optionsMaster table &quot;SYSTEM&quot;.&quot;SYS_IMPORT_SCHEMA_01&quot; successfully loaded/unloadedStarting &quot;SYSTEM&quot;.&quot;SYS_IMPORT_SCHEMA_01&quot;: system/******** directory=expdir dumpfile=full.emp schemas=fung Processing object type DATABASE_EXPORT/SCHEMA/USERORA-31684: Object type USER:&quot;FUNG&quot; already existsProcessing object type DATABASE_EXPORT/SCHEMA/GRANT/SYSTEM_GRANTProcessing object type DATABASE_EXPORT/SCHEMA/ROLE_GRANTProcessing object type DATABASE_EXPORT/SCHEMA/DEFAULT_ROLEProcessing object type DATABASE_EXPORT/SCHEMA/TABLESPACE_QUOTAProcessing object type DATABASE_EXPORT/SCHEMA/PROCACT_SCHEMAProcessing object type DATABASE_EXPORT/SCHEMA/TABLE/TABLEProcessing object type DATABASE_EXPORT/SCHEMA/TABLE/TABLE_DATA. . imported &quot;FUNG&quot;.&quot;OBJECT&quot; 26.63 MB 315008 rowsJob &quot;SYSTEM&quot;.&quot;SYS_IMPORT_SCHEMA_01&quot; completed with 1 error(s) at 19:13:25SQL&gt; select count(*) from fung.object; COUNT(*)---------- 315008 3.2 dump file中导出DDL语句对于任意一个dump文件，impdp中，可用sqlfile将dump文件中的DDL语句单独导出到一个文本文件中。sqlfile参数是取代了imp中的indexfile参数。1impdp system/oracle schemas=fung directory=expdir sqlfile=fung.sql dumpfile=fung.dmp 3.3 query用法123456expdp hr tables=mytest dumpfile=mytest.dmp logfile=mytest.log query=mytest:\\&quot;where rownum \\&lt; 5\\&quot;expdp hr tables=mytest dumpfile=mytest.dmp logfile=mytest.log query=\\&quot;where inc_datetime \\&lt;= to_date\\(\\&apos;2019/01/02\\&apos;,\\&apos;yyyy/mm/dd\\&apos;\\)\\&quot;-- 多表expdp hr tables=mytest,mytest2 dumpfile=mytest.dmp logfile=mytest.log query=mytest:\\&quot;where inc_datetime \\&lt;= to_date\\(\\&apos;2019/01/02\\&apos;,\\&apos;yyyy/mm/dd\\&apos;\\)\\&quot;, mytest2:\\&quot;where rownum = 5\\&quot; 4. wrap-up 不同版本导入导出，需遵循一个原则：低版本导出，高版本导入。 在10.2.0.1版本中，不支持network_link导入导出11g，跟compatible参数有关，带确认。 全库导出/导入时，由于可能存在目标端数据库文件存储跟源端不一致，因此有可能导致表空间无法创建，对象无法创建的现象。在做全库导出时，排除掉系统用户，这样可以降低EM出错的概率，全库导入时，先创建表空间，再指定业务用户导入。 data pump支持后台运行，如果导入导出过程中，不小心按掉ctrl+c，可以执行expdp status查看状态，并且删除job。 expdp脚本12345678910#!/bin/shexport HOME=/home/oracle. $HOME/.profileexport DATE=`date '+%Y%m%d%H%M'`export DMPFILE=$ORACLE_SID`date '+%Y%m%d%H%M'`_%U.dmpexport LOGFILE=$ORACLE_SID`date '+%Y%m%d%H%M'`.logexport EXPDIR=expdirexpdp system/oracle@linora schemas=fung,summer filesize=8192M \\directory=$EXPDIR dumpfile=$DMPFILE logfile=$LOGFILE parallel=2exit 0 5.补充data pump参数文件使用1234567SCHEMAS=HRDUMPFILE=expinclude.dmpDIRECTORY=dpump_dir1LOGFILE=expinclude.logINCLUDE=TABLE:&quot;IN (&apos;EMPLOYEES&apos;, &apos;DEPARTMENTS&apos;)&quot;INCLUDE=PROCEDUREINCLUDE=INDEX:&quot;LIKE &apos;EMP%&apos;&quot; 以上为名为hr.par的参数文件，以下为用法1expdp hr/hr parfile=hr.par 6. Finding out status of expdp/impdp DBA_DATAPUMP_JOBS 1234567select owner_name, job_name, operation, job_modefrom dba_datapump_jobswhere state='EXECUTING' ;OWNER_NAME JOB_NAME OPERATION JOB_MODE---------- ------------------ --------- --------SYSTEM SYS_IMPORT_FULL_01 IMPORT FULL DBA_DATAPUMP_SESSIONS 12345678910select owner_name, job_name, session_typefrom dba_datapump_sessions;select v.status, v.sid,v.serial#,io.block_changes,eventfrom v$sess_io io, v$session vwhere io.sid = v.sidand v.saddr in ( select saddr from dba_datapump_sessions) order by sid; Wait event for datapump 12345678select s.sid, s.module, s.state, substr(s.event, 1, 21) as event, s.seconds_in_wait as secs, substr(sql.sql_text, 1, 30) as sql_textfrom v$session sjoin v$sql sql on sql.sql_id = s.sql_idwhere s.module like 'Data Pump%'order by s.module, s.sid; Reference:https://docs.oracle.com/cd/B19306_01/server.102/b14215/dp_export.htm#i1007837 EOF","link":"/oracle-data-pump.html"},{"title":"Oracle Errorstack","text":"Error stack经常用于一些错误排除和debug，它可用来追踪当前进程的状态，以确定问题根源所在。 1. Error stack级别Error stack包含四种级别，解释分别如下: level description 0 Error stack only 1 Error stack and function call stack 2 As level 1 + process state 3 As level 2 + context area 2. 追踪方法Error stack可以在session级别和system级别进行追踪，同时还可以在spfile或者pfile中写入以下内容进行追踪：1event=&apos;1401 trace name errorstack, level 3&apos; 2.1 使用SQLPLUS追踪123456789101112131415161718SYS@linora&gt; create tablespace test datafile &apos;/oradata/datafile/linora/test01.dbf&apos; size 1024K autoextend off; --启动Error stack跟踪FUNG@linora&gt; alter session set events &apos;1652 trace name errorstack level 3&apos;;Session altered.--模拟1652事件FUNG@linora&gt; create table error_stack tablespace test as select * from dba_objects;create table error_stack tablespace test as select * from dba_objects*ERROR at line 1:ORA-01652: unable to extend temp segment by 8 in tablespace TEST--关闭跟踪FUNG@linora&gt; alter session set events=&apos;1652 trace name errorstack off&apos;;Session altered.FUNG@linora&gt; @traceVALUE--------------------------------------------------------------------------------/u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_2430.trc 2.2 使用oradebug追踪oradebug使用需要sysdba的权限，对于Error stack的用法如下：123456789101112131415--设置追踪session为本sessionSYS@linora&gt; oradebug setmypidStatement processed.SYS@linora&gt; oradebug event 942 trace name errorstack level 3;Statement processed.SYS@linora&gt; select * from t;select * from t *ERROR at line 1:ORA-00942: table or view does not existSYS@linora&gt; oradebug event 942 trace name errorstack off;Statement processed.SYS@linora&gt; oradebug tracefile_name/u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_2523.trc 其他session追踪：12345678910111213141516171819--找出需要追踪的sessionSYS@linora&gt; SELECT a.sid,b.spid,a.username 2 FROM v$session a,v$process b 3 WHERE a.TYPE != &apos;BACKGROUND&apos; and a.paddr=b.addr; SID SPID USERNAME---------- ---------- -------- 263 2652 256 2654 18 2583 SYS 257 2632 FUNG--以spid为例，如果是sid，则oradebug setorapid 257SYS@linora&gt; oradebug setospid 2632Oracle pid: 33, Unix process pid: 2632, image: oracle@linora (TNS V1-V3)SYS@linora&gt; oradebug event 942 trace name errorstack level 3;Statement processed.SYS@linora&gt; oradebug event 942 trace name errorstack off;Statement processed.SYS@linora&gt; oradebug tracefile_name/u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_2632.trc","link":"/oracle-errorstack.html"},{"title":"使用直方图(Histograms)","text":"1.何谓直方图 在分析表或索引时，直方图用于记录数据的分布。通过获得该信息，基于成本的优化器就可以决定使用将返回少量行的索引，而避免使用基于限制条件返回许多行的索引。直方图的使用不受索引的限制，可以在表的任何列上构建直方图。 构造直方图最主要的原因就是帮助优化器在表中数据严重偏斜时做出更好的规划：例如，如果一到两个值构成了表中的大部分数据(数据偏斜)，相关的索引就可能无法帮助减少满足查询所需的I/O数量。创建直方图可以让基于成本的优化器知道何时使用索引才最合适，或何时应该根据WHERE子句中的值返回表中80％的记录。 2.何时使用直方图 通常情况下在以下场合中建议使用直方图： 当Where子句引用了列值分布存在明显偏差的列时：当这种偏差相当明显时，以至于 WHERE 子句中的值将会使优化器选择不同的执行计划。这时应该使用直方图来帮助优化器来修正执行路径。（注意：如果查询不引用该列，则创建直方图没有意义。这种错误很常见，许多 DBA 会在偏差列上创建柱状图，即使没有任何查询引用该列。） 当列值导致不正确的判断时：这种情况通常会发生在多表连接时，例如，假设我们有一个五项的表联接，其结果集只有 10 行。Oracle 将会以一种使第一个联接的结果集（集合基数）尽可能小的方式将表联接起来。通过在中间结果集中携带更少的负载，查询将会运行得更快。为了使中间结果最小化，优化器尝试在 SQL 执行的分析阶段评估每个结果集的集合基数。在偏差的列上拥有直方图将会极大地帮助优化器作出正确的决策。如优化器对中间结果集的大小作出不正确的判断，它可能会选择一种未达到最优化的表联接方法。因此向该列添加直方图经常会向优化器提供使用最佳联接方法所需的信息。 3.直方图种类 Oracle利用直方图来提高非均匀数据分布的选择率和技术的计算精度。 但是实际上Oracle会采用另种不同的策略来生成直方图：其中一种是针对包含很少不同值的数据集；另一种是针对包含很多不同的数据集。 Oracle会针对第一种情况生成频率直方图，针对第二种情况生成高度均衡直方图。 通常情况下当BUCTET < 表的NUM_DISTINCT值得到的是HEIGHT BALANCED（高度平衡）直方图，而当BUCTET > 表的NUM_DISTINCT值的时候得到的是FREQUENCY（频率）直方图。 4.如何产生直方图 当产生直方图时，指定一个大小，此大小跟BUCKET的数量有关。每一个BUCKET包含了关于栏位值信息及行数。 1EXECUTE DBMS_STATS.GATHER_TABLE_STATS(&apos;scott&apos;,&apos;company&apos;,METHOD_OPT =&gt;&apos;FOR COLUMNS SIZE 10 company_code&apos;); The preceding query will create a ten-bucket histogram on the COMPANY table, as shown in Figure 2-2. The values for the COMPANY_CODE column will be divided into the ten buckets as displayed in the figure. This example shows a large number (80 percent) of the company_code is equal to 1430. As is also shown in the figure, most of the width-balanced buckets contain only 3 rows; a single bucket contains 73 rows. In the height-balanced version of this distribution, each bucket has the same number of rows and most of the bucket endpoints are '1430', reflecting the skewed distribution of the data. 5.实验 5.1.1创建实验表 1234567891011SQL&gt;createtableobj asselect* from dba_objects;SQL&gt;createindexobj_id_idx on obj(object_id)onlinenologging;SQL&gt;SELECTMAX(object_id),MIN(object_id)FROMobj;MAX(OBJECT_ID) MIN(OBJECT_ID)————– ————–58410 2–制造不均匀数据分布SQL&gt; UPDATE obj SET object_id =1000 WHERE object_id &gt;100ANDobject_id &lt;54000;SQL&gt;commit; 5.1.2创建直方图 123456789BEGIN DBMS_STATS.gather_table_stats(cascade =&gt;TRUE, degree =&gt;2, estimate_percent =&gt;100, force =&gt;TRUE, ownname =&gt;&apos;FUNG&apos;, tabname =&gt;&apos;OBJ&apos;);END;/ 在gather_table_stats方法中，默认的method_opt值为：FOR ALL COLUMNS SIZE AUTO，所以也是会收集直方图的统计信息（和oracle版本相关），其中degree 指定了并行度视主机的CPU 个数而定，estimate_percent 指定了采样比率， auto 目的是让oracle 来决定采样收集的比率，绘制直方图时会根据采样的数据分析结果来绘制，当然也可以人为指定采样比率。如： estimate_percent=>20 指定采样比率为20%，cascade=>true 指定收集相关表的索引的统计信息，该参数默认为false，因此 使用dbms_stats 收集统计信息时默认是不收集表的索引信息的。 –注意：ENDPOINT_NUMBER ，ENDPOINT_VALUE 的分布情况 123SQL&gt;SELECT * FROM user_histograms WHERE table_name =&apos;OBJ&apos;ANDcolumn_name =&apos;OBJECT_ID&apos;; 1234SQL&gt;SELECTCOLUMN_NAME,HISTOGRAM FROMUSER_TAB_COLS WHERE TABLE_NAME=&apos;OBJ&apos; AND column_name=&apos;OBJECT_ID&apos;;COLUMN_NAME HISTOGRAM——————– ——————————OBJECT_ID HEIGHT BALANCED 5.1.3直方图执行计划 SQL>selectobject_name from obj whereobject_id=100; CBO选择index range scan。 SQL>selectobject_name from obj whereobject_id=1000; 通过直方图统计信息，Oracle知道object_id为1000的值大概占了数据量总量的80%以上，于是选择了全表扫描。 5.1.4删除直方图执行计划 123456789101112BEGIN DBMS_STATS.gather_table_stats( cascade =&gt;TRUE, degree =&gt;2, estimate_percent =&gt;100, force =&gt;TRUE, ownname =&gt;&apos;FUNG&apos;, tabname =&gt;&apos;OBJ&apos;, method_opt =&gt;&apos;FOR ALL COLUMNS SIZE 1&apos; );END;/ 删除直方图，设置method_opt：FOR ALL COLUMNS SIZE 1即可 检查结果 12345SQL&gt;SELECTCOLUMN_NAME,HISTOGRAM FROMUSER_TAB_COLS WHERE TABLE_NAME=&apos;OBJ&apos;ANDcolumn_name=&apos;OBJECT_ID&apos;;COLUMN_NAME HISTOGRAM——————– ——————————OBJECT_ID NONE直方图信息已经被删除 仍然是index range scan，正确的。接下来看id=1000的执行计划： 很明显，这次要全表扫描，结果Oracle仍然傻傻的使用索引扫描。","link":"/oracle-histograms.html"},{"title":"Oracle 10g Silent Installation On Redhat Linux","text":"1. Oracle安装文件中有自带的response file，可以直接修改拿来使用。 也可以使用以下命令录制response file并且以OUI方式正常安装，记录下的response file可以在未来安装中使用，可以在最后一步取消安装，这样就只会记录response file。可使用./runInstaller -help查看OUI的所有可选参数 ./runInstaller -record -destinationFile /tmp/10gR2.rsp 2. 以response file静默安装数据库软件 ./runInstaller -silent -responseFile /tmp/10gR2.rsp INSTALL_TYPE的描述： #------------------------------------------------------------------------------ #Name : INSTALL_TYPE #Datatype : String #Description: Installation type of the component. # # The following choices are available. The value should contain # only one of these choices. # EE : Enterprise Edition # SE : Standard Edition # Custom : Custom #Example : INSTALL_TYPE = \"EE\" #------------------------------------------------------------------------------ # Name : n_configurationOption # Datatype : Number # Description: Determines the type of configuration to perform for the session. # # This entry should be specified as an number. The valid values # that you can use map to the following options: # 1 - Create a Database # 2 - Configure an ASM instance # 3 - Install Software Only # # Example : n_configurationOption=1 部分执行结果，最后以root用户执行 $ORACLE_BASE/oraInventory/orainstRoot.sh，$ORACLE_HOME/root.sh ----------------------------------------------------------------------------- Installation in progress (Mon Aug 19 16:48:08 CST 2013) ............................................................... 14% Done. ............................................................... 28% Done. ............................................................... 42% Done. ............................................................... 56% Done. ............................................................... 70% Done. ................ 74% Done. Install successful Linking in progress (Mon Aug 19 16:55:10 CST 2013) . 74% Done. Link successful Setup in progress (Mon Aug 19 17:00:30 CST 2013) .................. 100% Done. Setup successful End of install phases.(Mon Aug 19 17:00:42 CST 2013) WARNING:The following configuration scripts /u01/oracle/product/10gr2/root.sh need to be executed as root for configuring the system. If you skip the execution of the configuration tools, the configuration will not be complete and the product wont function properly. In order to get the product to function properly, you will be required to execute the scripts and the configuration tools after exiting the OUI. The installation of Oracle Database 10g was successful. Please check '/opt/oraInventory/logs/silentInstall2013-08-19_04-47-30PM.log' for more details. 3. 安装10.2.0.4补丁程序 修改./Disk1/response/patch.rsp，主要修改以下几个地方： UNIX_GROUP_NAME=\"oinstall\" FROM_LOCATION=\"/u01/10g/Disk1/stage/products.xml\" ORACLE_HOME_NAME=\"OraDb10g_home1\" ORACLE_HOME=\"/u01/oracle/product/10gr2\" 安装完成同样需执行$ORACLE_HOME/root.sh [ora10g@db12c:/home/ora10g]$ sqlplus \"/as sysdba\" SQL*Plus: Release 10.2.0.4.0 - Production on Mon Aug 19 17:36:57 2013 Copyright (c) 1982, 2007, Oracle. All Rights Reserved. Connected to an idle instance. 4. 自定义数据库静默安装 a) 利用OUI图形界面创建create database的template b) 选择custom database c) 其他按照需求自定义 d) 最后一步取消create database选项，改为选择create template e) 创建后模版文件位置：$ORACLE_HOME/assistants/dbca/templates 5. 修改安装文件内response文件dbca.rsp，主要修改GDBNAME、SID及TEMPLATENAME三个选项。如果需要使用Oracle Enterprise Manager，则还需要修改以下参数如下： 123EMCONFIGURATION=&quot;LOCAL&quot; SYSMANPASSWORD=&quot;password&quot; DBSNMPPASSWORD=&quot;password&quot; 6. 执行以下命令静默创建数据库 [ora10g@db12c:/home/ora10g]$ dbca -silent -createdatabase -responseFile ./dbca.rsp Creating and starting Oracle instance 1% complete 2% complete 5% complete Creating database files 6% complete 11% complete Creating data dictionary views 12% complete 14% complete 16% complete 17% complete 18% complete 19% complete 20% complete 23% complete 25% complete 26% complete 27% complete 28% complete Adding Oracle JVM 29% complete 37% complete 46% complete 54% complete 56% complete Adding Oracle XML DB 58% complete 59% complete 60% complete 61% complete 66% complete 67% complete Adding Oracle Intermedia 69% complete 84% complete Completing Database Creation 85% complete 87% complete 89% complete 94% complete 99% complete 100% complete Look at the log file \"/u01/oracle/product/10gr2/cfgtoollogs/dbca/ora10g/ora10g.log\" for further details. 7. 以文本模式编辑listener.ora 8. 验证数据库 1234567891011121314151617181920212223242526272829303132333435[ora10g@db12c:/home/ora10g]$ sqlplus &quot;/as sysdba&quot; SQL*Plus: Release 10.2.0.4.0 - Production on Fri Aug 23 12:05:48 2013 Copyright (c) 1982, 2007, Oracle. All Rights Reserved. Connected to: Oracle Database 10g Enterprise Edition Release 10.2.0.4.0 - 64bit Production With the Partitioning, OLAP, Data Mining and Real Application Testing options SQL&gt; col file_name for a50 SQL&gt; col tablespace_name for a30 SQL&gt; set linesize 200 SQL&gt; set pagesize 200 SQL&gt; select file_id,file_name,tablespace_name 2 from dba_data_files order by tablespace_name; FILE_ID FILE_NAME TABLESPACE_NAME ---------- -------------------------------------------------- ------------------------------ 3 /oradata/ora10g/sysaux01.dbf SYSAUX 1 /oradata/ora10g/system01.dbf SYSTEM 2 /oradata/ora10g/undotbs01.dbf UNDOTBS1 4 /oradata/ora10g/users01.dbf USERS SQL&gt; select file_id,file_name,tablespace_name from dba_temp_files; FILE_ID FILE_NAME TABLESPACE_NAME ---------- -------------------------------------------------- ------------------------------ 1 /oradata/ora10g/temp01.dbf TEMP SQL&gt; col member for a50 SQL&gt; select * from v$logfile 2 / GROUP# STATUS TYPE MEMBER IS_ ---------- ------- ------- -------------------------------------------------- --- 1 ONLINE /oradata/ora10g/redo01.log NO 2 ONLINE /oradata/ora10g/redo02.log NO 3 ONLINE /oradata/ora10g/redo03.log NO","link":"/oracle-silent-install.html"},{"title":"oracle TAF","text":"1.TAF简介 Transparent application failover，即对应用透明的故障切换，是Oracle8i以后推出的基于客户端的HA应用。在RAC环境中，如果实例挂了一个，应用可以通过TAF配置无缝切换。 在Oracle中，有三种FAILOVER方式，一种是Client-Side Connect time Failover，一种为TAF，一种为Server-Side TAF。 Client-Side如果客户端配置了多个IP，客户端请求连接时，会先尝试地址表中的第一个地址，如果连接失败，则继续尝试第二个地址，以此类推。如果连接过程中某个实例挂掉了，则客户端需要重新连接才能继续操作。启用这种Failover方式是在客户端的tnsnames中添加FAILOVER=ON条目。但默认为开启，即使不添加，也默认为打开状态。 TAF则在客户端tnsnames配置文件中添加TAF参数，具体参数见后续说明。这样的话，在当前连接的实例挂掉的时候，客户端会自动连接到其他可用实例中，而不用重新连接。 这两种配置的tnsnames范例如下： 1234567891011121314151617181920212223242526272829#Client-Side：orcl_test = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.56.125)(PORT = 1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.56.126)(PORT = 1521)) (LOAD_BALANCE = YES) ) (CONNECT_DATA = (SERVICE_NAME = orcl) ) )#TAF：orcl_taf = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.56.125)(PORT = 1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.56.126)(PORT = 1521)) (LOAD_BALANCE = yes) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl) (FAILOVER_MODE = (TYPE = SELECT) (METHOD = BASIC) (RETRIES = 180) (DELAY = 5) ) ) ) 请先看这两种方式的FAILOVER方式，因实验环境配置了Server-Side的TAF，先把对应的TAF Service停止掉： 1234567891011121314151617181920212223[oracle@oel1:/home/oracle]$ srvctl stop service -d orcl -s orcl_taf -i orcl1[oracle@oel1:/home/oracle]$ srvctl stop service -d orcl -s orcl_taf -i orcl2[oracle@oel1:/home/oracle]$ srvctl disable service -d orcl -s orcl_taf -i orcl1[oracle@oel1:/home/oracle]$ srvctl disable service -d orcl -s orcl_taf -i orcl2[oracle@oel1:/home/oracle]$ crs_stat -tName Type Target State Host------------------------------------------------------------ora....SM1.asm application ONLINE ONLINE oel1ora....L1.lsnr application ONLINE ONLINE oel1ora.oel1.gsd application ONLINE ONLINE oel1ora.oel1.ons application ONLINE ONLINE oel1ora.oel1.vip application ONLINE ONLINE oel1ora....SM2.asm application ONLINE ONLINE oel2ora....L2.lsnr application ONLINE ONLINE oel2ora.oel2.gsd application ONLINE ONLINE oel2ora.oel2.ons application ONLINE ONLINE oel2ora.oel2.vip application ONLINE ONLINE oel2ora.orcl.db application ONLINE ONLINE oel1ora....l1.inst application ONLINE ONLINE oel1ora....l2.inst application ONLINE ONLINE oel2ora...._taf.cs application OFFLINE OFFLINEora....cl1.srv application OFFLINE OFFLINEora....cl2.srv application OFFLINE OFFLINE 同时添加上述tns到Clinet端的tnsnames中。开两个窗口，分别通过CS及TAF模式连接，查看连接模式： 1234567891011121314151617181920212223242526[oracle@oel1:/home/oracle]$ sqlplus system/oracle@orcl_test SQL&gt; select username,failover_type,failover_method 2 from v$session where username='SYSTEM'; USERNAME FAILOVER_TYPE FAILOVER_M------------------------------ ------------- ----------SYSTEM NONE NONESQL&gt; select instance_name from v$instance; INSTANCE_NAME----------------orcl2 [oracle@oel1:/home/oracle]$ sqlplus system/oracle@orcl_tafSQL&gt; select username,failover_type,failover_method 2 from v$session where username='SYSTEM'; USERNAME FAILOVER_TYPE FAILOVER_M------------------------------ ------------- ----------SYSTEM SELECT BASICSQL&gt; select instance_name from v$instance; INSTANCE_NAME----------------orcl2 通过服务器端直接kill掉这两个进程： 123456789101112131415161718SQL&gt; select pid,spid from v$process 2 where addr in 3 (select paddr from v$session 4 where username='SYSTEM'); PID SPID---------- ------------ 22 8009 31 6694#两个进程的OS pid分别为8009和6694，调用OS kill命令直接杀死两个进程[oracle@oel2:/home/oracle]$ ps -ef|grep 8009oracle 8009 1 0 16:34 ? 00:00:00 oracleorcl2 (LOCAL=NO)oracle 9583 8707 0 16:38 pts/0 00:00:00 grep 8009[oracle@oel2:/home/oracle]$ ps -ef|grep 6694oracle 6694 1 0 16:30 ? 00:00:00 oracleorcl2 (LOCAL=NO)oracle 9610 8707 0 16:38 pts/0 00:00:00 grep 6694[oracle@oel2:/home/oracle]$ kill -9 8009[oracle@oel2:/home/oracle]$ kill -9 6694 返回窗口，执行SQL： 1234567891011121314151617181920212223#Client-Side配置：SQL&gt; select instance_name from v$instance;select instance_name from v$instance*ERROR at line 1:ORA-03113: end-of-file on communication channel SQL&gt; select instance_name from v$instance;ERROR:ORA-03114: not connected to ORACLE #TAF配置：SQL&gt; select instance_name from v$instance;select instance_name from v$instance*ERROR at line 1:ORA-03113: end-of-file on communication channel SQL&gt; select instance_name from v$instance; INSTANCE_NAME----------------orcl1 第三种Failover配置为Server-Side TAF，这是配置在服务器端的，在这种配置下，客户端可以不用tns就可以使用到TAF的好处。下面以Oracle 10g为例，说明TAF Server-side的配置。 2.配置信息 Server端： 12345678910111213141516171819202122232425262728293031323334353637[oracle@oel1:/u01/app/oracle/product/10.2.0/db_1/network/admin]$ cat tnsnames.ora# tnsnames.ora Network Configuration File: /u01/app/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora# Generated by Oracle configuration tools. RACDB_TAF = (DESCRIPTION = (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.56.125)(PORT = 1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = 192.168.56.126)(PORT = 1521)) (LOAD_BALANCE = yes) (CONNECT_DATA = (SERVER = DEDICATED) (SERVICE_NAME = orcl_taf) (FAILOVER_MODE = (TYPE = SELECT) (METHOD = BASIC) (RETRIES = 180) (DELAY = 5) ) ) ) LISTENERS_ORCL = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = TCP)(HOST = orcl1-vip)(PORT = 1521)) (ADDRESS = (PROTOCOL = TCP)(HOST = orcl2-vip)(PORT = 1521)) ) EXTPROC_CONNECTION_DATA = (DESCRIPTION = (ADDRESS_LIST = (ADDRESS = (PROTOCOL = IPC)(KEY = EXTPROC0)) ) (CONNECT_DATA = (SID = PLSExtProc) (PRESENTATION = RO) ) ) 3.切换测试 查看当前实例信息： 1234567891011121314151617181920212223SQL&gt; COLUMN instance_name FORMAT a13COLUMN host_name FORMAT a9COLUMN failover_method FORMAT a15COLUMN failed_over FORMAT a11SELECT instance_name , host_name , NULL AS failover_type , NULL AS failover_method , NULL AS failed_overFROM v$instanceUNIONSELECT NULL , NULL , failover_type , failover_method , failed_overFROM v$sessionWHERE username = 'SYSTEM';INSTANCE_NAME HOST_NAME FAILOVER_TYPE FAILOVER_METHOD FAILED_OVER------------- --------- ------------- --------------- -----------orcl1 oel1 SELECT BASIC NO 保持上述窗口不变，停止当前实例： 1234567[oracle@oel1:/home/oracle]$ srvctl status database -d orclInstance orcl1 is running on node oel1Instance orcl2 is running on node oel2[oracle@oel1:/home/oracle]$ srvctl stop instance -d orcl -i orcl1 -o abort[oracle@oel1:/home/oracle]$ srvctl status database -d orclInstance orcl1 is not running on node oel1Instance orcl2 is running on node oel2 回到上个SQL窗口，再次查询： 123INSTANCE_NAME HOST_NAME FAILOVER_TYPE FAILOVER_METHOD FAILED_OVER------------- --------- ------------- --------------- -----------orcl2 oel2 SELECT BASIC YES 从v$session中查询的结果可以看到，FAILED_OVER从原来的“NO”变成了”YES”，也就是说，这个会话是经过故障转移重新连接的会话。 4.参数及含义 在上述TNS配置中，在FAILOVER_MODE中有如下几个参数： 参数 描述 BACKUP 指定备用连接所用到的service name，在PRECONNECT模式中，必须要添加此参数。在BASIC模式中，强烈建议添加此参数，会减少因重连失败实例而带来的延时。 TYPE 指定故障切换的类型。OCI默认有三种切换类型。此参数只能通过dbms包修改。 SESSION 只是切换当前会话。即会话不会中断，但是查询语句需要重新执行。 SELECT SELECT模式，用户当前正在执行的SELECT语句会被转移到新的实例上，在新的节点继续返回后续结果。 NONE 表示不会进行任何切换操作，这是默认的模式。 METHOD 此参数决定从主节点到备用节点故障切换的速度。 BASIC 检测到故障时建立连接。 PRECONNECT 预先建立连接，一开始创建会话连接就连接到所有实例，当发生故障时，立刻可以快速切换到其他实例上。 RETRIES 节点故障时，重新尝试连接备用节点的次数。此参数只能通过dbms包修改。 DELAY 节点故障时，重新尝试连接备用节点的时间。此参数只能通过dbms包修改。 &nbsp; 5. 配置步骤 使用dbca配置： 通过dbca设置一个新的service name，称为orcl_taf 在欢迎界面，选择Oracle Real Application Cluster database，选择下一步 选择Service Management，选择下一步 选中需要修改的RAC数据库，选择下一步 点击Add，添加新的service name：orcl_taf 选择PREFERED，点击完成。 添加orcl_taf服务到tnsnames.ora中。 说明：在第五步中，PREFERRED跟AVALIABLE表示首选实例及后备实例。客户端会优先使用首选实例。因srvctl添加服务只会更新OCR信息而不会更新data dictionary及listener信息，还需要调用dbms包去更新信息，因此，建议通过dbca对Service进行更改。 命令行添加，添加另一个名为ORCL_TEST的服务： 首先添加服务 123456789101112131415[oracle@oel1:/home/oracle]$ srvctl add service -hUsage: srvctl add service -d &lt;name&gt; -s &lt;service_name&gt; -r &quot;&lt;preferred_list&gt;&quot; [-a &quot;&lt;available_list&gt;&quot;] [-P &lt;taf_policy&gt;] -d &lt;name&gt; Unique name for the database -s &lt;service&gt; Service name -r &quot;&lt;pref_list&gt;&quot; List of preferred instances -a &quot;&lt;avail_list&gt;&quot; List of available instances -P &lt;taf_policy&gt; TAF policy (NONE, BASIC, or PRECONNECT)Usage: srvctl add service -d &lt;name&gt; -s &lt;service_name&gt; -u &#123;-r &quot;&lt;new_pref_inst&gt;&quot; | -a &quot;&lt;new_avail_inst&gt;&quot;&#125; -d &lt;name&gt; Unique name for the database -s &lt;service&gt; Service name -u Add a new instance to service configuration -r &lt;new_pref_inst&gt; Name of new preferred instance -a &lt;new_avail_inst&gt; Name of new available instance -h Print usage[oracle@oel1:/home/oracle]$ srvctl add service -d orcl -s orcl_test -r orcl1,orcl2 -P BASIC 启动服务 1[oracle@oel1:/home/oracle]$ srvctl start service -d orcl -s orcl_test 执行dbms包，创建service 123456789101112SQL&gt;BeginDbms_service.modify_service(Service_name=&gt;'orcl_test',Failover_method=&gt;dbms_service.failover_method_basic,Failover_type=&gt;dbms_service.failover_type_select,Failover_retries=&gt;180,Failover_delay=&gt;5);End;/PL/SQL procedure successfully completed. 查看配置结果 123456789101112SQL&gt; show parameter name NAME TYPE VALUE------------------------------------ ----------- ------------------------------db_file_name_convert stringdb_name string orcldb_unique_name string orclglobal_names boolean FALSEinstance_name string orcl1lock_name_space stringlog_file_name_convert stringservice_names string orcl_taf, orcl, orcl_test 查看监听服务信息 123456789101112131415[oracle@oel1:/home/oracle]$ lsnrctl serviceService &quot;orcl_test&quot; has 2 instance(s). Instance &quot;orcl1&quot;, status READY, has 2 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready REMOTE SERVER (ADDRESS=(PROTOCOL=TCP)(HOST=oel1)(PORT=1521)) &quot;DEDICATED&quot; established:0 refused:0 state:ready LOCAL SERVER Instance &quot;orcl2&quot;, status READY, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready REMOTE SERVER (ADDRESS=(PROTOCOL=TCP)(HOST=oel2)(PORT=1521))The command completed successfully 6.总结 在Oracle 11g中，增加了SCAN-IP，即如果在Oracle中配置了DNS的SCAN的话，可以直接通过DNS进行负载均衡和故障切换，而大部分用户都是没有使用DNS的SCAN的，而是使用HOSTS文件进行解析。在11g RAC中，dbca已经没有service Management选项了，因此，要添加类似10g的Server-side的taf必须通过命令行去添加。 补充：删除服务 停止服务 1[oracle@oel1:/home/oracle]$ srvctl stop service -d orcl -s orcl_test 删除服务 123[oracle@oel1:/home/oracle]$ srvctl remove service -d orcl -s orcl_testorcl_test PREF: orcl1 orcl2 AVAIL:Remove service orcl_test from the database orcl? (y/[n]) y 查看数据字典内容 123456789SQL&gt; select name,failover_method,failover_type,goal,clb_goal from dba_services; NAME FAILOVER_METHOD FAILOVER_TYPE GOAL CLB_G--------------- -------------------- -------------------- ------------ -----SYS$BACKGROUND NONE SHORTSYS$USERS NONE SHORTorcl LONGorcl_taf NONE LONGorcl_test BASIC SELECT NONE LONG 删除数据字典内容 12345678910111213SQL&gt; begindbms_service.delete_service(service_name=&gt;'orcl_test');end;/PL/SQL procedure successfully completed.SQL&gt; select name,failover_method,failover_type,goal,clb_goal from dba_services; NAME FAILOVER_METHOD FAILOVER_TYPE GOAL CLB_G--------------- -------------------- -------------------- ------------ -----SYS$BACKGROUND NONE SHORTSYS$USERS NONE SHORTorcl LONGorcl_taf NONE LONG How To Configure Server Side Transparent Application Failover [ID 460982.1]","link":"/oracle-taf.html"},{"title":"Oracle追踪SQL的方法","text":"Oracle提供了几种方法可以使得DBA针对某些session或者语句进行trace跟踪。从9i开始，官方文档开始记载了如何激活SQL追踪的方法，初始化参数SQL_TRACE,dbms_session.set_sql_trace和dbms_system.set_sql_trace_in_session。然而，这三种方法都只能追踪到10046事件的1级别，10046级别如下图所示（不完全，11g有新增10046级别）： Table 1-1 10046 event level level description 0 禁止trace 1 激活trace，提供SQL语句，响应时间，服务时间，处理行数，逻辑读，物理读写，执行计划及额外的一些信息 4 包括1级别，同时提供绑定变量信息 8 包括1级别，同时提供等待事件信息：等待事件名字、持续时间等 12 同时启动4和8 由于官方文档提及的三种追踪方法都无法更详细的信息，因此，有如下几种方式可提供对SQL或者其他事件的追踪。 1. event事件对SQL的追踪主要有10046及10053事件，这两个事件都是不公开的，解析分别如下(10053仅有两个级别，一般会使用level 1，属于最高级别)：12345678[oracle@linora:/home/oracle]$ oerr ora 1004610046, 00000, &quot;enable SQL statement timing&quot;// *Cause:// *Action:[oracle@linora:/home/oracle]$ oerr ora 1005310053, 00000, &quot;CBO Enable optimizer trace&quot;// *Cause:// *Action: 10046显示SQL执行计划如何运行， 10053显示优化器为何选择这个执行计划。通过设置Event对SQL进行追踪，可以有两种方法，一种是alter session/alter system方法，或者使用oradebug工具。 1.1 alter session/alter system12345--开启session级别事件追踪alter session set events &apos;10046 trace name context forever,level 12&apos;;alter session set events &apos;10053 trace name context forever,level 1&apos;;--关闭事件ALTER SESSION SET EVENTS &apos;10053 trace name context off&apos;; 查找trace文件：12345678910111213141516171819#for 11gSELECT s.sql_trace, s.sql_trace_waits, s.sql_trace_binds,traceid, tracefileFROM v$session s JOIN v$process p ON (p.addr = s.paddr)WHERE audsid = USERENV (&apos;SESSIONID&apos;);#for 10gSELECT s.sid, s.serial#, pa.VALUE || &apos;/&apos; || LOWER (SYS_CONTEXT (&apos;userenv&apos;, &apos;instance_name&apos;)) || &apos;_ora_&apos; || p.spid || &apos;.trc&apos; AS trace_file FROM v$session s, v$process p, v$parameter pa WHERE pa.name = &apos;user_dump_dest&apos; AND s.paddr = p.addr AND s.audsid = SYS_CONTEXT (&apos;USERENV&apos;, &apos;SESSIONID&apos;); 1.2 oradebug#####oradebug追踪本sessionoradebug的用法可用oradebug help查看，关于oradebug其他功能，本文暂不予讨论。123456789SYS@linora&gt; oradebug setmypidStatement processed.SYS@linora&gt; oradebug event 10053 trace name context forever,level 1; Statement processed.SYS@linora&gt; oradebug event 10053 trace name context offStatement processed.SYS@linora&gt; oradebug tracefile_name/u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_2293.trcSYS@linora&gt; oradebug CLOSE_TRACE #####oradebug追踪其他session如果是OS系统进程ID，可使用oradebug setospid spid 。如果是Oracle ID可使用oradebug setorapid pid 进行追踪。SPID(system process id),表示該server process在OS层面的Porcess ID 即操作系统进程ID,PID(Oracle process id) 可以理解为Oracle自己用的，Oracle进程ID,SID(SESSION)标识，常用于连接其它列。首先通过v$session和v$process查找相关的pid或者spid：1234567891011SYS@linora&gt; SELECT a.sid,a.serial#,b.spid,a.username,a.machine,a.OSUSER,a.PROGRAMFROM v$session a,v$process bWHERE a.TYPE != &apos;BACKGROUND&apos; and a.paddr=b.addr; SID SERIAL# SPID USERNAME MACHINE OSUSER PROGRAM---------- ---------- ---------- ---------- -------------------- --------------- ------------------------------------------------ 26 37 2552 FUNG linora oracle sqlplus@linora (TNS V1-V3) 147 195 3316 SYS linora oracle sqlplus@linora (TNS V1-V3) 144 179 3318 linora oracle oracle@linora (J000) 20 101 3192 FUNG WORKGROUP\\PC0920 Administrator sqlplus.exe 22 23 3320 linora oracle oracle@linora (J001) 比如，要对sid=20,serial#=101,spid=3192的进程进行跟踪1234567891011SYS@linora&gt; oradebug setospid 3192Oracle pid: 30, Unix process pid: 3192, image: oracle@linora#或者oradebug setorapid 20SYS@linora&gt; oradebug event 10046 trace name context forever,level 12; Statement processed.SYS@linora&gt; oradebug event 10046 trace name context offStatement processed.SYS@linora&gt; oradebug tracefile_name/u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_3192.trcSYS@linora&gt; oradebug CLOSE_TRACEStatement processed. 2. dbms_system.set_ev这个procedure是为10g以前提供的，在我的环境下怎么也找不到生成的trace file，以下语句使用dbms包开启SQL追踪（默认sys用户执行）：12SYS@linora&gt; EXEC DBMS_SYSTEM.set_ev(si=&gt;20, se=&gt;101, ev=&gt;10046, le=&gt;12, nm=&gt;&apos; &apos;);PL/SQL procedure successfully completed. 关闭只需要将le改为0即可：12SYS@linora&gt; EXEC DBMS_SYSTEM.set_ev(si=&gt;20, se=&gt;101, ev=&gt;10046, le=&gt;0, nm=&gt;&apos; &apos;);PL/SQL procedure successfully completed. 这个包对应的解析如下：12345si binary_integer, -- SIDse binary_integer, -- Serial#ev binary_integer, -- Event code or number to set.le binary_integer, -- Usually level to tracenm varchar2 -- sets the Event Name. null = &quot;context forever&quot;. 3. dbms_monitor10g提供了一个新的包dbms_monitor可以用来启停SQL的追踪。使用这个包，不只是最终有一个官方的方式来全面利用SQL追踪，而且能够根据会话属性—客户端标记、服务名、模块名及操作名，开启或者关闭SQL追踪。默认情况下，只有DBA角色才运行执行这个包提供的过程。会话级别dbms_monitor分别提供了session_trace_enable和session_trace_disable两个存储过程。在10gR2中，当用session_trace_enbale开启追踪的时候，v$session视图的列sql_trace, sql_trace_waits, sql_trace_binds也会被设定跟上述存储过程相应的值。12345678SYS@linora&gt; exec dbms_monitor.session_trace_enable(session_id =&gt; 20, serial_num =&gt; 101, waits =&gt; TRUE, binds =&gt; TRUE);PL/SQL procedure successfully completed.SYS@linora&gt; SELECT sql_trace, sql_trace_waits, sql_trace_binds 2 FROM v$session 3 WHERE sid = 20;SQL_TRAC SQL_T SQL_T-------- ----- -----ENABLED TRUE TRUE 停止trace：12345678SYS@linora&gt; exec dbms_monitor.session_trace_disable(session_id =&gt; 20, serial_num =&gt; 101);PL/SQL procedure successfully completed.SYS@linora&gt; SELECT sql_trace, sql_trace_waits, sql_trace_binds 2 FROM v$session 3 WHERE sid = 20;SQL_TRAC SQL_T SQL_T-------- ----- -----DISABLED FALSE FALSE 4. tkproftkprof是格式化trace文件的一个工具，裸trace文件，读起来会有点困难，Oracle提供tkprof工具进行更为友好的阅读trace文件.此工具用法比较简单，在无其他参数的情况下，直接敲tkprof会得到简略的使用说明。注意，tkprof仅仅是作为对SQL跟踪的一种格式化工具，像10053或者其他错误信息导致的trace文件，tkprof是读取不了其中的信息的。12345678910SCOTT@linora&gt; alter session set events &apos;10046 trace name context forever,level 12&apos;;Session altered.SCOTT@linora&gt; select ename,job,sal,dname 2 from emp,dept where dept.deptno = emp.deptno and not exists 3 (select * from salgrade where emp.sal between losal and hisal);no rows selectedSCOTT@linora&gt; ALTER SESSION SET EVENTS &apos;10046 trace name context off&apos;;Session altered.[oracle@linora:/home/oracle]$ tkprof /u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_3899.trc \\10046.txt waits=yes aggregate=yes sys=no 有几个参数有必要说明一下： explainexplain=username/password，如果没有使用explain，在trace文件中看到的会是SQL的实际执行路径，如果使用了explain，则在trace不但输入了实际的执行路径，还会生成该SQL的执行计划。 syssys=yes/no，默认为yes，表示在trace文件中输出sys用户的操作，设置sys=no后，trace文件更具有可读性。 aggregateaggregate=yes/no，默认设置为yes，即将所有相同的SQL在输入文件中合并，如果设置为no，则分别列出每个sql的信息。 waitswaits=yes/no，waits=yes显示等待事件及等待时间信息等。 sortsort=option有大量的排序条件，一般对于查询的调优 常用的组合是 SYS=NO fchela， fchela即按照fetch阶段的elapsed time按照从大到小排列，fchela也是默认的方式。123456789101112131415161718Rows (1st) Rows (avg) Rows (max) Row Source Operation---------- ---------- ---------- --------------------------------------------------- 0 0 0 MERGE JOIN ANTI (cr=15 pr=0 pw=0 time=2769 us cost=11 size=840 card=14) 14 14 14 SORT JOIN (cr=8 pr=0 pw=0 time=1118 us cost=7 size=476 card=14) 14 14 14 MERGE JOIN (cr=8 pr=0 pw=0 time=839 us cost=6 size=476 card=14) 4 4 4 TABLE ACCESS BY INDEX ROWID DEPT (cr=2 pr=0 pw=0 time=323 us cost=2 size=52 card=4) 4 4 4 INDEX FULL SCAN PK_DEPT (cr=1 pr=0 pw=0 time=86 us cost=1 size=0 card=4)(object id 84557) 14 14 14 SORT JOIN (cr=6 pr=0 pw=0 time=430 us cost=4 size=294 card=14) 14 14 14 TABLE ACCESS FULL EMP (cr=6 pr=0 pw=0 time=175 us cost=3 size=294 card=14) 14 14 14 FILTER (cr=7 pr=0 pw=0 time=1420 us) 14 14 14 SORT JOIN (cr=7 pr=0 pw=0 time=699 us cost=4 size=130 card=5) 5 5 5 TABLE ACCESS FULL SALGRADE (cr=7 pr=0 pw=0 time=114 us cost=3 size=130 card=5)Elapsed times include waiting on following events: Event waited on Times Max. Wait Total Waited ---------------------------------------- Waited ---------- ------------ SQL*Net message to client 1 0.00 0.00 以上为实际的执行路径，以下为带执行计划的实际执行路径：123456789101112131415161718192021222324252627282930$ tkprof linora_ora_2392.trc explain_10046.txt sys=no aggregate=yes waits=yes explain=scott/oracleRows (1st) Rows (avg) Rows (max) Row Source Operation---------- ---------- ---------- --------------------------------------------------- 0 0 0 MERGE JOIN ANTI (cr=15 pr=0 pw=0 time=2769 us cost=11 size=840 card=14) 14 14 14 SORT JOIN (cr=8 pr=0 pw=0 time=1118 us cost=7 size=476 card=14) 14 14 14 MERGE JOIN (cr=8 pr=0 pw=0 time=839 us cost=6 size=476 card=14) 4 4 4 TABLE ACCESS BY INDEX ROWID DEPT (cr=2 pr=0 pw=0 time=323 us cost=2 size=52 card=4) 4 4 4 INDEX FULL SCAN PK_DEPT (cr=1 pr=0 pw=0 time=86 us cost=1 size=0 card=4)(object id 84557) 14 14 14 SORT JOIN (cr=6 pr=0 pw=0 time=430 us cost=4 size=294 card=14) 14 14 14 TABLE ACCESS FULL EMP (cr=6 pr=0 pw=0 time=175 us cost=3 size=294 card=14) 14 14 14 FILTER (cr=7 pr=0 pw=0 time=1420 us) 14 14 14 SORT JOIN (cr=7 pr=0 pw=0 time=699 us cost=4 size=130 card=5) 5 5 5 TABLE ACCESS FULL SALGRADE (cr=7 pr=0 pw=0 time=114 us cost=3 size=130 card=5)Rows Execution Plan------- --------------------------------------------------- 0 SELECT STATEMENT MODE: ALL_ROWS 0 NESTED LOOPS 14 NESTED LOOPS 14 MERGE JOIN (ANTI) 4 SORT (JOIN) 4 TABLE ACCESS MODE: ANALYZED (FULL) OF &apos;EMP&apos; (TABLE) 14 FILTER 14 SORT (JOIN) 14 TABLE ACCESS MODE: ANALYZED (FULL) OF &apos;SALGRADE&apos; (TABLE) 14 INDEX MODE: ANALYZED (UNIQUE SCAN) OF &apos;PK_DEPT&apos; (INDEX(UNIQUE)) 5 TABLE ACCESS MODE: ANALYZED (BY INDEX ROWID) OF &apos;DEPT&apos;(TABLE)Elapsed times include waiting on following events: Event waited on Times Max. Wait Total Waited ---------------------------------------- Waited ---------- ------------ SQL*Net message to client 1 0.00 0.00 5. 10046 trace文件阅读#####经过tkprof格式化后的文件：123456789101112131415161718192021222324252627TKPROF: Release 11.2.0.4.0 - Development on Thu Jul 24 23:17:09 2014Copyright (c) 1982, 2011, Oracle and/or its affiliates. All rights reserved.Trace file: linora_ora_2348.trcSort options: default********************************************************************************count = number of times OCI procedure was executedcpu = cpu time in seconds executing elapsed = elapsed time in seconds executingdisk = number of physical reads of buffers from diskquery = number of buffers gotten for consistent readcurrent = number of buffers gotten in current mode (usually for update)rows = number of rows processed by the fetch or execute call********************************************************************************SQL ID: 8gt5ty6pfca35 Plan Hash: 1070587533SELECT /* OPT_DYN_SAMP */ /*+ ALL_ROWS IGNORE_WHERE_CLAUSE NO_PARALLEL(SAMPLESUB) opt_param(&apos;parallel_execution_enabled&apos;, &apos;false&apos;) NO_PARALLEL_INDEX(SAMPLESUB) NO_SQL_TUNE */ NVL(SUM(C1),:&quot;SYS_B_0&quot;), NVL(SUM(C2),:&quot;SYS_B_1&quot;), COUNT(DISTINCT C3), NVL(SUM(CASE WHEN C3 IS NULL THEN :&quot;SYS_B_2&quot; ELSE :&quot;SYS_B_3&quot; END),:&quot;SYS_B_4&quot;), COUNT(DISTINCT C4), NVL(SUM(CASE WHEN C4 IS NULL THEN :&quot;SYS_B_5&quot; ELSE :&quot;SYS_B_6&quot; END), :&quot;SYS_B_7&quot;) FROM (SELECT /*+ NO_PARALLEL(&quot;SALGRADE&quot;) FULL(&quot;SALGRADE&quot;) NO_PARALLEL_INDEX(&quot;SALGRADE&quot;) */ :&quot;SYS_B_8&quot; AS C1, :&quot;SYS_B_9&quot; AS C2, &quot;SALGRADE&quot;.&quot;HISAL&quot; AS C3, &quot;SALGRADE&quot;.&quot;LOSAL&quot; AS C4 FROM &quot;SCOTT&quot;.&quot;SALGRADE&quot; &quot;SALGRADE&quot;) SAMPLESUB 上述信息包含了tkprof版本信息，trace文件名称，以及在一些图表中各个参数的解析。在上例中，我们看到有/* OPT_DYN_SAMP */信息，表示这个语句是CBO在做动态采样的SQL语句，也表明，我们这个SALGRADE表可能没做分析。Misses in library cache during 表示在解析及执行阶段library cache发生了miss，则说明是硬解析。call: 每一个游标的行为被分成三个步骤：Parse：表示SQL的分析阶段所耗资源。Execute：表示SQL的执行阶段所耗资源。Fetch：表示数据提取阶段所耗资源。Count：表示当前的操作被执行了多少次。Cpu：表示当前操作消耗的CPU事件，单位为秒。Elapsed：表示当前操作一共用时多少秒，包括CPU事件跟等待时间。Disk：表示当前操作的物理读，即磁盘IO次数。Query：表示当前操作的一致性读方式读取的数据块，通常是查询语句使用的方式。Current：表示当前操作的逻辑读取的数据块，通常是修改数据使用的方式。Rows：表示当前操作处理的数据记录数。1234567891011121314select ename,job,sal,dnamefrom emp,dept where dept.deptno = emp.deptno and not exists(select * from salgrade where emp.sal between losal and hisal)call count cpu elapsed disk query current rows------- ------ -------- ---------- ---------- ---------- ---------- ----------Parse 1 0.02 0.02 0 22 0 0Execute 1 0.00 0.00 0 0 0 0Fetch 1 0.00 0.00 0 15 0 0------- ------ -------- ---------- ---------- ---------- ---------- ----------total 3 0.02 0.02 0 37 0 0Misses in library cache during parse: 1Optimizer mode: ALL_ROWSParsing user id: 70 (SCOTT)Number of plan statistics captured: 1 接下来就是上面的我们执行的相关SQL信息，可以从上面的信息看到，优化器模式使用的是ALL_ROWS，且有一次硬解析，用户为SCOTT。此条SQL语句被分析了一次，执行了一次，数据提取了一次，消耗CPU时间为0.02秒，均花在解析阶段，一致性读取了37个块，没有磁盘读。 #####未经tkprof格式化的文件构建环境，加入一个绑定变量并生成trace123456789101112131415FUNG@linora&gt; VARIABLE loc VARCHAR2(30)FUNG@linora&gt; EXEC :loc:=&apos;South San Francisco&apos;PL/SQL procedure successfully completed.FUNG@linora&gt; alter session set events &apos;10046 trace name context forever, level 12&apos;;Session altered.FUNG@linora&gt; SELECT emp.last_name, emp.first_name, j.job_title, d.department_name, l.city,l.state_province, l.postal_code, l.street_address, emp.email,emp.phone_number, emp.hire_date, emp.salary, mgr.last_nameFROM hr.employees emp, hr.employees mgr, hr.departments d, hr.locations l, hr.jobs jWHERE l.city=:locAND emp.manager_id=mgr.employee_idAND emp.department_id=d.department_idAND d.location_id=l.location_idAND emp.job_id=j.job_id;FUNG@linora&gt; select * from v$diag_info; 未经tkprof格式化的trace文件123456789101112PARSING IN CURSOR # 140430523695752 len=430 dep=0 uid=66 oct=3 lid=66 tim=1406340835532883 hv=2605724446 ad=&apos;8b986bb8&apos; sqlid=&apos;6fdr5n2dp0csy&apos;SELECT emp.last_name, emp.first_name, j.job_title, d.department_name, l.city,l.state_province, l.postal_code, l.street_address, emp.email,emp.phone_number, emp.hire_date, emp.salary, mgr.last_nameFROM hr.employees emp, hr.employees mgr, hr.departments d, hr.locations l, hr.jobs jWHERE l.city=:locAND emp.manager_id=mgr.employee_idAND emp.department_id=d.department_idAND d.location_id=l.location_idAND emp.job_id=j.job_idEND OF STMTPARSE # 140430523695752:c=3000,e=3186,p=0,cr=0,cu=0,mis=1,r=0,dep=0,og=1,plh=0,tim=1406340835532850 CURSOR表示游标号，len表示SQL语句长度，dep表示SQL的递归深度，如果dep=0，表示不是递归SQL，UID为users$表中的user#，通过它可以查询到是谁发起的SQL，OCT=3为sql命令的类型，3表示select操作，11g可通过select command_type,command_name from V$SQLCOMMAND;获得对应关系，c和e都表示时间，一个是cpu消耗时间，一个是Elapsed时间，都以1/100W秒（微秒）为单位。1234567891011121314151617181920212223242526272829303132333435WAIT # 140430523695752: nam=&apos;db file sequential read&apos; ela= 9559 file#=8 block#=11515 blocks=1 obj#=84744 tim=1406340835774246WAIT # 140430523695752: nam=&apos;db file sequential read&apos; ela= 503 file#=8 block#=11476 blocks=1 obj#=84737 tim=1406340835774830WAIT # 140430523695752: nam=&apos;db file scattered read&apos; ela= 671 file#=8 block#=11477 blocks=3 obj#=84737 tim=1406340835776772WAIT # 140430523695752: nam=&apos;db file sequential read&apos; ela= 496 file#=8 block#=11458 blocks=1 obj#=84735 tim=1406340835777504WAIT # 140430523695752: nam=&apos;db file scattered read&apos; ela= 560 file#=8 block#=11459 blocks=5 obj#=84735 tim=1406340835778142WAIT # 140430523695752: nam=&apos;db file sequential read&apos; ela= 519 file#=8 block#=11490 blocks=1 obj#=84739 tim=1406340835779259WAIT # 140430523695752: nam=&apos;db file scattered read&apos; ela= 888 file#=8 block#=11491 blocks=5 obj#=84739 tim=1406340835780251WAIT # 140430523695752: nam=&apos;db file sequential read&apos; ela= 12191 file#=8 block#=11666 blocks=1 obj#=84747 tim=1406340835793607WAIT # 140430523695752: nam=&apos;db file scattered read&apos; ela= 725 file#=8 block#=11667 blocks=5 obj#=84747 tim=1406340835794438FETCH # 140430523695752:c=7000,e=60243,p=27,cr=19,cu=0,mis=0,r=1,dep=0,og=1,plh=2361458858,tim=1406340835794675WAIT # 140430523695752: nam=&apos;SQL*Net message from client&apos; ela= 458 driver id=1650815232 #bytes=1 p3=0 obj#=84747 tim=1406340835795214WAIT # 140430523695752: nam=&apos;SQL*Net message to client&apos; ela= 5 driver id=1650815232 #bytes=1 p3=0 obj#=84747 tim=1406340835795283FETCH # 140430523695752:c=0,e=69,p=0,cr=1,cu=0,mis=0,r=15,dep=0,og=1,plh=2361458858,tim=1406340835795333WAIT # 140430523695752: nam=&apos;SQL*Net message from client&apos; ela= 2045 driver id=1650815232 #bytes=1 p3=0 obj#=84747 tim=1406340835797425WAIT # 140430523695752: nam=&apos;SQL*Net message to client&apos; ela= 7 driver id=1650815232 #bytes=1 p3=0 obj#=84747 tim=1406340835797553FETCH # 140430523695752:c=0,e=141,p=0,cr=1,cu=0,mis=0,r=15,dep=0,og=1,plh=2361458858,tim=1406340835797621WAIT # 140430523695752: nam=&apos;SQL*Net message from client&apos; ela= 9520 driver id=1650815232 #bytes=1 p3=0 obj#=84747 tim=1406340835807188WAIT # 140430523695752: nam=&apos;SQL*Net message to client&apos; ela= 5 driver id=1650815232 #bytes=1 p3=0 obj#=84747 tim=1406340835807262FETCH # 140430523695752:c=0,e=149,p=0,cr=1,cu=0,mis=0,r=14,dep=0,og=1,plh=2361458858,tim=1406340835807391STAT # 140430523695752 id=1 cnt=45 pid=0 pos=1 obj=0 op=&apos;HASH JOIN (cr=22 pr=27 pw=0 time=60289 us cost=10 size=2580 card=15)&apos;STAT # 140430523695752 id=2 cnt=45 pid=1 pos=1 obj=0 op=&apos;HASH JOIN (cr=13 pr=15 pw=0 time=43883 us cost=8 size=2400 card=15)&apos;STAT # 140430523695752 id=3 cnt=45 pid=2 pos=1 obj=0 op=&apos;NESTED LOOPS (cr=7 pr=9 pw=0 time=42041 us cost=5 size=1995 card=15)&apos;STAT # 140430523695752 id=4 cnt=45 pid=3 pos=1 obj=0 op=&apos;NESTED LOOPS (cr=5 pr=5 pw=0 time=40180 us cost=5 size=1995 card=40)&apos;STAT # 140430523695752 id=5 cnt=1 pid=4 pos=1 obj=0 op=&apos;NESTED LOOPS (cr=4 pr=4 pw=0 time=30076 us cost=3 size=268 card=4)&apos;STAT # 140430523695752 id=6 cnt=1 pid=5 pos=1 obj=84729 op=&apos;TABLE ACCESS BY INDEX ROWID LOCATIONS (cr=2 pr=2 pw=0 time=27964 us cost=2 size=48 card=1)&apos;STAT # 140430523695752 id=7 cnt=1 pid=6 pos=1 obj=84752 op=&apos;INDEX RANGE SCAN LOC_CITY_IX (cr=1 pr=1 pw=0 time=19682 us cost=1 size=0 card=1)&apos;STAT # 140430523695752 id=8 cnt=1 pid=5 pos=2 obj=84732 op=&apos;TABLE ACCESS BY INDEX ROWID DEPARTMENTS (cr=2 pr=2 pw=0 time=2081 us cost=1 size=76 card=4)&apos;STAT # 140430523695752 id=9 cnt=1 pid=8 pos=1 obj=84748 op=&apos;INDEX RANGE SCAN DEPT_LOCATION_IX (cr=1 pr=1 pw=0 time=407 us cost=0 size=0 card=4)&apos;STAT # 140430523695752 id=10 cnt=45 pid=4 pos=2 obj=84744 op=&apos;INDEX RANGE SCAN EMP_DEPARTMENT_IX (cr=1 pr=1 pw=0 time=9811 us cost=0 size=0 card=10)&apos;STAT # 140430523695752 id=11 cnt=45 pid=3 pos=2 obj=84737 op=&apos;TABLE ACCESS BY INDEX ROWID EMPLOYEES (cr=2 pr=4 pw=0 time=1779 us cost=1 size=264 card=4)&apos;STAT # 140430523695752 id=12 cnt=19 pid=2 pos=2 obj=84735 op=&apos;TABLE ACCESS FULL JOBS (cr=6 pr=6 pw=0 time=1272 us cost=3 size=513 card=19)&apos;STAT # 140430523695752 id=13 cnt=107 pid=1 pos=2 obj=0 op=&apos;VIEW index$_join$_002 (cr=9 pr=12 pw=0 time=18317 us cost=2 size=1284 card=107)&apos;STAT # 140430523695752 id=14 cnt=107 pid=13 pos=1 obj=0 op=&apos;HASH JOIN (cr=9 pr=12 pw=0 time=17668 us)&apos;STAT # 140430523695752 id=15 cnt=107 pid=14 pos=1 obj=84739 op=&apos;INDEX FAST FULL SCAN EMP_EMP_ID_PK (cr=3 pr=6 pw=0 time=2049 us cost=1 size=1284 card=107)&apos;STAT # 140430523695752 id=16 cnt=107 pid=14 pos=2 obj=84747 op=&apos;INDEX FAST FULL SCAN EMP_NAME_IX (cr=6 pr=6 pw=0 time=13597 us cost=1 size=1284 card=107)&apos; wait表示等待事件信息，含有等待时间，操作时间(ela,单位为微秒)，等待事件的p1，p2，p3可用v$event_name获得，像上例中的等待事件&#39;db file sequential read&#39;，p1=file# 8，p2=block# ，p3=blocks，即表示该操作读取的是数据文件id号为8的文件，从p2块号开始，读取了几个块。fetch中，p和cr分别表示物理读和一致性读引起的buffer get，cu表示current read引起的buffer get，r表示处理的行数。stat表示在执行过程中消耗的资源信息统计，从stat可以划出执行计划步骤，正常的执行计划图：123456789101112131415161718192021------------------------------------------------------------------------------------------------------| Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time |------------------------------------------------------------------------------------------------------| 0 | SELECT STATEMENT | | 15 | 2580 | 10 (0)| 00:00:01 ||* 1 | HASH JOIN | | 15 | 2580 | 10 (0)| 00:00:01 ||* 2 | HASH JOIN | | 15 | 2400 | 8 (0)| 00:00:01 || 3 | NESTED LOOPS | | 15 | 1995 | 5 (0)| 00:00:01 || 4 | NESTED LOOPS | | 40 | 1995 | 5 (0)| 00:00:01 || 5 | NESTED LOOPS | | 4 | 268 | 3 (0)| 00:00:01 || 6 | TABLE ACCESS BY INDEX ROWID| LOCATIONS | 1 | 48 | 2 (0)| 00:00:01 ||* 7 | INDEX RANGE SCAN | LOC_CITY_IX | 1 | | 1 (0)| 00:00:01 || 8 | TABLE ACCESS BY INDEX ROWID| DEPARTMENTS | 4 | 76 | 1 (0)| 00:00:01 ||* 9 | INDEX RANGE SCAN | DEPT_LOCATION_IX | 4 | | 0 (0)| 00:00:01 ||* 10 | INDEX RANGE SCAN | EMP_DEPARTMENT_IX | 10 | | 0 (0)| 00:00:01 || 11 | TABLE ACCESS BY INDEX ROWID | EMPLOYEES | 4 | 264 | 1 (0)| 00:00:01 || 12 | TABLE ACCESS FULL | JOBS | 19 | 513 | 3 (0)| 00:00:01 || 13 | VIEW | index$_join$_002 | 107 | 1284 | 2 (0)| 00:00:01 ||* 14 | HASH JOIN | | | | | || 15 | INDEX FAST FULL SCAN | EMP_EMP_ID_PK | 107 | 1284 | 1 (0)| 00:00:01 || 16 | INDEX FAST FULL SCAN | EMP_NAME_IX | 107 | 1284 | 1 (0)| 00:00:01 |------------------------------------------------------------------------------------------------------ stat中的id对应就是plan table中的id，cnt表示返回的rows，在这里可以看到plan table中id=0只返回了15行，而10046返回的行数是真实执行返回的行数，plan table仅仅是根据表的统计信息(直方图，动态采样)而评估的返回结果。pid表示当前行源的父节点，pos表示同级行源的不同位置，一般同级行源先执行pos较小的操作。obj代表着dba_object.object_id，op对应plan table中的operation。 6. 10053事件10053解析的是CBO为何选择该执行计划。比如，CBO为何会选择index range scan？为何会选择table full scan？10053事件可以帮我们获取答案，10053仅有两个级别1和2，一般设置为1.12345678910111213141516171819FUNG@linora&gt; VARIABLE loc VARCHAR2(30)FUNG@linora&gt; EXEC :loc:=&apos;South San Francisco&apos; PL/SQL procedure successfully completed.FUNG@linora&gt; alter session set events &apos;10053 trace name context forever,level 1&apos;;Session altered.FUNG@linora&gt; SELECT emp.last_name, emp.first_name, j.job_title, d.department_name, l.city, 2 l.state_province, l.postal_code, l.street_address, emp.email, 3 emp.phone_number, emp.hire_date, emp.salary, mgr.last_name 4 FROM hr.employees emp, hr.employees mgr, hr.departments d, hr.locations l, hr.jobs j 5 WHERE l.city=:loc 6 AND emp.manager_id=mgr.employee_id 7 AND emp.department_id=d.department_id 8 AND d.location_id=l.location_id 9 AND emp.job_id=j.job_id;FUNG@linora&gt; alter session set events &apos;10053 trace name context off&apos;; 10053事件的trace中，包含有查询相关表的信息，包括表、索引统计信息，直方图信息，Clustering Factor，单表访问路径，多表联合的方式，对于n表联合，它会采取多重方式进行评估，理论上需要进行(n-1)!次组合，但是CBO当发现下一次组合的cost比最优的要大时，它会停止分析下去。对于表信息统计如下1234567891011121314151617181920212223242526***************************************BASE STATISTICAL INFORMATION***********************Table Stats:: Table: JOBS Alias: J #Rows: 19 #Blks: 5 AvgRowLen: 33.00 ChainCnt: 0.00 Column (# 1): JOB_ID( AvgLen: 8 NDV: 19 Nulls: 0 Density: 0.052632Index Stats:: Index: JOB_ID_PK Col#: 1 LVLS: 0 #LB: 1 #DK: 19 LB/K: 1.00 DB/K: 1.00 CLUF: 1.00***********************Table Stats:: Table: DEPARTMENTS Alias: D #Rows: 27 #Blks: 5 AvgRowLen: 21.00 ChainCnt: 0.00 Column (# 1): DEPARTMENT_ID( AvgLen: 4 NDV: 27 Nulls: 0 Density: 0.037037 Min: 10 Max: 270 Column (# 4): LOCATION_ID( AvgLen: 3 NDV: 7 Nulls: 0 Density: 0.018519 Min: 1400 Max: 2700 Histogram: Freq #Bkts: 7 UncompBkts: 27 EndPtVals: 7Index Stats:: Index: DEPT_ID_PK Col#: 1 LVLS: 0 #LB: 1 #DK: 27 LB/K: 1.00 DB/K: 1.00 CLUF: 1.00 Index: DEPT_LOCATION_IX Col#: 4 LVLS: 0 #LB: 1 #DK: 7 LB/K: 1.00 DB/K: 1.00 CLUF: 1.00*********************** rows表示CBO对这张表行数的预估，栏位信息中，NDV表示number of distinct values，Density表示密度，在索引中，有个比较关键的CLUF，表示Clustering Factor。在D表的统计中，Column 4是含有Freq HistogramHistogram。1234567891011121314151617181920Access path analysis for LOCATIONS***************************************SINGLE TABLE ACCESS PATH Single Table Cardinality Estimation for LOCATIONS[L] Column (# 4): CITY( AvgLen: 9 NDV: 23 Nulls: 0 Density: 0.043478 Table: LOCATIONS Alias: L Card: Original: 23.000000 Rounded: 1 Computed: 1.00 Non Adjusted: 1.00 Access Path: TableScan Cost: 3.00 Resp: 3.00 Degree: 0 Cost_io: 3.00 Cost_cpu: 41607 Resp_io: 3.00 Resp_cpu: 41607 Access Path: index (AllEqRange) Index: LOC_CITY_IX resc_io: 2.00 resc_cpu: 14673 ix_sel: 0.043478 ix_sel_with_filters: 0.043478 Cost: 2.00 Resp: 2.00 Degree: 1 Best:: AccessPath: IndexRange Index: LOC_CITY_IX Cost: 2.00 Degree: 1 Resp: 2.00 Card: 1.00 Bytes: 0 对L表单路径访问中，Card: Original: 23.000000 表示L表原始记录为23行，Rounded: 1表示预估输出结果，为1条记录。CBO认为可能使用以下2种方式访问T表：1.Access Path: TableScan2.Access Path: index (AllEqRange)其中，cost最低的为IndexRange。12345678910111213141516171819202122232425262728293031323334353637***************************************GENERAL PLANS***************************************Considering cardinality-based initial join order.Permutations for Starting Table :0Join order[1]: LOCATIONS[L]# 0 JOBS[J]# 1 DEPARTMENTS[D]# 2 EMPLOYEES[EMP]# 3 EMPLOYEES[MGR]# 4***********************Best so far: Table#: 0 cost: 2.0009 card: 1.0000 bytes: 48 Table#: 1 cost: 5.0033 card: 19.0000 bytes: 1425 Table#: 2 cost: 8.0440 card: 73.2857 bytes: 6862 Table#: 3 cost: 11.0873 card: 15.1429 bytes: 2400 Table#: 4 cost: 13.1681 card: 15.0013 bytes: 2580Join order[2]: LOCATIONS[L]# 0 JOBS[J]# 1 DEPARTMENTS[D]# 2 EMPLOYEES[MGR]# 4 EMPLOYEES[EMP]# 3Join order aborted: cost &gt; best plan cost--CBO停止计算Join order[3]: LOCATIONS[L]# 0 JOBS[J]# 1 EMPLOYEES[EMP]# 3 DEPARTMENTS[D]# 2 EMPLOYEES[MGR]# 4Join order[8]: LOCATIONS[L]# 0 DEPARTMENTS[D]# 2 EMPLOYEES[EMP]# 3 JOBS[J]# 1 EMPLOYEES[MGR]# 4***********************Best so far: Table#: 0 cost: 2.0009 card: 1.0000 bytes: 48 Table#: 2 cost: 3.0015 card: 3.8571 bytes: 268 Table#: 3 cost: 4.6329 card: 15.1429 bytes: 1995 Table#: 1 cost: 7.6730 card: 15.1429 bytes: 2400 Table#: 4 cost: 9.7539 card: 15.0013 bytes: 2580***************Now joining: EMPLOYEES[EMP]# 3***************Best:: JoinMethod: NestedLoop Cost: 4.63 Degree: 1 Resp: 4.63 Card: 15.14 Bytes: 133***************Now joining: JOBS[J]# 1***************Best:: JoinMethod: Hash Cost: 7.67 Degree: 1 Resp: 7.67 Card: 15.14 Bytes: 160***************Now joining: EMPLOYEES[MGR]# 4***************Best:: JoinMethod: Hash Cost: 9.75 Degree: 1 Resp: 9.75 Card: 15.00 Bytes: 172 以上为表的连接顺序，当遇到cost值大于最优的，CBO就会停止计算，从上面可以看出，Join 2~7都比1的COST要大，8的比1的要小。在Join order[8]中，CBO计算出与各个表连接COST最小的连接方式，最后在执行计划中体现出来。 7.CBO术语#####CardinalityCard是针对某条sql的某个具体执行步骤的执行结果所包含的记录的估算，在RAW 10046 trace文件中,STAT最后的card就表示每一个执行步骤结果集行数，而在10053 trace中，单表访问路径中包含了&#39;Card: Original: 5.000000 Rounded: 5 Computed: 5.00 Non Adjusted: 5.00&#39;，Orig表示CBD预估当前表总行数，Round则表示预估的返回结果四舍五入后的结果，Computed表示预估的返回结果。123456789101112131415# 10046 raw traceSTAT # 139958729041264 id=10 cnt=0 pid=1 pos=2 obj=84556 op=&apos;TABLE ACCESS BY INDEX ROWID DEPT (cr=0 pr=0 pw=0 time=0 us cost=1 size=13 card=1)&apos;# 10053 traceAccess path analysis for SALGRADE***************************************SINGLE TABLE ACCESS PATH Single Table Cardinality Estimation for SALGRADE[SALGRADE] Table: SALGRADE Alias: SALGRADE Card: Original: 5.000000 Rounded: 5 Computed: 5.00 Non Adjusted: 5.00 Access Path: TableScan Cost: 3.00 Resp: 3.00 Degree: 0 Cost_io: 3.00 Cost_cpu: 36557 Resp_io: 3.00 Resp_cpu: 36557 Best:: AccessPath: TableScan Cost: 3.00 Degree: 1 Resp: 3.00 Card: 5.00 Bytes: 0 ####SelectivitySelectivity=有谓词条件的返回结果记录数/未添加谓词的返回结果记录数，从定义上知道，如果sel越小，Card就越小，CBO估算的成本也就小。对于sel和card有如下关系：1Computed Card=Original * Sel ####NDVNDV=Number of distinct，表示表内不重复的值。如果目标列上既无直方图，也无NULL，则Sel=1/NDV。To be continued! Reference：Maclean教你读Oracle 10046 SQL TRACEMaclean教你读SQL TRACE TKProf报告","link":"/oracle-trace.html"},{"title":"Part of 12c New Features","text":"With the multitenant architecture, Oracle 12c provide some great new features. Such as RMAN table-level recovery, moving datafiles online and so on. This post will introduce some of the new features in 12c. 1. RMAN enhancementMost of previous RMAN commands are still supported in new 12c. In CDB environments, backup the whole CDB it means including backup ALL PDBs. You also can backup individual PDB just like previous version. 1.1 Table-level recoveryAs of 12c, RMAN provide a fast way to recover a dropped/truncated table than before, and this recovery procedure is without any affecting the remaining database objects. Before you can perform the table-level recovery, you must backup the SYSTEM,SYSAUX,UNDO and the relative tablespaces. If the table you want to recover is reside in PDB, you also need to backup the ROOT container&#39;s SYSTEM,SYSAUX, UNDO tablespaces along with PDB&#39;s SYSTEM,SYSAUX tablespaces.The grammar of table-level recovery is like below:12345678910RECOVER TABLE schema.tabname OF PLUGGABLE DATABASE pdbnameUNTIL TIME/SCNAUXILIARY DESTINATION &apos;auxiliary_dir&apos;DATAPUMP DESTINATION &apos;datapump_dir&apos;#if you want to restore the data into a different table#please use REMAP TABLE clause, it&apos;s suitable for truncated/deleted tableREMAP TABLE schema.t1:t2 #or import the data manually DUMP FILE &apos;dump_file_name&apos;NOTABLEIMPORT; Example of table level-recovery Create a table reside in PDB pdb12c.123456789101112SQL&gt; conn fung@db2srv:1522/pdb12cSQL&gt; create table user_t as select * from dba_users;#find the current scnSQL&gt; select current_scn from v$database;CURRENT_SCN----------- 1868050SQL&gt; select count(*) from user_t; COUNT(*)---------- 37 Perform a CDB full backup first.123456789101112131415161718[ora12c@db2srv:/home/ora12c]$ cat full.bk.sh #!/bin/bashsource ~/.bash_profile RMAN=$ORACLE_HOME/bin/rman BAKDIR=/u01/backupLOG=$BAKDIR/fullCDB.`date +%Y%m%d`.log$RMAN target / &lt;&lt;EOF |tee $LOGrun&#123;allocate channel t1 type disk format &apos;/u01/backup/full_%d_%T_%s&apos;;backup full database include current controlfileplus archivelog delete all input;release channel t1;&#125;exitEOF Now, truncate the table1SQL&gt; truncate table user_t; If in production environments, this table maybe still got some DBL operations, in this situation, it&#39;s recommended that use remap approach to recover this table.12345#connect to CDB with RMANRMAN&gt; recover table fung.t of pluggable database pdb12cuntil scn 1868050auxiliary destination &apos;/backup/tmpdb&apos;remap table fung.user_t:t_recv; Check the result:12345[ora12c@db2srv:/home/ora12c]$ sqlplus fung/oracle@db2srv:1522/pdb12cSQL&gt; select count(*) from T_RECV; COUNT(*)---------- 37 From the output, we can find what happened during the recovery: Create an auxiliary instance automatically Restore the dadafiles into the auxiliary instance Perform a point in time recovery Export the table Import the table to a specified table Do house keeping, delete the instance Some restrictions in table-level recovery: Additional disk space needed for storing the auxiliary instance SYS user tables cannot be recovered REMAP with NOT NULL constraints is not supported 1.2 Data Recovery AdvisorThis feature only support non-DCB or single-database. It provide possible resolutions regarding data loss analyze.1234567891011121314151617#delete datafile by accidentally ASMCMD [+data/ora12c/datafile] &gt; rm -rf FUNG.259.907875155RMAN&gt; list failure detail;using target database control file instead of recovery catalogDatabase Role: PRIMARYList of Database Failures=========================Failure ID Priority Status Time Detected Summary---------- -------- --------- ------------------- -------1142 HIGH OPEN 2016-03-31 16:54:35 One or more non-system datafiles are missing Impact: See impact for individual child failures List of child failures for parent failure ID 1142 Failure ID Priority Status Time Detected Summary ---------- -------- --------- ------------------- ------- 1145 HIGH OPEN 2016-03-31 16:54:35 Datafile 11: &apos;+DATA/ORA12C/DATAFILE/fung.259.907875155&apos; is missing Impact: Some objects in tablespace FUNG might be unavailable Show the advise of the resolutions:1234567891011121314151617181920212223242526RMAN&gt; advise failure 1145;Database Role: PRIMARYList of Database FailuresFailure ID Priority Status Time Detected Summary---------- -------- --------- ------------------- -------1145 HIGH OPEN 2016-03-31 16:54:35 Datafile 11: &apos;+DATA/ORA12C/DATAFILE/fung.259.907875155&apos; is missing Impact: Some objects in tablespace FUNG might be unavailableanalyzing automatic repair options; this may take some timeallocated channel: ORA_DISK_1channel ORA_DISK_1: SID=26 device type=DISKanalyzing automatic repair options completeMandatory Manual Actions========================no manual actions availableOptional Manual Actions=======================1. If file +DATA/ORA12C/DATAFILE/fung.259.907875155 was unintentionally renamed or moved, restore itAutomated Repair Options========================Option Repair Description------ ------------------1 Restore and recover datafile 11 Strategy: The repair includes complete media recovery with no data loss Repair script: /u01/app/ora12c/diag/rdbms/ora12c/ora12c/hm/reco_467016983.hm The repair script generated by RMAN as below:12345[ora12c@db2srv ~]$ cat /u01/app/ora12c/diag/rdbms/ora12c/ora12c/hm/reco_467016983.hm # restore and recover datafile restore ( datafile 11 ); recover datafile 11; sql &apos;alter database datafile 11 online&apos;; Follow the script to repair the failure:123RMAN&gt; restore ( datafile 11 );RMAN&gt; recover datafile 11;RMAN&gt; sql &apos;alter database datafile 11 online&apos;; If the failure still remain in DRA, you can remove it by manually:1RMAN&gt; change failure 1145 closed; 1.3 Execute SQLs in RMANAs of 12c, not like previous version, RMAN can execute SQLs directly without any pre-sql commands, but you cannot change the containers in RMAN session.123456789101112RMAN&gt; select id,name,phoneno from fung.t1; ID NAME PHONENO---------- ---------- ---------- 51369 FUNG 13800RMAN&gt; alter session set container=&apos;CDB$ROOT&apos;;RMAN-00571: ===========================================================RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============RMAN-00571: ===========================================================RMAN-03002: failure of sql statement command at 03/31/2016 17:24:29RMAN-06815: cannot change the container in RMAN session. 2. Invisible columnThis feature is like hidden column in DB2 database. Below example is the hidden column in DB2.12345678910111213141516171819db2 &quot;create table t (id int, name char(10), phoneno char(13) implicitly hidden) &quot;db2 &quot;insert into t (id,name,phoneno) values (51369,&apos;FUNG&apos;,&apos;13800&apos;)&quot;[db2v97i@db2srv ~]$ db2 &quot;select * from t&quot;ID NAME ----------- ---------- 51369 FUNG [db2v97i@db2srv ~]$ db2 &quot;select id,name,phoneno from t&quot;ID NAME PHONENO ----------- ---------- ------------- 51369 FUNG 13800 [db2v97i@db2srv ~]$ db2 describe table t Data type ColumnColumn name schema Data type name Length Scale Nulls------------------------------- --------- ------------------- ---------- ----- ------ID SYSIBM INTEGER 4 0 Yes NAME SYSIBM CHARACTER 10 0 Yes PHONENO SYSIBM CHARACTER 13 0 Yes In Oracle 12c, the invisible column just like the DB2&#39;s hidden column, the difference is in Oracle 12c, you cannot use describe table to show the invisible columns.1234567891011121314151617181920212223242526SQL&gt; create table t1(id int,name varchar(10), phoneno number(10) invisible);SQL&gt; insert into t1(id,name,phoneno) values(51369,&apos;FUNG&apos;,&apos;13800&apos;);SQL&gt; commit;SQL&gt; select * from t1; ID NAME---------- -------------------- 51369 FUNGSQL&gt; select id,name,phoneno from t1; ID NAME PHONENO---------- -------------------- ---------- 51369 FUNG 13800SQL&gt; desc t1; Name Null? Type ----------------------------------------- -------- ---------------------------- ID NUMBER(38) NAME VARCHAR2(10)SQL&gt; select dbms_metadata.get_ddl(&apos;TABLE&apos;,&apos;T1&apos;,&apos;FUNG&apos;) from dual;DBMS_METADATA.GET_DDL(&apos;TABLE&apos;,&apos;T1&apos;,&apos;FUNG&apos;)-------------------------------------------------------------------------------- CREATE TABLE &quot;FUNG&quot;.&quot;T1&quot; ( &quot;PHONENO&quot; NUMBER(10,0) INVISIBLE, #invisible column &quot;ID&quot; NUMBER(*,0), &quot;NAME&quot; VARCHAR2(10) ) SEGMENT CREATION IMMEDIATE External table, temporary table and cluster table are not supported invisible column. 3. Online rename/move datafilesPlease refer to previous post Moving Files in Database . 4. DDL loggingEnable this feature by turning parameter enable_ddl_logging to true. Then the DDL statement can be logged into a XML file. The default DDL log location is $ORACLE_BASE/diag/rdbms/DBNAME/log/ddl1234567SQL&gt; show parameter loggNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------enable_ddl_logging boolean FALSESQL&gt; alter system set enable_ddl_logging=true ;#Initial a DDL statementSQL&gt; create index t1 on fung.t1(id); You can find the log under the diag directory:12345678[ora12c@db2srv:/u01/app/ora12c/diag/rdbms/ora12c/ora12c/log/ddl]$ more log.xml &lt;msg time=&apos;2016-03-31T17:41:26.009+08:00&apos; org_id=&apos;oracle&apos; comp_id=&apos;rdbms&apos; msg_id=&apos;kpdbLogDDL:18370:2946163730&apos; type=&apos;UNKNOWN&apos; group=&apos;diag_adl&apos; level=&apos;16&apos; host_id=&apos;db2srv&apos; host_addr=&apos;192.168.56.110&apos; version=&apos;1&apos;&gt; &lt;txt&gt;create index t1 on fung.t1(id) #DDL logging &lt;/txt&gt;&lt;/msg&gt; This post only covers some of the 12c new features, more freatures will be discovered in the future&#39;s post. EOF","link":"/part-of-12c-new-features.html"},{"title":"RAC Datafile in Local Node","text":"客户在创建数据文件时，误将ASM数据文件创建在本地磁盘，导致重启的时候另一个节点怎么也起不来。客户现场无法记录操作日志，本文用虚拟机模拟类似场景。环境为11.2.0.4双节点RAC，使用ASM存储。 #####节点1模拟创建表空间12345678910111213141516171819SQL&gt; create tablespace data datafile &apos;/backup/rac11g/data01.dbf&apos; size 100M autoextend off;Tablespace altered.SQL&gt; alter user fung default tablespace data;User altered.SQL&gt; col name for a50SQL&gt; select name,status from v$datafile;NAME STATUS-------------------------------------------------- --------------+DATA/rac11g/datafile/system.259.848925423 SYSTEM+DATA/rac11g/datafile/sysaux.260.848925443 ONLINE+DATA/rac11g/datafile/undotbs1.261.848925457 ONLINE+DATA/rac11g/datafile/undotbs2.263.848925475 ONLINE+DATA/rac11g/datafile/users.264.848925483 ONLINE+DATA/rac11g/datafile/fung.298.849353657 ONLINE+DATA/rac11g/datafile/data.286.849526463 ONLINE/backup/rac11g/data01.dbf ONLINE 节点1创建文件没任何问题：123SQL&gt; create table fung.obj as select * from user_objects;Table created. 节点2创建会报错：123456SQL&gt; create table fung.obj2 as select * from fung.obj;create table fung.obj2 as select * from fung.obj *ERROR at line 1:ORA-01157: cannot identify/lock data file 7 - see DBWR trace fileORA-01110: data file 7: &apos;/backup/rac11g/data01.dbf&apos; 重启集群，会发现节点2起不来123456789101112[grid@fung01:/home/grid]$ srvctl stop database -d rac11g[grid@fung01:/home/grid]$ srvctl start database -d rac11gPRCR-1079 : Failed to start resource ora.rac11g.dbCRS-5017: The resource action &quot;ora.rac11g.db start&quot; encountered the following error: ORA-01157: cannot identify/lock data file 7 - see DBWR trace fileORA-01110: data file 7: &apos;/backup/rac11g/data01.dbf&apos;. For details refer to &quot;(:CLSN00107:)&quot; in &quot;/u01/app/11gr2/grid/log/fung02/agent/crsd/oraagent_oracle/oraagent_oracle.log&quot;.CRS-2674: Start of &apos;ora.rac11g.db&apos; on &apos;fung02&apos; failedCRS-2632: There are no more servers to try to place resource &apos;ora.rac11g.db&apos; on that would satisfy its placement policy #####解决方案 1. ASM CPASM CP命令是11g提供的，能将OS文件复制到ASM里面。而在10g中，使用DBMS_FILE_TRANSFER包进行处理。 DBMS_FILE_TRANSFER可以在同一台Oracle服务器上或两台Oracle 服务器之间复制文件。它使用directory对象来指定源directory和目的directory，因为directory支持ASM路径名称，所以DBMS_FILE_TRANSFER也支持ASM路径名。这使得从常规文件系统的ASM存储区移入和移出文件变得十分简单。 11g ASM CP命令12345678910111213141516171819ASMCMD&gt; pwd+data/rac11g/datafileASMCMD&gt; lsFUNG.298.849353657SYSAUX.260.848925443SYSTEM.259.848925423UNDOTBS1.261.848925457UNDOTBS2.263.848925475USERS.264.848925483ASMCMD&gt; cp /backup/rac11g/data01.dbf ./copying /backup/rac11g/data01.dbf -&gt; +data/rac11g/datafile/data01.dbfASMCMD&gt; lsFUNG.298.849353657SYSAUX.260.848925443SYSTEM.259.848925423UNDOTBS1.261.848925457UNDOTBS2.263.848925475USERS.264.848925483data01.dbf #####在节点1使用rename重命名该数据文件12345678910111213141516171819202122232425262728SQL&gt; alter tablespace data offline;Tablespace altered.SQL&gt; alter database rename file &apos;/backup/rac11g/data01.dbf&apos; to &apos;+data/rac11g/datafile/data01.dbf&apos;;Database altered.SQL&gt; alter tablespace data online;alter tablespace data online*ERROR at line 1:ORA-01113: file 7 needs media recoveryORA-01110: data file 7: &apos;+DATA/rac11g/datafile/data01.dbf&apos;SQL&gt; recover datafile 7;Media recovery complete.SQL&gt; alter tablespace data online;Tablespace altered.#查看修改后的结果SQL&gt; select name,status from v$datafile;NAME STATUS-------------------------------------------------- --------------+DATA/rac11g/datafile/system.259.848925423 SYSTEM+DATA/rac11g/datafile/sysaux.260.848925443 ONLINE+DATA/rac11g/datafile/undotbs1.261.848925457 ONLINE+DATA/rac11g/datafile/undotbs2.263.848925475 ONLINE+DATA/rac11g/datafile/users.264.848925483 ONLINE+DATA/rac11g/datafile/fung.298.849353657 ONLINE+DATA/rac11g/datafile/data01.dbf ONLINE #####开启节点2实例，同时观察实例后台日志是否正常1[oracle@fung02:/home/oracle]$ srvctl start instance -d rac11g -i rac11g2 2. RMAN copy功能1234567891011121314151617181920212223242526272829303132333435RMAN&gt; sql &quot;alter tablespace data offline&quot;;using target database control file instead of recovery catalogsql statement: alter tablespace data offlineRMAN&gt; copy datafile &apos;/backup/rac11g/data01.dbf&apos; to &apos;+data/rac11g/datafile/data01.dbf&apos;;Starting backup at 2014-06-20 11:28:30allocated channel: ORA_DISK_1channel ORA_DISK_1: SID=78 instance=rac11g1 device type=DISKchannel ORA_DISK_1: starting datafile copyinput datafile file number=00007 name=/backup/rac11g/data01.dbfoutput file name=+DATA/rac11g/datafile/data01.dbf tag=TAG20140620T112831 RECID=20 STAMP=850735714channel ORA_DISK_1: datafile copy complete, elapsed time: 00:00:03Finished backup at 2014-06-20 11:28:34RMAN&gt; sql &quot;alter database rename file &apos;&apos;/backup/rac11g/data01.dbf&apos;&apos; to &apos;&apos;+data/rac11g/datafile/data01.dbf&apos;&apos;&quot;;SQL&gt; alter tablespace data online;Tablespace altered.#查看修正结果SQL&gt; col tablespace_name for a10SQL&gt; col file_name for a50SQL&gt; set line 200SQL&gt; select tablespace_name,file_name,status,online_status from dba_data_files;TABLESPACE FILE_NAME STATUS ONLINE_STATUS---------- -------------------------------------------------- ------------------ --------------SYSTEM +DATA/rac11g/datafile/system.259.848925423 AVAILABLE SYSTEMSYSAUX +DATA/rac11g/datafile/sysaux.260.848925443 AVAILABLE ONLINEUNDOTBS1 +DATA/rac11g/datafile/undotbs1.261.848925457 AVAILABLE ONLINEUNDOTBS2 +DATA/rac11g/datafile/undotbs2.263.848925475 AVAILABLE ONLINEUSERS +DATA/rac11g/datafile/users.264.848925483 AVAILABLE ONLINEFUNG +DATA/rac11g/datafile/fung.298.849353657 AVAILABLE ONLINEDATA +DATA/rac11g/datafile/data01.dbf AVAILABLE ONLINE 3. 10g DBMS_FILE_TRANSFER创建transfer所需directory：1234SQL&gt; create directory fs as &apos;/backup/rac11g&apos;;Directory created.SQL&gt; create directory asm as &apos;+data/rac11g/datafile&apos;;Directory created. 使用transfer包进行复制123456789101112131415161718192021222324252627282930SQL&gt; alter tablespace data offline;Tablespace altered.SQL&gt; exec dbms_file_transfer.copy_file(&apos;FS&apos;,&apos;data01.dbf&apos;,&apos;ASM&apos;,&apos;data01.dbf&apos;);PL/SQL procedure successfully completed.#asm磁盘组中查看是否有文件过来ASMCMD [+data/rac11g/datafile] &gt; lsCOPY_FILE.501.850736539FUNG.298.849353657SYSAUX.260.848925443SYSTEM.259.848925423UNDOTBS1.261.848925457UNDOTBS2.263.848925475USERS.264.848925483data01.dbfSQL&gt; alter database rename file &apos;/backup/rac11g/data01.dbf&apos; to &apos;+data/rac11g/datafile/data01.dbf&apos;;Database altered.SQL&gt; alter tablespace data online;Tablespace altered.SQL&gt; select tablespace_name,file_name,status,online_status from dba_data_files;TABLESPACE FILE_NAME STATUS ONLINE_STATUS---------- -------------------------------------------------- ------------------ --------------SYSTEM +DATA/rac11g/datafile/system.259.848925423 AVAILABLE SYSTEMSYSAUX +DATA/rac11g/datafile/sysaux.260.848925443 AVAILABLE ONLINEUNDOTBS1 +DATA/rac11g/datafile/undotbs1.261.848925457 AVAILABLE ONLINEUNDOTBS2 +DATA/rac11g/datafile/undotbs2.263.848925475 AVAILABLE ONLINEUSERS +DATA/rac11g/datafile/users.264.848925483 AVAILABLE ONLINEFUNG +DATA/rac11g/datafile/fung.298.849353657 AVAILABLE ONLINEDATA +DATA/rac11g/datafile/data01.dbf AVAILABLE ONLINE 4. 总结在对数据库增加数据文件或者表空间时，首先要确认这些数据文件是存放在本地还是ASM或者是裸设备中，不要盲目的自以为根目录下的/oradata就是数据文件存放地。总之身为一个DBA，任何情况下对生产系统的操作，都要小心谨慎，且在做任何操作前，有时间备份，先进行备份，绝对不做一个给别人留坑的DBA！","link":"/rac-datafile-in-local-node.html"},{"title":"心跳丢失引起RAC节点不断重启","text":"客户双节点RAC在8月22号晚上节点2异常终止，随即自动重新启动，但启动失败，25号下午17点多手动启动节点2上的Cluster，结果在26号客户巡检发现节点2在不停的重启。环境：11.2.0.3 + Linux 64bit 双节点 RAC在8月22号开始，节点2首次出现123Fri Aug 22 19:26:27 2014PMON (ospid: 13912): terminating the instance due to error 481Instance terminated by PMON, pid = 13912 节点2开始自动重启，重启过程中出现123NOTE: client +ASM2:+ASM registered, osid 20296, mbr 0x0WARNING: failed to online diskgroup resource ora.DATA.dg (unable to communicate with CRSD/OHASD)WARNING: failed to online diskgroup resource ora.RECOVERY.dg (unable to communicate with CRSD/OHASD) 再次报错123Fri Aug 22 19:41:42 2014PMON (ospid: 20218): terminating the instance due to error 481Instance terminated by PMON, pid = 20218 ora-00481错误信息如下：123ORA-00481:LMON process terminated with errorCause: The global enqueue service monitor process diedAction: Warm start instance LMON: Global Enqueue Service Monitor。LMON用于监控整个集群的global enqueues和resources， 而且会执行global enqueue recovery。实例异常终止后，会由LMON来进行GCS内存方面的处理。当一个实例加入或者离开集群后，LMON会对lock和resource进行reconfiguration.另外LMON会在不同的实例间进行通讯检查，如果发现对方通讯超时，就会发出节点eviction。22号相关日志：1234567891011121314151617--alter_db2.logFri Aug 22 19:26:25 2014 --第一次错误发生时间为22号19:26NOTE: ASMB terminatingErrors in file /opt/u01/app/oracle/diag/rdbms/dbrac/dbrac2/trace/dbrac2_asmb_26030.trc:ORA-15064: ? ASM ??????ORA-03113: ??????????? ID: ?? ID: 82 ???: 35Errors in file /opt/u01/app/oracle/diag/rdbms/dbrac/dbrac2/trace/dbrac2_asmb_26030.trc:ORA-15064: ? ASM ??????ORA-03113: ??????????? ID: ?? ID: 82 ???: 35ASMB (ospid: 26030): terminating the instance due to error 15064Instance terminated by ASMB, pid = 26030Fri Aug 22 19:28:02 2014Starting ORACLE instance (normal) --开始自动重启Cluster #####alternode2.log:12342014-08-22 19:26:16.065 --时间为22号19:26[cssd(13669)]CRS-1612:50% 的超时时间间隔内缺少与节点 dbserver_node1 (1) 的网络通信。将在 14.140 秒后从集群中删除此节点2014-08-22 19:26:23.079[cssd(13669)]CRS-1611:75% 的超时时间间隔内缺少与节点 dbserver_node1 (1) 的网络通信。将在 7.130 秒后从集群中删除此节点 #####ocssd.log：1234567892014-08-22 19:26:16.065: [ CSSD][1113200960]clssnmPollingThread: node dbserver_node1 (1) at 50% heartbeat fatal, removal in 14.140 seconds --Heartbeat不通2014-08-22 19:26:16.065: [ CSSD][1113200960]clssnmPollingThread: node dbserver_node1 (1) is impending reconfig, flag 2491406, misstime 158602014-08-22 19:26:16.065: [ CSSD][1113200960]clssnmPollingThread: local diskTimeout set to 27000 ms, remote disk timeout set to 27000, impending reconfig status(1)2014-08-22 19:26:16.066: [ CSSD][1106893120]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030317, wrtcnt, 27424336, LATS 576293252, lastSeqNo 25251022, uniqueness 1399539197, timestamp 1408706775/5763745022014-08-22 19:26:17.005: [ CSSD][1114777920]clssnmSendingThread: sending status msg to all nodes2014-08-22 19:26:17.005: [ CSSD][1114777920]clssnmSendingThread: sent 4 status msgs to all nodes2014-08-22 19:26:17.068: [ CSSD][1106893120]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030317, wrtcnt, 27424342, LATS 576294252, lastSeqNo 27424336, uniqueness 1399539197, timestamp 1408706776/576375512 --心跳出问题，内部通信有问题 26号部分日志，情况跟22号一样： #####db alter_node2.log12345678910111213141516Tue Aug 26 15:15:21 2014 --时间在15:15分左右NOTE: ASMB terminatingErrors in file /opt/u01/app/oracle/diag/rdbms/dbrac/dbrac2/trace/dbrac2_asmb_27935.trc:ORA-15064: ? ASM ??????ORA-03113: ??????????? ID: ?? ID: 4 ???: 5Errors in file /opt/u01/app/oracle/diag/rdbms/dbrac/dbrac2/trace/dbrac2_asmb_27935.trc:ORA-15064: ? ASM ??????ORA-03113: ??????????? ID: ?? ID: 4 ???: 5ASMB (ospid: 27935): terminating the instance due to error 15064Instance terminated by ASMB, pid = 27935Tue Aug 26 15:17:00 2014Starting ORACLE instance (normal) #####ocssd.log12345678910112014-08-26 15:15:11.914: [ CSSD][1100093760]clssnmPollingThread: node dbserver_node1 (1) at 50% heartbeat fatal, removal in 14.070 seconds2014-08-26 15:15:11.914: [ CSSD][1100093760]clssnmPollingThread: node dbserver_node1 (1) is impending reconfig, flag 2491406, misstime 159302014-08-26 15:15:11.914: [ CSSD][1100093760]clssnmPollingThread: local diskTimeout set to 27000 ms, remote disk timeout set to 27000, impending reconfig status(1)2014-08-26 15:15:11.915: [ CSSD][1088473408]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030399, wrtcnt, 28415629, LATS 906787192, lastSeqNo 0, uniqueness 1399539197, timestamp 1409037311/9068714222014-08-26 15:15:11.915: [ CSSD][1108830528]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030399, wrtcnt, 28415631, LATS 906787192, lastSeqNo 28412102, uniqueness 1399539197, timestamp 1409037311/9068714322014-08-26 15:15:12.917: [ CSSD][1088473408]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030399, wrtcnt, 28415635, LATS 906788192, lastSeqNo 28415629, uniqueness 1399539197, timestamp 1409037312/9068724422014-08-26 15:15:12.917: [ CSSD][1108830528]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030399, wrtcnt, 28415637, LATS 906788192, lastSeqNo 28415631, uniqueness 1399539197, timestamp 1409037312/9068724522014-08-26 15:15:13.920: [ CSSD][1088473408]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030399, wrtcnt, 28415641, LATS 906789202, lastSeqNo 28415635, uniqueness 1399539197, timestamp 1409037313/9068734422014-08-26 15:15:13.920: [ CSSD][1108830528]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030399, wrtcnt, 28415643, LATS 906789202, lastSeqNo 28415637, uniqueness 1399539197, timestamp 1409037313/9068734522014-08-26 15:15:14.921: [ CSSD][1088473408]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030399, wrtcnt, 28415647, LATS 906790202, lastSeqNo 28415641, uniqueness 1399539197, timestamp 1409037314/9068744422014-08-26 15:15:14.922: [ CSSD][1108830528]clssnmvDHBValidateNCopy: node 1, dbserver_node1, has a disk HB, but no network HB, DHB has rcfg 295030399, wrtcnt, 28415649, LATS 906790202, lastSeqNo 28415643, uniqueness 1399539197, timestamp 1409037314/906874452 最后ping 大包，确定心跳网络有问题，丢包率达到15%。1ping -s 1500 node2-priv","link":"/rac-private-network-loss.html"},{"title":"Recovering a dropped table in Oracle and DB2","text":"When DBA dropped a table accidentally, always need a quick way to recover the dropped table. What I mean &quot;quick way&quot; is not only recovering the dropped table as soon as possible, but also should not affect other applications in the same database. 1. Recover a dropped table in OracleIf your database version is above 10g, and the recyclebin is enable, you can just simply use recyclebin feature to UNDO the dropped table.123456789101112131415161718192021222324SQL&gt; show parameter recyclebinNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------recyclebin string on--drop a tableSQL&gt; conn fung/oracleConnected.SQL&gt; select count(*) from t; COUNT(*)---------- 86260SQL&gt; drop table t;Table dropped.SQL&gt; show recyclebinORIGINAL NAME RECYCLEBIN NAME OBJECT TYPE DROP TIME---------------- ------------------------------ ------------ -------------------T BIN$LSJDDhSaBtDgU8g4qMAzSA==$0 TABLE 2016-03-03:17:02:45SQL&gt; flashback table t to before drop;Flashback complete.SQL&gt; select count(*) from t; COUNT(*)---------- 86260 1.1 explanation of recyclebinYou can find more details in &quot;recyclebin&quot; view:1234SQL&gt; select object_name,original_name,operation,DROPTIME,CAN_UNDROP,CAN_PURGE from recyclebin;OBJECT_NAME ORIGINAL_NAME OPERATION DROPTIME CAN_UN CAN_PU------------------------- -------------------- ------------------ -------------------------------------- ------ ------BIN$LSJDDhSbBtDgU8g4qMAzSA==$0 T DROP 2016-03-03:17:31:13 YES YES Recyclebin can be purged, if you don&#39;t want to keep the dropped in recyclebin, also can issue drop table command with purge options:1234567891011--purge recyclebinSQL&gt; purge recyclebin;Recyclebin purged.SQL&gt; select * from recyclebin;no rows selected--drop table with purge optionSQL&gt; create table t as select * from dba_objects;Table created.SQL&gt; drop table t purge;Table dropped.SQL&gt; show recyclebin; Enable and disable recylebin feature:123456789--disable recyclebin, this step need to restart the instanceSQL&gt; alter system set recyclebin=off scope=spfile;System altered.SQL&gt; show parameter recyclebinNAME TYPE VALUE------------------- ---------------------- ------------------------------recyclebin string OFF--enable recyclebin, also need to restart the instanceSQL&gt; alter system set recyclebin=on scope=spfile; Multiple version in recyclebin, you may drop a table in couple of times, this action will generate multiple object with the same original name in recyclbin.123456789101112131415161718SQL&gt; create table t as select * from dba_objects;Table created.SQL&gt; drop table t;Table dropped.SQL&gt; create table t as select * from dba_users;Table created.SQL&gt; drop table t;Table dropped.SQL&gt; create table t as select * from dba_tables;Table created.SQL&gt; drop table t;Table dropped.SQL&gt; show recyclebinORIGINAL NAME RECYCLEBIN NAME OBJECT TYPE DROP TIME---------------- ------------------------------ ------------ -------------------T BIN$LSLiyo5tB/LgU8g4qMDT/Q==$0 TABLE 2016-03-03:17:47:52T BIN$LSLiyo5qB/LgU8g4qMDT/Q==$0 TABLE 2016-03-03:17:47:38T BIN$LSLiyo5iB/LgU8g4qMDT/Q==$0 TABLE 2016-03-03:17:47:25 As we can see, each dropped table T is assigned a unique name in the recyclebin, if you flashback the dropped table at that time, the most recently dropped table with that original name is retrieved from recyclebin, you also can indicate the unique name to specify the exactly table you want to recover.123--specified the unique nameSQL&gt; flashback table &quot;BIN$LSLiyo5iB/LgU8g4qMDT/Q==$0&quot; to before drop;Flashback complete. Below action should be the most recently dropped table, which unique name is &quot;BIN$LSLiyo5tB/LgU8g4qMDT/Q==$0&quot;, because we recover a same original name, you cannot recover it without indicate the &quot;rename&quot; option, or you should get &quot;ORA-38312: original name is used by an existing object&quot; error123456SQL&gt; flashback table t to before drop rename to t1;Flashback complete.SQL&gt; show recyclebinORIGINAL NAME RECYCLEBIN NAME OBJECT TYPE DROP TIME---------------- ------------------------------ ------------ -------------------T BIN$LSLiyo5qB/LgU8g4qMDT/Q==$0 TABLE 2016-03-03:17:47:38 2. Recover a dropped table in DB2Recovery dropped in DB2 is somewhat more complex than in Oracle. In Oracle 10g and above, if you enable recyclebin feature(default enabled), you can easily take recovery without any downtime, no rman recovery need.But in DB2, you need a backup image to accomplish this task. With backup image, restore the tablespace which the dropped table reside on, and import the data from recover data. Here&#39;s an example.12345678910111213141516[db2v97i@db2srv ~]$ db2 &quot;create table fung.t(id varchar(10),name varchar(20)) in fung&quot;DB20000I The SQL command completed successfully.[db2v97i@db2srv ~]$ db2 &quot;insert into fung.t values(51369,&apos;fung&apos;)&quot;DB20000I The SQL command completed successfully.[db2v97i@db2srv ~]$ db2 terminateDB20000I The TERMINATE command completed successfully.[db2v97i@db2srv ~]$ db2 deactivate db mysampleDB20000I The DEACTIVATE DATABASE command completed successfully.--take a offline backup[db2v97i@db2srv ~]$ db2 backup db mysample to /db2/backup/db2v97i/mysample/ compressBackup successful. The timestamp for this backup image is : 20160307161004--drop the table T [db2v97i@db2srv ~]$ db2 drop table fung.tDB20000I The SQL command completed successfully. First, try to find out whether the tablespace support &quot;DROPPED TABLE RECOVERY&quot; or not12345678910[db2v97i@db2srv ~]$ db2 &quot;select substr(TBSPACE,1,20) as TBS,TBSPACETYPE,DROP_RECOVERY from SYSCAT.TABLESPACES&quot;TBS TBSPACETYPE DROP_RECOVERY-------------------- ----------- -------------SYSCATSPACE D N TEMPSPACE1 S N USERSPACE1 D Y IBMDB2SAMPLEREL D Y SYSTOOLSPACE D Y SYSTOOLSTMPSPACE S N FUNG D Y ` Second, find out the dropped table12345678910111213141516171819[db2v97i@db2srv ~]$ db2 list history dropped table all for mysample List History File for mysample Op Obj Timestamp+Sequence Type Dev Earliest Log Current Log Backup ID -- --- ------------------ ---- --- ------------ ------------ -------------- D T 20160307161043 000000000000f6b800060004 ---------------------------------------------------------------------------- &quot;FUNG &quot;.&quot;T&quot; resides in 1 tablespace(s): 00001 FUNG ---------------------------------------------------------------------------- Comment: DROP TABLE Start Time: 20160307161043 End Time: 20160307161043 Status: A ---------------------------------------------------------------------------- EID: 604 DDL: CREATE TABLE &quot;FUNG &quot;.&quot;T&quot; ( &quot;ID&quot; VARCHAR(10) , &quot;NAME&quot; VARCHAR(20) ) IN &quot;FUNG&quot; ; ---------------------------------------------------------------------------- From the output, we can retrieve the dropped table name, which tablespace did the table reside on, and the DDL of the table.Third, restore a database-level or tablespace-level backup image taken before the table was dropped.1234567891011121314151617181920212223242526--find out available backup image [db2v97i@db2srv ~]$ db2 list history backup all for mysample List History File for mysample Op Obj Timestamp+Sequence Type Dev Earliest Log Current Log Backup ID -- --- ------------------ ---- --- ------------ ------------ -------------- B D 20160307161004001 F D S0000380.LOG S0000380.LOG ---------------------------------------------------------------------------- Contains 5 tablespace(s): 00001 SYSCATSPACE 00002 USERSPACE1 00003 IBMDB2SAMPLEREL 00004 SYSTOOLSPACE 00005 FUNG ---------------------------------------------------------------------------- Comment: DB2 BACKUP MYSAMPLE OFFLINE Start Time: 20160307161004 End Time: 20160307161012 Status: A ---------------------------------------------------------------------------- EID: 602 Location: /db2/backup/db2v97i/mysample--execute the restore command[db2v97i@db2srv ~]$ db2 &quot;restore db mysample tablespace (FUNG) online from /db2/backup/db2v97i/mysample/ taken at 20160307161004&quot;DB20000I The RESTORE DATABASE command completed successfully. Next, create an export directory to which files contaning the table data are to be written, and rollforward to a PIT.123456789101112[db2v97i@db2srv ~]$ mkdir -p /restore[db2v97i@db2srv ~]$ db2 &quot;ROLLFORWARD DB mysample TO END OF LOGS TABLESPACE ONLINE RECOVER DROPPED TABLE 000000000000f6b800060004 TO /restore&quot; Rollforward Status Input database alias = mysample Number of members have returned status = 1 Member ID = 0 Rollforward status = not pending Next log file to be read = Log files processed = - Last committed transaction = 2016-03-07-08.10.43.000000 UTCDB20000I The ROLLFORWARD command completed successfully. Next, re-create the dropped table (DDL can obtain from list history command ).12db2 =&gt; CREATE TABLE &quot;FUNG &quot;.&quot;T&quot; ( &quot;ID&quot; VARCHAR(10) , &quot;NAME&quot; VARCHAR(20) ) IN &quot;FUNG&quot;DB20000I The SQL command completed successfully. Finally, we can import the data from restore directory.123456789101112131415161718192021--import the data from that was export during the roll forward operation into the table[db2v97i@db2srv ~]$ db2 &quot;IMPORT FROM /restore/NODE0000/data OF DEL INSERT INTO FUNG.T&quot;SQL3109N The utility is beginning to load data from file &quot;/restore/NODE0000/data&quot;.SQL3110N The utility has completed processing. &quot;1&quot; rows were read from the input file.SQL3221W ...Begin COMMIT WORK. Input Record Count = &quot;1&quot;.SQL3222W ...COMMIT of any database changes was successful.SQL3149N &quot;1&quot; rows were processed from the input file. &quot;1&quot; rows were successfully inserted into the table. &quot;0&quot; rows were rejected.Number of rows read = 1Number of rows skipped = 0Number of rows inserted = 1Number of rows updated = 0Number of rows rejected = 0Number of rows committed = 1[db2v97i@db2srv ~]$ db2 &quot;select * from fung.t&quot;ID NAME ---------- --------------------51369 fung 1 record(s) selected. 3. SupplementalThere&#39;s still one mistaken operation that always happens. Delete table records happens frequently, maybe you delete some records, or you delete all the table records. So, what&#39;s the difference between DB2 and Oracle database while recovering &quot;deleted records&quot;? 3.1 recovering deleted records in OracleIt&#39;s very simple to use flashback query feature to undo the deleted data in tables. If you didn&#39;t commit the delete command, you also can rollback the delete statement easily.123456SQL&gt; select count(*) from fung.t; COUNT(*)---------- 86260SQL&gt; !dateMon Mar 7 19:24:40 CST 2016 Now, let&#39;s delete table data and commit it.1234SQL&gt; delete from fung.t;86260 rows deleted.SQL&gt; commit;Commit complete. Undo the delete operation by using flashback query feature:123456789101112SQL&gt; select count(*) from fung.t as of timestamp to_timestamp(&apos;2016-03-07 19:24:00&apos;,&apos;yyyy-mm-dd hh24:mi:ss&apos;); COUNT(*)---------- 86260SQL&gt; insert into fung.t select * from fung.t as of timestamp to_timestamp(&apos;2016-03-07 19:24:00&apos;,&apos;yyyy-mm-dd hh24:mi:ss&apos;);86260 rows created.SQL&gt; commit;Commit complete.SQL&gt; select count(*) from fung.t; COUNT(*)---------- 86260 Data is back. If you don&#39;t know what the exactly deletion time, you can adjust the timestamp until find the proper one. Flashback query feature is based on undo tablespace, if undo tablespace or the parameter undo_retention (value by seconds) not big or long enough, you also may need take a RMAN recovery to undo the detetion.1234SQL&gt; show parameter undo_retentionNAME TYPE VALUE------------------------------------ ---------------------- ------------------------------undo_retention integer 900 3.2 recovering deleted records in DB2DB2 recovery technology is always more complex than Oracle. Oracle can just use flashback feature to recover deleted records. And auto-commit is enable in DB2 by default, if you didn&#39;t disable auto-commit, you cann&#39;t even use rollback to undo the delete command.12[db2ace@oc7421025535 ~]$ db2 list command options |grep -i commit -c Auto-Commit ON In DB2, the best way to recover a deleted table is redirect restore. Let&#39;s simulate a circumstance to explain it.1234567891011--duplicate a system table structure [db2v97i@db2srv ~]$ db2 &quot;create table fung.t1 like syscat.tables in FUNG&quot;DB20000I The SQL command completed successfully.--insert some records into the table [db2v97i@db2srv ~]$ db2 &quot;insert into fung.t1 select * from syscat.tables&quot;DB20000I The SQL command completed successfully.[db2v97i@db2srv ~]$ db2 &quot;select count(*) from fung.t1&quot;1 ----------- 502 1 record(s) selected. I didn&#39;t take any backup after I create this table. I use the previous backup in step 2.12345678910[db2v97i@db2srv ~]$ dateMon Mar 7 17:57:00 CST 2016--delete all the records [db2v97i@db2srv ~]$ db2 &quot;delete from fung.t1&quot;DB20000I The SQL command completed successfully.[db2v97i@db2srv ~]$ db2 &quot;select count(*) from fung.t1&quot;1 ----------- 0 1 record(s) selected. Generate the redirect restore command, I don&#39;t want to pollute current production environment. So I decide restore the DB/Tablespace in another place.123[db2v97i@db2srv ~]$ db2 &quot;restore db mysample rebuild with tablespace (SYSCATSPACE,FUNG) from /db2/backup/db2v97i/mysample/ taken at 20160307161004 redirect generate script redirect.clp&quot;DB20000I The RESTORE DATABASE command completed successfully. Edit the redirect.clp file to proper values, modify the DBPATH, LOGPATH and the DBNAME, and execute the restore operation.1234--change the DBPATH to /restore/mysample[db2v97i@db2srv ~]$ mkdir -p /restore/mysample--change the log path to /restore/mysample/log[db2v97i@db2srv ~]$ mkdir -p /restore/mysample/log After I edited the redirect.clp file, it should like below.12345678910111213141516171819[db2v97i@db2srv ~]$ grep -v ^- redirect.clp UPDATE COMMAND OPTIONS USING S ON Z ON MYSAMPLE_NODE0000.out V ON;SET CLIENT ATTACH_MEMBER 0;SET CLIENT CONNECT_MEMBER 0;RESTORE DATABASE MYSAMPLEREBUILD WITH TABLESPACE ( &quot;SYSCATSPACE&quot;, &quot;TEMPSPACE1&quot;, &quot;SYSTOOLSTMPSPACE&quot;, &quot;FUNG&quot;)FROM &apos;/db2/backup/db2v97i/mysample/&apos;TAKEN AT 20160307161004ON &apos;/restore/mysample&apos;INTO NEWDBNEWLOGPATH &apos;/restore/mysample/log&apos;REDIRECT;RESTORE DATABASE MYSAMPLE CONTINUE; Redirect the database into NEWDB with rebuild tablespace option:123456789101112131415161718[db2v97i@db2srv ~]$ db2 -tvf redirect.clp UPDATE COMMAND OPTIONS USING S ON Z ON MYSAMPLE_NODE0000.out V ONDB20000I The UPDATE COMMAND OPTIONS command completed successfully.SET CLIENT ATTACH_MEMBER 0DB20000I The SET CLIENT command completed successfully.SET CLIENT CONNECT_MEMBER 0DB20000I The SET CLIENT command completed successfully.RESTORE DATABASE MYSAMPLE REBUILD WITH TABLESPACE ( &quot;SYSCATSPACE&quot; , &quot;TEMPSPACE1&quot; , &quot;SYSTOOLSTMPSPACE&quot; , &quot;FUNG&quot; ) FROM &apos;/db2/backup/db2v97i/mysample/&apos; TAKEN AT 20160307161004 ON &apos;/restore/mysample&apos; INTO NEWDB NEWLOGPATH &apos;/restore/mysample/log&apos; REDIRECTSQL1277W A redirected restore operation is being performed. During a table space restore, only table spaces being restored can have their paths reconfigured. During a database restore, storage group storage paths and DMS table space containers can be reconfigured.DB20000I The RESTORE DATABASE command completed successfully.RESTORE DATABASE MYSAMPLE CONTINUEDB20000I The RESTORE DATABASE command completed successfully. Find out which logs are needed by rollforward operation, and copy those logs file into the new log path:123456789101112131415161718192021222324252627282930313233343536[db2v97i@db2srv ~]$ db2 rollforward database newdb QUERY STATUS Rollforward Status Input database alias = newdb Number of members have returned status = 1 Member ID = 0 Rollforward status = DB pending Next log file to be read = S0000380.LOG Log files processed = - Last committed transaction = 2016-03-07-08.10.12.000000 UTC[db2v97i@db2srv ~]$ db2 get db cfg |grep -i log Path to log files = /db2/log/db2v97i/mysample/NODE0000/LOGSTREAM0000/ First active log file = S0000385.LOG First log archive method (LOGARCHMETH1) = DISK:/db2/arch/mysample/[db2v97i@db2srv ~]$ find /db2 -name &quot;S0000380.LOG&quot;/db2/arch/mysample/db2v97i/MYSAMPLE/NODE0000/LOGSTREAM0000/C0000001/S0000380.LOG[db2v97i@db2srv ~]$ cp /db2/arch/mysample/db2v97i/MYSAMPLE/NODE0000/LOGSTREAM0000/C0000001/S000038*.LOG \\/restore/mysample/log/NODE0000/LOGSTREAM0000/[db2v97i@db2srv ~]$ cp /db2/log/db2v97i/mysample/NODE0000/LOGSTREAM0000/S0000385.LOG \\/restore/mysample/log/NODE0000/LOGSTREAM0000/[db2v97i@db2srv ~]$ db2 &quot;rollforward database newdb to 2016-03-07-17.57.00.000000 USING LOCAL TIME and stop&quot;SQL1271W Database &quot;NEWDB&quot; is recovered but one or more table spaces are offline on members or nodes &quot;0&quot;.[db2v97i@db2srv ~]$ db2 connect to newdb Database Connection Information Database server = DB2/LINUXX8664 10.1.5 SQL authorization ID = DB2V97I Local database alias = NEWDB[db2v97i@db2srv ~]$ db2 &quot;select count(*) from fung.t1&quot;1 ----------- 502 1 record(s) selected. And now, you can export the data from the redirect db to the source db:1234567891011121314151617181920212223242526272829303132333435363738394041424344--export from newdb[db2v97i@db2srv ~]$ db2 &quot;export to t1.ixf of ixf select * from fung.t1 &quot;SQL3132W The character data in column &quot;STATISTICS_PROFILE&quot; will be truncated to size &quot;32700&quot;.SQL3104N The Export utility is beginning to export data to file &quot;t1.ixf&quot;.SQL3105N The Export utility has finished exporting &quot;502&quot; rows.Number of rows exported: 502--import to sourcedb[db2v97i@db2srv ~]$ db2 terminateDB20000I The TERMINATE command completed successfully.[db2v97i@db2srv ~]$ db2 connect to mysample Database Connection Information Database server = DB2/LINUXX8664 10.1.5 SQL authorization ID = DB2V97I Local database alias = MYSAMPLE[db2v97i@db2srv ~]$ db2 &quot;select count(*) from fung.t1&quot;1 ----------- 0 1 record(s) selected.[db2v97i@db2srv ~]$ db2 &quot;import from t1.ixf of ixf allow write access insert into fung.t1&quot;SQL3150N The H record in the PC/IXF file has product &quot;DB2 02.00&quot;, date &quot;20160307&quot;, and time &quot;190757&quot;.SQL3153N The T record in the PC/IXF file has name &quot;t1.ixf&quot;, qualifier &quot;&quot;, and source &quot; &quot;.SQL3109N The utility is beginning to load data from file &quot;t1.ixf&quot;.SQL3110N The utility has completed processing. &quot;502&quot; rows were read from the input file.SQL3221W ...Begin COMMIT WORK. Input Record Count = &quot;502&quot;.SQL3222W ...COMMIT of any database changes was successful.SQL3149N &quot;502&quot; rows were processed from the input file. &quot;502&quot; rows were successfully inserted into the table. &quot;0&quot; rows were rejected.Number of rows read = 502Number of rows skipped = 0Number of rows inserted = 502Number of rows updated = 0Number of rows rejected = 0Number of rows committed = 502[db2v97i@db2srv ~]$ db2 &quot;select count(*) from fung.t1&quot;1 ----------- 502 1 record(s) selected. 4. summaryRecover a deleted table is very simple in Oracle, but you need recover it as soon as possible, because depends on your production environment, no one knows how long will the undo data retain in the undo tablespace. So when you created your database, modify the parameter &quot;undo_retention&quot; to meet your business requirments.In DB2, the &quot;dropped table recovery&quot; feature do not support export XML column, so when recovering this type of data, PIT recovery should be a better choice. Besides, import will generate lots of logs and may have big impact of performance, when loading large tables into the source db, db2 LOAD utilities will be more suitable. EOF","link":"/recovering-a-dropped-table-in-oracle-and-db2.html"},{"title":"无备份恢复丢失的数据文件","text":"1.环境模拟：Archive log模式下，无数据库备份，但有完整archivelog，模拟数据文件直接被OS命令删除，进行完全恢复的情况。 123456789101112131415161718192021[ora10g@db12c:/oradata/ora10g]$ sqlplus &quot;/as sysdba&quot; SQL*Plus: Release 10.2.0.4.0 - Production on Fri Aug 30 10:26:06 2013 Copyright (c) 1982, 2007, Oracle. All Rights Reserved. Connected to an idle instance. SQL&gt; startup ORACLE instance started. Total System Global Area 599785472 bytes Fixed Size 2085776 bytes Variable Size 163581040 bytes Database Buffers 427819008 bytes Redo Buffers 6299648 bytes Database mounted. ORA-01157: cannot identify/lock data file 5 - see DBWR trace file ORA-01110: data file 5: &apos;/oradata/ora10g/test01.dbf&apos; SQL&gt; archive log list; Database log mode Archive Mode Automatic archival Enabled Archive destination /u01/oracle/product/10gr2/dbs/arch Oldest online log sequence 25 Next log sequence to archive 27 Current log sequence 27 2.重新创建丢失的数据文件 123456789101112131415161718192021222324SQL&gt; select name from v$datafile; NAME -------------------------------------------------------------------------------- /oradata/ora10g/system01.dbf /oradata/ora10g/undotbs01.dbf /oradata/ora10g/sysaux01.dbf /oradata/ora10g/users01.dbf /oradata/ora10g/test01.dbf SQL&gt; alter database create datafile &apos;/oradata/ora10g/test01.dbf&apos;; Database altered. SQL&gt; recover datafile 5; ORA-00279: change 379376 generated at 08/30/2013 10:14:43 needed for thread 1 ORA-00289: suggestion : /u01/oracle/product/10gr2/dbs/arch1_24_824210512.dbf ORA-00280: change 379376 for thread 1 is in sequence #24 Specify log: &#123;&lt;ret&gt;=suggested | filename | AUTO | CANCEL&#125; auto Log applied. Media recovery complete.&lt;/ret&gt; SQL&gt; alter database open; 参考：http://www.eygle.com/archives/2004/10/recover_without_datafile_backup.html","link":"/recovery-datafile-without-backup.html"},{"title":"管理redo文件","text":"Oracle 的Online redo log 是为确保已经提交的事务不会丢失而建立的一个机制。 因为这种健全的机制，才能让我们在数据库crash时，恢复数据，保证数据不丢失。 1.Redo简介 REDO为oracle重做机制，redo log最重要的功能是记录所有对数据库的修改信息，这些信息可用于实例崩溃的恢复。在数据库中，redo的功能主要通过三个组件来实现：redo log buffer，LGWR和redo log file。 Redo log buffer为SGA内存结构，允许用户进程将他们的redo entries(重做条目)写入内存以便加速对数据库修改的追踪，redo log buffer避免了用户进程额外花时间将重做条目直接写入磁盘，而是将所有用户进程产生的重做条目写入内存，从而避免导致数据库性能下降的磁盘资源的争用。 Redo Entries包含了由于增删改DML及create、alter或drop所做的修改操作而需要对数据库重新组织或重做的必须信息。这些信息在必要时可用用于数据库的恢复。 2.为什么要有redo Redo的作用是能保证数据库的回退性。其工作机制与LGWR，CKPT，DBWn密不可分。首先说说DBWn，将内存数据写入磁盘是一个相当复杂的过程，在此过程中，首先要保证安全，所谓安全，就是在写的过程中，如果发生实例崩溃，要有一套完整的机制保证用户已提交但尚未写入磁盘的数据不丢失；再者也要保证写的效率，磁盘I/O是最昂贵的操作，应该尽可能的将内存的脏数据收集到一定程度，再批量写入。 这种机制确实大大提高了性能，但可以想象的是，当实例崩溃，必然导致部分已提交但尚未写入磁盘的数据丢失。那么该如何保证这些脏数据的安全性呢？于是Oracle引进redo机制，通过连续的、顺序的日志条目写出，而将随机的、分散的数据块写出推延。跟redo log buffer一样，redo log file也是循环使用的。当一个日志文件写满，会发生日志切换动作，此时，数据库会发生一个检查点事件(Checkpoint)，Checkpoint会促使DBWn进程将已经写入日志文件记录的脏数据写回磁盘。 由于redo机制的保护，当实例崩溃时候，Oracle可以通过redo重演进行数据恢复。此时又会产生一个问题：该从何时恢复呢？ 如果读取的redo过多，恢复时间必然过长；如果读取的redo太少，也意味着DBWn写太频繁，导致IO过高，这也是不合理的。为了确定这个恢复的时间点，Oracle引进了CKPT这个后台进程。 当Checkpoint发生时，DBWn会从内存写脏数据到磁盘，Checkpoint完成后，CKPT进程会相应的更新控制文件和数据文件头，记录检查点信息。因此，在这个Checkpoint前的所有数据都保证已经写入磁盘了，此后的实例崩溃，则只需要从最后一次完成的Checkpoint恢复即可。 3.Redo Log File的管理 3.1.查找日志文件 123456789SQL&gt; select thread#,v$log.group#,v$logfile.type,member from v$log,v$logfile where v$log.group#=v$logfile.group#; THREAD# GROUP# TYPE MEMBER ---------- ---------- ------- -------------------------------------------------- 1 1 ONLINE +DATA/racdb/onlinelog/group_1.257.837708897 1 2 ONLINE +DATA/racdb/onlinelog/group_2.258.837708905 2 3 ONLINE +DATA/racdb/onlinelog/group_3.265.837711217 2 4 ONLINE +DATA/racdb/onlinelog/group_4.266.837711231 3.2.增加日志组(默认为100M) 1234567891011121314SQL&gt; alter database add logfile thread 1 group 5; Database altered. SQL&gt; select thread#,v$log.group#,v$logfile.type,member 2 from v$log,v$logfile 3 where v$log.group#=v$logfile.group#; THREAD# GROUP# TYPE MEMBER ---------- ---------- ------- -------------------------------------------------- 1 1 ONLINE +DATA/racdb/onlinelog/group_1.257.837708897 1 2 ONLINE +DATA/racdb/onlinelog/group_2.258.837708905 2 3 ONLINE +DATA/racdb/onlinelog/group_3.265.837711217 2 4 ONLINE +DATA/racdb/onlinelog/group_4.266.837711231 1 5 ONLINE +DATA/racdb/onlinelog/group_5.291.842790561 备注：非OMF管理需指定文件路径 12SQL&gt; alter database add logfile group 5 (&apos;/oradata/linora/redo5_a.log&apos;) size 100m; SQL&gt; alter database add logfile group 5 (&apos;/oradata/linora/redo5_a.log&apos;,&apos;/oradata/linora/redo5_b.log&apos;) size 100m; 3.3.添加日志组成员 1234567891011121314151617SQL&gt; alter database add logfile member &apos;+DATA/racdb/onlinelog/redo5_b.log&apos; to group 5; Database altered. SQL&gt; select thread#,v$log.group#,v$logfile.type,member 2 from v$log,v$logfile 3 where v$log.group#=v$logfile.group#; THREAD# GROUP# TYPE MEMBER ---------- ---------- ------- -------------------------------------------------- 1 1 ONLINE +DATA/racdb/onlinelog/group_1.257.837708897 1 2 ONLINE +DATA/racdb/onlinelog/group_2.258.837708905 2 3 ONLINE +DATA/racdb/onlinelog/group_3.265.837711217 2 4 ONLINE +DATA/racdb/onlinelog/group_4.266.837711231 1 5 ONLINE +DATA/racdb/onlinelog/group_5.291.842790561 1 5 ONLINE +DATA/racdb/onlinelog/redo5_b.log 6 rows selected. 3.4.删除成员 123SQL&gt; alter database drop logfile member &apos;+DATA/racdb/onlinelog/redo5_b.log&apos;; Database altered. 3.5.删除组 1234567891011121314SQL&gt; ALTER DATABASE DROP LOGFILE GROUP 5; Database altered. SQL&gt; select thread#,v$log.group#,v$logfile.type,member 2 from v$log,v$logfile 3 where v$log.group#=v$logfile.group#; THREAD# GROUP# TYPE MEMBER ---------- ---------- ------- -------------------------------------------------- 1 1 ONLINE +DATA/racdb/onlinelog/group_1.257.837708897 1 2 ONLINE +DATA/racdb/onlinelog/group_2.258.837708905 2 3 ONLINE +DATA/racdb/onlinelog/group_3.265.837711217 2 4 ONLINE +DATA/racdb/onlinelog/group_4.266.837711231 备注：删除前必须遵守如下原则，每个实例必须至少有两个日志组；当一个组处于ACTIVE或者CURRENT的状态时不可删除；只有status(v$log)为inactive并且archived 为YES时方可删除日志组。删除日志组的操作只对数据库进行更改，操作系统的文件尚未删除；当删除时适用DROP LOGFILE GROUP N语句时，此时GROUP N内的所有成员都将被删除。 对于日志文件三个状态inactive，active和current在恢复中有如下原理：Oracle日志是用循环写的方式，日志的切换(log switch)到触发checkpoint动作，checkpoint会启动DBWR将内存中的脏数据写入磁盘。而DBWR写磁盘操作为分散写，这就导致DBWR可能需要较长时间才能将脏数据写完，如果日志的切换要等待DBWR写完，就形成了等待，因此8i以后，使用了Incremental Checkpoint算法。当发生checkpoint动作时，只是在控制文件中记录当时的Checkpoint SCN，DBWR同时也开始后台写进程。在这种情况下，有可能出现这种情况，三个日志组中，group1的内容已经由DBWR写完，则标记状态为inactive，group2对应的DBWR还没完成，则标记为active，group3正在使用，标记为current。对于active和current状态的日志而言，日志里面的修改都尚未写入磁盘，因此在恢复的时候，这两个日志都需要，区别在于，如果active日志丢失，由于active已经归档，可用归档日志代替，不会造成数据丢失；如果current日志丢失，则会丢失数据。 增加日志文件大小需要重建日志文件。 4.Redo log恢复 Redo log在某些情况下可能会被误删，可分几种情况分析。 4.1.恢复非活动redo log 如果丢失的是INACTIVE的日志组，由于已经完成checkpoint动作，数据不会丢失，此时只需要clear重建该日志即可恢复。 SQL> select group#,thread#,bytes,archived,status from v$log; GROUP# THREAD# BYTES ARC STATUS ---------- ---------- ---------- --- ---------------- 1 1 52428800 YES INACTIVE 2 1 52428800 NO CURRENT 3 1 52428800 YES INACTIVE SQL> SQL> !mv /oradata/datafile/linora/redo03.log ~ 切换日志，查看后台日志： 123456789SQL&gt; alter system archive log current; alter system archive log current *ERROR at line 1: ORA-00313: open failed for members of log group 3 of thread 1 ORA-00312: online log 3 thread 1: &apos;/oradata/datafile/linora/redo03.log&apos; ORA-27037: unable to obtain file status Linux-x86_64 Error: 2: No such file or directory Additional information: 3 查看当前数据库状态： 1234SQL&gt; select open_mode from v$database; OPEN_MODE -------------------- READ WRITE 清理日志： 12345678910111213141516171819SQL&gt; alter database clear unarchived logfile group 3; Database altered. SQL&gt; alter system archive log current; System altered. SQL&gt; alter system archive log current; System altered. SQL&gt; alter system archive log current; System altered. SQL&gt; select group#,thread#,bytes,archived,status from v$log; GROUP# THREAD# BYTES ARC STATUS ---------- ---------- ---------- --- ---------------- 1 1 52428800 NO CURRENT 2 1 52428800 YES INACTIVE 3 1 52428800 YES INACTIVE 如果实例关闭为shutdown immediate，按照上述步骤恢复即可，如果shutdown abort，则需要从备份或者归档恢复。 在异机恢复中，绝大多数情况都是原文件路径跟目标文件路径不一致的，在restore database完成之后，有时候忘记更改控制文件中redo log的位置，通过可以在open resetlogs前完成clear log的动作： SQL> select member from v$logfile; MEMBER -------------------------------------------------------------------------------- /oradata/linora/redo/redo03.log /oradata/linora/redo/redo02.log /oradata/linora/redo/redo01.log SQL> alter database rename file '/oradata/linora/redo/redo03.log' to '/oradata_test/linora/redo/redo03.log'; ... SQL> alter database clear unarchived logfile group 1; ... SQL> alter database open resetlogs; 4.2.恢复当前或者活动redo log 如果当前或者ACTIVE状态的日志组被删除，则会发生数据丢失。 查看日志状态： 1234567SQL&gt; select group#,thread#,bytes,archived,status from v$log; GROUP# THREAD# BYTES ARC STATUS ---------- ---------- ---------- --- ---------------- 1 1 52428800 YES INACTIVE 2 1 52428800 YES ACTIVE 3 1 52428800 NO CURRENT 模拟删除group 2： 1SQL&gt; !mv /oradata/datafile/linora/redo02.log ~ 切换日志，后台开始报错： 12345678910SQL&gt; alter system switch logfile; System altered. Errors in file /u01/app/oracle/diag/rdbms/linora/linora/trace/linora_arc2_4896.trc: ORA-00313: open failed for members of log group 2 of thread 1 ORA-00312: online log 2 thread 1: &apos;/oradata/datafile/linora/redo02.log&apos; ORA-27037: unable to obtain file status Linux-x86_64 Error: 2: No such file or directory Additional information: 3 在我的实验过程中，重启数据库会报错，需要启动到mount状态： 1234567891011121314151617181920212223242526SQL&gt; shutdown immediate Database closed. Database dismounted. ORACLE instance shut down. SQL&gt; startup ORACLE instance started. Total System Global Area 835104768 bytes Fixed Size 2257840 bytes Variable Size 536874064 bytes Database Buffers 289406976 bytes Redo Buffers 6565888 bytes Database mounted. ORA-03113: end-of-file on communication channel Process ID: 5062 Session ID: 125 Serial number: 5 SQL&gt; startup mount ORACLE instance started. Total System Global Area 835104768 bytes Fixed Size 2257840 bytes Variable Size 536874064 bytes Database Buffers 289406976 bytes Redo Buffers 6565888 bytes Database mounted. 在mount状态进行clear log的动作： 12345678910111213141516171819SQL&gt; alter database clear unarchived logfile group 2; Database altered. SQL&gt; alter database clear unarchived logfile group 3; Database altered. SQL&gt; alter database clear unarchived logfile group 1; Database altered. SQL&gt; alter database open; Database altered. SQL&gt; select group#,thread#,bytes,archived,status from v$log; GROUP# THREAD# BYTES ARC STATUS ---------- ---------- ---------- --- ---------------- 1 1 52428800 YES UNUSED 2 1 52428800 NO CURRENT 3 1 52428800 YES UNUSED 上述情况是正常关闭数据库，即是是正常关闭的库，也有可能导致日志无法清理，需要作一个基于取消的不完全恢复。那如果不正常关闭，会发生什么情况呢？ 1234567891011121314151617181920212223242526272829303132SQL&gt; select group#,thread#,bytes,archived,status from v$log; GROUP# THREAD# BYTES ARC STATUS ---------- ---------- ---------- --- ---------------- 1 1 52428800 YES UNUSED 2 1 52428800 NO CURRENT 3 1 52428800 YES UNUSED SQL&gt; !mv /oradata/datafile/linora/redo02.log ~ SQL&gt; shutdown abort ORACLE instance shut down. SQL&gt; startup mount ORACLE instance started. Total System Global Area 835104768 bytes Fixed Size 2257840 bytes Variable Size 536874064 bytes Database Buffers 289406976 bytes Redo Buffers 6565888 bytes Database mounted. SQL&gt;SQL&gt; alter database clear unarchived logfile group 1; Database altered. SQL&gt; alter database clear unarchived logfile group 2; alter database clear unarchived logfile group 2 *ERROR at line 1: ORA-01624: log 2 needed for crash recovery of instance linora (thread 1) ORA-00312: online log 2 thread 1: &apos;/oradata/datafile/linora/redo02.log&apos; SQL&gt; alter database clear unarchived logfile group 3; Database altered. 显然，在被删除的日志文件上，无法清除。这个时候需要通过RMAN作不完全恢复， 123456789SQL&gt; recover database until cancel; ORA-00279: change 1084383 generated at 03/21/2014 15:50:43 needed for thread 1 ORA-00289: suggestion : /oradata/arch/1_21_842800816.arc ORA-00280: change 1084383 for thread 1 is in sequence #21 Specify log: &#123;&amp;lt;RET&gt;=suggested | filename | AUTO | CANCEL&#125; cancel ORA-01547: warning: RECOVER succeeded but OPEN RESETLOGS would get error below ORA-01194: file 1 needs more recovery to be consistent ORA-01110: data file 1: &apos;/oradata/datafile/linora/system01.dbf&apos; 基于取消的不完全恢复也不行！！！只能从备份恢复： 123456789101112[oracle@linora:/home/oracle]$ ls -lt /oradata/arch/ total 199680 -rw-r----- 1 oracle oinstall 1536 Mar 21 15:43 1_17_842800816.arc RMAN&gt; run&#123; 2&gt; set until sequence 17; 3&gt; restore database; 4&gt; recover database; 5&gt; alter database open resetlogs; 6&gt; &#125;RMAN&gt; alter database open resetlogs; database opened 如果连备份都没有，那就只能通过_allow_resetlogs_corruption隐藏参数强制跳过一致性检查去开启数据库，然后导出数据，再重新导入数据。","link":"/redo-manage.html"},{"title":"重做记录","text":"大师Jonathan Lewis在《Oracle Core》提到Oracle的一个重要特性，就是在Oracle 6中首次提出的change vector，即改变向量。改变向量是描述数据块变化的机制，是redo和undo的核心。关于数据改变的方法，大师在《Oracle Core》描述如下： 创建一个重做改变向量，描述如何往undo块插入一条undo记录 创建一个重做改变向量，描述数据块的改变 合并这两个重做记录为一条日志记录，并写到重做日志缓冲区 向undo块插入undo记录 改变数据块中的数据在理解重做记录和改变向量之前，需要理解SCN、数据块版本号和RBA等概念。 1. 基本概念1.1 SCNSCN是Oracle的内部时钟机制，SCN由两部分共6字节组成，4字节为base(底值)，2字节为Wrap(进位值)。当前的base随时间的流逝和变更操作的执行而递增，在用尽之后开始循环，此时wrap递增。123456789--查询SCN的方法SYS@linora&gt; select current_scn from v$database 2 union all 3 select dbms_flashback.get_system_change_number from dual;CURRENT_SCN----------- 3107373 3107373 如果之前数据库是干净关闭的，mount状态下查看控制文件和数据文件头部信息的SCN，可以发现这两者的值是一样的：123456789101112131415161718192021222324252627282930313233343536373839404142--dump控制文件的scnSYS@linora&gt; alter session set events &apos;immediate trace name controlf level 8&apos;;Session altered.--Trace 文件内容Database checkpoint: Thread=1 scn: 0x0000.002ded1f--Database checkpoint scn...Controlfile Checkpointed at scn: 0x0000.002de9f1 08/22/2014 14:36:37 -- controlfile checkpoint scn...***************************************************************************DATA FILE RECORDS*************************************************************************** (size = 520, compat size = 520, section max = 100, section in-use = 10, last-recid= 161, old-recno = 0, last-recno = 0) (extent = 1, blkno = 11, numrecs = 100)DATA FILE # 1: name # 4: /oradata/datafile/linora/system01.dbfCheckpoint cnt:539 scn: 0x0000.002ded1f 08/22/2014 14:46:09 -- datafile checkpoint scn in controflile ...DATA FILE # 2: name # 5: /oradata/datafile/linora/sysaux01.dbfcreation size=76800 block size=8192 status=0xe head=5 tail=5 dup=1 tablespace 1, index=2 krfil=2 prev_file=0 unrecoverable scn: 0x0000.00000000 01/01/1988 00:00:00 Checkpoint cnt:534 scn: 0x0000.002ded1f 08/22/2014 14:46:09--尝试在mount状态下dump数据文件和数据文件头，发现和控制文件dump的scn是一致的SYS@linora&gt; alter session set events &apos;immediate trace name file_hdrs level 8&apos;;Session altered.DATA FILE # 1: name # 4: /oradata/datafile/linora/system01.dbfcreation size=89600 block size=8192 status=0xe head=4 tail=4 dup=1 tablespace 0, index=1 krfil=1 prev_file=0 unrecoverable scn: 0x0000.00000000 01/01/1988 00:00:00 Checkpoint cnt:539 scn: 0x0000.002ded1f 08/22/2014 14:46:09 Stop scn: 0x0000.002ded1f 08/22/2014 14:46:09 ...DATA FILE # 2: name # 5: /oradata/datafile/linora/sysaux01.dbfcreation size=76800 block size=8192 status=0xe head=5 tail=5 dup=1 tablespace 1, index=2 krfil=2 prev_file=0 unrecoverable scn: 0x0000.00000000 01/01/1988 00:00:00 Checkpoint cnt:534 scn: 0x0000.002ded1f 08/22/2014 14:46:09 Stop scn: 0x0000.002ded1f 08/22/2014 14:46:09 SCN是以scn: 0x0000.002ded1f存储在dump文件中，可以通过函数转换成16进制：1234SYS@linora&gt; select to_number(&apos;2ded1f&apos;,&apos;xxxxxx&apos;) from dual;TO_NUMBER(&apos;2DED1F&apos;,&apos;XXXXXX&apos;)---------------------------- 3009823 1.2 数据块版本当同一个SCN包含多条重做记录时候，说明有一个以上的操作分配到了同样的SCN，此时，引入一个SUBSCN，如&#39;SCN: 0x0000.002de89d SUBSCN: 1&#39;，当修改完成后，SCN和SUBSCN会被保存在被修改的数据块的头部，占用7字节，但此时SUBSCN变为SEQ，SCN+SEQ就是数据块版本号：12345SYS@linora&gt; ALTER SYSTEM DUMP LOGFILE &apos;/oradata/datafile/linora/redo02.log&apos;;System altered.--redo record头部信息REDO RECORD - Thread:1 RBA: 0x000097.00000002.0010 LEN: 0x026c VLD: 0x05SCN: 0x0000.002de89d SUBSCN: 1 08/22/2014 14:22:02 --修改前版本号 1.3 RBARBA全称为Redo Byte Address，其作用类似rowid对于表的作用。即重做日志中的物理地址，RBA由四部分组成：日志线程号、日志序列号、日志文件块号和日志文件块字节偏移量，共10字节。1234567SYS@linora&gt; ALTER SYSTEM DUMP LOGFILE &apos;/oradata/datafile/linora/redo02.log&apos;;System altered.SYS@linora&gt; select value from v$diag_info where name=&apos;Default Trace File&apos;;--Trace文件部分信息DUMP OF REDO FROM FILE &apos;/oradata/datafile/linora/redo02.log&apos;REDO RECORD - Thread:1 RBA: 0x00009a.00000002.0010 LEN: 0x0080 VLD: 0x06SCN: 0x0000.002f0ea5 SUBSCN: 1 08/23/2014 22:56:28 可以看到，在dump文件中，RBA以RBA: 0x00009a.00000002.0010的形式存在，其含义为Thread 1，log sequence=154的redo log的第2个块中的第16字节处，对于16进制转换，参照如下方法，文件结尾后面总结了一些比较常用的进制转换方法。1234SYS@linora&gt; select to_number(&apos;9a&apos;,&apos;xxxxxxx&apos;) from dual;TO_NUMBER(&apos;9A&apos;,&apos;XXXXXXX&apos;)------------------------- 154 2. 重做记录本例以修改hr.empployees中员工号为100的薪资(修改后薪水为原来的120%)为例，来简单探索重做记录和改变向量。123456--先查看当前记录所在行的物理地址和原来的薪水SYS@linora&gt; select rowid,salary,first_name,last_name 2 from hr.employees where employee_id=100;ROWID SALARY FIRST_NAME LAST_NAME------------------ ---------- -------------------- -------------------------AAAUsBAAIAAACzUAAA 24000 Steven King rowid以Base64的形式出现，该结构前6位代表segment_id—AAAUsB(84737)，随后三位代表数据文件号—AAI(8)，接下来的6位代表数据块编号—AAACzU(11476)，最后三位代表行号—AAA(0)。 因此，在上述结果中，emp id=100的员工其数据存在的物理位置为：存储在第8号文件的第11476块上第0行(关于ROWID的说明请参照Oracle ROWID学习)。使用dbms_rowid函数查看：12345678SYS@linora&gt; SELECT DBMS_ROWID.ROWID_OBJECT(rowid) &quot;OBJECT&quot;, 2 DBMS_ROWID.ROWID_RELATIVE_FNO(rowid) &quot;FILE&quot;, 3 DBMS_ROWID.ROWID_BLOCK_NUMBER(rowid) &quot;BLOCK&quot;, 4 DBMS_ROWID.ROWID_ROW_NUMBER(rowid) &quot;ROW&quot; 5 FROM hr.employees where employee_id=100; OBJECT FILE BLOCK ROW---------- ---------- ---------- ---------- 84737 8 11476 0 由于redo log包含的范围比较广，因此在dump日志文件的时候可基于scn值去dump相关时间段的内容(其他方式的dump，如基于DBA，请参照文章结尾)：12345678910111213141516SYS@linora&gt; set serverout onSYS@linora&gt; declare 2 SCN1 number; 3 SCN2 number; 4 begin 5 select current_scn into SCN1 from v$database; 6 dbms_output.put_line(&apos;Before Updata SCN: &apos;||SCN1); 7 update hr.employees set salary=salary*1.2 where employee_id=100; 8 commit; 9 select current_scn into SCN2 from v$database; 10 dbms_output.put_line(&apos;After Update SCN: &apos;||SCN2); 11 end; 12 /Before Updata SCN: 3109548After Update SCN: 3109551PL/SQL procedure successfully completed. 查找当前日志文件所在路径：1234567SYS@linora&gt; col member for a50SYS@linora&gt; select member,sequence# from v$logfile a,v$log b 2 where b.group#=a.group# 3 and b.status=&apos;CURRENT&apos;;MEMBER SEQUENCE#-------------------------------------------------- ----------/oradata/datafile/linora/redo03.log 155 dump相关日志文件：12SYS@linora&gt; alter system dump logfile &apos;/oradata/datafile/linora/redo03.log&apos; scn min 3109548 scn max 3109551;System altered. 2.1 头部信息123REDO RECORD - Thread:1 RBA: 0x00009b.00002c33.0010 LEN: 0x0278 VLD: 0x05SCN: 0x0000.002f72ac SUBSCN: 1 08/24/2014 17:14:38(LWN RBA: 0x00009b.00002c33.0010 LEN: 0002 NST: 0001 SCN: 0x0000.002f72ab) 重做记录头部信息包含了以下信息：RBA，数据块版本号等。以上信息表明重做记录的头部信息记录在Thread 1，log sequence#为155上(和之前查询的结果一致)的第11315块上的第16字节处。当前数据块版本号：SCN: 0x0000.002f72ac SUBSCN: 1，转换如下：123456789101112SYS@linora&gt; select to_number(&apos;9b&apos;,&apos;xxxxxxx&apos;) from dual;TO_NUMBER(&apos;9B&apos;,&apos;XXXXXXX&apos;)------------------------- 155SYS@linora&gt; select to_number(&apos;2c33&apos;,&apos;xxxxxxx&apos;) from dual;TO_NUMBER(&apos;2C33&apos;,&apos;XXXXXXX&apos;)--------------------------- 11315SYS@linora&gt; select to_number(&apos;10&apos;,&apos;xxxxxx&apos;) from dual;TO_NUMBER(&apos;10&apos;,&apos;XXXXXX&apos;)------------------------ 16 2.2 CHANGE # 1123CHANGE # 1 TYP:0 CLS:23 AFN:3 DBA:0x00c000b0 OBJ:4294967295 SCN:0x0000.002f724b SEQ:1 OP:5.2 ENC:0 RBL:0ktudh redo: slt: 0x0004 sqn: 0x00000530 flg: 0x000a siz: 184 fbi: 0 uba: 0x00c0cc3e.00f6.01 pxid: 0x0000.000.00000000 第一个改变向量是记录了如何对3号文件的176块进行修改，该数据块是undo segment头部，地址由AFN绝对文件号(对应v$datafile.file#)和DBA(Data Block Address)表示。当前数据块版本号为：SCN:0x0000.002f724b SEQ:1，修改数据后此数据块的版本号为:SCN: 0x0000.002f72ac SUBSCN: 1 (来自重做记录头部信息)。其中DBA包括文件编号和数据块编号，长度为4字节，使用dbms_utility可以进行转换：123456789SYS@linora&gt; select to_number(&apos;c000b0&apos;,&apos;xxxxxxx&apos;) from dual;TO_NUMBER(&apos;C000B0&apos;,&apos;XXXXXXX&apos;)----------------------------- 12583088SYS@linora&gt; select dbms_utility.data_block_address_file(12583088) as rfile,dbms_utility.data_block_address_block(12583088) as block from dual; RFILE BLOCK---------- ---------- 3 176 通过AFN和DBA查找对象：123456789101112131415161718SYS@linora&gt; col tablespace_name for a20 SYS@linora&gt; col segment_type for a10 SYS@linora&gt; col segment_name for a20 SYS@linora&gt; col owner for a8 SYS@linora&gt; SELECT tablespace_name, segment_type, owner, segment_name 2 FROM dba_extents 3 WHERE file_id = &amp;fileid 4 and &amp;blockid between block_id AND block_id + blocks - 1;Enter value for fileid: 3old 3: WHERE file_id = &amp;fileidnew 3: WHERE file_id = 3Enter value for blockid: 176old 4: and &amp;blockid between block_id AND block_id + blocks - 1new 4: and 176 between block_id AND block_id + blocks - 1TABLESPACE_NAME SEGMENT_TY OWNER SEGMENT_NAME-------------------- ---------- -------- --------------------UNDOTBS1 TYPE2 UNDO SYS _SYSSMU4_3538150892$ 很明显，当前矢量修改的是undo segment &#39;_SYSSMU4_3538150892$&#39;。修改undo segment的目的是创建事务表。这是因为update命令发起了事务，Oracle必须为每个事务分配undo segment，在undo segment中创建一张事务表，该表用来保存事务产生的旧数据，用于支持事务的回滚和查询的一致性读。一个事务产生的所有旧数据都存放在同一个事务表中，一个undo segment又可以包含多个事务表。 2.3 CHANGE # 212345678910111213141516171819202122CHANGE # 2 TYP:1 CLS:24 AFN:3 DBA:0x00c0cc3e OBJ:4294967295 SCN:0x0000.002f72ac SEQ:1 OP:5.1 ENC:0 RBL:0ktudb redo: siz: 184 spc: 0 flg: 0x000a seq: 0x00f6 rec: 0x01 xid: 0x0004.004.00000530 ktubl redo: slt: 4 rci: 0 opc: 11.1 [objn: 84737 objd: 84737 tsn: 8]Undo type: Regular undo Begin trans Last buffer split: No Temp Object: No Tablespace Undo: No 0x00000000 prev ctl uba: 0x00c0cc3d.00f6.22 prev ctl max cmt scn: 0x0000.002f6e01 prev tx cmt scn: 0x0000.002f6e0a txn start scn: 0xffff.ffffffff logon user: 0 prev brb: 12635193 prev bcl: 0 BuExt idx: 0 flg2: 0KDO undo record:KTB Redo op: 0x04 ver: 0x01 compat bit: 4 (post-11) padding: 1op: L itl: xid: 0x000a.020.00000513 uba: 0x00c003fe.00d2.01 flg: C--- lkc: 0 scn: 0x0000.002f0291KDO Op code: URP row dependencies Disabled --Operation Code为Update xtype: XA flags: 0x00000000 bdba: 0x02002cd4 hdba: 0x02002cd2 --bdba:正在更新的块的地址 hdba:该对象段头块地址itli: 2 ispac: 0 maxfr: 4858 --itli：事务槽，即第二个事务槽tabn: 0 slot: 0(0x0) flag: 0x2c lock: 0 ckix: 0 ncol: 11 nnew: 1 size: 0 --size：表示存储数据是否改变，如果原来是三位，后面增加了一位，则size：1col 7: [ 3] c3 03 29 --update前的数据 第一个矢量负责创建事务表，第二个则负责在事务表中创建具体的撤销数据，以上信息记录了如何对AFN=3，DBA:0x00c0cc3e(52286号)的数据块进行修改。在tabn中，slot：0(0x0)表示数据块中的第一行被update命令修改，col 7: [ 3] c3 03 29表示改行的第8个字段，在update前是16进制c30329，长度3字节，可以通过dump查看：1234SYS@linora&gt; select dump(24000,16) from dual;DUMP(24000,16)--------------------Typ=2 Len=3: c3,3,29 2.4 CHANGE # 3前两个变更矢量只是表明undo record该如何生成，尚未提及100号员工所在的数据块—8号文件11476块如何修改，这是CHANGE # 3的任务。12345678910111213CHANGE # 3 TYP:2 CLS:1 AFN:8 DBA:0x02002cd4 OBJ:84737 SCN:0x0000.002f7210 SEQ:1 OP:11.5 ENC:0 RBL:0KTB Redo op: 0x11 ver: 0x01 compat bit: 4 (post-11) padding: 1op: F xid: 0x0004.004.00000530 uba: 0x00c0cc3e.00f6.01Block cleanout record, scn: 0x0000.002f72ac ver: 0x01 opt: 0x02, entries follow... itli: 1 flg: 2 scn: 0x0000.002f7210KDO Op code: URP row dependencies Disabled xtype: XA flags: 0x00000000 bdba: 0x02002cd4 hdba: 0x02002cd2itli: 2 ispac: 0 maxfr: 4858tabn: 0 slot: 0(0x0) flag: 0x2c lock: 2 ckix: 0ncol: 11 nnew: 1 size: 0col 7: [ 3] c3 03 59 --修改后的数据 第一行记录了AFN和DBA，tabn记录了slot(行)及最后以后记录了col(字段)，因此，这个矢量才是update的真正目的。将8号文件11476块的第一行(slot 0)的第八个字段(col 7)修改为c30359，这个16进制的转换涉及到Oracle存储Number类型的内部原理，可参照老盖的Blog:How Oracle Store Number internal，根据老盖的介绍作一个简要的说明： 由于[ 3]是表示以三位存储这个16进制，因此，需要分开c3-03-59分别转换成10进制：12345678SYS@linora&gt; select to_number(&apos;c3&apos;,&apos;xxxxxx&apos;) from dual;TO_NUMBER(&apos;C3&apos;,&apos;XXXXXX&apos;)------------------------ 195SYS@linora&gt; select to_number(&apos;59&apos;,&apos;xxxxxx&apos;) from dual;TO_NUMBER(&apos;59&apos;,&apos;XXXXXX&apos;)------------------------ 89 因此，实际存储则为十进制:195,3,89，按照老盖的说明： 指数：195-193=2，为正数，数字1：3-1 = 21002-0 20000 ，数字2: 89 -1 =881001-0 8800 。因此，这个Number类型的值为20000+8800=28800跟我们预期的结果一致！使用dump函数dump一下28800的16进制和10进制：12345678910--16进制SYS@linora&gt; select dump(28800,16) from dual;DUMP(28800,16)--------------------Typ=2 Len=3: c3,3,59--10进制SYS@linora&gt; select dump(28800,10) from dual;DUMP(28800,10)---------------------Typ=2 Len=3: 195,3,89 用其他函数验证(dump逆函数)：12345678910--16进制转10进制SYS@linora&gt; select utl_raw.cast_to_number(&apos;c30359&apos;) from dual;UTL_RAW.CAST_TO_NUMBER(&apos;C30359&apos;)-------------------------------- 28800--10进制转16进制SYS@linora&gt; select utl_raw.cast_from_number(&apos;28800&apos;) value from dual;VALUE------------------------------C30359 2.5 CHANGE # 4123456789101112131415CHANGE # 4 MEDIA RECOVERY MARKER SCN:0x0000.00000000 SEQ:0 OP:5.19 ENC:0session number = 261serial number = 119current username = SYSlogin username = SYSclient info = OS username = oracleMachine name = linoraOS terminal = pts/1OS process id = 2215OS program name = sqlplus@linora (TNS V1-V3)transaction name = version 186647552audit sessionid 4294967295Client Id = 第四个改变向量没有说明任何更改意图，其作用包括提供恢复操作完结点，提供有限的事后审计。上述update命令的目的是修改8号文件的11476块(CHANGE # 3)，但是要先在CHANGE # 1中往undo segment即3号文件(undotbs01.bdf)176号数据块注册事务表，并在事务表的的3号文件52286块保存undo data以保证读一致性及回滚，因此，在Oracle数据库中，最简单的DML指令至少要修改三个数据块。 3. OP Code说明在以上的重做记录分析中，存在着一个重要的操作代码，OP=Operation Code，代表了操作的类型：对于DML事务，Level为11，具体操作代码：对于UNDO的操作，其代码如下所示：因此，在CHANGE # 1 OP=5.2，表示更新undo segment头部信息，CHANGE # 2 OP=5.1表示undo segment头部信息，CHANGE # 3 OP=11.5表示更新操作。 4. 相关dump redo方法archive log属于redo的离线，因此dump archived log语法和redo一样，参照MOS：1031381.612345678910111213141516--dump redo headeralter session set events &apos;immediate trace name redohdr level 10&apos;;Session altered.--dump an entire redo file alter system dump logfile &apos;/oradata/datafile/linora/redo03.log&apos;;--dump redo base on DBA --10g及以上版本： ALTER SYSTEM DUMP LOGFILE &apos;/oradata/datafile/linora/redo03.log&apos; DBA MIN 5 31125 DBA MAX 5 31150; --9i版本： ALTER SYSTEM DUMP LOGFILE &apos;/oradata/datafile/linora/redo03.log&apos; DBA MIN 5 . 31125 DBA MAX 5 . 31150;--dump redo base on RBAALTER SYSTEM DUMP LOGFILE &apos;/oradata/datafile/linora/redo03.log&apos; RBA MIN 2050 . 13255 RBA MAX 2255 . 15555;--dump redo base on SCNalter system dump logfile &apos;/oradata/datafile/linora/redo03.log&apos; scn min 3109548 scn max 3109551;--dump redo base on timeALTER SYSTEM DUMP LOGFILE &apos;/oradata/datafile/linora/redo03.log&apos; TIME MIN 299425687 TIME MAX 299458800; 5. 相关函数简单说明5.1 dumpOracle通过相应的数据库内部算法转换来进行数据存储，dump函数能查看数据在Oracle内部存储内容。1234567891011--用法：DUMP(expr[,number_format[,start_position][,length]]) --用法说明： dump(col_name,8|10|16|17) ,其中8|10|16|17 为number_format，分别为8进制，--10进制（默认值），16进制，单字符。SYS@linora&gt; select dump(24000,10) from dual;DUMP(24000,10)---------------------Typ=2 Len=3: 195,3,41SYS@linora&gt; select dump(24000,16) from dual;DUMP(24000,16)--------------------Typ=2 Len=3: c3,3,29 5.2 utl_raw对于dump出来的内容，通常不能直观的了解到想要的信息，可以通过utl_raw来实现。以dump hr.employees员工号100所在数据块为例，来说明此函数的用法。12345678910111213141516--查询数据所在DBASYS@linora&gt; SELECT DBMS_ROWID.ROWID_OBJECT(rowid) &quot;OBJECT&quot;,DBMS_ROWID.ROWID_RELATIVE_FNO(rowid) &quot;FILE&quot;, 2 3 DBMS_ROWID.ROWID_BLOCK_NUMBER(rowid) &quot;BLOCK&quot;, 4 DBMS_ROWID.ROWID_ROW_NUMBER(rowid) &quot;ROW&quot; 5 FROM hr.employees where employee_id=100; OBJECT FILE BLOCK ROW---------- ---------- ---------- ---------- 84737 8 11476 0SYS@linora&gt; alter system dump datafile 8 block 11476;System altered.SYS@linora&gt; @traceVALUE--------------------------------------------------------------------------------/u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_3141.trc 查看trace文件信息：123456789101112131415161718192021222324252627282930--表结构数据类型SYS@linora&gt; desc hr.employees Name Null? Type --------------------------------- -------- ------------------ EMPLOYEE_ID NOT NULL NUMBER(6) FIRST_NAME VARCHAR2(20) LAST_NAME NOT NULL VARCHAR2(25) EMAIL NOT NULL VARCHAR2(25) PHONE_NUMBER VARCHAR2(20) HIRE_DATE NOT NULL DATE JOB_ID NOT NULL VARCHAR2(10) SALARY NUMBER(8,2) COMMISSION_PCT NUMBER(2,2) MANAGER_ID NUMBER(6) DEPARTMENT_ID NUMBER(4)--此块中的row=0行信息，即我们查询的员工号=100的数据存储block_row_dump:tab 0, row 0, @0x3c3tl: 62 fb: --H-FL-- lb: 0x2 cc: 11col 0: [ 2] c2 02col 1: [ 6] 53 74 65 76 65 6ecol 2: [ 4] 4b 69 6e 67col 3: [ 5] 53 4b 49 4e 47col 4: [12] 35 31 35 2e 31 32 33 2e 34 35 36 37col 5: [ 7] 78 67 06 11 01 01 01col 6: [ 7] 41 44 5f 50 52 45 53col 7: [ 3] c3 03 59col 8: *NULL*col 9: *NULL*col 10: [ 2] c1 5b 我们找其中几个字段进行转换：1234SYS@linora&gt; select employee_id,LAST_NAME,SALARY from hr.employees where employee_id=100;EMPLOYEE_ID LAST_NAME SALARY----------- ------------------------- ---------- 100 King 28800 #####employee_id此字段为col 0，类型为Number，在数据库里面存储为&#39;c2 02&#39;，用函数转换一下：1234SYS@linora&gt; select utl_raw.cast_to_number(&apos;c202&apos;) employee_id from dual;EMPLOYEE_ID----------- 100 上面的写法，当utl_raw.cast_to_number()引号中的内容多时，用起来不方便。可以加个replace()函数，处理起来便于阅读。12--replace函数用法：replace(&apos;exp1&apos;,&apos;exp2&apos;,&apos;exp3&apos;)从exp1中找出exp2字符串，用exp3代替select utl_raw.cast_to_number(replace(&apos;c2 02&apos;,&apos; &apos;)) v from dual; #####LAST_NAME此字段存储于表中的第三个栏位，即col 2，类型为varchar2，存储数据为&#39;4b 69 6e 67&#39;，使用函数进行转换：12345--转换为字符串SYS@linora&gt; select utl_raw.cast_to_varchar2(replace(&apos;4b 69 6e 67&apos;,&apos; &apos;)) last_name from dual;LAST_NAME----------King #####SALARY此字段存储与表的第八个字段，即col 7，类型为Number，存储数据为&#39;c3 03 59&#39;，使用函数进行转换：12345--转换为10进制数字SYS@linora&gt; select utl_raw.cast_to_number(replace(&apos;c3 03 59&apos;,&apos; &apos;)) SAL from dual; SAL---------- 28800 同时，utl_raw还存在cast_from_number，此函数用法有点类似dump：12345--由数字转换为16进制SYS@linora&gt; select utl_raw.cast_from_number(28800) SAL from dual;SAL--------------------C30359 Reference:《深入浅出Oracle》--盖国强《Oracle Core-Essential Internals for DBAs and Developers》--Jonathan Lewis《临危不惧-Oracle 11g数据库恢复技术》--包光磊","link":"/redo-record.html"},{"title":"Rename RAC dbname and GI diskgroup name","text":"Customer wants to use Oracle OEM to manage all the database RACs, due to unoptimized plan of installation, they want to standardize naming conversion of DBNAME and diskgroup name, with NID utility, it&#39;s easy to modify the database name, but modify diskgroup name is a little bit complicated. 1. Modify DBNAME with nidFirst of all, backup is essential before any changes. Bring RAC database in exclusive mode 1SQL&gt; alter system set cluster_database=false scope=both; Stop the database and bring database in mount mode 123$srvctl stop database -d orcl$sqlplus \"/as sysdba\"SQL&gt; startup mount Modify dbname with nid 123456789101112131415161718192021222324252627&lt;localhost:/home/oracle&gt;$ nid target=/ dbname=ccmsDBNEWID: Release 12.1.0.2.0 - Production on Thu Feb 21 11:59:50 2019Copyright (c) 1982, 2014, Oracle and/or its affiliates. All rights reserved.Connected to database ORCL (DBID=625082333)Connected to server version 12.1.0Control Files in database: +DATA/ORCL/CONTROLFILE/current.267.998418721Change database ID and database name ORCL to CCMS? (Y/[N]) =&gt; yProceeding with operationChanging database ID from 625082333 to 2262823414Changing database name from ORCL to CCMS Control File +DATA/ORCL/CONTROLFILE/current.267.998418721 - modified Datafile +DATA/ORCL/DATAFILE/system.270.99841872 - dbid changed, wrote new name Datafile +DATA/ORCL/DATAFILE/sysaux.271.99841872 - dbid changed, wrote new name Datafile +DATA/ORCL/DATAFILE/undotbs1.272.99841872 - dbid changed, wrote new name Datafile +DATA/ORCL/DATAFILE/undotbs2.274.99841874 - dbid changed, wrote new name Datafile +DATA/ORCL/DATAFILE/users.275.99841874 - dbid changed, wrote new name Datafile +DATA/ORCL/TEMPFILE/temp.273.99841872 - dbid changed, wrote new name Control File +DATA/ORCL/CONTROLFILE/current.267.998418721 - dbid changed, wrote new name Instance shut downDatabase name changed to CCMS.Modify parameter file and generate a new password file before restarting.Database ID for database CCMS changed to 2262823414.All previous backups and archived redo logs for this database are unusable.Database has been shutdown, open database with RESETLOGS option.Succesfully changed database name and ID.DBNEWID - Completed succesfully. Bring database back in mount mode and modify DBNAME in database 12345678910111213141516SQL&gt; startup mountORACLE instance started.Total System Global Area 3.2481E+11 bytesFixed Size 7668016 bytesVariable Size 4.6171E+10 bytesDatabase Buffers 2.7703E+11 bytesRedo Buffers 1602940928 bytesORA-01103: database name 'CCMS' in control file is not 'ORCL'SQL&gt; alter system set db_name=ccms scope=spfile;System altered.--Bring database backup in cluster modeSQL&gt; alter system set cluster_database=true scope=spfile;System altered.SQL&gt; startup force mount Open database with resetlogs option 12345678910111213141516SQL&gt; alter database open resetlogs;Database altered.SQL&gt; show parameter nameNAME TYPE VALUE------------------------------------ ----------- ------------------------------cell_offloadgroup_name stringdb_file_name_convert stringdb_name string CCMSdb_unique_name string CCMSglobal_names boolean FALSEinstance_name string orcl1lock_name_space stringlog_file_name_convert stringpdb_file_name_convert stringprocessor_group_name stringservice_names string CCMS Modify instance names 12345SQL&gt; create pfile='/home/oracle/pfile.ora' from spfile;--replace old instance name with new instance in pfile--It's recommened create and initSID.ora file in $ORACLE_HOME/dbsSQL&gt; startup nomountSQL&gt; create spfile='+DATA/ORCL/spfile.ora' from pfile='/home/oracle/pfile.ora'; Remove old database and register new database 123456789101112131415161718192021222324SQL&gt; shutdown immediate$srvctl remove database -d orcl$srvctl add database -d ccms -o $ORACLE_HOME -spfile '+DATA/ORCL/spfile.ora' -startoption OPEN -policy AUTOMATIC -v--add instance attach to GI$srvctl add instance -d ccms -i ccms1 -n localhost1$srvctl add instance -d ccms -i ccms2 -n localhost2--check the status of database$srvctl config database -d ccms$crsctl stat res -tSQL&gt; show parameter nameNAME TYPE VALUE------------------------------------ ----------- ------------------------------cell_offloadgroup_name stringdb_file_name_convert stringdb_name string ccmsdb_unique_name string ccmsglobal_names boolean FALSEinstance_name string ccms1lock_name_space stringlog_file_name_convert stringpdb_file_name_convert stringprocessor_group_name stringservice_names string ccms 2. Modify ASM diskgroup name with renamedg Dismount diskgroups which need to be renamed 1234$srvctl stop database -d ccms--with grid user dismount diskgroup with both node&lt;/home/grid&gt;$ sqlplus / as sysasmSQL&gt; alter diskgroup DATA dismount; Rename DG name with renamedg 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;/home/grid&gt;$ renamedg phase=both dgname=DATA \\newdgname=DATADG asm_diskstring='/dev/asmdisk*' verbose=trueParsing parameters..Parameters in effect: Old DG name : DATA New DG name : DATADG Phases : Phase 1 Phase 2 Discovery str : /dev/asmdisk* Clean : TRUE Raw only : TRUErenamedg operation: phase=both dgname=DATA newdgname=DATADG asm_diskstring=/dev/asmdisk* verbose=trueExecuting phase 1Discovering the groupPerforming discovery with string:/dev/asmdisk*Identified disk UFS:/dev/asmdisk5 with disk number:1 and timestamp (33081105 1165527040)Identified disk UFS:/dev/asmdisk4 with disk number:0 and timestamp (33081105 1165527040)Checking for hearbeat...Re-discovering the groupPerforming discovery with string:/dev/asmdisk*Identified disk UFS:/dev/asmdisk5 with disk number:1 and timestamp (33081105 1165527040)Identified disk UFS:/dev/asmdisk4 with disk number:0 and timestamp (33081105 1165527040)Checking if the diskgroup is mounted or used by CSSChecking disk number:1Checking disk number:0Generating configuration file..ccms1.__large_pool_size=8053063680Completed phase 1ccms1.__data_transfer_cache_size=0Executing phase 2Looking for /dev/asmdisk5Modifying the headerLooking for /dev/asmdisk4Modifying the headerCompleted phase 2Terminating kgfd context 0x7f09cb8ec0a0 Remove old diskgroup name in GI 123SQL&gt; alter diskgroup DATADG mount ;$srvctl modify database -db ccms -o $ORACLE_HOME -spfile '+DATADG/ORCL/spfile.ora' -diskgroup 'DATADG'$srvctl remove diskgroup -g DATA Re-create controlfile to reflect new datafile localtion 1234567891011121314151617181920212223SQL&gt; alter database backup controlfile to trace as '/home/oracle/cntl.ctl';--modify cntl.ctl to reflect new file locationsSQL&gt; STARTUP NOMOUNTCREATE CONTROLFILE REUSE DATABASE \"CCMS\" RESETLOGS NOARCHIVELOG MAXLOGFILES 192 MAXLOGMEMBERS 3 MAXDATAFILES 1024 MAXINSTANCES 32 MAXLOGHISTORY 2920LOGFILE GROUP 1 '+DATADG/CCMS/ONLINELOG/group_1.268.1000814621' SIZE 50M BLOCKSIZE 512, GROUP 2 '+DATADG/CCMS/ONLINELOG/group_2.269.1000814621' SIZE 50M BLOCKSIZE 512-- STANDBY LOGFILEDATAFILE '+DATADG/ORCL/DATAFILE/system.270.998418723', '+DATADG/ORCL/DATAFILE/sysaux.271.998418725', '+DATADG/ORCL/DATAFILE/undotbs1.272.998418727', '+DATADG/ORCL/DATAFILE/undotbs2.274.998418741', '+DATADG/ORCL/DATAFILE/users.275.998418741'CHARACTER SET AL32UTF8;--open database with resetlogs optionSQL&gt; alter database open resetlogs; Modify pfile to reflect new controlfile location Don&#39;t forget to modify cluster_database=true and set db_create_file_dest to new diskgroup name.123SQL&gt; create spfile='+DATADG/ORCL/spfile.ora' from pfile='/home/oracle/pfile.ora'$srvctl stop database -d ccms$srvctl start database -d ccms 3. Troubleshooting &amp; Tips Open resetlogs encountered ORA-01618 12345678$ srvctl start database -d histPRCR-1079 : Failed to start resource ora.hist.dbCRS-5017: The resource action &quot;ora.hist.db start&quot; encountered the following error:ORA-01618: redo thread 2 is not enabled - cannot mount. For details refer to &quot;(:CLSN00107:)&quot; in &quot;/grid/app/grid/diag/crs/histpdb02a/crs/trace/crsd_oraagent_oracle.trc&quot;.CRS-2674: Start of &apos;ora.hist.db&apos; on &apos;histpdb02a&apos; failedCRS-2632: There are no more servers to try to place resource &apos;ora.hist.db&apos; on that would satisfy its placement policy Solution: add logfile for thread 2, and enable thread2. 12345678--Create log file in node 2ALTER DATABASE ADD LOGFILE THREAD 2 GROUP 9 ('+DATADG') SIZE 4096M BLOCKSIZE 512, GROUP 10 ('+DATADG') SIZE 4096M BLOCKSIZE 512, GROUP 11 ('+DATADG') SIZE 4096M BLOCKSIZE 512, GROUP 12 ('+DATADG') SIZE 4096M BLOCKSIZE 512;--Enable log thread 2 in node 1SQL&gt; alter database enable thread 2; Before using renamedg, all the diskgroups must be dismounted from all nodes, and it&#39;s recommended to specify ask_disktrings parameter in the command line. Otherwise, below error maybe occur:1KFNDG-00407: Could not find disks for disk group EOF","link":"/rename-RAC-dbname-and-GI-diskgroup-name.html"},{"title":"利用rman增量备份恢复adg gap","text":"由于网络变更，导致部分ADG链路中断，在部分数据库上，没有配置RMAN的删除归档策略，主库归档已经被删除，备库无法继续应用日志。 1. 错误描述使用dgmgrl监控adg状态，出现以下错误：123456789101112131415161718192021222324DGMGRL&gt; show configuration;Configuration - ADG_CONFIG Protection Mode: MaxAvailability Databases: CDB01 - Primary database Error: ORA-16810: multiple errors or warnings detected for the database CDB02 - Physical standby databaseFast-Start Failover: DISABLEDConfiguration Status:ERRORDGMGRL&gt; show database 'CDB01';Database - CDB01 Role: PRIMARY Intended State: TRANSPORT-ON Instance(s): cdb011 cdb012 Database Error(s): ORA-16783: cannot resolve gap for database cdb02 Database Warning(s): ORA-16629: database reports a different protection level from the protection modeDatabase Status:ERROR 通过以下SQL确实有gap：123456789101112131415161718192021222324252627282930313233set line 200 pagesize 200col hostname for a30with db as (SELECT NAME DB_NAME, database_role db_role FROM GV$DATABASE), inst as (SELECT inst_id, UPPER(SUBSTR(HOST_NAME, 1, (DECODE(INSTR(HOST_NAME, '.'), 0, LENGTH(HOST_NAME), (INSTR(HOST_NAME, '.') - 1))))) HOSTNAME FROM GV$INSTANCE), log1 as (SELECT thread#, MAX(SEQUENCE#) LOG_ARCHIVED FROM GV$ARCHIVED_LOG WHERE DEST_ID = 1 AND ARCHIVED = 'YES' group by thread#), log2 as( SELECT thread#, MAX(SEQUENCE#) LOG_APPLIED FROM GV$ARCHIVED_LOG WHERE DEST_ID = 2 AND APPLIED = 'YES' group by thread#), log3 as (SELECT thread#,TO_CHAR(MAX(COMPLETION_TIME), 'yyyy-mm-dd HH24:MI') APPLIED_TIME FROM GV$ARCHIVED_LOG WHERE DEST_ID = 2 AND APPLIED = 'YES' group by thread#)select distinct DB_NAME, db_role, HOSTNAME, LOG_ARCHIVED, LOG_APPLIED,APPLIED_TIME, LOG_ARCHIVED - LOG_APPLIED LOG_GAP from db, inst, log1, log2, log3 where log1.thread# = log2.thread# and log2.thread# = log3.thread# and inst.inst_id = log1.thread#;DB_NAME DB_ROLE HOSTNAME LOG_ARCHIVED LOG_APPLIED APPLIED_TIME LOG_GAP--------- ---------------- -------------------- ------------ ----------- ---------------- ----------CDB01 PRIMARY SZDB1 3209 3184 2019-09-01 03:28 25CDB01 PRIMARY SZDB2 1862 1835 2019-09-01 11:22 27 2. 解决方案2.1 停止standby应用日志Standby操作：123dgmgrl /edit database cdb02 set state='APPLY-OFF';show database cdb02 2.2 主库从备库最后SCN进行增量备份备库查找当前SCN值:1select current_scn from gv$database; 主库开始备份:12345--primaryrun&#123;allocate channel c1 type disk;backup incremental from scn 5125186024 database format '/tmpbak/backup/standby_%d_%t_%c_%p';&#125; 2.3 备库进行recover将备份片传送到备库相应位置，对备库进行还原: 重启备库到mount状态 12srvctl stop database -d cdb02srvctl start database -d cdb02 -startoption mount 对备库进行recover 12345678--standbyrman target /catalog start with '/home/oracle/backup';run&#123;allocate channel c1 type disk;allocate channel c2 type disk;recover database noredo;&#125; 2.4 备库restore控制文件12345678910--primary--主库备份standby控制文件alter database create standby controlfile as '/home/oracle/standby.ctl';--重启备库，仅让其中一个节点启动到nomount状态srvctl stop database -d cdb02startup nomountshow parameter control_filesRMAN&gt; restore controlfile from '/home/oracle/standby.ctl'; 2.5 catalog备库数据文件控制文件重新还原过来，需要对数据库文件进行catalog，因为数据文件路径不一致需要对数据文件进行重命名。1234--standbyMAN&gt; alter database mount;RMAN&gt; catalog start with '+DATA2/CDB02';RMAN&gt; switch database to copy; 由于路径不一致，有可能导致日志无法写入备库，建议在此时添加log_file_name_convert参数。1alter system set log_file_name_convert ='+FRA/CDB01','+FRA/CDB02' scope=spfile sid='*'; 在dgbroker启用后，同时要调整broker参数：1edit database cdb02 set property 'LogFileNameConvert'='+FRA/CDB01,+FRA/CDB02'; 重启数据库到RAC模式:12shutdown immediate;srvctl start database -d cdb02 2.6 清空备库standby日志12345678--standbyalter database clear logfile group 10;alter database clear logfile group 11;alter database clear logfile group 12;alter database clear logfile group 13;alter database clear logfile group 14;alter database clear logfile group 15;alter database clear logfile group 16; 2.7 开启备库日志应用1edit database cdb02 set state='APPLY-ON'; 3. Trouble shooting3.1 备库日志路径与主库不一致主库后台日志报以下错误：123456789Wed Sep 04 16:25:03 2019Errors in file /u01/app/oracle/diag/rdbms/cdb01/cdb011/trace/cdb011_arc0_153792.trc:ORA-16041: Remote File Server fatal errorWed Sep 04 16:25:03 2019ARC0: FAL archive failed with error 16041. See trace for detailsWed Sep 04 16:25:03 2019Errors in file /u01/app/oracle/diag/rdbms/cdb01/cdb011/trace/cdb011_arc0_153792.trc:ORA-16055: FAL request rejectedARCH: FAL archive failed. Archiver continuing DGBroker报以下错误：12345678910111213DGMGRL&gt; show database agxxxprof Database - cdb02 Role: PHYSICAL STANDBY Intended State: APPLY-ON Transport Lag: 0 seconds (computed 1 second ago) Apply Lag: 0 seconds (computed 1 second ago) Average Apply Rate: 2.12 MByte/s Real Time Query: OFF Instance(s): cdb02 Database Warning(s): ORA-16789: standby redo logs configured incorrectly Database Status: WARNING 解决方法：主库重新添加备库日志，如果主备库路径不一致，备库需要添加log_file_name_convert参数进行路径转换。1234567891011121314151617alter database drop standby logfile group 1;alter database drop standby logfile group 2;alter database drop standby logfile group 3;alter database drop standby logfile group 4;alter database drop standby logfile group 5;alter database drop standby logfile group 6;alter database drop standby logfile group 7;alter database drop standby logfile group 8;alter database add standby logfile thread 1 group 1 ('+FRA') size 4096M blocksize 4096;alter database add standby logfile thread 1 group 2 ('+FRA') size 2048M blocksize 4096;alter database add standby logfile thread 1 group 3 ('+FRA') size 2048M blocksize 4096;alter database add standby logfile thread 1 group 4 ('+FRA') size 2048M blocksize 4096;alter database add standby logfile thread 2 group 5 ('+FRA') size 2048M blocksize 4096;alter database add standby logfile thread 2 group 6 ('+FRA') size 2048M blocksize 4096;alter database add standby logfile thread 2 group 7 ('+FRA') size 2048M blocksize 4096;alter database add standby logfile thread 2 group 8 ('+FRA') size 2048M blocksize 4096; EOF","link":"/restore-standby-service-by-rman-incremental-backup.html"},{"title":"RMAN完全恢复和不完全恢复","text":"完全恢复和不完全恢复在前文RMAN Recovery Concepts已经简单描述过。本文简单描述下基于RMAN的完全恢复和不完全恢复。完全恢复一般用于物理介质故障，如介质失败，磁盘或者数据文件故障；不完全恢复一般用于逻辑业务故障，如用户误删除关键业务数据，或者用于日志不全的情况下的恢复，比如丢失数据文件，要做完全恢复，发现部分归档已经无法使用。此时只能恢复到可用归档日志的那一刻时间点。通过RMAN完全恢复，可以将数据库恢复到失败点状态；通过RMAN不完全恢复，可以将数据库恢复到备份点与失败点之间某个时刻的状态。下表列出了在数据库遇到故障时候应该采取何种恢复策略。 Table 1-1 RMAN恢复策略 需要介质恢复的文件 恢复动作 数据文件，所有日志都可用 完全恢复 数据文件，部分日志不可用 不完全恢复 控制文件 restore控制文件 在线日志文件 清除或者重建日志文件，或者不完全恢复，参照Handling Online Redo Log Failures SPFILE restore spfile 归档日志 从备份还原归档 没有RMAN信息的控制文件(重建控制文件后) 使用catalog命令或者DBMS_BACKUP_RESTORE 1.完全恢复1.1OPEN状态丢失数据文件12345678910111213141516ORA-01116: error in opening database file 5ORA-01110: data file 5: &apos;/oradata/datafile/linora/fung01.dbf&apos;ORA-27041: unable to open fileLinux-x86_64 Error: 2: No such file or directoryAdditional information: 3SQL&gt; select file#, status, error,recover from v$datafile_header; FILE# STATUS ERROR REC---------- ------- -------------------- --- 1 ONLINE NO 2 ONLINE NO 3 ONLINE NO 4 ONLINE NO 5 ONLINE CANNOT OPEN FILE 6 ONLINE NO 7 ONLINE NO 在执行恢复前可先用preview命令查看需要那些备份集和归档。1RMAN&gt; restore datafile 7 preview; 对单个数据文件执行恢复：12345678910111213141516171819RMAN&gt; sql &apos;alter database datafile 5 offline&apos;;#如果原来磁盘路径不可用,则#RMAN&gt; set newname for datafile 5 to &apos;/disk1/users01.dbf&apos;;RMAN&gt; restore datafile 5;RMAN&gt; recover datafile 5;RMAN&gt; sql &apos;alter database datafile 5 online&apos;;SQL&gt; select file#, status, error,recover from v$datafile_header; FILE# STATUS ERROR REC---------- ------- -------------------- --- 1 ONLINE NO 2 ONLINE NO 3 ONLINE NO 4 ONLINE NO 5 ONLINE NO 6 ONLINE NO 7 ONLINE NO7 rows selected. 如果丢失的是1号数据文件，则需要在mount状态下进行恢复和还原。而对于数据文件及表空间在OPEN状态下进行完整恢复首先要OFFLINE对应的objects。123456RMAN&gt; run &#123;2&gt; startup force mount;3&gt; restore datafile 1;4&gt; recover datafile 1;5&gt; sql &apos;alter database open&apos;;6&gt; &#125; 1.2整库的完整恢复1234RMAN&gt; startup mount;RMAN&gt; restore database;RMAN&gt; recover database;RMAN&gt; alter database open; 如果使用的是备份的控制文件而不是当前的控制文件，则需要resetlogs动作：123456RMAN&gt; startup nomount;RMAN&gt; restore controlfile from autobackup;RMAN&gt; alter database mount;RMAN&gt; restore database;RMAN&gt; recover database;RMAN&gt; alter database open resetlogs; RMAN restore默认会从最新的备份还原文件，如果需要从旧的备份中恢复，可执行until子句，但这样会增加完全恢复的时间，一般是最新的备份出问题才会使用以前的备份进行完全恢复。针对还原恢复过程中产生的归档删除，可用以下命令进行删除:123RMAN&gt; recover database delete archivelog;#保留归档区最大500M空间，超过此大小，归档会被删除RMAN&gt; recover database delete archivelog maxsize 500m; 1.3还原SPFILE及归档#####还原SPFILE12345678910111213141516#从autobackup恢复SPFILE到指定路径RMAN&gt; restore spfile to &apos;/home/oracle/spfile.ora&apos; from autobackup ;#从RMAN备份中恢复RMAN&gt; list backup of spfile;List of Backup Sets===================BS Key Type LV Size Device Type Elapsed Time Completion Time ------- ---- -- ---------- ----------- ------------ -------------------116 Incr 0 9.61M DISK 00:00:03 2014-06-01 10:20:32 BP Key: 116 Status: AVAILABLE Compressed: NO Tag: TAG20140601T101934 Piece Name: /oradata/backup/lv0_LINORA_20140601_123 SPFILE Included: Modification time: 2014-06-01 10:18:52 SPFILE db_unique_name: LINORARMAN&gt; restore spfile to &apos;/home/oracle/spfile.ora&apos; from &apos;/oradata/backup/lv0_LINORA_20140601_123&apos; ; #####还原归档日志1234567891011121314#还原所有RMAN已经备份的归档RMAN&gt; restore archivelog all;#从sequence 50开始还原RMAN&gt; restore archivelog from sequence 50;#指定sequence区间还原RMAN&gt; restore archivelog from sequence 5170 until sequence 5178 thread 1;RMAN&gt; restore archivelog sequence between 5170 and 5178 thread 1;#如果需要强行覆盖现有的归档，则使用force子句RMAN&gt; restore archivelog from sequence 1 force;#还原归档至非默认路径RMAN&gt; run&#123;2&gt; set archivelog destination to &apos;/ora01/archrest&apos;;3&gt; restore archivelog from sequence 5200;4&gt; &#125; 2.不完全恢复RMAN使用until子句，可基于时间，SCN，日志sequence和还原点进行不完全恢复。在restore中使用until子句，RMAN会根据until的时间点寻找合适的备份集进行恢复，如果restore不指定until，RMAN默认会从最新的可用备份还原。对于任何until子句，都只能恢复到这个点之前，而不包含这个点。使用不完全恢复，一定要数据库在mount状态进行。因为RMAN需要在mount状态下读写控制文件，同时，如果进行不完全恢复，system数据文件一般都要进行recovery，而system数据文件的recovery必须要OFFLINE。 2.1基于时间的不完全恢复12345678run&#123;allocate channel c1 type disk;set until time &quot;to_date(&apos;2014-06-08 12:00:00&apos;,&apos;yyyy-mm-dd hh24:mi:ss&apos;)&quot;;restore database;recover database;sql &apos;alter database open resetlogs&apos;;release channel c1;&#125; set子句一定要在run块里面。 2.2基于日志sequence的恢复12345678run&#123;allocate channel c1 type disk;set until sequence 65 thread 1;restore database;recover database;sql &apos;alter database open resetlogs&apos;;release channel c1;&#125; 2.3基于scn值恢复12345678run&#123;allocate channel c1 type disk;set until scn 1817351;restore database;recover database;sql &apos;alter database open resetlogs&apos;;release channel c1;&#125; SCN和log sequence关系可根据如下两个视图查找：1234567select sequence#, first_change#, first_timefrom v$log_historyorder by first_time;select sequence#, first_change#, first_timefrom v$archived_logorder by first_time; 2.4跨incarnation恢复当数据库以resetlogs open的时候，会充值log sequence，在RMAN中，incarnation也就改变了。12345678910111213RMAN&gt; list incarnation;List of Database IncarnationsDB Key Inc Key DB Name DB ID STATUS Reset SCN Reset Time------- ------- -------- ---------------- --- ---------- ----------1 1 LINORA 3385851293 PARENT 1 2014-02-08 11:47:412 2 LINORA 3385851293 PARENT 869112 2014-03-07 10:35:253 3 LINORA 3385851293 PARENT 870364 2014-03-07 10:58:415 5 LINORA 3385851293 PARENT 870978 2014-03-07 11:35:434 4 LINORA 3385851293 ORPHAN 871371 2014-03-07 11:17:096 6 LINORA 3385851293 PARENT 1082046 2014-03-21 15:20:167 7 LINORA 3385851293 PARENT 1082598 2014-03-21 16:01:508 8 LINORA 3385851293 PARENT 1817350 2014-06-09 15:19:469 9 LINORA 3385851293 CURRENT 1817351 2014-06-09 15:26:20 当试图恢复到之前的incarnation时候，会报以下错误123456789101112131415161718192021RMAN&gt; run&#123;2&gt; allocate channel c1 type disk;3&gt; set until scn 1817350;4&gt; restore database;5&gt; recover database;6&gt; sql &apos;alter database open resetlogs&apos;;7&gt; release channel c1;8&gt; &#125;allocated channel: c1channel c1: SID=10 device type=DISKexecuting command: SET until clauseStarting restore at 2014-06-09 15:35:15released channel: c1RMAN-00571: ===========================================================RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS ===============RMAN-00571: ===========================================================RMAN-03002: failure of restore command at 06/09/2014 15:35:15RMAN-20208: UNTIL CHANGE is before RESETLOGS change 出现以上错误就表示我们需要从旧的incarnation进行恢复。首先要从对应incarnation中还原控制文件。1234567891011121314151617181920212223RMAN&gt; restore controlfile from &apos;/oradata/backup/lv0_LINORA_20140601_123&apos; until time &quot;to_date(&apos;2014-06-09 15:19:46&apos;,&apos;yyyy-mm-dd hh24:mi:ss&apos;)&quot;;Starting restore at 2014-06-09 15:41:22using channel ORA_DISK_1channel ORA_DISK_1: restoring control filechannel ORA_DISK_1: restore complete, elapsed time: 00:00:03output file name=/oradata/datafile/linora/control01.ctloutput file name=/oradata/datafile/linora/control02.ctlFinished restore at 2014-06-09 15:41:25RMAN&gt; sql &apos;alter database mount&apos;;RMAN&gt; list incarnation; List of Database IncarnationsDB Key Inc Key DB Name DB ID STATUS Reset SCN Reset Time------- ------- -------- ---------------- --- ---------- ----------1 1 LINORA 3385851293 PARENT 1 2014-02-08 11:47:412 2 LINORA 3385851293 PARENT 869112 2014-03-07 10:35:253 3 LINORA 3385851293 PARENT 870364 2014-03-07 10:58:415 5 LINORA 3385851293 PARENT 870978 2014-03-07 11:35:434 4 LINORA 3385851293 ORPHAN 871371 2014-03-07 11:17:096 6 LINORA 3385851293 PARENT 1082046 2014-03-21 15:20:167 7 LINORA 3385851293 CURRENT 1082598 2014-03-21 16:01:50 在此例中，由于我们要恢复的时间点在2014-06-09，因此包含在incarnation 7中，不需要进行reset incarnation。如果需要恢复到2014-02-08，则需执行reset incarnation动作。1RMAN&gt; reset database to incarnation 1; 此例中，直接进行不完全恢复即可1234567891011121314151617181920run&#123;allocate channel c1 type disk;set until time &quot;to_date(&apos;2014-06-09 15:19:46&apos;,&apos;yyyy-mm-dd hh24:mi:ss&apos;)&quot;;restore database;recover database;sql &apos;alter database open resetlogs&apos;;release channel c1;&#125;RMAN&gt; list incarnation; List of Database IncarnationsDB Key Inc Key DB Name DB ID STATUS Reset SCN Reset Time------- ------- -------- ---------------- --- ---------- ----------1 1 LINORA 3385851293 PARENT 1 2014-02-08 11:47:412 2 LINORA 3385851293 PARENT 869112 2014-03-07 10:35:253 3 LINORA 3385851293 PARENT 870364 2014-03-07 10:58:415 5 LINORA 3385851293 PARENT 870978 2014-03-07 11:35:434 4 LINORA 3385851293 ORPHAN 871371 2014-03-07 11:17:096 6 LINORA 3385851293 PARENT 1082046 2014-03-21 15:20:167 7 LINORA 3385851293 PARENT 1082598 2014-03-21 16:01:508 8 LINORA 3385851293 CURRENT 1817350 2014-06-09 15:49:49 3.DBMS_BACKUP_RESTORE简单使用如果没有使用recovery catalog数据库，在re-create控制文件后，控制文件的备份信息都会丢失，在10g以上版本中，可用catalog start with命令在RMAN注册备份信息。如果是9i以下，则没有catalog命令去同步备份信息，如果9i中重建控制文件后需要恢复，则需要使用到DBMS_BACKUP_RESTORE从指定备份片还原数据库所需文件到指定位置。12345678910111213#For 10g and aboveRMAN&gt; catalog start with &apos;/oradata/backup&apos;;searching for all files that match the pattern /oradata/backupList of Files Unknown to the Database=====================================File Name: /oradata/backup/lv0_LINORA_20140601_123File Name: /oradata/backup/arch.shFile Name: /oradata/backup/lv0_LINORA_20140601_124File Name: /oradata/backup/full.shDo you really want to catalog the above files (enter YES or NO)? yes 3.1还原控制文件123456789101112131415161718192021222324252627SQL&gt; SET SERVEROUTPUT ONSQL&gt; DECLARE 2 finished BOOLEAN; 3 v_dev_name VARCHAR2(75); 4 BEGIN 5 -- Allocate a channel, when disk then type = null, if tape then type = sbt_tape. 6 v_dev_name := dbms_backup_restore.deviceAllocate(type=&gt;null, ident=&gt;&apos;d1&apos;); 7 -- 8 dbms_backup_restore.restoreSetDatafile; 9 dbms_backup_restore.restoreControlFileTo( 10 cfname=&gt;&apos;/oradata/datafile/linora/control01.ctl&apos;); 11 -- 12 dbms_backup_restore.restoreBackupPiece( 13 &apos;/oradata/backup/lv0_LINORA_20140601_123&apos;, finished); 14 -- 15 if finished then 16 dbms_output.put_line(&apos;Control file restored.&apos;); 17 else 18 dbms_output.put_line(&apos;Problem&apos;); 19 end if; 20 -- 21 dbms_backup_restore.deviceDeallocate(&apos;d1&apos;); 22 END; 23 /Control file restored.PL/SQL procedure successfully completed. 3.2从单一备份片还原数据文件1234567891011121314151617181920212223242526272829303132SQL&gt; SET SERVEROUTPUT ONSQL&gt; DECLARE 2 finished BOOLEAN; 3 v_dev_name VARCHAR2(75); 4 BEGIN 5 -- Allocate channels, when disk then type = null, if tape then type = sbt_tape. 6 v_dev_name := dbms_backup_restore.deviceAllocate(type=&gt;null, ident=&gt; &apos;d1&apos;); 7 -- 8 -- Set beginning of restore operation (does not restore anything yet). 9 dbms_backup_restore.restoreSetDatafile; 10 -- 11 -- Define datafiles and their locations for datafiles in first backup piece. 12 dbms_backup_restore.restoreDatafileTo(dfnumber=&gt;1,toname=&gt;&apos;/oradata/datafile/linora/system01.dbf&apos;); 13 dbms_backup_restore.restoreDatafileTo(dfnumber=&gt;2,toname=&gt;&apos;/oradata/datafile/linora/sysaux01.dbf&apos;); 14 dbms_backup_restore.restoreDatafileTo(dfnumber=&gt;4,toname=&gt;&apos;/oradata/datafile/linora/users01.dbf&apos;); 15 -- 16 -- Restore the datafiles in this backup piece. 17 dbms_backup_restore.restoreBackupPiece(done =&gt; finished, 18 handle=&gt;&apos;/oradata/backup/lv0_LINORA_20140601_122&apos;, params=&gt;null); 19 -- 20 IF finished THEN 21 dbms_output.put_line(&apos;Datafiles restored&apos;); 22 ELSE 23 dbms_output.put_line(&apos;Problem&apos;); 24 END IF; 25 -- 26 dbms_backup_restore.deviceDeallocate(&apos;d1&apos;); 27 END; 28 /Datafiles restoredPL/SQL procedure successfully completed. 3.3从多个备份片还原数据文件1234567891011121314151617181920212223242526272829303132333435363738394041SET SERVEROUTPUT ONDECLAREfinished BOOLEAN;v_dev_name VARCHAR2(75);TYPE v_filestable IS TABLE OF varchar2(500) INDEX BY BINARY_INTEGER;v_filename V_FILESTABLE;v_num_pieces NUMBER;BEGIN-- Allocate channels, when disk then type = null, if tape then type = sbt_tape.v_dev_name := dbms_backup_restore.deviceAllocate(type=&gt;null, ident=&gt; &apos;d1&apos;);---- Set beginning of restore operation (does not restore anything yet).dbms_backup_restore.restoreSetDatafile;---- Define backup pieces in backup set.v_filename(1) :=&apos;/oradata/backup/lv0_LINORA_20140601_122&apos;;v_filename(2) :=&apos;/oradata/backup/lv0_LINORA_20140601_123&apos;;v_filename(3) :=&apos;/oradata/backup/lv0_LINORA_20140601_124&apos;;-- There are 3 backup pieces in this backup set.v_num_pieces := 3;-- Define datafiles and locations.dbms_backup_restore.restoreDatafileTo(dfnumber=&gt;1,toname=&gt;&apos;/oradata/datafile/linora/system01.dbf&apos;);dbms_backup_restore.restoreDatafileTo(dfnumber=&gt;4,toname=&gt;&apos;/oradata/datafile/linora/users01.dbf&apos;);-- Restore the datafiles in this backup set.FOR i IN 1..v_num_pieces LOOPdbms_backup_restore.restoreBackupPiece(done =&gt; finished, handle=&gt; v_filename(i),params=&gt;null);END LOOP;--IF finished THENdbms_output.put_line(&apos;Datafiles restored&apos;);ELSEdbms_output.put_line(&apos;Problem&apos;);END IF;--dbms_backup_restore.deviceDeallocate(&apos;d1&apos;);END;/ 3.4还原归档日志1234567891011121314151617181920212223242526272829303132333435363738SQL&gt; SET SERVEROUTPUT ONSQL&gt; DECLARE 2 finished BOOLEAN; 3 v_dev_name VARCHAR2(75); 4 BEGIN 5 -- Allocate channels, when disk then type = null, if tape then type = sbt_tape. 6 v_dev_name := dbms_backup_restore.deviceAllocate(type=&gt;null, ident=&gt; &apos;d1&apos;); 7 -- 8 -- Set beginning of restore operation (does not restore anything yet). 9 dbms_backup_restore.restoreSetArchivedlog; 10 -- 11 -- Define archived redo log files to be restored. 12 dbms_backup_restore.restoreArchivedlog(thread=&gt;1, sequence=&gt; 45); 13 dbms_backup_restore.restoreArchivedlog(thread=&gt;1, sequence=&gt; 46); 14 -- 15 dbms_backup_restore.restoreBackupPiece(done=&gt;finished, handle=&gt; 16 &apos;/oradata/backup/lv0_LINORA_20140601_119&apos;, 17 params=&gt;null); 18 -- 19 IF finished THEN 20 dbms_output.put_line(&apos;Archived redo log files restored&apos;); 21 ELSE 22 dbms_output.put_line(&apos;Problem&apos;); 23 END IF; 24 -- 25 dbms_backup_restore.deviceDeallocate(&apos;d1&apos;); 26 END; 27 /Archived redo log files restoredPL/SQL procedure successfully completed.SQL&gt; ![oracle@linora:/home/oracle]$ cd /oradata/arch/[oracle@linora:/oradata/arch]$ lltotal 2048-rw-r----- 1 oracle oinstall 2090496 Jun 9 16:22 1_45_842803310.arc-rw-r----- 1 oracle oinstall 1024 Jun 9 16:22 1_46_842803310.arc 经过以上的restore，接下来就可以执行正常的recovery动作了，这个包在10g以上已经不建议使用，在9i的异机恢复中还是可以用上的。最后，备份很重要，有一个健全的备份机制策略，能最大限度的减少数据丢失的概率及数据库宕机的时间。Reference:Oracle® Database Backup and Recovery User&#39;s Guide 11g Release 2 (11.2)","link":"/rman-complete-and-incomplete-recovery.html"},{"title":"RMAN Compression And Unused Block Compression","text":"最近在检查备份的时候发现一个新库，在磁带上备份占用了将近1个T，而备份到本地磁盘才使用了200G。从v$segments看，空间占用大概200G左右，但是分配了仅1个T的空间。为此，专门查看了MOS文档，里面有几篇文档提及这个问题。 1. RMAN压缩的类型RMAN默认提供以下三种类型的备份压缩。其中，从10.2开始，null compression和Unused block compression默认自动会进行，不需要其他指定。但是，在一些情况下，unused block compression会失效。 1.1 Null compression当以备份集方式备份数据文件的时候，RMAN不会去备份没有被分配的数据块，例如，在一个数据文件中，分配了100M空间，但仅仅使用了50M，rman只会备份这个50M的块。 1.2 Unused block compression从10.2开始，rman会跳过当前没有包含数据的块，这个称之为unused block compression, 例如，当前数据文件100M，包含了50M数据，当用户drop包含25M的表时候，rman只会备份剩下的25M的空间。即是说，null compression只会备份使用了的包括使用过的块；而unused block compression只备份了当前含有数据的数据块。因此unused block compress比null compression要节省空间跟时间。 Unused block compression适用条件： COMPATIBLE必须是10.2及以上 没有定义还原点 数据文件为本地管理 数据文件必须是全备或者0级增量备份，且备份以备份集形式存在 备份集是存放到磁盘或者以Oracle Secure Backup备份到磁带，即其他第三方备份软件备份到磁带是不会具有这个功能 仅支持企业版 这也是为什么第三方备份软件备份到磁带上空间占用量要远高于磁盘了。 1.3 Binary compression二进制压缩需要在rman备份命令中指定AS COMPRESSED。以这种形式的压缩备份成为二进制压缩。在进行二进制压缩备份的时候，CPU会有开销，意味着备份时间更长，同时restore的时候，时间也比没有压缩的还原时间要长。从11.2开始，rman二进制压缩有以下三个级别： LOW - 最小的压缩比例和占用最少的CPU MEDIUM - 同时兼顾CPU跟压缩比，推荐使用 HIGH - 最佳的压缩比，同时CPU开销会更大，使用于磁盘空间不足，但CPU比较空闲，或者需要通过网络传输，但网络资源比较紧张的情况 通过查询V$RMAN_COMPRESSION_ALGORITHM可以看到Oracle支持的压缩算法： 12345678910SQL&gt; select ALGORITHM_NAME, ALGORITHM_DESCRIPTION, ALGORITHM_COMPATIBILITY from V$RMAN_COMPRESSION_ALGORITHM ;ALGORITHM_NAME ALGORITHM_DESCRIPTION ALGORITHM_COMPATIB--------------- ------------------------------------------------------------ ------------------BZIP2 good compression ratio 9.2.0.0.0BASIC good compression ratio 9.2.0.0.0LOW maximum possible compression speed 11.2.0.0.0ZLIB balance between speed and compression ratio 11.0.0.0.0MEDIUM balance between speed and compression ratio 11.0.0.0.0HIGH maximum possible compression ratio 11.2.0.0.0 通过rman以下命令可以改变默认的压缩类型： 1RMAN&gt; CONFIGURE COMPRESSION ALGORITHM '&lt;alg_name&gt;'; 2. Undo块的优化从11g开始，rman开始对undo块进行优化，在不需要进行recovery的undo block上，即已经提交的事务的undo block，这些undo block将会被rman排除掉。同时undo的备份优化需满足以下几个条件： 是备份集的备份 全备或者是0级增量备份 不是validate的rman备份有效性验证 备份片的版本是11.1及以上 用户没有禁用undo optimization： _undo_block_compression = FALSE 备份集是写入磁盘或者OSB的磁带 没有还原点 3. Example 数据量大小： 12345SQL&gt; select sum(bytes/1024/1024/1024) from dba_segments;SUM(BYTES/1024/1024/1024)-------------------------3.20123291 RMAN基于磁盘的备份： 1RMAN&gt; backup full database format '/home/oracle/backup/full_%U.bak'; 磁盘备份的大小： 123[oracle@db2srv:/home/oracle/backup]$ du -sh full_0*1.9G full_01u9pved_1_1.bak9.7M full_02u9pvfi_1_1.bak 模拟磁带备份 123456RMAN&gt; run &#123;allocate channel x1 type 'sbt_tape'parms=\"SBT_LIBRARY=oracle.disksbt,ENV=(BACKUP_DIR=/home/oracle/backup)\";BACKUP full database format 'type_%U.bak';&#125; 磁带备份大小 123[oracle@db2srv:/home/oracle/backup]$ du -sh type_0*9.3G type_08u9q0ma_1_1.bak17M type_09u9q0o2_1_1.bak 可以看到，磁带的备份是并没有排除空块的。从v$backup_datafile视图中，可以看出数据文件是否是full scan(%READ is 100): 1234567891011select file# fno, used_change_tracking BCT,datafile_blocks BLKS,block_size blksz, blocks_read READ,UNDO_OPTIMIZED,round((blocks_read/datafile_blocks) * 100,2) \"%READ\",blocks WRTN, round((blocks/datafile_blocks)*100,2) \"%WRTN\"from v$backup_datafile--where completion_time between-- to_date('25-jan-09 01:30:00', 'dd-mon-rr hh24:mi:ss') and-- to_date('26-jan-09 12:35:26', 'dd-mon-rr hh24:mi:ss')order by file#; Reference:Why is RMAN not using Unused Block Compression during backup? (Doc ID 798844.1)A Complete Understanding of RMAN Compression (Doc ID 563427.1)Why an SBT backup MAY take longer and create larger backuppieces than a DISK backup. (Doc ID 1349492.1) EOF","link":"/rman-compression-and-unused-block-compression.html"},{"title":"RMAN基础知识","text":"1. Concepts Backup Sets &amp; Image copiesRMAN backup的命令能备份出两种类型：备份集和镜像副本。RMAN默认会备份为备份集。备份集是一个逻辑结构，是由一个或者多个备份片组成，备份片则是真实存储备份数据的物理文件。如下所示，表示备份集47包含了1-6个数据文件，由一个备份片组成(/oradata/backup/bk_20140519_32_848006921_LINORA)：12345678910111213141516171819202122RMAN&gt; list backup of database;using target database control file instead of recovery catalogList of Backup Sets===================BS Key Type LV Size Device Type Elapsed Time Completion Time ------- ---- -- ---------- ----------- ------------ -------------------47 Full 962.68M DISK 00:01:13 2014-05-19 21:29:54 BP Key: 47 Status: AVAILABLE Compressed: NO Tag: HOT_DB_BK_LEVEL0 Piece Name: /oradata/backup/bk_20140519_32_848006921_LINORA List of Datafiles in backup set 47 File LV Type Ckp SCN Ckp Time Name ---- -- ---- ---------- ------------------- ---- 1 Full 1282313 2014-05-19 21:28:41 /oradata/datafile/linora/system01.dbf 2 Full 1282313 2014-05-19 21:28:41 /oradata/datafile/linora/sysaux01.dbf 3 Full 1282313 2014-05-19 21:28:41 /oradata/datafile/linora/undotbs01.dbf 4 Full 1282313 2014-05-19 21:28:41 /oradata/datafile/linora/users01.dbf 5 Full 1282313 2014-05-19 21:28:41 /oradata/datafile/linora/fung01.dbf 6 Full 1282313 2014-05-19 21:28:41 /oradata/datafile/linora/undotbs02.dbf 一个备份集能够包含一个或者多个数据文件，归档日志文件，控制文件。一个备份集默认只有一个备份片。同时，也可以通过maxpiecesize参数限制备份片的大小，超过这个参数值，一个备份片就会被分为多个备份片。指定fileperset参数则表示一个备份集中包含几个输入文件(datafile,archivelog等)。Backup set和Image copies最关键的区别在于，一个备份集可以同时从多个文件中的数据块写入到一个备份集中，而Image copy则只能是byte by byte，image copy就像OS的dd命令一样，属于完全一致的镜像复制。RMAN默认是以备份集的方式(backup as backupset)备份的，它只会备份分配了的数据块(处于高水位下的空块也包括)，而不是备份整个数据文件，相反，Image copy则是备份整个数据文件的所有块。由于在现实生产环境用Image copy用的少，在后续的讨论中，会忽略image copy的相关问题。 2. RMAN backup ModesRMAN的备份模式按照数据一致性可分为一致性(consistent)备份和非一致性(inconsistent)备份，按照增量水平可分为全备和增量备份，增量备份又分为差异增量(Differential Incremental)备份和累积增量(Cumulative Incremental)备份。 一致性备份当数据库干净的关闭后，然后进入mount模式进行的备份，这种备份模式如果在还原的时候是不需要进行recover的。 非一致性备份当数据库处于open(需要在归档模式下)或者非干净的关闭后的mount下进行的备份，非一致性备份在restore完后都是需要进行recover动作的。因此，在RMAN的backup命令中，如果处于归档模式，则数据库在open或者mount状态下均可备份，如果处于非归档模式，则需要干净的关闭数据库，并且进入mount模式下进行备份。 全备RMAN中backup database默认就是全备，即backup full database。全备表示所有曾经使用过的数据块都会被备份下来，不管它现在是否为空。 增量备份增量备份是相对于全备而言，增量备份只备份上一次备份以来所改变的数据块。增量备份需要显式指定incremental关键字。增量备份分为差异增量备份和累积增量备份。 差异增量备份是备份上级及同级备份以来所有变化的数据块，差异增量是默认增量备份方式。在lv1的差异增量备份中，RMAN备份自从在上一次lv1或者lv0备份后改变的数据块，如果lv0备份不可用，根据compatibility的不同，RMAN会有不同的做法：如果compatibility&gt;=10.0.0，RMAN会备份自从数据文件创建以来所有改变了的数据块，否则，RMAN执行0级备份。图示如下： 累积增量备份累积增量备份上级备份以来所有变化的块，如在lv1的累积增量备份中，它会备份上次lv0以后所有改变的数据块，在lv2的累积增量备份中，它会备份上次lv1以后所有改变的数据块，如果没有lv1，则会寻找lv0。图示如下：很明显，两种增量备份策略的差异在于，diff需要更少的备份空间，但是恢复时间更久，cumu需要的备份空间更多，但是恢复时间要少得多。如何选择，得综合两者考虑。同时，虽然存在2级增量备份，但是oracle不推荐使用2级增量备份。再者，0级增量和全备的区别在于：lv0可以用来增量恢复，而全备不可以，且lv0是增量备份基础。RMAN的默认设置里面，备份集是默认的，全备是默认的，增量备份中，差异增量备份是默认的。 3. RMAN formatRMAN通过backup命令的format子句指定生成备份的路径和文件名。format参数如下表所示： 表1-1 RMAN Format格式说明 参数 含义 %a 指定数据库的激活ID %b 11g新加参数，定义没有任何目录路径的文件名，只能被set newname命令使用，或者用于建立图像副本备份 %c 指定多路备份中备份片副本数量，如果没有使用多路备份，这个变量值是1(备份集)或者0(代理备份) %d 数据库名 %D 当前日期天数，格式为DD %e 指定归档日志的sequence NO %f 指定绝对的文件数 %F 提供唯一的和可重复的名称，包含了DBID，年月日等信息，这是系统留给控制文件自动备份用的格式，不是有效的用户指定格式 %h 指定归档日志线程号(thread number) %I 指定DBID %M 指定当前日期月份，格式为MM %N 指定表空间名称，此参数仅用于备份数据文件或者镜像复制 %n 指定数据库名称，右边用x字符填充至总长为8个字符，如DB_NAME为LINORA,使用此参数后为LINORAxx %p 表示备份集中的备份片数量，对于每个备份集，该值初始为1，在创建每个备份片时，该值增加1 %s 指定备份集数量。该数量是控制文件中的计数器。该数值在控制文件的生命周期中唯一 %t 表示备份集时间戳，这是根据从固定参考时间以来已经过去的秒数得出的4位字节值，结合%s可生成备份集唯一名称 %T 指定时间格式，格式为YYYYMMDD %u 生产8位字符名称，该名称由备份集数量及备份集创建时间的压缩表示组成 %U 默认的文件命名模式，在备份集中，%U表示%u_%p_%c组成，保证生成备份文件名唯一 %Y 表示当前日期年份，格式为YYYY %% 转义字符，表示希望使用%字符 4. 控制文件及spfile自动备份RMAN中，默认是不自动备份控制文件。通过以下命令可以开启控制文件及SPFILE的自动备份，且可以指定备份路径：12CONFIGURE CONTROLFILE AUTOBACKUP ON;CONFIGURE CONTROLFILE AUTOBACKUP FORMAT FOR DEVICE TYPE DISK TO &apos;/oradata/backup/%F.ctl&apos;; 同时，如果在归档模式下，只要有对控制文件内容有影响的数据库改变，都会导致控制文件自动备份，如创建表空间，创建表等。如果数据库版本是10g，则可立刻从alert日志看出控制文件的自动备份，但是在11gR2中，引进了控制文件自动备份延迟创建的特性。即使autobackup开启，在数据结构改变时不会立即看到控制文件的备份，而是过一段时间才能看到，这是为了改变性能而引进的，防止用户在一个脚本中多次对数据库结构的变化而创建多个控制文件备份。它是通过MMON后台完成的，因此，11gr2在alert日志中是看不到控制文件的自动备份信息的，而是写在m000 trace文件中。至于延长多久，是有隐含参数_controlfile_autobackup_delay来控制的，默认：300s。123456789101112131415161718#m000 trace文件部分信息Starting control autobackup*** 2014-06-01 09:06:48.030Control autobackup written to DISK device handle &apos;/oradata/backup/c-3385851293-20140601-01.ctl&apos;#查看隐含参数SQL&gt; set linesize 200SQL&gt; col KSPPINM for a30SQL&gt; col KSPPSTVL for a10SQL&gt; col KSPPDESC for a100SQL&gt; SELECT ksppinm, ksppstvl, ksppdesc 2 FROM x$ksppi x, x$ksppcv y 3 WHERE x.indx = y.indx 4 AND ksppinm = &apos;_controlfile_autobackup_delay&apos;;KSPPINM KSPPSTVL KSPPDESC------------------------------ ---------- ---------------------------------------------------------------_controlfile_autobackup_delay 300 time delay (in seconds) for performing controlfile autobackups 同时，如果设定AUTOBACKUP ON，则在任何一个backup命令成功后，都会备份控制文件及SPFILE。123Starting Control File and SPFILE Autobackup at 2014-06-01 09:24:07piece handle=/oradata/backup/c-3385851293-20140601-04.ctl comment=NONEFinished Control File and SPFILE Autobackup at 2014-06-01 09:24:10 如果备份的数据文件是system，即datafile 1，那么不管自动备份开启与否，RMAN都将自动备份控制文件与SPFILE。 5. RMAN备份示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071run&#123;allocate channel c1 type disk format &apos;/oradata/backup/lv0_%d_%T_%s&apos;;#分配通道c1，类型为disk，指定文件名和备份路径backup incremental level=0 database#进行0级增量备份include current controlfile#包含当前控制文件plus archivelog delete all input;#包含归档日志，且将备份完的归档删除release channel c1;#释放通道&#125;allocated channel: c1channel c1: SID=143 device type=DISKStarting backup at 2014-06-01 00:17:33current log archived #归档当前在线日志channel c1: starting archived log backup setchannel c1: specifying archived log(s) in backup setinput archived log thread=1 sequence=38 RECID=110 STAMP=849053853channel c1: starting piece 1 at 2014-06-01 00:17:33channel c1: finished piece 1 at 2014-06-01 00:17:34piece handle=/oradata/backup/lv0_LINORA_20140601_81 tag=TAG20140601T001733 comment=NONE#产生的备份文件名称channel c1: backup set complete, elapsed time: 00:00:01channel c1: deleting archived log(s)archived log file name=/oradata/arch/1_38_842803310.arc RECID=110 STAMP=849053853Finished backup at 2014-06-01 00:17:34#完成备份数据文件前的归档日志备份Starting backup at 2014-06-01 00:17:34channel c1: starting incremental level 0 datafile backup setchannel c1: specifying datafile(s) in backup setinput datafile file number=00001 name=/oradata/datafile/linora/system01.dbfinput datafile file number=00002 name=/oradata/datafile/linora/sysaux01.dbfinput datafile file number=00003 name=/oradata/datafile/linora/undotbs01.dbfinput datafile file number=00005 name=/oradata/datafile/linora/fung01.dbfinput datafile file number=00004 name=/oradata/datafile/linora/users01.dbfinput datafile file number=00006 name=/oradata/datafile/linora/undotbs02.dbfchannel c1: starting piece 1 at 2014-06-01 00:17:35channel c1: finished piece 1 at 2014-06-01 00:18:40piece handle=/oradata/backup/lv0_LINORA_20140601_82 tag=TAG20140601T001734 comment=NONEchannel c1: backup set complete, elapsed time: 00:01:05#完成数据文件备份channel c1: starting incremental level 0 datafile backup setchannel c1: specifying datafile(s) in backup setincluding current control file in backup setincluding current SPFILE in backup setchannel c1: starting piece 1 at 2014-06-01 00:18:41channel c1: finished piece 1 at 2014-06-01 00:18:42piece handle=/oradata/backup/lv0_LINORA_20140601_83 tag=TAG20140601T001734 comment=NONEchannel c1: backup set complete, elapsed time: 00:00:01Finished backup at 2014-06-01 00:18:42#完成控制文件的备份，同时spfile也包含在此备份集中Starting backup at 2014-06-01 00:18:42current log archived #归档当前日志，目的在于备份在此期间内的日志变化channel c1: starting archived log backup setchannel c1: specifying archived log(s) in backup setinput archived log thread=1 sequence=39 RECID=111 STAMP=849053922channel c1: starting piece 1 at 2014-06-01 00:18:42channel c1: finished piece 1 at 2014-06-01 00:18:43piece handle=/oradata/backup/lv0_LINORA_20140601_84 tag=TAG20140601T001842 comment=NONEchannel c1: backup set complete, elapsed time: 00:00:01channel c1: deleting archived log(s)archived log file name=/oradata/arch/1_39_842803310.arc RECID=111 STAMP=849053922Finished backup at 2014-06-01 00:18:43released channel: c1 6. RMAN维护确认过期/失效备份首先对RMAN备份集进行crosscheck，这个命令会更新catalog信息，以便RMAN得到的是最新的真实数据，例如在OS级别删除了备份文件，则需要crosscheck去同步catalog信息。report obsolete跟RMAN备份策略的冗余有关。1234RMAN&gt; crosscheck backup;RMAN&gt; report obsolete;RMAN&gt; delete obsolete;RMAN&gt; delete expired backup; RMAN listRMAN的list命令能查看备份状态12345678910RMAN&gt; list backup;RMAN&gt; list backup summary;RMAN&gt; list backup by file;RMAN&gt; list backup of database;RMAN&gt; list backup of controlfile;RMAN&gt; list backup of archivelog all; RMAN&gt; list backup of spfile;RMAN&gt; list expired backup;RMAN&gt; list backupset;RMAN&gt; list incarnation; RMAN备份完整性检测使用backup validate对备份数据进行完整性检测，跟备份过程完全相同，但不会执行真正的备份。如果要检测逻辑上的corruption，则添加check logical参数。123456789101112131415161718192021222324252627282930313233RMAN&gt; backup validate archivelog all;Starting backup at 2014-06-01 10:10:03current log archivedusing channel ORA_DISK_1channel ORA_DISK_1: starting archived log backup setchannel ORA_DISK_1: specifying archived log(s) in backup setinput archived log thread=1 sequence=45 RECID=117 STAMP=849089403channel ORA_DISK_1: backup set complete, elapsed time: 00:00:01List of Archived Logs=====================Thrd Seq Status Blocks Failing Blocks Examined Name---- ------- ------ -------------- --------------- ---------------1 45 OK 0 4082 /oradata/arch/1_45_842803310.arcFinished backup at 2014-06-01 10:10:04RMAN&gt; backup validate check logical archivelog all;Starting backup at 2014-06-01 10:10:25current log archivedusing channel ORA_DISK_1channel ORA_DISK_1: starting archived log backup setchannel ORA_DISK_1: specifying archived log(s) in backup setinput archived log thread=1 sequence=45 RECID=117 STAMP=849089403input archived log thread=1 sequence=46 RECID=118 STAMP=849089425channel ORA_DISK_1: backup set complete, elapsed time: 00:00:01List of Archived Logs=====================Thrd Seq Status Blocks Failing Blocks Examined Name---- ------- ------ -------------- --------------- ---------------1 45 OK 0 4082 /oradata/arch/1_45_842803310.arc1 46 OK 0 1 /oradata/arch/1_46_842803310.arcFinished backup at 2014-06-01 10:10:26 如果备份文件中存在corruption，可以通过查询V$DATABASE_BLOCK_CORRUPTION获得坏块位置。下面模拟一个物理坏块：1234567891011121314151617181920212223242526272829303132333435[oracle@linora:/oradata/datafile/linora]$ dd of=/oradata/datafile/linora/test01.dbf \\bs=8192 conv=notrunc seek=15 &lt;&lt;! &gt; abc&gt; !0+1 records in0+1 records out4 bytes (4 B) copied, 0.000733863 s, 5.5 kB/sRMAN&gt; validate datafile 8;Starting validate at 2014-06-01 10:25:37using channel ORA_DISK_1channel ORA_DISK_1: starting validation of datafilechannel ORA_DISK_1: specifying datafile(s) for validationinput datafile file number=00008 name=/oradata/datafile/linora/test01.dbfchannel ORA_DISK_1: validation complete, elapsed time: 00:00:03List of Datafiles=================File Status Marked Corrupt Empty Blocks Blocks Examined High SCN---- ------ -------------- ------------ --------------- ----------8 FAILED 0 1153 1280 1510913 File Name: /oradata/datafile/linora/test01.dbf Block Type Blocks Failing Blocks Processed ---------- -------------- ---------------- Data 0 0 Index 0 0 Other 1 127 validate found one or more corrupt blocksSee trace file /u01/app/oracle/diag/rdbms/linora/linora/trace/linora_ora_5245.trc for detailsFinished validate at 2014-06-01 10:25:40SQL&gt; select * from V$DATABASE_BLOCK_CORRUPTION; FILE# BLOCK# BLOCKS CORRUPTION_CHANGE# CORRUPTIO---------- ---------- ---------- ------------------ --------- 8 15 1 0 CORRUPT 查询结果跟我们预期的相同，都是在数据文件8，block 15上坏块。对于坏块的检测和处理，请参照前文Detect and Correct Corruption in Oracle。 7. 查看RMAN备份进度12345678910111213#查看RMAN备份进度SQL&gt; select sid,serial#,context,sofar,totalwork, 2 round(sofar/totalwork*100,2) &quot;%_COMPLETE&quot; 3 from v$session_longops 4 where opname like &apos;%RMAN%&apos; 5 and opname not like &apos;%aggregate%&apos; 6 and totalwork !=0 7 and sofar&lt;&gt;totalwork 8 / SID SERIAL# CONTEXT SOFAR TOTALWORK %_COMPLETE---------- ---------- ---------- ---------- ---------- ---------- 148 153 1 142204 250368 56.8 12345678910111213141516171819202122232425SQL&gt; col CLIENT_INFO for a10SQL&gt; col OPNAME for a20SQL&gt; col MESSAGE for a30SQL&gt; col SPID for a10SQL&gt; set linesize 200SQL&gt; select s.client_info,sl.opname,sl.message,sl.sid, sl.serial#, p.spid,sl.sofar, sl.totalwork,round(sl.sofar/sl.totalwork*100,2) &quot;% Complete&quot;from v$session_longops sl, v$session s, v$process pwhere p.addr = s.paddrand sl.sid=s.sidand sl.serial#=s.serial#and opname LIKE &apos;RMAN%&apos;and opname NOT LIKE &apos;%aggregate%&apos;and totalwork != 0and sofar &lt;&gt; totalwork;CLIENT_INF OPNAME MESSAGE SID SERIAL# SPID SOFAR TOTALWORK % Complete---------- -------------------- ------------------------------ ---------- ---------- ---------- ---------- ---------- ----------rman chann RMAN: full datafile RMAN: full datafile backup: Se 10 75 5425 249150 250368 99.51el=ch00 backup t Count 129: 249150 out of 250 368 Blocks done Reference：Oracle® Database Backup and Recovery User&#39;s Guide 11g Release 2 (11.2)","link":"/rman-fundamentals.html"},{"title":"RMAN恢复基本概念","text":"大部分recovery场景都需要经过两个阶段：restore(还原)和recover(恢复)。 Condition On Start-up Oracle Behavior DBA action CF checkpoint scn &lt; datafile Checkpoint scn Controlfile too old error restore a newer controlfile CF checkpoint scn &gt; datafile Checkpoint scn Media recovery required Most likely a datafile has been restored from a backup.Recovery is now required. CF checkpoint scn = datafile checkpoint scn Startup normally None Database mounted, instance thread status=OPEN Crash recovery needed NONE 在RMAN中，还原和恢复具有不同的含义。还原是指访问之前生产的备份集，从中得到一个或者多个对象，然后在磁盘的某个位置还原这些对象，包括数据文件，控制文件，归档日志，SPFILE等。恢复是指重新应用事务的重做日志到数据文件的过程。 1. 完全恢复和不完全恢复完全恢复意味着你能恢复所有在失败前已提交的事务。因此，完全恢复是不需要将所有数据文件都还原并且恢复的。我们需要做的只是恢复那些损坏了的数据文件。Oracle通过对比控制文件中的SCN值和dafatile header中的SCN值来确定哪些数据文件需要被恢复。1234567891011121314SQL&gt; select file#,status,checkpoint_change#, 2 to_char(checkpoint_time,'yyyy-mm-dd hh24:mi:ss') 3 from v$datafile_header; FILE# STATUS CHECKPOINT_CHANGE# TO_CHAR(CHECKPOINT_---------- ------- ------------------ ------------------- 1 ONLINE 1559658 2014-06-04 14:51:50 2 ONLINE 1559658 2014-06-04 14:51:50 3 ONLINE 1559658 2014-06-04 14:51:50 4 ONLINE 1559658 2014-06-04 14:51:50 5 ONLINE 1559658 2014-06-04 14:51:50 6 ONLINE 1559658 2014-06-04 14:51:50 7 ONLINE 1559658 2014-06-04 14:51:50 8 ONLINE 1559658 2014-06-04 14:51:50 不完全恢复意味着不是所有已提交事务都能进行恢复，所以肯定丢失部分数据。不完全恢复一般用在指定时间点的恢复，由于误操作而导致的数据丢失，可以采用不完全恢复至数据删除前一刻。不完全恢复是通过指定recover database until命令进行的。所以不完全恢复也被称之为基于时间点的恢复(database point-in-time recovery)。在选择何种恢复类型前(有些时候没得选择)，首先要明白Oracle数据库的一些后台进程及它们的工作原理。因为RMAN的完全恢复和不完全恢复都是基于日志的，对日志的操作，必不可少需要对一些后台进程有进一步的了解。只要细心的用户都会发现，无论多大多长久的事务，commit都会很快完成。这是因为Oracle对缓存区的dirty block，在它们提交的时候，并不确保这些数据都已经写入磁盘了，而是保证这些事务所有的redo entry都已经被写入online log，这样，在实例失败或者介质失败的时候，它可以通过日志文件中的redo entry重演事务的变化。data buffer cache和redo buffer cache目的完全不同，data buffer cache是为了能将用户需要的数据块尽可能的保留长久，以提高性能，而redo buffer cache是为了缓存重做日志，以提高日志文件写速度。因此，DBWn是在Checkpoint发生时候才会写脏数据至磁盘，而LGWR则是频繁地将缓冲区的redo写入到磁盘。当Checkpoint发生时，ckpt后台进程记录当前控制文件及数据文件头SCN值。Checkpoinnt能保证数据在这一时间点是一致性状态。DBWn和redo的关系可参照前文管理redo文件。 2. Crash RecoveryCrash Recovery等同于单实例的Instance Recovery，很多人认为它们是同一概念，在很多情况下，这两者并没有区别，唯一例外的情况是在RAC环境中，Instance Recovery指的的某一节点crash，其他节点通过日志前滚和回滚失败节点的事务。而Crash Recovery是对单实例或者RAC所有节点crash后的恢复。Crash Recovery是通过Oracle的SMON进程自动完成的，用户不需要参与。当掉电或者数据库没有干净的关闭(shutdown abort)时，Oracle需要进行Crash Recovery，将数据恢复到失败前的一致性状态，即所有在失败前已经提交的数据写入磁盘，未提交的数据回滚。以下为一个实例恢复的例子：123456789101112131415161718192021SQL&gt; shutdown abortORACLE instance shut down.SQL&gt; startup #alert.logBeginning crash recovery of 1 threads parallel recovery started with 2 processesStarted redo scanCompleted redo scan read 36 KB redo, 31 data blocks need recoveryStarted redo application at Thread 1: logseq 52, block 30273Recovery of Online Redo Log: Thread 1 Group 1 Seq 52 Reading mem 0 Mem# 0: /oradata/datafile/linora/redo01.logCompleted redo application of 0.01MBCompleted crash recovery at Thread 1: logseq 52, block 30346, scn 1584317 31 data blocks read, 31 data blocks written, 36 redo k-bytes read...SMON: enabling cache recovery...SMON: enabling tx recovery 实例崩溃的恢复包含两个阶段：前滚(roll forward)和回滚(roll back)。SMON会自动将上一次Checkpoint以后的online redo log进行前滚和应用，这个过程就是通过redo信息重新把数据库加载到缓冲区，然后对已经提交的数据写入数据文件。前滚完成后，Oracle通过undo或者rollback segment对未提交的事务进行回滚。只要将数据文件头部的检查点SCN和当前的在线日志最新的重做记录的SCN进行对比，便可得知该数据文件是否为&#39;旧&#39;，如果是，则表示不同步，需要前滚。前滚包括以下步骤： 读取数据文件头部检查点RBA，将RBA所指向的日志文件中的重做记录确定为前滚起点 根据RBA读取重做记录，获得改变向量中的AFN和DBA，得知哪些数据块需要被修改(重做) 根据改变向量中的DBA将数据块从数据文件中读至缓存，并比较数据块的实际版本(SCN+SEQ)与改变向量中记录的数据块版本 如版本相同，进入下一步骤。如改变向量的版本低于数据块的版本，Oracle会跳过当前重做记录，直接读取下一条重做记录；如果改变向量的版本高于数据块版本，前滚报错，crash recovery将意外终止 按顺序执行所有改变向量的操作，修改那些向量中DBA对应的数据块 重复上述步骤，直到用完在线日志的最后一条重做记录前滚完成后，已经提交的变更和没有提交的变更全部以数据块的形式从redo中恢复回来，接下来的任务就是回滚尚未提交的事务。关于RBA、DBA和重做记录及改变向量，可参照重做记录。在Oracle启动过程中，通过对比控制文件和datafile header的SCN值 [^1] 决定是正常开启数据库还是进行实例恢复或者进行介质恢复。两者的SCN值跟恢复动作关系如下表所示： SCN Oracle Start-up Checks Condition on Start-Up Oracle Behavior DBA Action CF checkpoint SCN &lt; Datafile checkpoint SCN &quot;Control file too old&quot; error Restore a newer control file. CF checkpoint SCN &gt; Datafile checkpoint SCN Media recovery required Most likely a datafile has been restored from a backup.Recovery is now required. CF checkpoint SCN = Datafile SCN Start up normally None. Database in mount mode, instance thread status = OPEN Crash recovery required None. 以下查询语句能找出当前数据库在mount状态下，是正常开启还是需要介质恢复。12345678910111213SELECTa.name,a.checkpoint_change#,b.checkpoint_change#,CASEWHEN ((a.checkpoint_change# - b.checkpoint_change#) = 0) THEN &apos;Startup Normal&apos;WHEN ((a.checkpoint_change# - b.checkpoint_change#) &gt; 0) THEN &apos;Media Recovery&apos;WHEN ((a.checkpoint_change# - b.checkpoint_change#) &lt; 0) THEN &apos;Old Control File&apos;ELSE &apos;what the ?&apos;END STATUSFROM v$datafile a, -- control file SCN for datafilev$datafile_header b -- datafile header SCNWHERE a.file# = b.file#; 以下动态性能视图能帮忙找到需要介质恢复的数据文件1234--from data file hearderselect file#, status, error,recover from v$datafile_header;--from controlfileselect file#, error from v$recover_file; 在启动阶段，Oracle检查实例的日志thread状态来决定crash recovery是否需要。当数据库正常开启时候，thread的状态是OPEN，当正常关闭时候，thread状态是CLOSED。当数据库异常终止，如shutdown abort，thread状态仍旧保持OPEN，在启动阶段，SMON检测到thread状态不正常，需要进行实例崩溃的恢复。1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#数据库OPEN状态SQL&gt; SELECT 2 a.thread#, b.open_mode, a.status, 3 CASE 4 WHEN ((b.open_mode=&apos;MOUNTED&apos;) AND (a.status=&apos;OPEN&apos;)) THEN &apos;Crash Recovery req.&apos; 5 WHEN ((b.open_mode=&apos;MOUNTED&apos;) AND (a.status=&apos;CLOSED&apos;)) THEN &apos;No Crash Rec. req.&apos; 6 WHEN ((b.open_mode=&apos;READ WRITE&apos;) AND (a.status=&apos;OPEN&apos;)) THEN &apos;Inst. already open&apos; 7 ELSE &apos;huh?&apos; 8 END STATUS 9 FROM v$thread a, 10 v$database b, 11 v$instance c 12 WHERE a.thread# = c.thread#; THREAD# OPEN_MODE STATUS STATUS---------- -------------------- ------ ------------------- 1 READ WRITE OPEN Inst. already open#数据库正常关闭SQL&gt; shutdown immediateSQL&gt; startup mountSQL&gt; SELECT 2 a.thread#, b.open_mode, a.status, 3 CASE 4 WHEN ((b.open_mode=&apos;MOUNTED&apos;) AND (a.status=&apos;OPEN&apos;)) THEN &apos;Crash Recovery req.&apos; 5 WHEN ((b.open_mode=&apos;MOUNTED&apos;) AND (a.status=&apos;CLOSED&apos;)) THEN &apos;No Crash Rec. req.&apos; 6 WHEN ((b.open_mode=&apos;READ WRITE&apos;) AND (a.status=&apos;OPEN&apos;)) THEN &apos;Inst. already open&apos; 7 ELSE &apos;huh?&apos; 8 END STATUS 9 FROM v$thread a, 10 v$database b, 11 v$instance c 12 WHERE a.thread# = c.thread#; THREAD# OPEN_MODE STATUS STATUS---------- -------------------- ------ ------------------- 1 MOUNTED CLOSED No Crash Rec. req.#数据库异常关闭SQL&gt; shutdown abortORACLE instance shut down.SQL&gt; startup mountSQL&gt; SELECT 2 a.thread#, b.open_mode, a.status, 3 CASE 4 WHEN ((b.open_mode=&apos;MOUNTED&apos;) AND (a.status=&apos;OPEN&apos;)) THEN &apos;Crash Recovery req.&apos; 5 WHEN ((b.open_mode=&apos;MOUNTED&apos;) AND (a.status=&apos;CLOSED&apos;)) THEN &apos;No Crash Rec. req.&apos; 6 WHEN ((b.open_mode=&apos;READ WRITE&apos;) AND (a.status=&apos;OPEN&apos;)) THEN &apos;Inst. already open&apos; 7 ELSE &apos;huh?&apos; 8 END STATUS 9 FROM v$thread a, 10 v$database b, 11 v$instance c 12 WHERE a.thread# = c.thread#; THREAD# OPEN_MODE STATUS STATUS---------- -------------------- ------ ------------------- 1 MOUNTED OPEN Crash Recovery req. 3. 确认备份集在恢复还原前，确认哪些备份集和文件是需要在恢复过程中用到的。preview的命令类似RMAN的list命令。123456789RMAN&gt; restore database preview;RMAN&gt; restore database preview summary;RMAN&gt; restore database preview;RMAN&gt; restore database from tag TAG20140601T101934 preview;RMAN&gt; restore datafile 1, 2, 3, 4 preview;RMAN&gt; restore archivelog all preview;RMAN&gt; restore archivelog from time &apos;sysdate - 1&apos; preview;RMAN&gt; restore archivelog from scn 3243256 preview;RMAN&gt; restore archivelog from sequence 29 preview; 检查备份的完整性，仅仅读取备份文件，不会真正做restore。1234567RMAN&gt; restore database validate;RMAN&gt; validate backupset 115;RMAN&gt; restore database from tag TAG20140601T101934 validate;RMAN&gt; restore datafile 1 validate;RMAN&gt; restore archivelog all validate;RMAN&gt; restore controlfile validate;RMAN&gt; restore tablespace users validate; 以上的检查只是物理性的检查，如果需要逻辑上检测备份集是否有问题，可用check logical子句，并且通过V$DATABASE_BLOCK_CORRUPTION查看检查结果。1restore database validate check logical; To Be Continued![^1]: V$DATAFILE_HEADER以数据文件为参考源.V$DATAFILE以控制文件为参考源.需要两者的checkpoint_change#相同才能正常开启数据库.","link":"/rman-recovery-concepts.html"},{"title":"RMAN RAC异机恢复","text":"1 前期准备工作 1.1 主库RAC数据库 数据库：erp1、erp2 归档路径：/archlog01、/archlog02 主库查找数据文件路径： SQL>select name from v$datafile; 1.2 备库数据文件规划 数据文件路径：/backup/oradata/app/erp (空间有1000GB) [说明]测试服务器数据库是单机模式，恢复后的数据文件采用文件系统。先创建目录erp $ mkdir –p /backup/oradata/app/erp 2 为备库创建初始化参数文件 2.1 [说明] 先为测试服务器创建相关文件目录，命令如下： $mkdir -p /backup/oradata/export/home/oracle/admin/erp/adump $mkdir -p /backup/oradata/export/home/oracle/admin/erp/bdump $mkdir -p /backup/oradata/export/home/oracle/admin/erp/cdump $mkdir -p /backup/oradata/export/home/oracle/admin/erp/dpdump $mkdir -p /backup/oradata/export/home/oracle/admin/erp/udump $mkdir -p /backup/oradata/app/erp/archivelog 2.2 登录主库RAC任一台： SQL> conn / as sysdba Connected. SQL> create pfile='/home/oracle/initerp.ora' from spfile; File created. 2.3 把文件/home/oracle/initerp.ora 拷贝到备库路径 /export/home/oracle/OraHome_1/dbs 2.4 在备库修改/export/home/oracle/OraHome_1/dbs的initerp.ora文件，注意去掉RAC相关参数 2.5 在备库创建密码文件 $ orapwd file=$ORACLE_HOME/dbs/orapwerp password=’www.sina.com’ entries=4 3 恢复控制文件 3.1 登录备份数据库,将数据库启动到nomount状态，如启动nomount状态成功则上一步的参数文件配置正确。 如启动nomount状态有错误，则需要检查上一步参数文件的配置是否正确。 SQL> conn / as sysdba Connected to an idle instance. SQL> startup nomount; ORACLE instance started. Total System Global Area 1610612736 bytes Fixed Size 2056504 bytes Variable Size 385879752 bytes Database Buffers 1207959552 bytes Redo Buffers 14716928 bytes 3.2 控制文件的备份集需要到主库上执行下面命令查看： $rman target / RMAN>list backup of controlfile; ……………………………. RMAN> list backup of controlfile; BS Key Type LV Size Device Type Elapsed Time Completion Time ------- ---- -- ---------- ----------- ------------ --------------- 4225 Full 15.25M SBT_TAPE 00:00:03 24-FEB-13 BP Key: 4223 Status: AVAILABLE Compressed: NO Tag: TAG20130224T041224 Handle: erp_ora_vls_full.ctl Media: 3d5212ac:50a0578f:0bec:001c Control File Included: Ckp SCN: 9026777113 Ckp time: 24-FEB-13 BS Key Type LV Size Device Type Elapsed Time Completion Time ------- ---- -- ---------- ----------- ------------ --------------- 4226 Full 15.25M SBT_TAPE 00:00:49 24-FEB-13 BP Key: 4224 Status: AVAILABLE Compressed: NO Tag: TAG20130224T041227 Handle: c-2428396893-20130224-00 Media: 3d5212ac:50a0578f:0bec:001c Control File Included: Ckp SCN: 9026777171 Ckp time: 24-FEB-13 3.3 备份集查看到主库做全库的备份，在备库使用rman恢复控制文件： $ rman target / RMAN>set DBID=2428396893 RMAN> run { allocate channel 'dev_0' type 'sbt_tape' parms 'SBT_LIBRARY=/opt/omni/lib/libob2oracle8_64bit.so, ENV=(OB2APPNAME=erp,OB2BARHOSTNAME=oratest)'; restore controlfile to '/backup/oradata/app/erp/control01.ctl' from 'erp_ora_vls_full.ctl'; release channel 'dev_0'; } 3.4 因为前面的initerp.ora中的参数指定了3个控制文件，我们可以通过命令拷贝2份即可： $ pwd /backup/oradata/app/erp $cp control01.ctl control02.ctl $cp control01.ctl control03.ctl 4 还原和恢复数据库文件 4.1 [说明] 生成数据文件对应路径脚本(在生产机上)： SQL> col name format a40 SQL> set linesize 100 SQL> set pagesize 100 SQL> select 'set newname for datafile ' || file# || ' to ''' || replace(name,'/dev/vgdata/rlverp_','/backup/oradata/app/erp/') || '.dbf'';' from v$datafile; 'SETNEWNAMEFORDATAFILE'||FILE#||' TO'''|| REPLACE(NAME,'/DEV/VGDATA/RLVERP_','/ORADATA/APP/erp/')||' ---------------------------------------------------------------------------------------------------- set newname for datafile 1 to '/backup/oradata/app/erp/system_2g.dbf'; set newname for datafile 2 to '/backup/oradata/app/erp/undotbs1_16g.dbf'; set newname for datafile 3 to '/backup/oradata/app/erp/sysaux_3g.dbf'; set newname for datafile 4 to '/backup/oradata/app/erp/undotbs2_16g.dbf'; set newname for datafile 5 to '/backup/oradata/app/erp/users_2g.dbf'; set newname for datafile 6 to '/backup/oradata/app/erp/data01_200g.dbf'; set newname for datafile 7 to '/backup/oradata/app/erp/data02_200g.dbf'; set newname for datafile 8 to '/backup/oradata/app/erp/data03_32g.dbf'; set newname for datafile 9 to '/backup/oradata/app/erp/data04_32g.dbf'; set newname for datafile 10 to '/backup/oradata/app/erp/data05_32g.dbf'; set newname for datafile 11 to '/backup/oradata/app/erp/data07_32g.dbf'; set newname for datafile 12 to '/backup/oradata/app/erp/data06_32g.dbf'; set newname for datafile 13 to '/backup/oradata/app/erp/data08_32g.dbf'; set newname for datafile 14 to '/backup/oradata/app/erp/data09_32g.dbf'; set newname for datafile 15 to '/backup/oradata/app/erp/data11_32g.dbf'; set newname for datafile 16 to '/backup/oradata/app/erp/data10_32g.dbf'; set newname for datafile 17 to '/backup/oradata/app/erp/data12_32g.dbf'; set newname for datafile 18 to '/backup/oradata/app/erp/data13_32g.dbf'; set newname for datafile 19 to '/backup/oradata/app/erp/data14_32g.dbf'; set newname for datafile 20 to '/backup/oradata/app/erp/data15_32g.dbf'; set newname for datafile 21 to '/backup/oradata/app/erp/data16_32g.dbf'; set newname for datafile 22 to '/backup/oradata/app/erp/data17_32g.dbf'; set newname for datafile 23 to '/backup/oradata/app/erp/data18_32g.dbf'; set newname for datafile 24 to '/backup/oradata/app/erp/data19_32g.dbf'; set newname for datafile 25 to '/backup/oradata/app/erp/data20_32g.dbf'; set newname for datafile 26 to '/backup/oradata/app/erp/data21_32g.dbf'; set newname for datafile 27 to '/backup/oradata/app/erp/data22_32g.dbf'; set newname for datafile 28 to '/backup/oradata/app/erp/data23_32g.dbf'; set newname for datafile 29 to '/backup/oradata/app/erp/data24_32g.dbf'; set newname for datafile 30 to '/backup/oradata/app/erp/data25_32g.dbf'; set newname for datafile 31 to '/backup/oradata/app/erp/data26_32g.dbf'; set newname for datafile 32 to '/backup/oradata/app/erp/data27_32g.dbf'; set newname for datafile 33 to '/backup/oradata/app/erp/data28_32g.dbf'; 33 rows selected. 4.2 查生产机备份的archivelog $ rman target / RMAN> list backup of archivelog all; BS Key Size Device Type Elapsed Time Completion Time ------- ---------- ----------- ------------ --------------- 4219 647.75M SBT_TAPE 00:00:07 23-FEB-13 BP Key: 4217 Status: AVAILABLE Compressed: NO Tag: TAG20130223T024428 Handle: erp_ora_vls_arch_del.arc Media: List of Archived Logs in backup set 4219 Thrd Seq Low SCN Low Time Next SCN Next Time ---- ------- ---------- --------- ---------- --------- 2 6188 9016300687 23-FEB-13 9016565667 23-FEB-13 2 6189 9016565667 23-FEB-13 9017090490 23-FEB-13 2 6190 9017090490 23-FEB-13 9017155280 23-FEB-13 4.3 测试机启动数据库到mount状态 SQL> alter database mount; Database altered. 4.4 还原和恢复数据文件 RMAN> run{ allocate channel 'dev_0' type 'sbt_tape' parms 'SBT_LIBRARY=/opt/omni/lib/libob2oracle8_64bit.so, ENV=(OB2APPNAME=erp,OB2BARHOSTNAME=oratest)'; allocate channel 'dev_1' type 'sbt_tape' parms 'SBT_LIBRARY=/opt/omni/lib/libob2oracle8_64bit.so, ENV=(OB2APPNAME=erp,OB2BARHOSTNAME=oratest)'; set newname for datafile 1 to '/backup/oradata/app/erp/system_2g.dbf'; set newname for datafile 2 to '/backup/oradata/app/erp/undotbs1_16g.dbf'; set newname for datafile 3 to '/backup/oradata/app/erp/sysaux_3g.dbf'; set newname for datafile 4 to '/backup/oradata/app/erp/undotbs2_16g.dbf'; set newname for datafile 5 to '/backup/oradata/app/erp/users_2g.dbf'; set newname for datafile 6 to '/backup/oradata/app/erp/data01_200g.dbf'; set newname for datafile 7 to '/backup/oradata/app/erp/data02_200g.dbf'; set newname for datafile 8 to '/backup/oradata/app/erp/data03_32g.dbf'; set newname for datafile 9 to '/backup/oradata/app/erp/data04_32g.dbf'; set newname for datafile 10 to '/backup/oradata/app/erp/data05_32g.dbf'; set newname for datafile 11 to '/backup/oradata/app/erp/data07_32g.dbf'; set newname for datafile 12 to '/backup/oradata/app/erp/data06_32g.dbf'; set newname for datafile 13 to '/backup/oradata/app/erp/data08_32g.dbf'; set newname for datafile 14 to '/backup/oradata/app/erp/data09_32g.dbf'; set newname for datafile 15 to '/backup/oradata/app/erp/data11_32g.dbf'; set newname for datafile 16 to '/backup/oradata/app/erp/data10_32g.dbf'; set newname for datafile 17 to '/backup/oradata/app/erp/data12_32g.dbf'; set newname for datafile 18 to '/backup/oradata/app/erp/data13_32g.dbf'; set newname for datafile 19 to '/backup/oradata/app/erp/data14_32g.dbf'; set newname for datafile 20 to '/backup/oradata/app/erp/data15_32g.dbf'; set newname for datafile 21 to '/backup/oradata/app/erp/data16_32g.dbf'; set newname for datafile 22 to '/backup/oradata/app/erp/data17_32g.dbf'; set newname for datafile 23 to '/backup/oradata/app/erp/data18_32g.dbf'; set newname for datafile 24 to '/backup/oradata/app/erp/data19_32g.dbf'; set newname for datafile 25 to '/backup/oradata/app/erp/data20_32g.dbf'; set newname for datafile 26 to '/oradata/app/erp/data21_32g.dbf'; set newname for datafile 27 to '/oradata/app/erp/data22_32g.dbf'; set newname for datafile 28 to '/oradata/app/erp/data23_32g.dbf'; set newname for datafile 29 to '/oradata/app/erp/data24_32g.dbf'; set newname for datafile 30 to '/oradata/app/erp/data25_32g.dbf'; set newname for datafile 31 to '/oradata/app/erp/data26_32g.dbf'; set newname for datafile 32 to '/oradata/app/erp/data27_32g.dbf'; set newname for datafile 33 to '/oradata/app/erp/data28_32g.dbf'; restore database; switch datafile all; release channel 'dev_0'; release channel 'dev_1'; } --还原Thread 2日志文件 RMAN>run{ allocate channel 'dev_0' type 'sbt_tape' parms 'SBT_LIBRARY=/opt/omni/lib/libob2oracle8_64bit.so, ENV=(OB2APPNAME=erp,OB2BARHOSTNAME=oratest)'; allocate channel 'dev_1' type 'sbt_tape' parms 'SBT_LIBRARY=/opt/omni/lib/libob2oracle8_64bit.so, ENV=(OB2APPNAME=erp,OB2BARHOSTNAME=oratest)'; restore archivelog from logseq=6191 until logseq=6196 thread 2; release channel 'dev_0'; release channel 'dev_1'; --还原Thread 1日志文件 RMAN> run{ allocate channel 'dev_0' type 'sbt_tape' parms 'SBT_LIBRARY=/opt/omni/lib/libob2oracle8_64bit.so, ENV=(OB2APPNAME=erp,OB2BARHOSTNAME=oratest)'; allocate channel 'dev_1' type 'sbt_tape' parms 'SBT_LIBRARY=/opt/omni/lib/libob2oracle8_64bit.so, ENV=(OB2APPNAME=erp,OB2BARHOSTNAME=oratest)'; restore archivelog from logseq=5908 until logseq=5911 thread 1; release channel 'dev_0'; release channel 'dev_1'; } --恢复数据 RMAN> recover database; Starting recover at 21-JAN-13 allocated channel: ORA_DISK_1 channel ORA_DISK_1: sid=1120 devtype=DISK starting media recovery archive log thread 1 sequence 5690 is already on disk as file /backup/oradata/app/erp/archivelog/1_5690_725969838.dbf archive log thread 2 sequence 5869 is already on disk as file /backup/oradata/app/erp/archivelog/2_5869_725969838.dbf archive log filename=/backup/oradata/app/erp/archivelog/1_5690_725969838.dbf thread=1 sequence=5690 archive log filename=/backup/oradata/app/erp/archivelog/2_5869_725969838.dbf thread=2 sequence=5869 unable to find archive log archive log thread=1 sequence=5691 RMAN-00571: =========================================================== RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS =============== RMAN-00571: =========================================================== RMAN-03002: failure of recover command at 01/21/2013 17:44:49 RMAN-06054: media recovery requesting unknown log: thread 1 seq 5691 lowscn 8638094832 5 为联机日志重命名和删除实例2的联机日志 5.1 登录测试数据库，为联机日志重命名 SQL> select member from v$logfile; MEMBER -------------------------------------------------------------------------------- /dev/vgdata/rlverp_redo1_1_512m /dev/vgdata/rlverp_redo2_1_512m /dev/vgdata/rlverp_redo3_1_512m /dev/vgdata/rlverp_redo4_1_512m /dev/vgdata/rlverp_redo1_2_512m /dev/vgdata/rlverp_redo2_2_512m /dev/vgdata/rlverp_redo3_2_512m /dev/vgdata/rlverp_redo4_2_512m 8 rows selected. SQL> alter database rename file '/dev/vgdata/rlverp_redo1_1_512m' to '/backup/oradata/app/erp/redo01.log'; Database altered. SQL> alter database rename file '/dev/vgdata/rlverp_redo2_1_512m' to '/backup/oradata/app/erp/redo02.log'; Database altered. SQL> alter database rename file '/dev/vgdata/rlverp_redo3_1_512m' to '/backup/oradata/app/erp/redo03.log'; Database altered. SQL> alter database rename file '/dev/vgdata/rlverp_redo4_1_512m' to '/backup/oradata/app/erp/redo04.log'; Database altered. SQL> alter database rename file '/dev/vgdata/rlverp_redo1_2_512m' to '/backup/oradata/app/erp/redo05.log'; Database altered. SQL> alter database rename file '/dev/vgdata/rlverp_redo2_2_512m' to '/backup/oradata/app/erp/redo06.log'; Database altered. SQL> alter database rename file '/dev/vgdata/rlverp_redo3_2_512m' to '/backup/oradata/app/erp/redo07.log'; Database altered. SQL> alter database rename file '/dev/vgdata/rlverp_redo4_2_512m' to '/backup/oradata/app/erp/redo08.log'; Database altered. 5.2 登录测试服务器数据库库，删除线程2的联机日志 SQL> select THREAD#, STATUS, ENABLED from v$thread; THREAD# STATUS ENABLED ---------- ------ -------- 1 OPEN PUBLIC 2 OPEN PUBLIC SQL> select group# from v$log where THREAD#=2; GROUP# ---------- 5 8 7 6 --打开数据库(resetlogs模式) SQL> alter database open resetlogs; Database altered. --屏蔽线程2的联机日志 SQL>alter database disable thread 2; Database altered. --删除线程2的联机日志 SQL> alter database drop logfile group 5; alter database drop logfile group 5 * ERROR at line 1: ORA-01623: log 5 is current log for instance erp2 (thread 2) - cannot drop ORA-00312: online log 5 thread 2: '/backup/oradata/app/erp/redo05.log' SQL> alter database drop logfile group 6; Database altered. SQL> alter database drop logfile group 7; Database altered. SQL> alter database drop logfile group 8; alter database drop logfile group 8 * ERROR at line 1: ORA-01624: log 8 needed for crash recovery of instance erp2 (thread 2) ORA-00312: online log 8 thread 2: '/backup/oradata/app/erp/redo08.log' --如有日志不能删除，可以做下面的操作，再删除。下面是group 5和8不能删除 SQL> alter database clear unarchived logfile group 5; Database altered. SQL> alter database clear unarchived logfile group 8; Database altered. SQL> alter database drop logfile group 5; Database altered. SQL> alter database drop logfile group 8; Database altered. --检查删除情况 SQL>select THREAD#, STATUS, ENABLED from v$thread; THREAD# STATUS ENABLED ---------- ------ -------- 1 OPEN PUBLIC 6 修改undo表空间 检查undo表空间参数 SQL> show parameter undo; NAME TYPE VALUE ------------------------------------ ----------- ------------------------------ undo_management string AUTO undo_retention integer 900 undo_tablespace string UNDOTBS1 SQL>select tablespace_name from dba_tablespaces where contents='UNDO'; TABLESPACE_NAME ------------------------------ UNDOTBS1 UNDOTBS2 SQL> drop tablespace UNDOTBS2 including contents and datafiles; Tablespace dropped. 7 为临时表空间增加数据文件 检查temp表空间参数 SQL> select name from v$tempfile; NAME -------------------------------------------------------------------------------- /dev/vgdata/rlverp_temp_10g SQL>select tablespace_name from dba_tablespaces where contents='TEMPORARY'; TABLESPACE_NAME ------------------------------ TEMP SQL> create temporary tablespace TEMP1 2 tempfile '/backup/oradata/app/erp/temp01.dbf' size 2000M; Tablespace created. SQL>alter database default temporary tablespace TEMP1; Database altered. SQL> drop tablespace TEMP including contents and datafiles; Tablespace dropped --修改temp tablespace大小： SQL> alter database tempfile '/backup/oradata/app/erp/temp01.dbf' resize 3000M; SQL>create temporary tablespace TEMP tempfile '/backup/oradata/app/erp/temp.dbf' size 3000M; alter database default temporary tablespace TEMP; drop tablespace TEMP1 including contents and datafiles; 8说明 以 $ 开始的提示符是使用的oracle用户, 执行的命令。 以 # 开始的提示符是使用的root用户，执行的命令。 建立在裸设备上的datafile恢复到文件系统时按照裸设备的大小创建，因此需要考虑文件系统空间是否够用。 TIPS:前期收集工作很重要，做好前期收集工作，后面的就简单多了。此次恢复数据900G+，restore耗时3.5H，recover等耗时0.5H。 9补充 ASM to ASM异机恢复遇到类似如下错误： RMAN-00571: =========================================================== RMAN-00569: =============== ERROR MESSAGE STACK FOLLOWS =============== RMAN-00571: =========================================================== RMAN-03002: failure of restore command at 04/19/2011 11:00:46 ORA-19504: failed to create file \"+EBS_DATA\" ORA-17502: ksfdcre:4 Failed to create file +EBS_DATA ORA-15001: diskgroup \"EBS_DATA\" does not exist or is not mounted ORA-15055: unable to connect to ASM instance ORA-15055: unable to connect to ASM instance ORA-19600: input file is control file (/qsynergy1/oradata/cntrl01.dbf) ORA-19601: output file is control file (+EBS_DATA) 解决思路： 1.ASM磁盘组权限不对，第一次没给Oracle用户加asmadmin权限，后面加了还是一样报错。 2.ASM实例没起来，用grid用户进入asmcmd，lsdg发现所有group都是mounted状态。 3.对比oracle用户及grid用户下$ORACLE_HOME/bin/oracle属性，发现grid下面此文件属性为777,应修改为chmod 6751 oracle 再次重启还原任务，成功还原 EOF","link":"/rman-restore-on-diff-machine.html"},{"title":"Rolling Update and Upgrade in HADR","text":"HADR can give you high availablity while applying fix pack via rolling update. The database or application downtime can be minimize or zero downtime. With properly ACR setting, it means no data loss and it&#39;s no visiable downtime to clients.Here&#39;s an examples how to apply fix pack and upgrade major version in HADR environment. Below is the example&#39;s environment.123HOSTNAME INSTANCE DBNAME DBVERSION ROLEnode1 db2inst1 mysample 10.1.0.0 primarynode2 db2inst1 mysample 10.1.0.0 standby 1. Rolling update in HADR with mininal downtimeThe general steps can be done as following: 1.Check the HADR status 2.Apply fix pack in standby 3.Swithover roles 4.Apply fix pack in original primary 5.Swithover HADR roles back to the original primary 6.Post-installation tasks in primary 1.1 Install fix pack in standby/primary serverIt&#39;s a simple task, I install the fix pack in a new directory: /opt/ibm/db2/V10.1_FP5, the original code directory is: /opt/ibm/db2/V10.1. 123456[root@node2 worktmp]# /opt/ibm/db2/V10.1_FP5/install/db2lsInstall Path Level Fix Pack Special Install Number Install Date Installer UID ---------------------------------------------------------------------------------------------------------------------/opt/ibm/db2/V10.1 10.1.0.0 0 Thu Mar 17 14:30:55 2016 CST 0 /opt/ibm/db2/V10.1_FP5 10.1.0.5 5 Thu Mar 17 16:24:42 2016 CST 0 1.2 Take over HADR in standbyCheck the HADR status before taking over in standby, rolling update only can be supported with peer state take over. It also measn when sychronization mode is async, we cannot rolling update without any downtime or data loss.1234567[db2inst1@node2 ~]$ db2pd -d mysample -hadr |grep -i state -A 5 HADR_STATE = PEER PRIMARY_MEMBER_HOST = node1 PRIMARY_INSTANCE = db2inst1 PRIMARY_MEMBER = 0 STANDBY_MEMBER_HOST = node2 STANDBY_INSTANCE = db2inst1 Deactivate the standby database first, if necessary, stop the standby instance.12345[db2inst1@node2 ~]$ db2 deactivate db mysample DB20000I The DEACTIVATE DATABASE command completed successfully.[db2inst1@node2 ~]$ db2stop03/17/2016 16:42:19 0 0 SQL1064N DB2STOP processing was successful.SQL1064N DB2STOP processing was successful. Perform instance update command in standby by root user and add license by instance user.12345678910[root@node2 worktmp]# /opt/ibm/db2/V10.1_FP5/instance/db2iupdt db2inst1[root@node2 worktmp]# su - db2inst1[db2inst1@node2 ~]$ db2licm -a /worktmp/db2ese_c.lic[db2inst1@node2 ~]$ db2licm -lProduct name: &quot;DB2 Enterprise Server Edition&quot;License type: &quot;CPU Option&quot;Expiry date: &quot;Permanent&quot;Product identifier: &quot;db2ese&quot;Version information: &quot;10.1&quot;Enforcement policy: &quot;Soft Stop&quot; Start instance in standby server, activate the database and perform switch roles in standby server.1234567[db2inst1@node2 ~]$ db2start03/17/2016 16:48:18 0 0 SQL1063N DB2START processing was successful.SQL1063N DB2START processing was successful.[db2inst1@node2 ~]$ db2 activate db mysampleDB20000I The ACTIVATE DATABASE command completed successfully.[db2inst1@node2 ~]$ db2 takeover hadr on db mysample DB20000I The TAKEOVER HADR ON DATABASE command completed successfully. 1.3 Repeat above steps in original primary1234567891011121314[db2inst1@node1 ~]$ db2 terminate[db2inst1@node1 ~]$ db2 deactivate db mysample[db2inst1@node1 ~]$ db2stop[root@node1 worktmp]# /opt/ibm/db2/V10.1_FP5/instance/db2iupdt db2inst1[db2inst1@node1 ~]$ db2licm -a /worktmp/db2ese_c.lic[db2inst1@node1 ~]$ db2start[db2inst1@node1 ~]$ db2 activate db mysample[db2inst1@node1 ~]$ db2pd -d mysample -hadr |grep -i state -A 5 HADR_STATE = PEER PRIMARY_MEMBER_HOST = node2 PRIMARY_INSTANCE = db2inst1 PRIMARY_MEMBER = 0 STANDBY_MEMBER_HOST = node1 STANDBY_INSTANCE = db2inst1 1.4 Perform take over from original primary database12[db2inst1@node1 ~]$ db2 takeover hadr on db mysample DB20000I The TAKEOVER HADR ON DATABASE command completed successfully. 1.5 Post-installation tasks in primary databaseFirst, update the database by using db2updv10 as instance owner.1[db2inst1@node1 ~]$ /opt/ibm/db2/V10.1_FP5/bin/db2updv10 -d mysample Next, bind the packages and rbind.123456[db2inst1@node1 ~]$ db2 connect to mysample [db2inst1@node1 ~]$ db2 BIND /opt/ibm/db2/V10.1_FP5/bnd/db2schema.bnd BLOCKING ALL GRANT PUBLIC SQLERROR CONTINUE[db2inst1@node1 ~]$ db2 BIND /opt/ibm/db2/V10.1_FP5/bnd/@db2ubind.lst BLOCKING ALL GRANT PUBLIC ACTION ADD[db2inst1@node1 ~]$ db2 BIND /opt/ibm/db2/V10.1_FP5/bnd/@db2cli.lst BLOCKING ALL GRANT PUBLIC ACTION ADD[db2inst1@node1 ~]$ db2rbind mysample -l ./rbind.log all Rebind done successfully for database &apos;MYSAMPLE&apos;. You can confirm your update result by using following commands.123456789101112131415161718[db2inst1@node1 ~]$ db2level[db2inst1@node1 ~]$ db2 &quot;SET SERVEROUTPUT ON&quot;DB20000I The SET SERVEROUTPUT command completed successfully.[db2inst1@node1 ~]$ db2 &quot; BEGIN&gt; DECLARE v_version VARCHAR(80);&gt; DECLARE v_compat VARCHAR(80);&gt; CALL DBMS_UTILITY.DB_VERSION(v_version, v_compat);&gt; CALL DBMS_OUTPUT.PUT_LINE(&apos;Version: &apos; || v_version);&gt; CALL DBMS_OUTPUT.PUT_LINE(&apos;Compatibility: &apos; || v_compat);&gt; end&quot;DB20000I The SQL command completed successfully.Version: DB2 v10.1.0.5Compatibility: DB2 v10.1.0.5[db2inst1@node1 ~]$ db2pd -vInstance db2inst1 uses 64 bits and DB2 code release SQL10015 with level identifier 0206010EInformational tokens are DB2 v10.1.0.5, s150624, IP23772, Fix Pack 5. With these rolling update steps, you can minimize your downtime. 2. Upgrade HADR database across major versionBecause rolling upgrade across major version is not supported, when you meet this request, you need to plan database outage, this request is actually requiring a new build HADR, previous post can be referred HADR in DB2. The general steps of upgrade major version in single standby database as follow. Break HADR relationship by rolling forward the standby Deactivate the standby, stop the HADR on standby Issue rolling forward to complete command in standby 12345[db2inst1@node2 ~]$ db2 deactivate db mysample DB20000I The DEACTIVATE DATABASE command completed successfully.[db2inst1@node2 ~]$ db2 stop hadr on db mysample DB20000I The STOP HADR ON DATABASE command completed successfully.[db2inst1@node2 ~]$ db2 rollforward db mysample complete Install New Version DB2 code on standby and primary Upgrade the instance and apply license on both servers 123456789[db2inst1@node1 ~]$ db2 deactivate db sample DB20000I The DEACTIVATE DATABASE command completed successfully.[db2inst1@node1 ~]$ db2 stop hadr on db sample DB20000I The STOP HADR ON DATABASE command completed successfully.[db2inst1@node1 ~]$ db2stop 03/18/2016 16:41:08 0 0 SQL1064N DB2STOP processing was successful.SQL1064N DB2STOP processing was successful.[root@node1 worktmp]# /opt/ibm/db2/V10.5/instance/db2iupgrade -k db2inst1[db2inst1@node1 ~]$ db2licm -a /worktmp/db2ese_c_v10.5.lic Upgrade the database on primary 12[db2inst1@node1 ~]$ db2start[db2inst1@node1 ~]$ db2 upgrade db mysample Re-establish HADR You can follow the instuctions by previous post HADR in DB2. EOF","link":"/rolling-update-and-upgrade-in-hadr.html"},{"title":"Rolling Upgrade RAC from 11g to 12c","text":"What I mean rolling is Grid Infrastructure upgrade by rolling, but RDBMS still need outage. To minimize the downtime, and I think upgrade with rolling is more easier than non-rolling, so use rolling upgrade GI is advisable. At the end of this post, I will try to reverse the whole process, that is downgrade RDBMS and GI to before version.I already have a two-node 11gr2 RAC installed in my VM machine, and I&#39;ll perform a out-of-place upgrade for GI and RDBMS. Out-of-place upgrade can let you rollback or downgrade more easier. New directories have been created as below. [Below infomation should be the same on both nodes]12345678910111213141516[root@node1 ~]# mkdir -p /u02 [root@node1 ~]# chown -R grid:oinstall /u02[grid@node1:/home/grid]$ cp .bash_profile .bash_profile_11g [grid@node1:/home/grid]$ sed -i 's/u01/u02/g' .bash_profile[grid@node1:/home/grid]$ echo $ORACLE_BASE/u02/app/12.1.0[grid@node1:/home/grid]$ echo $ORACLE_HOME/u02/app/grid/12.1.0[grid@node1:/home/grid]$ mkdir -p $ORACLE_BASE $ORACLE_HOME[grid@node1:/home/grid]$ chmod -R 775 /u02 [oracle@node1:/home/oracle]$ cp .bash_profile .bash_profile_11g[oracle@node1:/home/oracle]$ echo $ORACLE_HOME/u02/app/oracle/product/12.1.0/db1[oracle@node1:/home/oracle]$ echo $ORACLE_BASE/u02/app/oracle[oracle@node1:/home/oracle]$ mkdir -p $ORACLE_HOME Whenever upgrade a system, remember that upgrade is a high risk operation, backup is always essential, backup the whole database, the GI and RDBMS home, the configuration files, and so on. Below backup actions is recommended. GI and RDBMS home A manually physical OCR/OLR backup Full database backup 1. Some restrictions of rolling upgrade GI Not support for block devices or RAW devices If the OCR and voting disks is located on raw or block devices, need to migrate them to ASM before upgrade. Below table is the compatibility matrix of clusterware which can be upgrade to 12c directly. Table 1-1 Oracle version Compatibility Oracle 10.1.0.5 Direct upgrade possible Oracle 10.2.0.3 Direct upgrade possible Oracle 11.1.0.6 Direct upgrade possible oracle 11.2.0.2 Direct upgrade possible: patch set 11.2.0.2.3 (PSU 3) or later must be applied 2. Pre-upgrade tasksVerify node readiness by running pre-upgrade check script under the source code directory: 123[grid@node1:/worktmp/grid]$ ./runcluvfy.sh stage -pre crsinst -upgrade -rolling \\-src_crshome /u01/app/11gr2/grid -dest_crshome /u02/app/12.1.0/grid \\-dest_version 12.1.0.2.0 -fixup -verbose Fix violations until the verify script pass. 3. Performing rolling upgrade GI by response fileBefore perform upgrade, the GI environment parameters need to unset or set to new one, I have copied a old profile as .bash_profile_11g, and create a new profile .bash_profile, changed the new parameters direct to 12c. 3.1 Configure the upgrade GI response file123456789101112131415161718192021222324252627282930313233343536373839404142434445[grid@node1:/home/grid]$ cat gi.rsp oracle.install.responseFileVersion=/oracle/install/rspfmt_crsinstall_response_schema_v12.1.0ORACLE_HOSTNAME=node1.INVENTORY_LOCATION=/u02/app/oraInventorySELECTED_LANGUAGES=enoracle.install.option=UPGRADEORACLE_BASE=/u02/app/12.1.0ORACLE_HOME=/u02/app/grid/12.1.0oracle.install.asm.OSDBA=asmdbaoracle.install.asm.OSOPER=oracle.install.asm.OSASM=asmadminoracle.install.crs.config.gpnp.scanName=oracle.install.crs.config.gpnp.scanPort= oracle.install.crs.config.ClusterType=STANDARDoracle.install.crs.config.clusterName=racdboracle.install.crs.config.gpnp.configureGNS=falseoracle.install.crs.config.autoConfigureClusterNodeVIP=trueoracle.install.crs.config.gpnp.gnsOption=CREATE_NEW_GNSoracle.install.crs.config.gpnp.gnsClientDataFile=oracle.install.crs.config.gpnp.gnsSubDomain=oracle.install.crs.config.gpnp.gnsVIPAddress=oracle.install.crs.config.clusterNodes=node1:,node2:oracle.install.crs.config.networkInterfaceList=oracle.install.crs.config.storageOption=LOCAL_ASM_STORAGEoracle.install.crs.config.sharedFileSystemStorage.votingDiskLocations=oracle.install.crs.config.sharedFileSystemStorage.votingDiskRedundancy=NORMALoracle.install.crs.config.sharedFileSystemStorage.ocrLocations=oracle.install.crs.config.sharedFileSystemStorage.ocrRedundancy=NORMAL oracle.install.crs.config.useIPMI=falseoracle.install.crs.config.ipmi.bmcUsername=oracle.install.crs.config.ipmi.bmcPassword=oracle.install.asm.SYSASMPassword=oracle.install.asm.diskGroup.name=CRSoracle.install.asm.diskGroup.redundancy=oracle.install.asm.diskGroup.AUSize=1oracle.install.asm.diskGroup.disks=oracle.install.asm.diskGroup.diskDiscoveryString=oracle.install.asm.monitorPassword=oracle.install.asm.ClientDataFile=oracle.install.crs.config.ignoreDownNodes=false #if force upgrade enable, turn this to trueoracle.install.config.managementOption=NONEoracle.install.config.omsHost=oracle.install.config.omsPort=0oracle.install.config.emAdminUser=oracle.install.config.emAdminPassword= 3.2 Execute the runInstaller to upgrade the GIGI tools or commands cannot be run until the post root script is executed.123456789101112131415161718[grid@node1:/worktmp/grid]$ ./runInstaller -ignorePrereq -silent -force -responseFile ~/gi.rsp As a root user, execute the following script(s): 1. /u02/app/grid/12.1.0/rootupgrade.shExecute /u02/app/grid/12.1.0/rootupgrade.sh on the following nodes: [node1, node2]Run the script on the local node first. After successful completion, you can start the script in parallel on all other nodes, except a node you designate as the last node. When all the nodes except the last node are done successfully, run the script on the last node.Successfully Setup Software.As install user, execute the following script to complete the configuration. 1. /u02/app/grid/12.1.0/cfgtoollogs/configToolAllCommands RESPONSE_FILE=&lt;response_file&gt; Note: 1. This script must be run on the same host from where installer was run. 2. This script needs a small password properties file for configuration assistants that require passwords (refer to install guide documentation). 3.3 Execute the post-scriptDuring the post script execution, the database services still remain online, but only one node can serve as normal, another node is out of service at that time. The details will show in the output logs. 12345678[root@node1 ~]# /u02/app/grid/12.1.0/rootupgrade.sh[root@node2 ~]# /u02/app/grid/12.1.0/rootupgrade.sh#after execute the script on node1, the activeversion is 11.2, #but the softwareversion is 12.1 now[grid@node1:/home/grid]$ crsctl query crs softwareversionOracle Clusterware version on node [node1] is [12.1.0.2.0][grid@node1:/home/grid]$ crsctl query crs activeversionOracle Clusterware active version on the cluster is [11.2.0.4.0] You can find &quot;2016/04/19 20:07:19 CLSRSC-482: Running command: &#39;/u02/app/grid/12.1.0/bin/crsctl set crs activeversion&#39;&quot; in log file at last node to specify the script will set the activeversion in the last node. [when last node root script finished]1234[grid@node2:/home/grid]$ crsctl query crs softwareversionOracle Clusterware version on node [node2] is [12.1.0.2.0][grid@node2:/home/grid]$ crsctl query crs activeversionOracle Clusterware active version on the cluster is [12.1.0.2.0] Following script is executed by GRID user, only in the upgrade node: 12345[grid@node1:/home/grid]$ cd $ORACLE_HOME/cfgtoollogs [grid@node1:/u02/app/grid/12.1.0/cfgtoollogs]$ touch cfgrsp.properties [grid@node1:/u02/app/grid/12.1.0/cfgtoollogs]$ vi cfgrsp.properties [grid@node1:/u02/app/grid/12.1.0/cfgtoollogs]$ chmod 600 cfgrsp.properties [grid@node1:/u02/app/grid/12.1.0/cfgtoollogs]$ ./configToolAllCommands RESPONSE_FILE=./cfgrsp.properties The GI status after upgrade: [the GI status after upgrade]1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859[grid@node1:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------Name Target State Server State details --------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.CRS.dg ONLINE ONLINE node1 STABLE ONLINE ONLINE node2 STABLEora.DATA.dg ONLINE ONLINE node1 STABLE ONLINE ONLINE node2 STABLEora.FRA.dg ONLINE ONLINE node1 STABLE ONLINE ONLINE node2 STABLEora.LISTENER.lsnr ONLINE ONLINE node1 STABLE ONLINE ONLINE node2 STABLEora.asm ONLINE ONLINE node1 Started,STABLE ONLINE ONLINE node2 Started,STABLEora.net1.network ONLINE ONLINE node1 STABLE ONLINE ONLINE node2 STABLEora.ons ONLINE ONLINE node1 STABLE ONLINE ONLINE node2 STABLE--------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE node2 STABLEora.LISTENER_SCAN2.lsnr 1 ONLINE ONLINE node1 STABLEora.LISTENER_SCAN3.lsnr 1 ONLINE ONLINE node1 STABLEora.MGMTLSNR 1 ONLINE ONLINE node1 169.254.2.91 10.10.1 0.101,STABLEora.cvu 1 ONLINE ONLINE node2 STABLEora.mgmtdb 1 ONLINE ONLINE node1 Open,STABLEora.node1.vip 1 ONLINE ONLINE node1 STABLEora.node2.vip 1 ONLINE ONLINE node2 STABLEora.oc4j 1 ONLINE ONLINE node2 STABLEora.racdb.db 1 ONLINE ONLINE node1 Open,STABLE 2 ONLINE ONLINE node2 Open,STABLEora.scan1.vip 1 ONLINE ONLINE node2 STABLEora.scan2.vip 1 ONLINE ONLINE node1 STABLEora.scan3.vip 1 ONLINE ONLINE node1 STABLE-------------------------------------------------------------------------------- The ASM diskgroup status: 12345678910111213SQL&gt; col name for a10col COMPATIBILITY for a15col DATABASE_COMPATIBILITY for a15select name,type,state,total_mb,free_mb,COMPATIBILITY, DATABASE_COMPATIBILITY from gv$asm_diskgroup;NAME TYPE STATE TOTAL_MB FREE_MB COMPATIBILITY DATABASE_COMPAT---------- ------ ----------- ---------- ---------- --------------- ---------------FRA EXTERN MOUNTED 20480 20332 11.2.0.0.0 10.1.0.0.0DATA EXTERN MOUNTED 30720 28756 11.2.0.0.0 10.1.0.0.0CRS NORMAL MOUNTED 24576 15430 11.2.0.0.0 10.1.0.0.0FRA EXTERN MOUNTED 20480 20332 11.2.0.0.0 10.1.0.0.0DATA EXTERN MOUNTED 30720 28756 11.2.0.0.0 10.1.0.0.0CRS NORMAL MOUNTED 24576 15430 11.2.0.0.0 10.1.0.0.0 4. Upgrade GI force when some nodes were inactiveWhen some of the nodes in the cluster are inaccessible, perform a forced upgrade is available. Execute rootupgrade script by root user with force option. 1$GRID_HOME/rootupgrade -force When the inaccessible nodes become active after a forced upgrade, execute the following command in the first node to let the inaccessible node join the cluster. 1$GRID_HOME/crs/install/rootcrs.pl -join -existNode node1 upgrade_node node2 5. Performing upgrade RDBMSAlthough RDBMS can upgrade directly, but it&#39;s recommended install a new RDBMS binary code and then perform a upgrade command. 5.1 RDBMS software installationRDBMS installation response file : 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455[oracle@node1.:/home/oracle]$ cat db.rsp |grep -v ^# |grep -v ^$oracle.install.responseFileVersion=/oracle/install/rspfmt_dbinstall_response_schema_v12.1.0oracle.install.option=INSTALL_DB_SWONLYORACLE_HOSTNAME=node1.UNIX_GROUP_NAME=oinstallINVENTORY_LOCATION=/u01/app/oraInventorySELECTED_LANGUAGES=enORACLE_HOME=/u02/app/oracle/product/12.1.0/db1ORACLE_BASE=/u02/app/oracleoracle.install.db.InstallEdition=EEoracle.install.db.DBA_GROUP=dbaoracle.install.db.OPER_GROUP=oracle.install.db.BACKUPDBA_GROUP=dbaoracle.install.db.DGDBA_GROUP=dbaoracle.install.db.KMDBA_GROUP=dbaoracle.install.db.rac.configurationType=oracle.install.db.CLUSTER_NODES=node1,node2oracle.install.db.isRACOneInstall=falseoracle.install.db.racOneServiceName=oracle.install.db.rac.serverpoolName=oracle.install.db.rac.serverpoolCardinality=0oracle.install.db.config.starterdb.type=GENERAL_PURPOSEoracle.install.db.config.starterdb.globalDBName=oracle.install.db.config.starterdb.SID=oracle.install.db.ConfigureAsContainerDB=falseoracle.install.db.config.PDBName=oracle.install.db.config.starterdb.characterSet=oracle.install.db.config.starterdb.memoryOption=falseoracle.install.db.config.starterdb.memoryLimit=oracle.install.db.config.starterdb.installExampleSchemas=falseoracle.install.db.config.starterdb.password.ALL=oracle.install.db.config.starterdb.password.SYS=oracle.install.db.config.starterdb.password.SYSTEM=oracle.install.db.config.starterdb.password.DBSNMP=oracle.install.db.config.starterdb.password.PDBADMIN=oracle.install.db.config.starterdb.managementOption=DEFAULToracle.install.db.config.starterdb.omsHost=oracle.install.db.config.starterdb.omsPort=0oracle.install.db.config.starterdb.emAdminUser=oracle.install.db.config.starterdb.emAdminPassword=oracle.install.db.config.starterdb.enableRecovery=falseoracle.install.db.config.starterdb.storageType=oracle.install.db.config.starterdb.fileSystemStorage.dataLocation=oracle.install.db.config.starterdb.fileSystemStorage.recoveryLocation=oracle.install.db.config.asm.diskGroup=oracle.install.db.config.asm.ASMSNMPPassword=MYORACLESUPPORT_USERNAME=MYORACLESUPPORT_PASSWORD=SECURITY_UPDATES_VIA_MYORACLESUPPORT=falseDECLINE_SECURITY_UPDATES=truePROXY_HOST=PROXY_PORT=PROXY_USER=PROXY_PWD=COLLECTOR_SUPPORTHUB_URL= Install RDBMS with above response file in silent mode: 1234567[oracle@node1:/worktmp/database]$ ./runInstaller -silent -responseFile /home/oracle/db.rsp -ignorePrereq -ignoreSysPreReqs -ignoreDiskWarningThe installation of Oracle Database 12c was successful.Please check &apos;/u01/app/oraInventory/logs/silentInstall2016-04-20_08-58-39PM.log&apos; for more details.As a root user, execute the following script(s): 1. /u02/app/oracle/product/12.1.0/db1/root.shExecute /u02/app/oracle/product/12.1.0/db1/root.sh on the following nodes: [node1, node2] Execute root script as root user. 12[root@node1 ~]# /u02/app/oracle/product/12.1.0/db1/root.sh[root@node2 ~]# /u02/app/oracle/product/12.1.0/db1/root.sh 5.2 Pre-upgrade tasks12345678SQL&gt; @/u02/app/oracle/product/12.1.0/db1/rdbms/admin/preupgrd.sql ACTIONS REQUIRED:1. Review results of the pre-upgrade checks: /u01/app/oracle/cfgtoollogs/racdb/preupgrade/preupgrade.log2. Execute in the SOURCE environment BEFORE upgrade: /u01/app/oracle/cfgtoollogs/racdb/preupgrade/preupgrade_fixups.sql3. Execute in the NEW environment AFTER upgrade: /u01/app/oracle/cfgtoollogs/racdb/preupgrade/postupgrade_fixups.sql Fix warnings and errors in the preupgrade.log, then execute the preupgrade_fixups.sql 1SQL&gt; @/u01/app/oracle/cfgtoollogs/racdb/preupgrade/preupgrade_fixups.sql 5.3 Performing upgrade databaseBefore perform upgrade, it&#39;s important to copy the database password file to new $ORACLE_HOME/dbs. 12[oracle@node1:/home/oracle]$ cp -p $ORACLE_HOME/dbs/orapwracdb1 /u02/app/oracle/product/12.1.0/db1/dbs/[oracle@node2:/home/oracle]$ cp -p $ORACLE_HOME/dbs/orapwracdb2 /u02/app/oracle/product/12.1.0/db1/dbs/ Disable archival is also advisable, for avoiding excessive archive logs generation during upgrade. 12345[oracle@node1:/home/oracle]$ srvctl stop database -d racdb -o immediate[oracle@node1:/home/oracle]$ sqlplus &quot;/as sysdba&quot;SQL&gt; startup mountSQL&gt; alter database noarchivelog;SQL&gt; shutdown immediate Create a legacy init file to local from spfile, modify cluster_database to false, do some necessary modify. I modified the ORACLE_BASE to /u02, the adump to /u02, created the adump directory, and deleted the remote_listener. 1SQL&gt; create pfile=&apos;/home/oracle/init.ora&apos; from spfile; Now, SET the new ORACLE variables to 12c, and add the following entry to /etc/oratab in both nodes: 12345678[oracle@node1:/home/oracle]$ . .bash_profile[oracle@node1:/home/oracle]$ echo $ORACLE_HOME /u02/app/oracle/product/12.1.0/db1[oracle@node1:/home/oracle]$ which sqlplus/u02/app/oracle/product/12.1.0/db1/bin/sqlplus[root@node2 ~]# tail -2 /etc/oratab #racdb:/u01/app/oracle/product/11gr2:N # line added by Agentracdb:/u02/app/oracle/product/12.1.0/db1:N Exectue startup upgrade now: 12[oracle@node1:/home/oracle]$ sqlplus &quot;/as sysdba&quot;SQL&gt; startup upgrade pfile=&apos;/home/oracle/init.ora&apos;; But when I upgrade by manually, the ASM diskgroup cannot be mounted as encounterred &quot;permission denied&quot; errors. [Fix permission denied error of ASM disk]123456789[grid@node1:/home/grid]$ cd $ORACLE_HOME/bin[grid@node1:/u02/app/grid/12.1.0/bin]$ ll /u01/app/oracle/product/11gr2/bin/oracle-rwsr-s--x 1 oracle asmadmin 239626641 Apr 20 17:15 /u01/app/oracle/product/11gr2/bin/oracle[grid@node1:/u02/app/grid/12.1.0/bin]$ ll /u02/app/oracle/product/12.1.0/db1/bin/oracle-rwsr-s--x 1 oracle oinstall 323762228 Apr 20 21:06 /u02/app/oracle/product/12.1.0/db1/bin/oracle#change the group of 12c's bin/oracle to asmadmin in both nodes[grid@node1.:/u02/app/grid/12.1.0/bin]$ ./setasmgidwrap o=/u02/app/oracle/product/12.1.0/db1/bin/oracle[grid@node2.:/home/grid]$ cd $ORACLE_HOME/bin[grid@node2.:/u02/app/grid/12.1.0/bin]$ ./setasmgidwrap o=/u02/app/oracle/product/12.1.0/db1/bin/oracle After changed the oracle binary attributes, the upgrade works now: [Execute upgrade again]12345678910SQL&gt; startup upgrade pfile='/home/oracle/init.ora';ORACLE instance started.Total System Global Area 2483027968 bytesFixed Size 2927432 bytesVariable Size 721421496 bytesDatabase Buffers 1744830464 bytesRedo Buffers 13848576 bytesDatabase mounted.Database opened.SQL&gt; Execute upgrade utility: 123[oracle@node1:/home/oracle]$ cd $ORACLE_HOME/rdbms/admin[oracle@node1:/u02/app/oracle/product/12.1.0/db1/rdbms/admin]$ [oracle@node1:/u02/app/oracle/product/12.1.0/db1/rdbms/admin]$ $ORACLE_HOME/perl/bin/perl catctl.pl -n 4 -l /tmp catupgrd.sql 5.4 Post-upgrade tasksDatabase will automatically shutdown once the previous command successfully completes. Then I need to perform some tasks to enable CLUSTER_DATABASE, enable ARCHIVE etc.: 12345678#modify cluster_database to true, uncommet the remote_listener in the init fileSQL&gt; startup mount pfile=&apos;/home/oracle/init.ora&apos;;SQL&gt; ALTER DATABASE ARCHIVELOG;SQL&gt; SHUTDOWN IMMEDIATE;SQL&gt; STARTUP pfile=&apos;/home/oracle/init.ora&apos;;SQL&gt; create spfile=&apos;+DATA/RACDB/spfileracdb.ora&apos; from pfile=&apos;/home/oracle/init.ora&apos;;#add following entries to $ORACLE_HOME/dbs/initracdb1(2).ora to both nodesSPFILE=&apos;+DATA/racdb/spfileracdb.ora&apos; Executing compile scripts: 123456SQL&gt; execute dbms_stats.gather_fixed_objects_stats;SQL&gt; @?/rdbms/admin/utlrp.sql --recomiples all invalid objects on the databaseSQL&gt; @?/rdbms/admin/utluiobj.sql --verfies the validity of all packages/classes on the databaseSQL&gt; @?/rdbms/admin/catuppst.sqlSQL&gt; @?/rdbms/admin/utlu121s.sql --displays database upgrade summarySQL&gt; SHUTDOWN IMMEDIATE; Upgrade the database version in OCR by using the following command: 12[oracle@node1:/home/oracle]$ srvctl upgrade database -d racdb -o /u02/app/oracle/product/12.1.0/db1[oracle@node1:/home/oracle]$ srvctl start database -d racdb -o open Run postupgrade_fixups.sql script 1SQL&gt; @/u01/app/oracle/cfgtoollogs/racdb/preupgrade/postupgrade_fixups.sql Adjust the compatibility of ASM diskgroup&#39;s attribute &quot;compatible.asm&quot; and &quot;compatible.rdbms&quot; to 12.1 if necessary, for example, convert non-CDB to PDB, it&#39;s necessary to update these values to 12.1. For the convenience of downgrade, this step will be omitted. [Executed under with GRID user] 12ALTER DISKGROUP data SET ATTRIBUTE 'compatible.asm' = '12.1';ALTER DISKGROUP data SET ATTRIBUTE 'compatible.rdbms' = '12.1', Upgrade the TIMEZONE file, this can refer to previous post Upgrade Single Database to 12c. Confirm the tnsnames file and the listener file in the new Oracle 12c home are correct, if necessary, copy them from 11g oracle home. 5.5 Detach 11g grid and rdbms homeThis step is optional, or if the new 12c is stable for a long time, you need to deinstall the 11G software to save space, you can detach the relative home, and then deinstall them. Detach 11g grid home in node1 and node2 123[grid@node1:/home/grid]$ /u01/app/11gr2/grid/oui/bin/runInstaller -silent \\-detachHome -invPtrLoc /etc/oraInst.loc ORACLE_HOME=\"/u01/app/11gr2/grid\" \\ORACLE_HOME_NAME=\"Ora11g_gridinfrahome1\" CLUSTER_NODES=\"&#123;node1,node2&#125;\" -local Detach 11g rdbms home in node1 and node2 1234[oracle@node1:/home/oracle]$ /u01/app/oracle/product/11gr2/oui/bin/runInstaller \\-silent -detachHome -invPtrLoc /etc/oraInst.loc \\ORACLE_HOME=&quot;/u01/app/oracle/product/11gr2&quot; \\ORACLE_HOME_NAME=&quot;OraDb11g_home1&quot; CLUSTER_NODES=&quot;&#123;node1,node2&#125;&quot; -local Verify the detach result 12$GRID_HOME/OPatch/opatch lsinventory -oh $OLD_GRID_HOME$ORACLE_HOME/OPatch/opatch lsinventory -oh $OLD_ORACLE_HOME 6. Downgrade RDBMSDisable the CLUSTER_DATABASE initialization parameter by editing the legacy init file, and stop the database as follows: 123456SQL&gt; create pfile=&apos;/home/oracle/init.ora&apos; from spfile;[oracle@node1:/home/oracle]$ srvctl stop database -d racdb#Modify init file to meet the downgrade requirementsSQL&gt; startup downgrade pfile=&apos;/home/oracle/init.ora&apos;;SQL&gt; SPOOL /tmp/dbdowngrade.logSQL&gt; @?/rdbms/admin/catdwgrd.sql The catdwgrd.sql script under the Oracle 12c /rdbms/admin home downgrades the 12c Database components to the previous release. If encounter any ORA issues during the course of downgrade, fix the issue and rerun the downgrade script once again. After complete this script, shutdown the database, and set the ORACLE variables to 11g&#39;s: 12345678SQL&gt; shutdown immediate[oracle@node1:/home/oracle]$. .bash_profile_11g[oracle@node1:/home/oracle]$ which sqlplus/u01/app/oracle/product/11gr2/bin/sqlplus#Startup in upgrade mode to reload the 11g components by running 11g ORACLE_HOME catrelod.sqlSQL&gt; startup upgrade pfile=&apos;/home/oracle/init.ora&apos;SQL&gt; spool /tmp/dbdowngrade.logSQL&gt; @?/rdbms/admin/catrelod.sql If you previously installed a recent version of the time zone file and used the DBMS_DST PL/SQL package to upgrade TIMESTAMP WITH TIME ZONE data to that version, then install the same version of the time zone file in the release to which you are downgrading. Or you will get the following errors. 123SELECT TO_NUMBER(&apos;MUST_BE_SAME_TIMEZONE_FILE_VERSION&apos;)ERROR at line 1:ORA-01722: invalid number Try to copy the 12c timezone file to 11g, and re-run the catrelod.sql. 1234567#confirm current tz fileSQL&gt; select * from V$TIMEZONE_FILE;#copy the 12c timezone file to 11g[oracle@node1:/home/oracle]$ cp /u02/app/oracle/product/12.1.0/db1/oracore/zoneinfo/timezone_18.dat \\$ORACLE_HOME/oracore/zoneinfo/[oracle@node1:/home/oracle]$ cp /u02/app/oracle/product/12.1.0/db1/oracore/zoneinfo/timezlrg_18.dat \\$ORACLE_HOME/oracore/zoneinfo/ Enable the CLUSTER_DATABASE by edit the init file, create a spfile from pfile, and then startup the database, recompile all invalid objects: 12345#Edit init.ora file to enable CLUSTER_DATABASE=trueSQL&gt; create spfile=&apos;+DATA/RACDB/spfileracdb.ora&apos; from pfile=&apos;/home/oracle/init.ora&apos;;SQL&gt; shutdown immediateSQL&gt; startup SQL&gt; @?/rdbms/admin/utlrp.sql Downgrade the database version in OCR using srvctl in 12c oracle database home: 12[oracle@node1:/home/oracle]$ /u02/app/oracle/product/12.1.0/db1/bin/srvctl downgrade \\database -d racdb -o /u01/app/oracle/product/11gr2 -t 11.2.0.4.0 Verify the downgrade result: 12345678910111213141516171819202122232425262728293031323334353637383940414243[oracle@node1.oraclema.com:/home/oracle]$ srvctl config database -d racdb -a Database unique name: racdbDatabase name: racdbOracle home: /u01/app/oracle/product/11gr2Oracle user: oracleSpfile: +DATA/RACDB/spfileracdb.oraDomain: Start options: openStop options: immediateDatabase role: PRIMARYManagement policy: AUTOMATICServer pools: racdbDatabase instances: racdb1,racdb2Disk Groups: DATAMount point paths: Services: Type: RACDatabase is enabledDatabase is administrator managed#Verify the database componentsSQL&gt; set pagesize 9999set line 200col comp_name for a50col version for a15 col status for a10select comp_name,version,status from dba_registry;COMP_NAME VERSION STATUS-------------------------------------------------- --------------- ----------OWB 11.2.0.4.0 VALIDOracle Application Express 3.2.1.00.12 VALIDSpatial 11.2.0.4.0 VALIDOracle Multimedia 11.2.0.4.0 VALIDOracle XML Database 11.2.0.4.0 VALIDOracle Text 11.2.0.4.0 VALIDOracle Workspace Manager 11.2.0.4.0 VALIDOracle Database Catalog Views 11.2.0.4.0 VALIDOracle Database Packages and Types 11.2.0.4.0 VALIDJServer JAVA Virtual Machine 11.2.0.4.0 VALIDOracle XDK 11.2.0.4.0 VALIDOracle Database Java Packages 11.2.0.4.0 VALIDOLAP Analytic Workspace 11.2.0.4.0 VALIDOracle OLAP API 11.2.0.4.0 VALIDOracle Real Application Clusters 11.2.0.4.0 VALID Shutdown the database, and startup by using srvctl tools in 11g oracle database home: 12SQL&gt; shutdown immediate[oracle@node1:/home/oracle]$ srvctl start database -d racdb -o open 7. Downgrade GIFor downgrade 12c GI, run new 12c $GI_HOME/crs/install/rootcrs.sh -downgrade with root user at all nodes one by one, after all nodes successfully executing preceding command, back to the first node, run $GI_HOME/crs/install/rootcrs.sh -downgrade -lastnode. The -force option can be used when a failed upgrade happened. Run this command from a directory that has write permissions for the Oracle Grid Infrastructure installation user. [This process will downgrade the OCR and set to the previous release]123456789#At node1[root@node1 ~]# cd /home/grid[root@node1 ~]# /u02/app/grid/12.1.0/crs/install/rootcrs.sh -downgrade#At node2[root@node2 ~]# cd /home/grid[root@node2 ~]# /u02/app/grid/12.1.0/crs/install/rootcrs.sh -downgrade #At node1[root@node1 ~]# cd /home/grid[root@node1 ~]# /u02/app/grid/12.1.0/crs/install/rootcrs.sh -downgrade -lastnode Running the following script on the nodes where the preceding rootcrs.sh has run successfully, this script must be run as GI user, and from 12c oracle GI home: 1234[grid@node1:/home/grid]$ /u02/app/grid/12.1.0/oui/bin/runInstaller -nowait -waitforcompletion \\-ignoreSysPrereqs -updateNodeList -silent CRS=false ORACLE_HOME=/u02/app/grid/12.1.0[grid@node2:/home/grid]$ /u02/app/grid/12.1.0/oui/bin/runInstaller -nowait -waitforcompletion \\-ignoreSysPrereqs -updateNodeList -silent CRS=false ORACLE_HOME=/u02/app/grid/12.1.0 After successfully preceding commands, as the root user, bring up the previous release cluster stack using the following command on each node in the cluster: 12[root@node1 grid]# /u01/app/11gr2/grid/bin/crsctl start crs[root@node2 grid]# /u01/app/11gr2/grid/bin/crsctl start crs ####Below script can be used to delete the installation environment directly [Please do not do this in production]1234567891011121314151617181920212223rm -rf /etc/oraInst.loc /etc/oratab /etc/ohasdrm -rf /tmp/.oracle /var/tmp/.oraclerm -rf /etc/oracle /opt/ORCLfmap/rm -rf /etc/rc.d/init.d/ohasdrm -rf /var/lock/subsys/ohasdrm -rf /usr/local/bin/coraenvrm -rf /usr/local/bin/dbhomerm -rf /usr/local/bin/oraenvrm -f /etc/init.d/init.cssdrm -f /etc/init.d/init.crsrm -f /etc/init.d/init.crsdrm -f /etc/init.d/init.evmdrm -rf /tmp/ora* /tmp/CVU* /tmp/Ora*rm -rf /u01/app/*rm -rf /u02/app/*rm -f /etc/init.d/init.ohasddd if=/dev/zero of=/dev/sdb bs=4096 count=1dd if=/dev/zero of=/dev/sdc bs=4096 count=1dd if=/dev/zero of=/dev/sdd bs=4096 count=1dd if=/dev/zero of=/dev/sde bs=4096 count=1dd if=/dev/zero of=/dev/sdf bs=4096 count=1chown -R grid:oinstall /u01 /u02chmod -R 775 /u01 /u02 Reference:How to Upgrade to Oracle Grid Infrastructure 12c Release 1 EOF","link":"/rolling-upgrade-rac-from-11g-to-12c.html"},{"title":"[shell学习笔记]sed流编辑器","text":"1.sed简介 sed也叫流编辑器，它能执行vi相同的编辑任务。但是sed没有破坏性，它不会修改文件，默认情况下，所有的输出行将被列印到屏幕上。 通过shell脚本中调用sed，可以将原文件重定向到新文件中执行编辑任务。同样，sed支持grep中的正则表达式。 表1-1 sed使用的正则表达式元字符 元字符 功能 示例 匹配对象 ^ 行首定位符 '^love' 匹配所有以love开头的行 $ 行尾定位符 'love$' 匹配所有以love结尾的行 . 匹配单个字符 'l..e' 匹配包含一个l，后面跟两个字符，再跟一个e的行 * 匹配0或者多个重复的位于*前的字符 '*love' 匹配包含跟在0个或者多个字符后的love的行 [] 匹配一组字符中的任意一个 '[Ll]ove' 匹配Love或者love [^] 匹配不在指定组内的字符 '[^A-Z]' 匹配不在范围A至Z之间的任意一个字符 \\&lt; 词首定位符 '\\&lt;love' 匹配包含以love开头的词的行 \\&lt; 词尾定位符 'love/&gt;' 匹配包含以love结尾的词的行 \\(..\\) 标记匹配到的字符 '\\(love\\)ing' 模式love被保存在1号寄存器中，之后可用\\1引用它 x\\{m\\}或x\\{m,\\}或x\\{m,n\\} 字符x的重复次数：m次、至少m次、至少m次但不超过n次 'o\\{5\\}','o\\{5,\\}','o\\{5,10\\}' 匹配连续出现5个o、至少5个o或者5~10个o的行 &amp; 保存查找串以便在替换串中引用 's/love/**&amp;**/' 符号&amp;代表查找传。字符串love将替换前后各加了两个*号的引用，即love变成**love** 说明： 123456[root@linora shell]# grep &apos;Fung&apos; lettle [root@linora shell]# echo $? 1[root@linora shell]# sed -n &apos;/Fung/p&apos; lettle [root@linora shell]# echo $? 0 使用grep时，正则表达式Fung没有包含在分隔符中，如果找到模式Fung，grep命令退出状态为0，否则不为0，但是sed不管找到与否，退出状态都为0。这是因为sed只会在发生语法错误的时候，退出状态才不为0。 1.1.定址 定址可以决定对哪些行进行编辑。地址的形式可以是数字或是正则表达式。如果没有指定地址，sed默认处理输入文件中的所有行。 如果指定地址是一个数字，则这个数字代表行号。美元符号表示输入文件的最后一行。如果给出的是逗号分隔的两个行号，那么需要处理的地址就是包括两行之间的范围。 123456[root@linora shell]# wc -l myfile 6 myfile [root@linora shell]# sed &apos;1,3d&apos; myfile The winning ticket is 55222. The ticket I got is 54333 and Dee got 55544. Guy fell down while running around the south bend in his last event. 上述sed命令表示删除myfile中1~3行。 1.2.命令与选项 表1-2 sed命令 命令 功能 a\\ 在当前行添加一行或者多行 c\\ 用新文本修改(替换)当前行中的文本 d 删除行 i\\ 在当前行之前插入文本 h 把模式空间里的内容复制到暂存缓冲区 H 把模式空间里的内容追加到暂存缓冲区 g 去除暂存缓冲的内容，将其复制到模式空间，覆盖该处原有的内容 G 去除暂存缓冲的内容，将其复制到模式空间，追加在原有内容的后面 l 列出非打印字符 p 打印行 n 读入下一输入行，并从下一条命令而不是第一条命令开始对其的处理 q 退出sed r 从文件中读取输入行 ! 对所选行以外的所有行应用命令 s 用一个字符串替换另一个 替换标志 g 在行内进行全局替换 p 打印行 w 将行写入文件 x 交互暂存缓冲区与模式空间的内容 y 将字符转为另一个字符(不能对正则表达式使用y命令) 表1-3 sed选项 选项 功能 -e 运行多项编辑 -f 指定sed脚本文件名 -n 取消默认的输出 1.3.sed范例 1.3.1打印：p命令 默认情况下，sed把输入行打印在屏幕上，但当-n和命令p同时出现时候，sed可打印选定的内容。 12345678910[root@linora shell]# sed &apos;/55222/p&apos; myfile Unusual occurrences happened at the fair. Patty won fourth place in the 50 yard dash square and fair. Occurrences like this are rare. The winning ticket is 55222. The winning ticket is 55222. The ticket I got is 54333 and Dee got 55544. Guy fell down while running around the south bend in his last event. [root@linora shell]# sed -n &apos;/55222/p&apos; myfile The winning ticket is 55222. 1.3.2删除：d命令 命令d用于删除输入行。Sed将输入行从文件复制到模式缓冲区，然后对该行执行sed命令。最后将缓冲区的内容显示在屏幕上。 123[root@linora shell]# sed &apos;3,$d&apos; myfile Unusual occurrences happened at the fair. Patty won fourth place in the 50 yard dash square and fair. 删除第三行到最后一行，美元符号表示最后一行。 1.3.3替换：s命令 替换和取代文件中的文本可通过sed中的s命令来实现。s后包含在斜杠中的文本是正则表达式，后面跟着的是需要替换的文本，可以通过g标志对行进行全局替换。 12345678910[root@linora shell]# sed -n &apos;s/5/6/&apos; myfile The winning ticket is 65222. The ticket I got is 64333 and Dee got 55544. [root@linora shell]# sed &apos;s/5/6/g&apos; myfile Unusual occurrences happened at the fair. Patty won fourth place in the 60 yard dash square and fair. Occurrences like this are rare. The winning ticket is 66222. The ticket I got is 64333 and Dee got 66644. Guy fell down while running around the south bend in his last event. 当“&amp;”符号用在替换串中时，它代表在查找串中匹配到的内容，以下sed命令表示找到5个数字后面跟句号结尾的字符串，在此字符串后加上6.结尾： 123[root@linora shell]# sed -n &apos;s/[0-9]\\&#123;5\\&#125;\\.$/&amp;6./p&apos; myfile The winning ticket is 55222.6. The ticket I got is 54333 and Dee got 55544.6. 以上功能同样可以使用 \\(\\)替代标签实现： 123[root@linora shell]# sed -n &apos;s/\\([0-9]\\&#123;5\\&#125;\\)\\.$/\\1.6\\./p&apos; myfile The winning ticket is 55222.6. The ticket I got is 54333 and Dee got 55544.6. 说明： \\([0-9]\\{5\\}\\) 此正则表达式表示将含有5个数字的字符串以标签形式保存在缓冲区中，因为它是第一个标签，所以，被标记为\\1。 \\.$ 反斜杠对句号进行转义，$表示结尾，综合起来就是以五个数字加句号结尾的字符串。 1.3.4指定行的范围：逗号 行的范围从文件中的一个地址开始，在另一个地址结束。地址范围可以是行号，正则表达式或者是两者的结合。如果结束条件无法满足，就会一直操作到文件结尾。如果结束条件满足，则继续查找满足开始条件的位置，范围重新开始。 打印从第五行开始到east开头的所有行。 1[root@linora shell]# sed -n &apos;5,/^east/s/$/**VA**/p&apos; datafile 说明： 打印第五行开始到以east开头的行，并且在行尾添加**VA**。 1.3.5多重编辑命令：e命令 如果需要sed执行多个编辑任务，可用-e命令。在下一行开始编辑前，所有的编辑动作都将应用到缓冲区中的行上。即多个命令的结果是有顺序性的。 1[root@linora shell]# sed -e &apos;1,3d&apos; -e &apos;s/Hemenway/Jones/&apos; datafile 说明： 上例中，sed首先删除1~3行，然后将剩余行中的Hemingway取代为Jones。 1.3.6读写命令 sed使用r命令将一个文本文件中的内容添加到当前文件的特定位置上。 123456789[root@linora shell]# cat newfile Hi,I&apos;m a new file!!! [root@linora shell]# cat oldfile Hi,I&apos;m a oldfile! Next comming up is a newfile! [root@linora shell]# sed &apos;/newfile/r newfile&apos; oldfile Hi,I&apos;m a oldfile! Next comming up is a newfile! Hi,I&apos;m a new file!!! sed使用w命令将当前文件中的一些行写入到另一个文件中。 12345[root@linora shell]# sed -n &apos;/north/w newfile&apos; datafile [root@linora shell]# cat newfile northwest NW Charles Main 3.0 .98 3 34 northeast NE AM Main Jr. 5.1 .94 3 13 north NO Margot Weber 4.5 .89 5 9 1.3.7其他命令 12[root@linora shell]# sed -n &apos;/eastern/&#123; n; s/AM/PM/p; &#125;&apos; datafile northeast NE PM Main Jr. 5.1 .94 3 13 说明： n命令表示获取下一行，上例中，sed查找eastern模式，然后在下一行中执行s/AM/PM/命令，即替换AM为PM。然后在继续往下处理。 1234567[root@linora shell]# sed &apos;1,3y/abcdefghijklmnopqrstuvwxyz/ABCDEFGHIJKLMNOPQRSTUVWXYZ/&apos; myfile UNUSUAL OCCURRENCES HAPPENED AT THE FAIR. PATTY WON FOURTH PLACE IN THE 50 YARD DASH SQUARE AND FAIR. OCCURRENCES LIKE THIS ARE RARE. The winning ticket is 55222. The ticket I got is 54333 and Dee got 55544. Guy fell down while running around the south bend in his last event. 说明： y命令表示替换命令，上例中，将1~3行小写字母全部替换成大写字母。 1[root@linora shell]# sed &apos;10,20s/cow/COW/g&apos; datafile 说明： 将10~20行替换后的结果输出。 1[root@linora shell]# sed -n &apos;/The/s/$/!!!/p&apos; myfile 说明： 在所有含有The的行尾添加！！！。 1.4.sed脚本范例 123456789101112131415[root@linora shell]# cat -n sedding1 1 # My first sed script 2 /Lewis/a\\ 3 Lewis is the TOP Salesperson for April!!\\ 4 Lewis is moving to the southern district next month.\\ 5 CONGRATULATIONS! 6 /Margot/c\\ 7 *******************\\ 8 MARGOT HAS RETIRED\\ 9 ******************** 10 1i\\ 11 EMPLOYEE DATABASE\\ 12 ------------------------- 13 $d 14 /^ *$/d 说明： 第二行表示如果找到包含模式Lewis，就将3~5行加到它后面。所有追加内容中，除了最后一行外，每一行都以反斜杠结尾。反斜杠后必须紧跟换行符；如果换行符后有多余的文字，哪怕是空格，sed都会报错。所追加的最后一行内容不需要以反斜杠结尾，于是sed知道这是要追加的最后一行，下一行便属于另一条命令了。 第六行查找所有包含模式Margot的行，并且以7~9三行替换(c命令)。 第十行，第一个字符是数字1，表示11~12行被插入到第一行的前面(i命令)。 第十三行，最后一行被删除。 第十四行，删除空行。 1.5.sed总结 表1-4 sed总结 命令 功能 sed –n '10,20p file 打印10~20行 sed '1,10s/AM/PM/g' file 将1~10行所有AM修改为PM sed '/March/!d' file 删除所有不含March的行 sed '/reports/s/5/8' file 将所有包含reports的行出现的第一个5改为8 sed 's/....//' file 删除每行的前四个字符 sed 's/...$//' file 删除每行的后三个字符 sed '/east/,/west/s/A/B/' file 把从east到west这个范围内所有行中出现的A改为B sed -n '/Time/w newfile' file 将file中所有包含Time的行写入到newfile中 sed 's/\\([Oo]ccur\\)ence/\\1rence/' file 将所有的Occurrence替换成Occurrence，将所有的occurrence替换成occurrence 练习： Write a sed script that will a. Insert above the first line the title PERSONNEL FILE. b. Replace the line containing Jose with JOSE HAS RETIRED. c. Change Popeye's birthday to 11/14/46. Assume you don't know Popeye's original birthday. Use a regular expression to search for it. d. Remove the salaries ending in 500. e. Append three asterisks to the end of lines starting with Fred. f. Print the contents of the file with the last names and first names reversed. g. Append at the end of the file THE END. ANSWER: 1234567891011#My first sed exercise 1i\\ PERSONNEL FILE /Jose/c\\ JOSE HAS RETIRED /Popey/s/[0-9]\\&#123;1,2\\&#125;\\/[0-9]\\&#123;1,2\\&#125;\\/[0-9]\\&#123;1,2\\&#125;/11\\/14\\/46/ s/[0-9]*500$// /^Fred/s/$/***/ s/\\([a-zA-Z]*\\) \\([a-zA-Z]*\\)/\\2 \\1/ $a\\ THE END EOF","link":"/sed-study.html"},{"title":"Setting Up the Git Server","text":"GITHUB is a free and open source public code repository, from small to big project. Many developers are using GitHub everyday, even me, although I&#39;m not a coder. But because of its open source, everyone can visit your code, including sensitive data. Based on this, many develop teams will build their own git server. This post will show you how to build a git server on Linux platform. Setup ssh keys for authenticationWith ssh keys authentication, there&#39;s no web interface for git server management. And for safety, it&#39;s recommended to disable git user login with ssh. The first step we should do is creating a git user, setting up the ssh keys for authentication, and disabling git user for ssh login. Create git user on server 12groupadd -g 510 git #Creating groupuseradd -g git -m -d /home/git git #Creating user Setup ssh authentication Generate the ssh key from you local user, and put the ssh keys to git server. 123456789# On the clientssh-keygen -C \"admin@oracle ma.com\"# On the server with git usermkdir .ssh &amp;&amp; chmod 700 .sshtouch .ssh/authorized_keys &amp;&amp; chmod 600 .ssh/authorized_keys# scp the authentication to git serverscp .ssh/id_rsa.pub git@node1:~/.ssh/authorized_keys Disable ssh login On the server end, disable shell login for git user. 1usermod -s /usr/bin/git-shell git Setting remote repositoryOn the server, I created a directory for my project. 1234mkdir -p /git/projectchown -R git:git /git/project/git init --bare project.gitchown -R git:git /git/project/project.git/ git init and git init --bare Repository created by git init are called working directories. Working directories will include two type of files, one is your real project files, another is the .git file folder contains the git configuration information about the repository, that is metadata of git repository. But with git init --bare, it creates bare repositories, which only contains metadata of git repository. And do not have a .git file in the bare repositories. For initializing remote repository or git server, it&#39;s recommended to use --bare options. With the working directory, we need to modify the git configuration first. 1234# Adding below line to remote repository if we're using working directory on git server$ tail -2 .git/config[receive] denyCurrentBranch = ignore After we pushed from the local to remote, if you want to see the changes on the git server, you need to run git reset --hard HEAD command. Using git server from local machineAssume my local repository is /worktmp/git-tutorial. 1234567891011121314[root@node2]# cd /worktmp/git-tutorial/[root@node2]# cat &gt;&gt;hello.md&lt;&lt; EOF&gt; Hello, World!&gt; EOF[root@node2]# git init .[root@node2]# git add .[root@node2]# git commit -m \"initial commit\"[root@node2]# git remote add origin git@node1:/git/project/project.git/[root@node2]# git push origin masterCounting objects: 3, done.Writing objects: 100% (3/3), 217 bytes, done.Total 3 (delta 0), reused 0 (delta 0)To git@node1:/git/project/project.git/ * [new branch] master -&gt; master Now we can clone this repository from somewhere else. 123456789101112[root@node2]# mkdir /worktmp/test[root@node2]# cd /worktmp/test/[root@node2]# git clone git@node1:/git/project/project.gitInitialized empty Git repository in /worktmp/test/project/.git/remote: Counting objects: 3, done.remote: Total 3 (delta 0), reused 0 (delta 0)Receiving objects: 100% (3/3), done.[root@node2]# ls -ltrtotal 4drwxr-xr-x 3 root root 4096 Jul 14 14:31 project[root@node2]# cat project/hello.mdHello, World! Do some changes and push to server. 1234567891011121314151617181920212223242526[root@node2 /worktmp/test:(1)] # cd project/[root@node2 /worktmp/test/project:(1)] # cat &gt;&gt;hello.md&lt;&lt; EOF&gt; Adding some lines&gt; EOF[root@node2 /worktmp/test/project:(1)] # git add .[root@node2 /worktmp/test/project:(1)] # git commit -m \"adding lines\"[master 9fa2159] adding lines Committer: root &lt;root@node2.(none)&gt;Your name and email address were configured automatically basedon your username and hostname. Please check that they are accurate.You can suppress this message by setting them explicitly: git config --global user.name \"Your Name\" git config --global user.email you@example.comIf the identity used for this commit is wrong, you can fix it with: git commit --amend --author='Your Name &lt;you@example.com&gt;' 1 files changed, 1 insertions(+), 0 deletions(-)[root@node2 /worktmp/test/project:(1)] # git push origin masterCounting objects: 5, done.Writing objects: 100% (3/3), 268 bytes, done.Total 3 (delta 0), reused 0 (delta 0)To git@node1:/git/project/project.git 55bc36f..9fa2159 master -&gt; master From the original local directory, pull the newest update to local repository. 12345678910111213141516171819[root@node2:/worktmp/git-tutorial]$ls -ltrtotal 4-rw-r--r-- 1 root root 14 Jul 14 14:24 hello.md[root@node2:/worktmp/git-tutorial]$git pull origin masterremote: Counting objects: 5, done.remote: Total 3 (delta 0), reused 0 (delta 0)Unpacking objects: 100% (3/3), done.From node1:/git/project/project * branch master -&gt; FETCH_HEADUpdating 55bc36f..9fa2159Fast-forward hello.md | 1 + 1 files changed, 1 insertions(+), 0 deletions(-)[root@node2:/worktmp/git-tutorial]$ls -ltrtotal 4-rw-r--r-- 1 root root 32 Jul 14 14:44 hello.md[root@node2:/worktmp/git-tutorial]$cat hello.mdHello, World!Adding some lines Now, we can push, pull, add, clone this remote repository which only accessible by authorized users.Next topic will introduce the git commands. EOF","link":"/setting-up-the-git-server.html"},{"title":"Setup DNS Server in RHEL6","text":"In the previous post 11gr2 RAC SCAN DNS Configuration describes 11gr2 SCAN concepts and how to setup SCAN DNS in rhel5. But as I upgraded the OS to version RHEL6, found something different wiht RHEL5, this post is explain how to setup primary and slave DNS server in RHEL6. Below is my testing environment: 1234567192.168.56.101 node1 #primary DNS server192.168.56.102 node2 #slave DNS server192.168.56.103 node1-vip #below are node machines IP address192.168.56.104 node2-vip192.168.56.110 racdb-scan192.168.56.111 racdb-scan192.168.56.112 racdb-scan 1. Primary server setup steps1.1 Install necessary rpms1[root@node1 ~]# yum install bind* -y 1.2 Configure named daemon file12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758[root@node1 ~]# vi /etc/named.conf[root@node1 ~]# cat /etc/named.conf//// named.conf//// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS// server as a caching only nameserver (as a localhost DNS resolver only).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//options &#123; listen-on port 53 &#123; 127.0.0.1; 192.168.56.101; &#125;; //Master DNS server IP addr listen-on-v6 port 53 &#123; ::1; &#125;; directory \"/var/named\"; dump-file \"/var/named/data/cache_dump.db\"; statistics-file \"/var/named/data/named_stats.txt\"; memstatistics-file \"/var/named/data/named_mem_stats.txt\"; allow-query &#123; localhost; 192.168.56.0/24; &#125;; //define the IP range which can be resolved allow-transfer &#123; localhost; 192.168.56.102; &#125;; // Slave DNS Servers IP recursion yes; dnssec-enable yes; dnssec-validation yes; dnssec-lookaside auto; /* Path to ISC DLV key */ bindkeys-file \"/etc/named.iscdlv.key\"; managed-keys-directory \"/var/named/dynamic\";&#125;;logging &#123; channel default_debug &#123; file \"data/named.run\"; severity dynamic; &#125;;&#125;;zone \".\" IN &#123; type hint; file \"named.ca\";&#125;;zone \"kkdba.com\" IN &#123; //add forward zone file type master; file \"node1.kkdba.zero\"; //this zone file should be located at /var/named/ allow-update &#123; none; &#125;;&#125;;zone \"56.168.192.in-addr.arpa\" IN &#123; //add reserve zone file type master; file \"56.168.192.local\"; //reserve zone file also located at /var/named/ allow-update &#123; none; &#125;;&#125;;include \"/etc/named.rfc1912.zones\";include \"/etc/named.root.key\"; 1.4 Configure the forward and reserve zone file123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657[root@node1 ~]# cd /var/named/[root@node1 ~]# cp /var/named/named.localhost /var/named/node1.kkdba.zero[root@node1 ~]# cp /var/named/named.localhost /var/named/56.168.192.local[root@node1 named]# ls -ltr...-rw-r----- 1 root named 1345 Apr 18 17:22 node1.kkdba.zero-rw-r----- 1 root named 1099 Apr 18 17:24 56.168.192.local[root@node1 named]# cat node1.kkdba.zero$TTL 86400@ IN SOA node1.kkdba.com. root.kkdba.com. ( 42 ; serial (d. adams) 3H ; refresh 15M ; retry 1W ; expiry 1D ) ; minimum@ IN NS node1.kkdba.com.@ IN NS node2.kkdba.com.@ IN A 192.168.56.110@ IN A 192.168.56.111@ IN A 192.168.56.112@ IN A 192.168.56.101@ IN A 192.168.56.102@ IN A 192.168.56.103@ IN A 192.168.56.104racdb-scan IN A 192.168.56.110racdb-scan IN A 192.168.56.111racdb-scan IN A 192.168.56.112node1-vip IN A 192.168.56.103node2-vip IN A 192.168.56.104node1 IN A 192.168.56.101node2 IN A 192.168.56.102[root@node1 named]# cat 56.168.192.local$TTL 86400@ IN SOA node1.kkdba.com. root.kkdba.com. ( 1997022700 ; Serial 28800 ; Refresh 14400 ; Retry 3600000 ; Expire 86400 ) ; Minimum@ IN NS node1.kkdba.com.@ IN NS node2.kkdba.com.@ IN PTR kkdba.comnode1 IN A 192.68.56.101node2 IN A 192.168.56.102node1-vip IN A 192.168.56.103node2-vip IN A 192.168.56.104racdb-scan IN A 192.168.56.110racdb-scan IN A 192.168.56.111racdb-scan IN A 192.168.56.112101 IN PTR node1.kkdba.com.102 IN PTR node2.kkdba.com.110 IN PTR racdb-scan.kkdba.com.111 IN PTR racdb-scan.kkdba.com.112 IN PTR racdb-scan.kkdba.com.102 IN PTR node1-vip.kkdba.com.103 IN PTR node2-vip.kkdba.com. After edited the forward and reserve files, run a error test. 1234567[root@node1 named]# named-checkconf /etc/named.conf[root@node1 named]# named-checkzone kkdba.com ./node1.kkdba.zerozone kkdba.com/IN: loaded serial 42OK[root@node1 named]# named-checkzone 56.168.192.in-addr.arpa ./56.168.192.localzone 56.168.192.in-addr.arpa/IN: loaded serial 1997022700OK If no errors, the named process can be started now: 1234[root@node1 named]# service named restartStopping named: . [ OK ]Starting named: [ OK ][root@node1 named]# chkconfig named on Finally, take a look at dig and nslookup command to check whether can resolve the domain or not: 1234567891011121314151617181920212223242526272829303132[root@node1 named]# dig node1.kkdba.com; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.el6_4.6 &lt;&lt;&gt;&gt; node1.kkdba.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 56422;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 1;; QUESTION SECTION:;node1.kkdba.com. IN A;; ANSWER SECTION:node1.kkdba.com. 86400 IN A 192.168.56.101;; AUTHORITY SECTION:kkdba.com. 86400 IN NS node2.kkdba.com.kkdba.com. 86400 IN NS node1.kkdba.com.;; ADDITIONAL SECTION:node2.kkdba.com. 86400 IN A 192.168.56.102;; Query time: 1 msec;; SERVER: 192.168.56.101# 53(192.168.56.101);; WHEN: Mon Apr 18 18:02:13 2016;; MSG SIZE rcvd: 102[root@node1 named]# nslookup node1.kkdba.comServer: 192.168.56.101Address: 192.168.56.101# 53Name: node1.kkdba.comAddress: 192.168.56.101 2. Slave DNS server setup steps2.1 Install necessary rpms1[root@node1 ~]# yum install bind* -y 2.2 Configure named daemon file1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556[root@node2 ~]# cat /etc/named.conf//// named.conf//// Provided by Red Hat bind package to configure the ISC BIND named(8) DNS// server as a caching only nameserver (as a localhost DNS resolver only).//// See /usr/share/doc/bind*/sample/ for example named configuration files.//options &#123; listen-on port 53 &#123; 127.0.0.1; 192.168.56.102; &#125;; listen-on-v6 port 53 &#123; ::1; &#125;; directory \"/var/named\"; dump-file \"/var/named/data/cache_dump.db\"; statistics-file \"/var/named/data/named_stats.txt\"; memstatistics-file \"/var/named/data/named_mem_stats.txt\"; allow-query &#123; localhost; 192.168.56.0/24; &#125;; //IP address range recursion yes; dnssec-enable yes; dnssec-validation yes; dnssec-lookaside auto; /* Path to ISC DLV key */ bindkeys-file \"/etc/named.iscdlv.key\"; managed-keys-directory \"/var/named/dynamic\";&#125;;logging &#123; channel default_debug &#123; file \"data/named.run\"; severity dynamic; &#125;;&#125;;zone \".\" IN &#123; type hint; file \"named.ca\";&#125;;zone \"kkdba.com\" IN &#123; //define forward zone file type slave; file \"slaves/node1.kkdba.zero\"; masters &#123; 192.168.56.101; &#125;;&#125;;zone \"56.168.192.in-addr.arpa\" IN &#123; //define reserve zone file type slave; file \"slaves/56.168.192.local\"; masters &#123; 192.168.56.101; &#125;;&#125;;include \"/etc/named.rfc1912.zones\";include \"/etc/named.root.key\"; After edit the named.conf file, no need to create or edit the zone files, when named process start, these files would be created automatically. 1234[root@node2 ~]# service named restartStopping named: [ OK ]Starting named: [ OK ][root@node2 ~]# chkconfig named on The two zone files are generated automatically by named process: 1234[root@node2 ~]# ls -l /var/named/slaves/total 8-rw-r--r-- 1 named named 720 Apr 8 21:53 56.168.192.local-rw-r--r-- 1 named named 691 Apr 18 16:43 node1.kkdba.zero 2.3 Check the resolve result12345678910111213141516171819202122232425262728293031323334353637383940[root@node2 ~]# dig node2.kkdba.com; &lt;&lt;&gt;&gt; DiG 9.8.2rc1-RedHat-9.8.2-0.17.rc1.el6_4.6 &lt;&lt;&gt;&gt; node2.kkdba.com;; global options: +cmd;; Got answer:;; -&gt;&gt;HEADER&lt;&lt;- opcode: QUERY, status: NOERROR, id: 9104;; flags: qr aa rd ra; QUERY: 1, ANSWER: 1, AUTHORITY: 2, ADDITIONAL: 1;; QUESTION SECTION:;node2.kkdba.com. IN A;; ANSWER SECTION:node2.kkdba.com. 86400 IN A 192.168.56.102;; AUTHORITY SECTION:kkdba.com. 86400 IN NS node1.kkdba.com.kkdba.com. 86400 IN NS node2.kkdba.com.;; ADDITIONAL SECTION:node1.kkdba.com. 86400 IN A 192.168.56.101;; Query time: 1 msec;; SERVER: 192.168.56.101# 53(192.168.56.101);; WHEN: Mon Apr 18 19:05:23 2016;; MSG SIZE rcvd: 102[root@node2 ~]# nslookup node1.kkdba.comServer: 192.168.56.101Address: 192.168.56.101# 53Name: node1.kkdba.comAddress: 192.168.56.101[root@node2 ~]# nslookup 192.168.56.102Server: 192.168.56.101Address: 192.168.56.101# 53102.56.168.192.in-addr.arpa name = node1-vip.kkdba.com.102.56.168.192.in-addr.arpa name = node2.kkdba.com.102.56.168.192.in-addr.arpa name = node2.102.56.168.192.in-addr.arpa name = node1-vip. 3. Client settingFor this scenario, the node1 and node2 both can be treated as clients. 3.1 Edit the hostname file[Edit the hostname]1234567[root@node1 ~]# cat /etc/sysconfig/networkNETWORKING=yesHOSTNAME=node1.kkdba.comGATEWAY=192.168.56.1NOZEROCONF=yes[root@node1 ~]# hostnamenode1.kkdba.com No need to manually change hostname to node1.kkdba.com, when named services is effective, the hostname can turn to node1.kkdba.com automatically. 3.2 Edit Network Interface Card settingThis step can generate /etc/resolve.conf file as specified automatically. Adding following line to NIC configuration files, for example, /etc/sysconfig/network-scripts/ifcfg-eth0 . [Edit NIC Configuration]123DNS1=192.168.56.101DNS2=192.168.56.102DOMAIN=kkdba.com 3.3 Change the resolve orderThis step grantee the hostname resolve by DNS instead of hosts files /etc/hosts. 12345[root@node1 ~]# cat /etc/host.conforder bind,hostsmulti on[root@node1 ~]# grep -i dns /etc/nsswitch.conf |grep -v ^#hosts: dns files That&#39;s it, I can setup my SCAN in Oracle RAC environment now. EOF","link":"/setup-dns-server-in-rhel6.html"},{"title":"Solarized Color Theme in Gnome-terminal and Vim","text":"Solarized color theme is the most popular color theme in the world. For me, solarized color not only can protect my eyes from the computer but also can make my typing more efficiency. My laptop is using RHEL6 gnome desktop, all the configurations of this post will base on gnome terminal. Gnome-terminal settingDownloading the source code from githubDownload the dircolor(for ls command colorized) setting and solarized color theme for gnome-terminal from github: dircolors-solarized, Solarized Colorscheme for Gnome Terminal. 12git clone https://github.com/seebi/dircolors-solarizedgit clone https://github.com/Anthony25/gnome-terminal-colors-solarized Configuring the dircolor and solarized for gnome-terminalAfter downloaded the source code, do the following steps: 12345678910111213141516171819##I'd like to put all my configurations into the .vim directorycp -rp ./dircolors-solarized/dircolors.256dark ~/.vim/dircolorsln -s ~/.vim/dircolors ~/.dircolorseval `dircolors ~/.dircolors`cp -rp ./gnome-terminal-colors-solarized ~/.vim##setting solarized color for gnome-terminalcd ~/.vim/gnome-terminal-colors-solarized./set_dark.sh##Just for ubuntu#For ubuntu solarized color, put following lines into .profile in ubuntuif [ -x /usr/bin/dircolors ]; then test -r ~/.dircolors &amp;&amp; eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\"fialias l.='ls -d .* --color'alias ll='ls -l --color'alias ls='ls --color' Now, my gnome-terminal looks like this (I am also using tmux): It looks perfect, doesn&#39;t it? My bash PS1: 12345if [ \"`id -u`\" -eq 0 ]; then PS1=\"\\e[0;32m|\\d \\t| \\e[0;37m[\\e[0;31m\\u\\e[0;32m@\\[\\e[0;34m\\]\\h \\e[0;34m\\e[4;35m\\w\\e[0m\\e[0;37m:(\\$(ls | wc -l))]\\n\\e[0;31m# \\[\\e[0m\\]\"else PS1=\"\\e[0;36m|\\d \\t| \\e[0;37m[\\e[0;31m\\u\\e[0;32m@\\[\\e[0;34m\\]\\h \\e[4;35m\\w\\e[0m\\e[0;37m:(\\$(ls | wc -l))]\\n$ \\[\\e[0m\\]\"fi VIM color theme settingWhen I configured the VIM solarized color, I faced one issue. The result looks ugly: I don&#39;t know why, but I found a solution via google, below code snippet is from my vimrc file: 123456789101112#Try to change the color number from 16 to 256 or versa vise while the color looks weirdif $TERM == \"xterm-256color\" set t_Co=256endifif $COLORTERM == 'gnome-terminal' set t_Co=256endiflet g:solarized_termcolors=16set background=darkcolorscheme solarized After that, my vim color theme looks perfect: EOF","link":"/solarized-color-theme-in-gnome-terminal-and-vim.html"},{"title":"使用SPM固定执行计划","text":"数据库在运行过程中，会由于各种原因的变化，存在执行计划不稳定的情况。Oracle 11g开始有SQL Plan Management来管理，稳定执行计划。一般执行计划不稳定有以下几种原因引起（包括但不限于）： 数据倾斜 统计信息不准确 数据库升级 1. 绑定变量带来的问题从Oracle 9i开始，引进了绑定变量窥视（bind peeking）新特性，在对数据倾斜的绑定变量中，在ORACLE第一次解析SQL时会将变量的真实值代入产生执行计划，以后对所有的同样的绑定变量SQL都采用这个执行计划了。这种特性在大部分情况下能结合绑定变量减少SQL的解析时间，但对存在数据倾斜的SQL有可能产生极其糟糕的执行计划。在11g开始，引进自适应游标共享（Adaptive Cursor Sharing，ACS），对一个绑定变量生成多个子执行计划，以求减低数据倾斜对执行计划的影响,从而达到动态调整执行计划的目的。 1.1 绑定变量相关视图v$sql中新增IS_BIND_SENSITIVE和IS_BIND_AWARE字段：123select is_bind_sensitive, is_bind_aware, sql_id, child_numberfrom v$sqlwhere sql_id = '&amp;1'; 如果游标中存在绑定变量，数据库会根据传入的实际值判断不同的值能否会影响执行计划，如果会，则游标被标记为Bind-Sensitive。在v$sql视图中的IS_BIND_SENSITIVE值则为Y。当该SQL被执行过几次后，数据库会根据传入的实际值来决定是否需要修改执行计划，如果需要，则该游标是Bind-Aware，在v$sql视图中IS_BIND_AWARE也被标记为Y。 V$SQL_CS_SELECTIVITY视图则展示了不同值的selectivity。V$SQL_CS_STATISTICS视图展示了标记为Bind-Sensitive和Bind-Aware游标的一些统计信息，如内存读，CPU时间等。123456789select child_number,bind_set_hash_value,peeked,executions,rows_processed,buffer_gets,cpu_timefrom v$sql_cs_statisticswhere sql_id = '&amp;1'; 1.2 查询绑定变量值 从AWR查找 12345678910111213141516171819col name for a30col value_string for a30set line 200 pagesize 9999select SNAP_ID,name,datatype_string,value_string,datatype from DBA_HIST_SQLBIND where sql_id='&amp;1'set line 200 pagesize 9999col bind1 for a30col bind2 for a30col bind3 for a30col bind4 for a30selectsnap_id,SQL_ID,PLAN_HASH_VALUE,dbms_sqltune.extract_bind(bind_data,1).value_string bind1,dbms_sqltune.extract_bind(bind_data,2).value_string bind2,dbms_sqltune.extract_bind(bind_data,3).value_string bind3,dbms_sqltune.extract_bind(bind_data,4).value_string bind4from dba_hist_sqlstatwhere sql_id = '&amp;1'order by snap_id; 从cursor中查找 12345678select ADDRESS ,HASH_VALUE ,CHILD_NUMBER ,name ,DATATYPE_STRING ,VALUE_STRING ,LAST_CAPTUREDfrom v$sql_bind_capture where sql_id ='&amp;1'; 1.3 从共享内存中删除游标 通过SQL ID查找SQL地址及hash值 1234--查找sql的address和hash_valueselect address, hash_value, sql_textfrom v$sqlareawhere sql_id='&amp;1'; 调用dbms_shared_pool清除游标 将产生的address及hash_value代入 &amp;1， &amp;2, 其中，c代表需要purge的类型是cursor，r表示trigger,q表示sequence等. 1exec dbms_shared_pool.purge('&amp;1,&amp;2','C'); 2. 如何使用SPM管理执行计划2.1 相关术语 SPM SPM是管理SQL执行计划的框架。其主要目的是防止由于执行计划改变而导致的SQL性能的退化。同时也提供了动态调整SQL执行计划的框架。 SQL Plan Baseline 当一个新的执行计划产生时候，SPM不一定会立即启用它，只有确认这些执行计划不会带来性能下降或者能提升性能，SPM才会采用(Accepted),而这些accepted的执行计划则被成为baseline(以下简称基线)。 Plan Evolution 把accepted的执行计划加入到基线的过程。 SQL Management Base(SMB) 存储基线、执行计划历史等的数据字典。 2.2 工作原理SPM通过两个动态初始化参数进行控制, 两个参数均为PDB级别可修改。 optimizer_capture_sql_plan_baselines 自动识别重复的SQL语句，并且为这些语句生成基线(从另一个侧面说明，SPM需要结合绑定变量使用，如果不使用绑定变量，建议使用SQL profile+ force_match参数)。该参数默认为false。 optimizer_use_sql_plan_baselines 启用或者关闭SMB中的基线，默认为true。当启用时，优化器会从SMB中查找相应的基线并且挑选cost最小的作为该SQL的执行计划;如果是新执行计划，数据库会自动把这些新计划以unaccepted状态加入到基线中。 其工作流程如下图所示： 如果存在基线，优化器根据新产生的执行计划是否在基线中而作出不同选择： 如果新计划在基线中，则会执行此计划 如果新计划不在基线中，优化器会把新产生的执行计划标记为accepted，且加入到plan history中，接下来优化器会根据以下情况作出不同选择： 如果fixed plan存在于基线中，优化器会使用最低代价的fixed plan 如果没有fixed plan，优化器挑选基线中代价最低的 如果基线中不存在reproduced的执行计划，比如所有执行计划相关的索引都drop掉了，优化器会采用新产生的执行计划 2.3 创建基线创建基线有以下几种方式： 使用SQL Tuning Set(STS) 从缓存/AWR中加载(new for 12.2) 从其他库导出并导入 自动收集(optimizer_capture_sql_plan_baselines=TRUE) 2.3.1 从缓存中进行加载 游标中已经存在较优的执行计划: 123456789101112131415161718declare pls number;begin pls := DBMS_SPM.LOAD_PLANS_FROM_CURSOR_CACHE(sql_id =&gt; '&amp;1', --plan_hash_value =&gt; &amp;2, enabled =&gt; 'YES');end;/set serveroutput onvar n numberbegin:n:=dbms_spm.load_plans_from_cursor_cache(sql_id=&gt;'&amp;sql_id', plan_hash_value=&gt;&amp;plan_hash_value, fixed =&gt;'NO', enabled=&gt;'YES');end;/EXEC dbms_output.put_line('Number of plans loaded: ' || :n); 通过filter筛选SQL 123exec :pls := dbms_spm.load_plans_from_cursor_cache( - attribute_name =&gt; &apos;SQL_TEXT&apos;, - attribute_value =&gt; &apos;&amp;1&apos;); 2.3.2 从AWR中加载1exec pls := dbms_spm.load_plans_from_awr(begin_snap =&gt; &amp;1, end_snap =&gt; &amp;2); 2.4 查询基线通过以下视图查询基线状态:12345678910111213141516171819select sql_text, plan_name, enabled, accepted from dba_sql_plan_baselines;--通过sql_id查找基线col sql_handle for a30col plan_name for a50set line 200 pagesize 9999select s.sql_id, s.plan_hash_value, b.sql_handle, b.plan_name,b.signature, b.enabled, b.accepted, b.fixed, s.sql_textfrom v$sqlarea s JOIN dba_sql_plan_baselines bon (s.exact_matching_signature = b.signature) and s.sql_id = '&amp;1';--查找仅来源于手动加载的基线col sql_handle for a30col plan_name for a30col creator for a30set line 200 pagesize 200select sql_handle, plan_name, origin, enabled, accepted,fixed,creator,optimizer_cost,sql_textfrom dba_sql_plan_baselines where origin = 'MANUAL-LOAD'; dba_sql_plan_baselines中栏位的含义:如果是Enabled=No或者是Reproduced=No, 则优化器不会考虑相关的执行计划。 可通过dbms_spm.alter_sql_plan_baseline去调整这些参数值。如:12345678910111213141516171819var temp varchar2(4000)exec :temp := dbms_spm.alter_sql_plan_baseline(sql_handle=&gt;'&amp;SQL_HANDLE',plan_name=&gt;'&amp;SQL_PLAN',attribute_name=&gt;'enabled',attribute_value=&gt;'YES');var pbsts varchar2(30);exec :pbsts := dbms_spm.alter_sql_plan_baseline('&amp;SQL_HANDLE','&amp;SQL_PLAN','accepted','NO');SET SERVEROUTPUT ONDECLARE l_plans_altered PLS_INTEGER;BEGIN l_plans_altered := DBMS_SPM.alter_sql_plan_baseline( sql_handle =&gt; '&amp;SQL_HANDLE', plan_name =&gt; '&amp;SQL_PLAN', attribute_name =&gt; 'fixed', attribute_value =&gt; 'YES'); DBMS_OUTPUT.put_line('Plans Altered: ' || l_plans_altered);END;/ 查询基线执行计划:12345678SELECT PLAN_TABLE_OUTPUTFROM V$SQL s, DBA_SQL_PLAN_BASELINES b, TABLE( DBMS_XPLAN.DISPLAY_SQL_PLAN_BASELINE(b.sql_handle,b.plan_name,'all') ) tWHERE s.EXACT_MATCHING_SIGNATURE=b.SIGNATUREAND b.PLAN_NAME=s.SQL_PLAN_BASELINEAND s.SQL_ID='&amp;SQL_ID'; 2.5 发展基线Plan Evolution(发展基线)就是优化器识别新执行计划(unaccepted)并加入到基线的过程。创建发展基线的大致步骤（12c）： Create Evolve Task (dbms_spm.create_evolve_task) Execute Evolve Task (dbms_spm.execute_evolve_task) Report Evolve Task (dbms_spm.report_evolve_task) Accept Recommendation (dbms_spm.accept_sql_plan_baseline) 2.5.1 手工创建发展基线(12c) 创建evolve任务 12345678910VARIABLE cnt NUMBERVARIABLE tk_name VARCHAR2(50)VARIABLE exe_name VARCHAR2(50)VARIABLE evol_out CLOBEXECUTE :tk_name := DBMS_SPM.CREATE_EVOLVE_TASK( sql_handle =&gt; '&amp;SQL_HANDLE', plan_name =&gt; '&amp;SQL_PLAN');SELECT :tk_name FROM DUAL; 执行该任务 12EXECUTE :exe_name :=DBMS_SPM.EXECUTE_EVOLVE_TASK(task_name=&gt;:tk_name);SELECT :exe_name FROM DUAL; 查看报告 12EXECUTE :evol_out := DBMS_SPM.REPORT_EVOLVE_TASK( task_name=&gt;:tk_name, execution_name=&gt;:exe_name );SELECT :evol_out FROM DUAL; 实施推荐 1EXECUTE :cnt := DBMS_SPM.IMPLEMENT_EVOLVE_TASK( task_name=&gt;:tk_name, execution_name=&gt;:exe_name ); 2.5.2 手动发展基线(11g)123var report clob;exec :report := dbms_spm.evolve_sql_plan_baseline('&amp;SQL_HANDLE');print :report 2.5.3 自动发展基线(12c)通过SYS_AUTO_SPM_EVOLVE_TASK可以在12c中自动发展基线， 查看当前自动任务配置信息：12345678COLUMN parameter_name FORMAT A25COLUMN parameter_value FORMAT a25SELECT parameter_name, parameter_valueFROM dba_advisor_parametersWHERE task_name = 'SYS_AUTO_SPM_EVOLVE_TASK'AND parameter_value != 'UNUSED'ORDER BY parameter_name; 关闭自动任务:1234567BEGIN DBMS_SPM.set_evolve_task_parameter( task_name =&gt; 'SYS_AUTO_SPM_EVOLVE_TASK', parameter =&gt; 'ACCEPT_PLANS', value =&gt; 'FALSE');END;/ 查看自动任务执行结果：12SET LONG 1000000 PAGESIZE 1000 LONGCHUNKSIZE 100 LINESIZE 100SELECT DBMS_SPM.report_auto_evolve_task FROM dual; 2.6 删除基线12345678910111213141516171819202122232425--指定某一个baseline删除dbms_spm.drop_sql_plan_baseline(sql_handle=&gt;'&amp;SQL_HANDLE',plan_name=&gt;'&amp;SQL_PLAN')--根据sql handle删除DECLARE v_dropped_plans number;BEGIN v_dropped_plans := DBMS_SPM.DROP_SQL_PLAN_BASELINE ( sql_handle =&gt; '&amp;SQL_HANDLE'); DBMS_OUTPUT.PUT_LINE('dropped ' || v_dropped_plans || ' plans');END;/--或者指定plan name删除SET SERVEROUTPUT ONDECLARE l_plans_dropped PLS_INTEGER;BEGIN l_plans_dropped := DBMS_SPM.drop_sql_plan_baseline ( sql_handle =&gt; NULL, plan_name =&gt; '&amp;SQL_PLAN'); DBMS_OUTPUT.put_line(l_plans_dropped);END;/ 2.7 管理SBM 查询当前SBM配置 123456SELECT PARAMETER_NAME, PARAMETER_VALUE FROM DBA_SQL_MANAGEMENT_CONFIG;PARAMETER_NAME PARAMETER_VALUE-------------------------------------------------- ---------------SPACE_BUDGET_PERCENT 10PLAN_RETENTION_WEEKS 53 上述结果为默认配置，SBM可使用的空间上限为sysaux的10%，保留期限为53周。 修改SBM配置 12345--修改空间限制为30%:EXECUTE DBMS_SPM.CONFIGURE('space_budget_percent',30);--修改SBM保留期限, 修改为105周，默认为53周EXECUTE DBMS_SPM.CONFIGURE('plan_retention_weeks',105); Reference:SQL Plan Management with Oracle Database 12c Release 2Managing SQL Plan BaselinesHow to Load SQL Plans into SQL Plan Management (SPM) from the Automatic Workload Repository (AWR) (Doc ID 789888.1)White Papers and Blog Entries for Oracle Optimizer (Doc ID 1337116.1)How to Use SQL Plan Management (SPM) - Plan Stability Worked Example (Doc ID 456518.1) EOF","link":"/stabilization-of-execution-plan-via-spm.html"},{"title":"Sysdate Different From Server and Client","text":"某客户最近搬迁，在支援的过程中发现几点很好玩的东西。现在记录下来。 1.AIX RAC共享磁盘属性设置错误导致OCR只能在一个节点启动这套系统通过存储镜像进行LUN迁移，主机不变，仅仅是更换机房。然而，在启动集群的时候，报1CRS-1714:Unable to discover any voting files, retrying discovery in 15 seconds 第一反应就是ocr文件损坏了，但是仔细一看，一个节点已经运行正常了，报错的是另一个节点，就是说不管哪个节点起集群，都能run，但是另一节点就加入不了集群。怀疑共享磁盘属性设置有问题，一查看：12lsattr -El hdisk12|grep -i reservereserve_policy single_path Reserve Policy True 果真是，建议客户备份数据库，同时，不建议通过chdev直接修改磁盘属性，可以考虑通过删除磁盘组磁盘，再修改属性，再加进去。但是后来客户自己直接修改了磁盘属性，集群目前运行正常。 2.11g grid infrastructure时区配置文件导致sysdate输出不一致这套系统也通过存储镜像进行迁移，但是更换了主机，同时存在10g和11g数据库。用select sysdate from dual查看时间，11g的服务端和客户端时间返回不一致，通过select dbtimezone from dual发现时区为+8:00，OS为AIX 7.1，时区为BEIST-8.AIX7已经没有BEIST-8的时区了，建议客户修改为Asia/Shanghai，修改完后还是不正确。这套11g的系统是用ASM管理的，就意味着存在GI，查看MOS ID 1209444.1，里面有提及12. For 11.2.0.2 and above, TZ entry in $GRID_HOME/crs/install/s_crsconfig_&lt;nodename&gt;_env.txt sets to correct time zone. 查看该文件，发现TZ=CST6CDT，估计安装GI的时候OS时区不正确导致，修改成Asia/Shanghai，重启CRS，sysdate返回结果正常。1[root@oel6 ~]# cat `find / -name s_crsconfig_$HOSTNAME*.txt -print` 3.模拟sysdate server client返回不一致：12[grid@oel6:/home/grid]$ grep TZ `find $ORACLE_HOME -name s_crsconfig_$HOSTNAME*.txt`TZ=CST6CDT 服务器上查询：1234567891011[grid@oel6:/home/grid]$ cat /etc/sysconfig/clock ZONE=&quot;Asia/Shanghai&quot;[oracle@oel6:/home/oracle]$ dateThu Jun 11 19:03:20 CST 2015[oracle@oel6:/home/oracle]$ exitSQL&gt; alter session set nls_date_format=&apos;yyyy-dd-mm hh24:mi:ss&apos;;Session altered.SQL&gt; select sysdate,dbtimezone,current_date from dual;SYSDATE DBTIME CURRENT_DATE------------------- ------ -------------------2015-11-06 19:03:31 +08:00 2015-11-06 19:03:31 客户端查询：123456SQL&gt; alter session set nls_date_format=&apos;yyyy-dd-mm hh24:mi:ss&apos;;会话已更改。SQL&gt; select sysdate,dbtimezone,current_date from dual;SYSDATE DBTIME CURRENT_DATE------------------- ------ -------------------2015-11-06 06:05:06 +08:00 2015-11-06 19:05:06 修改GI时区配置文件，TZ=Asia/Shanghai1[grid@oel6:/home/grid]$ sed -i &apos;s/CST6CDT/Asia\\/Shanghai/g&apos; $ORACLE_HOME/crs/install/s_crsconfig_oel6_env.txt 重启crs，查看结果client端：123456SQL&gt; alter session set nls_date_format=&apos;yyyy-dd-mm hh24:mi:ss&apos;;Session altered.SQL&gt; select sysdate from dual;SYSDATE-------------------2015-11-06 19:23:52 服务器端：123456SQL&gt; alter session set nls_date_format=&apos;yyyy-dd-mm hh24:mi:ss&apos;;Session altered.SQL&gt; select sysdate from dual;SYSDATE-------------------2015-11-06 19:24:30 Reference:ID 1209444.1如何诊断rac环境下sysdate 返回错误时间问题 EOF","link":"/sysdate-different-from-server-and-client.html"},{"title":"Oracle表连接类型","text":"在Oracle优化器中，多表的连接顺序，连接方法的不同，对CBO产生的COST有很大的差异。在优化器解析含表连接的SQL时，它会根据目标SQL的写法来决定表连接的顺序、表连接的方法和单表访问路径来决定此SQL的最终执行计划。Oracle表之间的连接总的分为内连接(Inner Join)和外连接(Outer Join)，外连接又包含左外连接(Left Outer Join)，右外连接(Right Outer Join)和全外连接(Full Outer Join)。 1. 内连接在标准SQL和Oracle中，默认的连接都为Inner Join，因此，在写SQL的时候，Inner Join是不需要明确指出来的。内连接是指多表连接的连接结果只包含那些满足连接条件的记录。123456789101112131415161718192021222324252627282930313233343536373839#创建测试表FUNG@linora&gt; create table t1 (id number,name varchar2(20));Table created.FUNG@linora&gt; create table t2 (id number,job varchar2(10));Table created.FUNG@linora&gt; insert into t1 values(1,&apos;fung&apos;);insert into t1 values(2,&apos;kong&apos;);insert into t1 values(3,&apos;kyun&apos;);insert into t1 values(4,&apos;jordan&apos;);insert into t2 values(1,&apos;dba&apos;);insert into t2 values(2,&apos;sa&apos;);insert into t2 values(3,&apos;hr&apos;);insert into t2 values(4,&apos;dev&apos;);insert into t2 values(5,&apos;mgr&apos;);insert into t1 values(6,&apos;pippen&apos;);commit;FUNG@linora&gt; select * from t1; ID NAME---------- -------------------- 1 fung 2 kong 3 kyun 4 jordan 6 pippenFUNG@linora&gt; select * from t2; ID JOB---------- ---------- 1 dba 2 sa 3 hr 4 dev 5 mgrFUNG@linora&gt; select t1.id,t1.name,t2.job from t1,t2 where t1.id=t2.id; ID NAME JOB---------- -------------------- ---------- 1 fung dba 2 kong sa 3 kyun hr 4 jordan dev 上述SQL改写为标准SQL为1234select t1.id,t1.name,t2.job from t1 join t2 on (t1.id=t2.id);--或者select id,t1.name,t2.job from t1join t2 using (id); 还有一种特殊的JOIN Using叫自然连接(Natural Join)，自然连接的含义是表连接的连接列是表连接的两个表所有的同名列。如123select id,t1.name,t2.jobfrom t1natural join t2; 在现实中，并不推荐自然连接的写法，因为列名相同，但其含义不一定相同，使用自然连接会导致目标SQL结果出错的风险(包括同名列数据类型不一样也会报错)。 2. 外连接外连接指表连接的连接结果除了包含完全满足连接条件的外，还包含驱动表中所有不满足连接条件的记录。外连接的SQL写法中，可以忽略outer关键字。 2.1 左外连接123456789FUNG@linora&gt; select t1.id,t1.name,t2.job from t1left outer join t2 on (t1.id=t2.id); ID NAME JOB---------- -------------------- ---------- 1 fung dba 2 kong sa 3 kyun hr 4 jordan dev 6 pippen 等价于(Oracle SQL写法)：1select t1.id,t1.name,t2.job from t1,t2 where t1.id=t2.id(+); 在上例中，驱动表是位于关键字&#39;left outer join&#39;左边的T1表，因此，返回的结果不仅包含符合连接条件的所有记录，还包含了T1表所有不符合连接条件的记录。Oracle的&#39;+&#39;号写法，是要把&#39;+&#39;号放在被驱动表栏位。对于被驱动表中不符合连接条件的查询记录，以NULL补充(关键字&#39;+&#39;出现在哪个表的连接列后面，就表明哪个表会以NULL来填充那些不满足连接条件并位于该表的查询列)。如果需要查找驱动表符合连接条件外的其他记录，可以在外连接上添加一个where子句，&#39;where t2.id is NULL&#39;。 2.2 右外连接12345678910FUNG@linora&gt; select t1.id,t1.name,t2.job from t1right outer join t2 on (t1.id=t2.id); ID NAME JOB---------- -------------------- ---------- 1 fung dba 2 kong sa 3 kyun hr 4 jordan dev mgr 等价于(Oracle SQL写法)：1select t1.id,t1.name,t2.job from t1,t2 where t1.id(+)=t2.id 对于左外和右外的解释，可以看文章开始的图片，对于两张表内连接，在数学上可以视为两者的交集，左/右外连接，是相对于交集的左/右边而言。 2.3 全外连接12345678910FUNG@linora&gt; select t1.id,t1.name,t2.job from t1full outer join t2 on (t1.id=t2.id); ID NAME JOB---------- -------------------- ---------- 1 fung dba 2 kong sa 3 kyun hr 4 jordan dev mgr 6 pippen 可以看到，全外连接查询的结果包含了满足连接条件的记录和不满足连接条件的记录(包括T1和T2表)，不满足条件的记录所对应的另外一个表中的查询列会以NULL填充。 Reference:基于Oracle的SQL优化","link":"/table-join-type.html"},{"title":"Upgrade 10gr2 RAC to 11gr2 RAC","text":"本文演示了如何从10gr2 RAC升级至11gr2 RAC，示例中的10g版本为10.2.0.4，可以直接升级至11.2.0.4。11g升级路径如下： 直接升级路径：9.2.0.8 +，10.1.0.5+，10.2.0.2+，11.1.0.6+ 9.0.1.3=&gt;9.0.1.4=&gt;10.2.0.4=&gt;11.2 9.2.0.3=&gt;9.2.0.8=&gt;11.2 一些语法及惯用语说明: ORACLE_HOME、ORACLE_BASE：Database软件安装目录 GRID_HOME：11g Grid Infrastructure软件安装目录 CRS_HOME：10g Clusterware安装目录 以#开头表示root用户执行，以$表示grid或者oracle用户执行，SQL&gt; 则表示SQL*Plus执行。 在升级前，有些地方需要注意: CRS必须在DB前升级 11g新版本带来很多改变，10g中的CRS和ASM HOME均不存在了，而是集中到同一个地方：GRID_HOME，同时也引进了SCAN的概念 Raw Device在RAC升级中，仍旧支持OCR及Voting disk，但在全新的安装中，已经不支持裸设备存储OCR及Voting Disk了 在11g中，GI的安装及管理用户单独分离出来，常见以grid命名。虽然仍然可以用同一用户安装维护，但Oracle强烈建议分开。 在以前的版本中，ORACLE_HOME都在ORACLE_BASE目录下，但是在11g RAC中，GRID_HOME则不是在GRID_BASE中，两者是在同一级目录下。ORACLE_HOME则还是在ORACLE_BASE下。 11g以后patch是和base一起的，因此不需要跟10g一样先安装base版本再打补丁。 本次实验升级方法：以非滚动升级方式升级。 1.升级前准备 1.1.升级前信息收集 升级前后信息对比如下，在升级前，先要创建grid用户，创建相关目录并且赋权。 1.2.创建相关目录 在两个节点执行相同内容。 #创建grid用户，添加环境变量 1234567891011121314151617[root@oel1:/u01/app]# useradd -u 54322 grid -g oinstall -G dba[root@oel1:/u01/app]# cat /home/grid/.bash_profileexport TMP=/tmpexport TMPDIR=$TMPexport ORACLE_SID=+ASM1export ORACLE_BASE=/u01/app/gridexport ORACLE_HOME=/u01/app/11gr2/gridexport JAVA_HOME=$ORACLE_HOME/jdkexport ORACLE_TERM=xtermexport NLS_DATE_FORMAT=&quot;yyyy-mm-dd Hh34:MI:SS&quot;export ORA_NLS11=$ORACLE_HOME/nls/dataexport LD_LIBRARY_PATH=$ORACLE_HOME/lib:/lib:/usr/libexport CLASSPATH=$ORACLE_HOME/JRE:$ORACLE_HOME/jlib:$ORACLE_HOME/rdbms/jlibexport PATH=/usr/sbin:$ORACLE_HOME/bin:$JAVA_HOME:$PATHexport PS1=&apos;[$LOGNAME@$HOSTNAME:$PWD]$ &apos;umask 022export DISPLAY=192.168.56.1:0.0 #创建相关目录并且授权 1234567[root@oel1:/u01/app]# mkdir -p /u01/app/grid/[root@oel1:/u01/app]# mkdir -p /u01/app/11gr2/grid[root@oel1:/u01/app]# chown -R grid:oinstall grid/[root@oel1:/u01/app]# chown -R grid:oinstall 11gr2/[grid@oel2:/u01/app]$ chmod g+w grid/[grid@oel2:/u01/app]$ chmod g+w 11gr2/[oracle@oel2:/u01/app/oracle/product]$ mkdir -p /u01/app/oracle/product/11gr2 #添加grid用户ssh等效性 12345678910[grid@oel1:/home/grid]$ mkdir -p ~/.ssh[grid@oel1:/home/grid]$ mkdir -p ~/.ssh[grid@oel1:/home/grid]$ ssh-keygen -t rsa[grid@oel1:/home/grid]$ ssh-keygen -t dsa[grid@oel1:/home/grid]$ cd .ssh[grid@oel1:/home/grid/.ssh]$ touch authorized_keys[grid@oel1:/home/grid/.ssh]$ cat ~/.ssh/*.pub &gt;&gt;authorized_keys[grid@oel1:/home/grid/.ssh]$ ssh oel1 cat ~/.ssh/id_rsa.pub &gt;&gt;authorized_keys[grid@oel1:/home/grid/.ssh]$ ssh oel2 cat ~/.ssh/id_rsa.pub &gt;&gt;authorized_keys[grid@oel1:/home/grid/.ssh]$ scp authorized_keys oel2:.ssh/authorized_keys 验证并且通过测试。 1.3.验证安装条件 123456789101112#查看rpm包是否齐全：[root@oel1:/u01/app]# rpm -q binutils compat-libstdc++-33 elfutils-libelf \\elfutils-libelf-devel elfutils-libelf-devel-static \\gcc gcc-c++ glibc glibc-common glibc-devel \\glibc-headers kernel-headers ksh libaio libaio-devel \\libgcc libgomp libstdc++ libstdc++-devel make \\numactl-devel sysstat unixODBC unixODBC-devel#将没安装的包安装上：[root@oel1:/u01/app]# mount /dev/cdrom /mnt[root@oel1:/u01/app]# yum install -y numactl-devel#两个节点安装cvu包：[root@oel1:/u01/worktmp/11gr2/grid/rpm]# rpm -ivh cvuqdisk-1.0.9-1.rpm 1.4.SCAN DNS设置 本例中SCAN的名字为rac-scan.kkdba.com。IP地址如下： 123456789101112131415161718192021[root@oel2:/u01/app]# cat /etc/hosts# Do not remove the following line, or various programs# that require network functionality will fail.127.0.0.1 localhost.localdomain localhost#Public192.168.56.123 oel1.kkdba.com oel1192.168.56.124 oel2.kkdba.com oel2#Vip192.168.56.125 orcl1-vip.kkdba.com orcl1-vip192.168.56.126 orcl2-vip.kkdba.com orcl2-vip#Private10.10.56.123 orcl1-prv10.10.56.124 orcl2-prv#11gr2 SCAN#192.168.56.120 rac-scan.kkdba.com rac-scan#192.168.56.121 rac-scan.kkdba.com rac-scan#192.168.56.122 rac-scan.kkdba.com rac-scan 因在DNS中已经存在rac-scan的解析，因此/etc/hosts文件中取消此解析。11gr2 SCAN DNS简单设置请参照前文： 11gr2 RAC SCAN DNS Configuration。 1.5.NTP时间设置 在11gr2中，取消Linux自带的ntpd时间服务，而采用Oracle自带的CTSS(Cluster Time Synchronization Service)服务。因此，ntpd需要停止，以免造成冲突导致集群无法同步。 12[root@oel2:/u01/app]# /etc/init.d/ntpd statusntpd is stopped 两个节点的ntpd已经停止，10g的环境是采用rdate同步。直接屏蔽即可，同时移除ntp设定文档。 123[root@oel2:/u01/app]# crontab -l*/1 * * * * rdate -s 192.168.56.123[root@oel1:/root]# mv /etc/ntp.conf /etc/ntp.conf.org 1.6.创建GI使用的ASM磁盘组 1234567891011[root@oel1:/root]# /etc/init.d/oracleasm createdisk OCR1 /dev/sdh1Marking disk &quot;OCR1&quot; as an ASM disk: [ OK ][root@oel1:/root]# /etc/init.d/oracleasm createdisk OCR2 /dev/sdi1Marking disk &quot;OCR2&quot; as an ASM disk: [ OK ][root@oel1:/root]# /etc/init.d/oracleasm createdisk OCR3 /dev/sdj1Marking disk &quot;OCR3&quot; as an ASM disk: [ OK ][root@oel2:/root]# /etc/init.d/oracleasm listdisksOCR1OCR2OCR3DATA1 1.7.备份数据库 在升级前先做好备份，可以用于紧急回退。需要备份的数据有OCR，Votiedisk，ORACLE_HOME目录，CRS_HOME目录及数据库RMAN备份。 123456789#节点1：[root@oel1:/backup]# dd if=/dev/raw/raw1 of=./ocr_disk_10gr2.bk401562+0 records in401562+0 records out205599744 bytes (206 MB) copied, 214.279 seconds, 959 kB/s[root@oel1:/backup]# dd if=/dev/raw/raw3 of=votedisk_10gr2.bk401562+0 records in401562+0 records out205599744 bytes (206 MB) copied, 233.01 seconds, 882 kB/s 注意，OCR备份方式也可以使用Oracle自带命令。 1[root@oel1:/backup]# /u01/app/oracle/product/crs/bin/ocrconfig -export /backup/ocr.dmp 1234567#备份软件HOME目录：[root@oel1:/backup]# tar -cvzf oel1.crs.tgz /u01/app/oracle/product/crs/*[root@oel1:/backup]# tar -cvzf oel1.db.tgz /u01/app/oracle/product/10.2.0/db_1/*[root@oel1:/backup]# cp /etc/inittab etc_inittab[root@oel1:/backup]# mkdir ./etc_init.d/[root@oel1:/backup]# cp /etc/init.d/init.* ./etc_init.d/[root@oel1:/backup]# tar -cvzf oel1.etcoracle.tgz /etc/oracle/* 1234567#节点2：[root@oel2:/backup]# tar -cvzf oel2.crs.tgz /u01/app/oracle/product/crs/*[root@oel2:/backup]# tar -cvzf oel2.db.tgz /u01/app/oracle/product/10.2.0/db_1/*[root@oel2:/backup]# tar -cvzf oel2.etcoracle.tgz /etc/oracle/*[root@oel2:/backup]# cp /etc/inittab /backup/etc_inittab[root@oel2:/backup]# mkdir -p /backup/etc_init.d/[root@oel2:/backup]# cp /etc/init.d/init* /backup/etc_init.d/ RMAN全备数据库： 1234567891011121314151617run &#123;ALLOCATE CHANNEL ch00 TYPE DISK;ALLOCATE CHANNEL ch01 TYPE DISK;sql &apos;alter system archive log current&apos;;BACKUPAS BACKUPSETSKIP INACCESSIBLETAG hot_db_bk_level0 FORMAT &apos;/backup/rman/bk_%s_%p_%U_%T_%d&apos;FULL DATABASE;sql &apos;alter system archive log current&apos;;sql &apos;alter system archive log current&apos;;sql &apos;alter system archive log current&apos;;backup archivelog all delete input format &apos;/backup/rman/arch_%U_%T_%d&apos;;backup current controlfile tag &apos;ctl&apos; format &apos;/backup/rman/ctl_%U_%T_%d&apos;;RELEASE CHANNEL ch00;RELEASE CHANNEL ch01;&#125; 如果有EM，需要停止EM。如有需要，可以关闭归档。 1emctl stop dbconsole 2.非滚动升级 为了安装11g GI，需要屏蔽掉10g的CRS，否则两者会有冲突。滚动升级不需要此步骤。 2.1.关闭CRS 12[root@oel1:/root]# /u01/app/oracle/product/crs/bin/crsctl stop crs[root@oel2:/root]# /u01/app/oracle/product/crs/bin/crsctl stop crs 2.2.重命名CRS相关文件及目录 123456[root@oel1:/root]# mv /etc/oracle /etc/oracle_orig[root@oel1:/root]# mkdir /etc/init.d/bk[root@oel1:/root]# mv /etc/init.d/init* /etc/init.d/bk[root@oel2:/root]# mv /etc/oracle /etc/oracle_orig[root@oel2:/root]# mkdir /etc/init.d/bk[root@oel2:/root]# mv /etc/init.d/init* /etc/init.d/bk 2.3.两个节点屏蔽/etc/inittab中RAC启动相关选项 123456[root@oel2:/backup]# tail -5 /etc/inittab# Run xdm in runlevel 5x:5:respawn:/etc/X11/prefdm -nodaemon#h1:35:respawn:/etc/init.d/init.evmd run &gt;/dev/null 2&gt;&amp;1 &lt;/dev/null#h3:35:respawn:/etc/init.d/init.cssd fatal &gt;/dev/null 2&gt;&amp;1 &lt;/dev/null#h4:35:respawn:/etc/init.d/init.crsd run &gt;/dev/null 2&gt;&amp;1 &lt;/dev/null 2.4.删除网络接口文件 1234[root@oel1:/root]# rm -rf /var/tmp/.oracle[root@oel2:/root]# rm -rf /var/tmp/.oracle[root@oel2:/root]# rm -rf /tmp/.oracle/[root@oel1:/root]# rm -rf /tmp/.oracle/ 2.5.重启系统 12[root@oel1:/root]# shutdown -ry 0[root@oel2:/root]# shutdown -ry 0 3.安装Grid Infrastructure 以grid用户执行安装 export CVUQDISK_GRP=oinstall 123#安装前检查：[grid@oel1:/u01/worktmp/11gr2/grid]$ ./runcluvfy.sh stage -pre crsinst \\-n oel1,oel2 -fixup -fixupdir /home/grid/ -verbose 以root用户执行输出脚本 1234567891011121314151617181920212223#安装步骤：[grid@oel1:/u01/worktmp/11gr2/grid]$ ./runInstallerDownload Software Update:SkipSelect Installation Option: Install and Configure Grid Infrastructure for a ClusterSelect Installation Type:Advanced InstallationSelect Product Language: English &amp; Simplified ChineseGrid Plug and Play Information: Cluster Name:orcl SCAN Name:rac-scan SCAN port:1521Cluster Node Information: refer to /etc/hostsSpecify Network Interface Usage:Storage Option Information:ASMCreate ASM Disk Group: DG Name:CRS Redundency:Normal Change Discovery Path:/dev/oracleasm/disks/*Specify ASM Password:Failure Isolation Support: Do not use IPMIPrivileged OS Group:defaultSpecify Installation Home: Oracle Base:/u01/app/grid Software Location:/u01/app/11gr2/grid 安装完成以root用户执行/u01/app/11gr2/grid/root.sh脚本。脚本完成后，11gr2的高可用服务(CRS，CSS及EVMD)就起来了。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849#确认GI集群状态：[grid@oel1:/worktmp/11g/grid]$ crsctl query crs activeversionOracle Clusterware active version on the cluster is [11.2.0.4.0][grid@oel1:/worktmp/11g/grid]$ crsctl query crs softwareversionOracle Clusterware version on node [oel1] is [11.2.0.4.0][grid@oel1:/worktmp/11g/grid]$ ocrcheckStatus of Oracle Cluster Registry is as follows : Version : 3 Total space (kbytes) : 262120 Used space (kbytes) : 2832 Available space (kbytes) : 259288 ID : 1417014589 Device/File Name : +CRS Device/File integrity check succeeded Device/File not configured Device/File not configured Device/File not configured Device/File not configured Cluster registry integrity check succeeded Logical corruption check bypassed due to non-privileged user[grid@oel1:/worktmp/11g/grid]$ crsctl query css votedisk## STATE File Universal Id File Name Disk group-- ----- ----------------- --------- --------- 1. ONLINE 3756bd45b9214f22bf4f45e87da09fa8 (/dev/oracleasm/disks/OCR1) [CRS] 2. ONLINE 2968da754a974fc1bf86b19fb18afad5 (/dev/oracleasm/disks/OCR2) [CRS] 3. ONLINE 2e7ea902e0514f97bf258b70d975a9b6 (/dev/oracleasm/disks/OCR3) [CRS]Located 3 voting disk(s).[root@oel1:/root]# /u01/app/11gr2/grid/bin/crsctl stat res -t[root@oel1:/root]# /u01/app/11gr2/grid/bin/crsctl check cluster -all**************************************************************oel1:CRS-4537: Cluster Ready Services is onlineCRS-4529: Cluster Synchronization Services is onlineCRS-4533: Event Manager is online**************************************************************oel2:CRS-4537: Cluster Ready Services is onlineCRS-4529: Cluster Synchronization Services is onlineCRS-4533: Event Manager is online**************************************************************[root@oel1:/root]# /u01/app/11gr2/grid/bin/crsctl check ctssCRS-4701: The Cluster Time Synchronization Service is in Active mode.CRS-4702: Offset (in msec): 0 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485#确认集群状态无误后查看监听配置情况：[grid@oel2:/home/grid]$ srvctl config listener -l listenerName: LISTENERNetwork: 1, Owner: gridHome: &lt;crs home&gt;End points: TCP:1521[grid@oel2:/home/grid]$ crs_stat -tName Type Target State Host------------------------------------------------------------ora....ER.lsnr ora....er.type ONLINE ONLINE oel1ora....N1.lsnr ora....er.type ONLINE ONLINE oel2ora....N2.lsnr ora....er.type ONLINE ONLINE oel1ora....N3.lsnr ora....er.type ONLINE ONLINE oel1ora.OCR.dg ora....up.type ONLINE ONLINE oel1ora.asm ora.asm.type ONLINE ONLINE oel1ora.cvu ora.cvu.type ONLINE ONLINE oel1ora.gsd ora.gsd.type OFFLINE OFFLINEora....network ora....rk.type ONLINE ONLINE oel1ora.oc4j ora.oc4j.type ONLINE ONLINE oel1ora....SM1.asm application ONLINE ONLINE oel1ora....L1.lsnr application ONLINE ONLINE oel1ora.oel1.gsd application OFFLINE OFFLINEora.oel1.ons application ONLINE ONLINE oel1ora.oel1.vip ora....t1.type ONLINE ONLINE oel1ora....SM2.asm application ONLINE ONLINE oel2ora....L2.lsnr application ONLINE ONLINE oel2ora.oel2.gsd application OFFLINE OFFLINEora.oel2.ons application ONLINE ONLINE oel2ora.oel2.vip ora....t1.type ONLINE ONLINE oel2ora.ons ora.ons.type ONLINE ONLINE oel1ora....ry.acfs ora....fs.type ONLINE ONLINE oel1ora.scan1.vip ora....ip.type ONLINE ONLINE oel2ora.scan2.vip ora....ip.type ONLINE ONLINE oel1ora.scan3.vip ora....ip.type ONLINE ONLINE oel1[grid@oel2:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------NAME TARGET STATE SERVER STATE_DETAILS--------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.LISTENER.lsnr ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.OCR.dg ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.asm ONLINE ONLINE oel1 Started ONLINE ONLINE oel2 Startedora.gsd OFFLINE OFFLINE oel1 OFFLINE OFFLINE oel2ora.net1.network ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.ons ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.registry.acfs ONLINE ONLINE oel1 ONLINE ONLINE oel2--------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE oel2ora.LISTENER_SCAN2.lsnr 1 ONLINE ONLINE oel1ora.LISTENER_SCAN3.lsnr 1 ONLINE ONLINE oel1ora.cvu 1 ONLINE ONLINE oel1ora.oc4j 1 ONLINE ONLINE oel1ora.oel1.vip 1 ONLINE ONLINE oel1ora.oel2.vip 1 ONLINE ONLINE oel2ora.scan1.vip 1 ONLINE ONLINE oel2ora.scan2.vip 1 ONLINE ONLINE oel1ora.scan3.vip 1 ONLINE ONLINE oel1[grid@oel2:/home/grid]$ 以上为整个GI集群状态。 4.迁移10g ASM磁盘组 将原来数据文件存放的ASM磁盘迁移至11gr2 GI管理。先用grid用户调用asmca，利用asmca挂载原有磁盘组DATA1，这样，DATA1磁盘组就能自动在GI里面注册了。 1[grid@oel1:/home/grid]$ asmca 1234567891011121314151617181920212223242526272829#查看ASM磁盘组状态，以grid用户调用SQLPLUS：SQL&gt; col path for a30SQL&gt; col instance_name for a10SQL&gt; select name,state,type,total_mb,free_mbfrom gv$asm_diskgroup;NAME STATE TYPE TOTAL_MB FREE_MB------------------------------ ----------- ------ ---------- ----------OCR MOUNTED NORMAL 3057 2131DATA MOUNTED EXTERN 8189 6918OCR MOUNTED NORMAL 3057 2131DATA MOUNTED EXTERN 8189 6918SQL&gt; select group_number,path,state,total_mb,free_mbfrom v$asm_disk;GROUP_NUMBER PATH STATE TOTAL_MB FREE_MB------------ ------------------------------ -------- ---------- ---------- 1 /dev/oracleasm/disks/OCR3 NORMAL 1019 710 1 /dev/oracleasm/disks/OCR2 NORMAL 1019 710 1 /dev/oracleasm/disks/OCR1 NORMAL 1019 711 2 /dev/oracleasm/disks/DATA1 NORMAL 8189 6919#从inventory删除旧的crs home。Detach Old CRS home from Inventory[grid@oel1:/worktmp/11g/grid]$ /u01/app/oracle/product/crs/oui/bin/runInstaller \\-detachHome -silent -local ORACLE_HOME=/u01/app/oracle/product/crsStarting Oracle Universal Installer...No pre-requisite checks found in oraparam.ini, no system pre-requisite checks will be executed.The inventory pointer is located at /etc/oraInst.locThe inventory is located at /u01/app/oracle/oraInventory&apos;DetachHome&apos; was successful. 5.升级10g数据库 5.1.安装11gr2 Database软件 以oracle用户安装11gr2软件至NEW ORACLE_HOME目录，建议的做法是备份原先的profile，重新使用新的profile，主要修改ORACLE_HOME变量： 1234567891011121314151617181920212223242526272829[oracle@oel1:/home/oracle]$ cp .bash_profile .profileexport EDITOR=vi# User specific environment and startup programsPATH=$PATH:$HOME/binexport ORACLE_BASE=/u01/app/oracle#export ORA_CRS_HOME=$ORACLE_BASE/product/crs#export ORACLE_HOME=$ORACLE_BASE/product/10.2.0/db_1export ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1export ORACLE_SID=orcl1export PATH=.:$&#123;PATH&#125;:$HOME/bin:$ORACLE_BASE/product/crs/bin:$ORACLE_HOME/binexport PATH=$&#123;PATH&#125;:/usr/bin:/bin:/usr/bin/X11:/usr/local/binexport PATH=$&#123;PATH&#125;:$ORACLE_BASE/common/oracle/bin:$ORACLE_BASE/product/crs/binexport ORACLE_TERM=xtermexport TNS_ADMIN=$ORACLE_HOME/network/admin#export ORA_NLS10=$ORACLE_HOME/nls/dataexport ORA_NLS11=$ORACLE_HOME/nls/dataexport LD_LIBRARY_PATH=$ORACLE_HOME/libexport LD_LIBRARY_PATH=$&#123;LD_LIBRARY_PATH&#125;:$ORACLE_HOME/oracm/libexport LD_LIBRARY_PATH=$&#123;LD_LIBRARY_PATH&#125;:/lib:/usr/lib:/usr/local/libexport CLASSPATH=$ORACLE_HOME/JREexport CLASSPATH=$&#123;CLASSPATH&#125;:$ORACLE_HOME/jlibexport CLASSPATH=$&#123;CLASSPATH&#125;:$ORACLE_HOME/rdbms/jlibexport CLASSPATH=$&#123;CLASSPATH&#125;:$ORACLE_HOME/network/jlibexport THREADS_FLAG=nativeexport TEMP=/tmpexport TMPDIR=/tmpexport DISPLAY=192.168.56.1:0.0export PS1=&apos;[$LOGNAME@$HOSTNAME:$PWD]$ &apos;umask 022 12345678910111213#安装步骤如下：[oracle@oel1:/u01/worktmp/11gr2/database]$ ./runInstallerConfigure Security Updates：NoneDown Software Updates：Skip software updatesInstallation Option：Install Database software onlyGrid Installation Option：select ALL NODESProduct Language：English &amp; Simplified ChineseInstallation Location： ORACLE_BASE：/u01/app/oracle ORACLE_HOME：/u01/app/oracle/product/11.2.0/db_1Operating System Groups： OSDBA：dba OSOPER：NONE 安装完成后，两个节点复制相关到11G目录下 1234[root@oel2:/root]# cp /u01/app/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora /u01/app/oracle/product/11.2.0/db_1/network/admin/[root@oel1:/root]# cp /u01/app/oracle/product/10.2.0/db_1/network/admin/tnsnames.ora /u01/app/oracle/product/11.2.0/db_1/network/admin/[oracle@oel1:/home/oracle]$ scp /u01/app/oracle/product/10.2.0/db_1/dbs/orapworcl1 $ORACLE_HOME/dbs[oracle@oel2:/home/oracle]$ scp /u01/app/oracle/product/10.2.0/db_1/dbs/orapworcl2 $ORACLE_HOME/dbs 5.2.手工升级数据库 修改初始化文件，由于10G的rac spfile在共享磁盘上，因此，先需要从ASM中复制到文件系统，这一步可以在停止CRS前做。 123456789101112131415161718192021[grid@oel2:/home/grid]$ asmcmd -pASMCMD [+] &gt; lsCRS/DATA/ASMCMD [+] &gt; cd dataASMCMD [+data] &gt; lsORCL/arch/ASMCMD [+data] &gt; cd orclASMCMD [+data/orcl] &gt; lsARCHIVELOG/CONTROLFILE/DATAFILE/ONLINELOG/PARAMETERFILE/TEMPFILE/spfileorcl.oraASMCMD [+data/orcl] &gt; cp spfileorcl.ora /tmpcopying +data/orcl/spfileorcl.ora -&gt; /tmp/spfileorcl.oraSQL&gt; create pfile=&apos;/tmp/init.ora&apos; from spfile=&apos;/tmp/spfileorcl.ora&apos;;File created. 移除11g废弃参数，如background_dump_dest，user_dump_dest等，改为11g的diagnostic_dest。修改版本兼容号compatible，修改cluster_database=false。屏蔽掉监听参数。修改后对比如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243[oracle@oel1:/home/oracle]$ cat /u01/app/oracle/product/11.2.0/db_1/dbs/initorcl1.oraorcl2.__db_cache_size=427819008orcl1.__db_cache_size=427819008orcl2.__java_pool_size=4194304orcl1.__java_pool_size=4194304orcl2.__large_pool_size=4194304orcl1.__large_pool_size=4194304orcl2.__shared_pool_size=155189248orcl1.__shared_pool_size=155189248orcl2.__streams_pool_size=0orcl1.__streams_pool_size=0*.audit_file_dest=&apos;/u01/app/oracle/admin/orcl/adump&apos;#*.background_dump_dest=&apos;/u01/app/oracle/admin/orcl/bdump&apos;*.cluster_database_instances=2#*.cluster_database=true*.cluster_database=false#*.compatible=&apos;10.2.0.3.0&apos;*.compatible=&apos;11.2.0.0.0&apos;*.control_files=&apos;+DATA/orcl/controlfile/current.256.844116025&apos;*.core_dump_dest=&apos;/u01/app/oracle/admin/orcl/cdump&apos;*.db_block_size=8192*.db_create_file_dest=&apos;+DATA&apos;*.db_domain=&apos;&apos;*.db_file_multiblock_read_count=16*.db_name=&apos;orcl&apos;orcl2.instance_number=2orcl1.instance_number=1*.job_queue_processes=10*.log_archive_dest_1=&apos;LOCATION=+DATA/arch&apos;*.log_archive_format=&apos;%t_%s_%r.dbf&apos;*.open_cursors=300*.pga_aggregate_target=199229440*.processes=150#*.remote_listener=&apos;LISTENERS_ORCL&apos;*.remote_login_passwordfile=&apos;exclusive&apos;*.sga_target=597688320orcl2.thread=2orcl1.thread=1*.undo_management=&apos;AUTO&apos;orcl1.undo_tablespace=&apos;UNDOTBS1&apos;orcl2.undo_tablespace=&apos;UNDOTBS2&apos;#*.user_dump_dest=&apos;/u01/app/oracle/admin/orcl/udump&apos;*.diagnostic_dest=&apos;/u01/app/oracle&apos; 添加11g HOME目录到/etc/oratab orcl:/u01/app/oracle/product/11.2.0/db_1:N 1234567891011121314151617181920#开始手工升级：[oracle@oel1:/home/oracle]$ export ORACLE_SID=orcl1[oracle@oel1:/home/oracle]$ export ORACLE_HOME=$ORACLE_BASE/product/11.2.0/db_1[oracle@oel1:/home/oracle]$ which sqlplus/u01/app/oracle/product/11.2.0/db_1/bin/sqlplus[oracle@oel1:/home/oracle]$ sqlplus &quot;/as sysdba&quot;SQL*Plus: Release 11.2.0.4.0 Production on Sun Apr 6 18:26:19 2014Copyright (c) 1982, 2013, Oracle. All rights reserved.Connected to an idle instance.SQL&gt; startup upgradeORACLE instance started.Total System Global Area 597098496 bytesFixed Size 2255552 bytesVariable Size 176162112 bytesDatabase Buffers 415236096 bytesRedo Buffers 3444736 bytesDatabase mounted.Database opened.SQL&gt; spool upgrade.logSQL&gt; @?/rdbms/admin/catupgrd.sql 在run上述脚本时候报了一个错误： 1234SELECT TO_NUMBER(&apos;MUST_HAVE_RUN_PRE-UPGRADE_TOOL_FOR_TIMEZONE&apos;) *ERROR at line 1:ORA-01722: invalid number 为timezone的问题，MOS上解决方法，ID 1466464.1： 1234567891011121314151617181920212223SQL&gt; CREATE TABLE registry$database( platform_id NUMBER, platform_name VARCHAR2(101), edition VARCHAR2(30), tz_version NUMBER );Table created.SQL&gt; truncate table registry$database;Table truncated.SQL&gt; INSERT into registry$database (platform_id, platform_name, edition, tz_version)VALUES ((select platform_id from v$database), (select platform_name from v$database), NULL, (select version from v$timezone_file));1 row created.SQL&gt; commit;SQL&gt; col PLATFORM_NAME for a30SQL&gt; select * from sys.registry$database;PLATFORM_ID PLATFORM_NAME EDITION TZ_VERSION----------- -------------------------- ------------------------------ ---------- 13 Linux x86 64-bit 14 再次执行升级脚本： 12SQL&gt; spool upgrade.logSQL&gt; @?/rdbms/admin/catupgrd.sql 升级完后，会自动关闭数据库，以正常模式启动数据库，并执行以下查询： 123456789101112131415161718192021222324252627282930313233343536373839SQL&gt; set lines 200;SQL&gt; set pages 1000;SQL&gt; column comp_name format a40;SQL&gt; column version format a12;SQL&gt; column status format a15;SQL&gt; select comp_name, version, status from dba_registry;COMP_NAME VERSION STATUS---------------------------------------- ------------ ---------------Oracle Workspace Manager 11.2.0.4.0 VALIDOracle Database Catalog Views 11.2.0.4.0 VALIDOracle Database Packages and Types 11.2.0.4.0 VALIDOracle Real Application Clusters 11.2.0.4.0 VALIDSQL&gt; @?/rdbms/admin/utlu112s.Oracle Database 11.2 Post-Upgrade Status Tool 04-06-2014 19:29:05.Component Current Version Elapsed TimeName Status Number HH:MM:SS.Oracle Server. VALID 11.2.0.4.0 00:41:01Oracle Real Application Clusters. VALID 11.2.0.4.0 00:00:02Oracle Workspace Manager. VALID 11.2.0.4.0 00:01:29Final Actions. 00:02:03Total Upgrade Time: 00:44:38PL/SQL procedure successfully completed.#执行脚本catuppst，This script will migrate the Baseline data on a pre-11g database to the 11g database.SQL&gt; @?/rdbms/admin/catuppst.sql#编译非法对象SQL&gt; spool recompile.logSQL&gt; @?/rdbms/admin/utlrp.sql#关闭数据库，修改参数文件，改为集群模式*.cluster_database=&apos;true&apos;*.remote_listener=&apos;rac-sca:1521&apos; 重启数据库，创建spfile，同时修改initorcl1.ora为以下内容： 123456789101112SQL&gt; create spfile=&apos;+DATA/orcl/spfileorcl.ora&apos; from pfile;[oracle@oel1:/home/oracle]$ cat /u01/app/oracle/product/11.2.0/db_1/dbs/initorcl1.oraSPFILE=&apos;+DATA/orcl/spfileorcl.ora&apos;#节点2拷贝[oracle@oel2:/home/oracle]$ cp /u01/app/oracle/product/10.2.0/db_1/dbs/initorcl2.ora $ORACLE_HOME/dbs/[oracle@oel2:/home/oracle]$ cat $ORACLE_HOME/dbs/initorcl2.oraSPFILE=&apos;+DATA/orcl/spfileorcl.ora&apos;SQL&gt; show parameter spfileNAME TYPE VALUE------------------------------------ ----------- ------------------------------spfile string +DATA/orcl/spfileorcl.ora 12345678910111213141516171819202122232425#关闭数据库，添加升级好的11g RAC到GI集群：[oracle@oel1:/home/oracle]$ srvctl add database -d orcl -m kkdba.com \\-o /u01/app/oracle/product/11.2.0/db_1 -p +data/orcl/spfileorcl.ora -y AUTOMATIC[oracle@oel1:/home/oracle]$ srvctl add instance -d orcl -i orcl1 -n oel1[oracle@oel1:/home/oracle]$ srvctl add instance -d orcl -i orcl2 -n oel2[oracle@oel1:/home/oracle]$ srvctl modify database -d orcl -n orcl[oracle@oel1:/home/oracle]$ srvctl config database -d orcl -aDatabase unique name: orclDatabase name: orclOracle home: /u01/app/oracle/product/11.2.0/db_1Oracle user: oracleSpfile: +data/orcl/spfileorcl.oraDomain: kkdba.comStart options: openStop options: immediateDatabase role: PRIMARYManagement policy: AUTOMATICServer pools: orclDatabase instances: orcl1,orcl2Disk Groups:Mount point paths:Services:Type: RACDatabase is enabledDatabase is administrator managed 12345678#节点2 Detach 10g CRS_HOME[oracle@oel2:/home/oracle]$ /u01/app/oracle/product/crs/oui/bin/runInstaller \\-detachHome -silent -local ORACLE_HOME=/u01/app/oracle/product/crsStarting Oracle Universal Installer...No pre-requisite checks found in oraparam.ini, no system pre-requisite checks will be executed.The inventory pointer is located at /etc/oraInst.locThe inventory is located at /u01/app/oracle/oraInventory&apos;DetachHome&apos; was successful. 通过srvctl启动集群数据库，并查看状态： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105[oracle@oel1:/home/oracle]$ srvctl start database -d orcl[grid@oel1:/home/grid]$ crsctl stat res -t--------------------------------------------------------------------------------NAME TARGET STATE SERVER STATE_DETAILS--------------------------------------------------------------------------------Local Resources--------------------------------------------------------------------------------ora.CRS.dg ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.DATA.dg ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.LISTENER.lsnr ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.asm ONLINE ONLINE oel1 Started ONLINE ONLINE oel2 Startedora.gsd OFFLINE OFFLINE oel1 OFFLINE OFFLINE oel2ora.net1.network ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.ons ONLINE ONLINE oel1 ONLINE ONLINE oel2ora.registry.acfs ONLINE ONLINE oel1 ONLINE ONLINE oel2--------------------------------------------------------------------------------Cluster Resources--------------------------------------------------------------------------------ora.LISTENER_SCAN1.lsnr 1 ONLINE ONLINE oel2ora.LISTENER_SCAN2.lsnr 1 ONLINE ONLINE oel1ora.LISTENER_SCAN3.lsnr 1 ONLINE ONLINE oel1ora.cvu 1 ONLINE ONLINE oel1ora.oc4j 1 ONLINE ONLINE oel1ora.oel1.vip 1 ONLINE ONLINE oel1ora.oel2.vip 1 ONLINE ONLINE oel2ora.orcl.db 1 ONLINE ONLINE oel1 Open 2 ONLINE ONLINE oel2 Openora.scan1.vip 1 ONLINE ONLINE oel2ora.scan2.vip 1 ONLINE ONLINE oel1ora.scan3.vip 1 ONLINE ONLINE oel1[grid@oel1:/home/grid]$ crs_stat -tName Type Target State Host------------------------------------------------------------ora.CRS.dg ora....up.type ONLINE ONLINE oel1ora.DATA.dg ora....up.type ONLINE ONLINE oel1ora....ER.lsnr ora....er.type ONLINE ONLINE oel1ora....N1.lsnr ora....er.type ONLINE ONLINE oel2ora....N2.lsnr ora....er.type ONLINE ONLINE oel1ora....N3.lsnr ora....er.type ONLINE ONLINE oel1ora.asm ora.asm.type ONLINE ONLINE oel1ora.cvu ora.cvu.type ONLINE ONLINE oel1ora.gsd ora.gsd.type OFFLINE OFFLINEora....network ora....rk.type ONLINE ONLINE oel1ora.oc4j ora.oc4j.type ONLINE ONLINE oel1ora....SM1.asm application ONLINE ONLINE oel1ora....L1.lsnr application ONLINE ONLINE oel1ora.oel1.gsd application OFFLINE OFFLINEora.oel1.ons application ONLINE ONLINE oel1ora.oel1.vip ora....t1.type ONLINE ONLINE oel1ora....SM2.asm application ONLINE ONLINE oel2ora....L2.lsnr application ONLINE ONLINE oel2ora.oel2.gsd application OFFLINE OFFLINEora.oel2.ons application ONLINE ONLINE oel2ora.oel2.vip ora....t1.type ONLINE ONLINE oel2ora.ons ora.ons.type ONLINE ONLINE oel1ora.orcl.db ora....se.type ONLINE ONLINE oel1ora....ry.acfs ora....fs.type ONLINE ONLINE oel1ora.scan1.vip ora....ip.type ONLINE ONLINE oel2ora.scan2.vip ora....ip.type ONLINE ONLINE oel1ora.scan3.vip ora....ip.type ONLINE ONLINE oel1[oracle@oel1:/u01/app/oracle/product/10.2.0/db_1/network/admin]$ lsnrctl serviceLSNRCTL for Linux: Version 11.2.0.4.0 - Production on 06-APR-2014 22:26:50Copyright (c) 1991, 2013, Oracle. All rights reserved.Connecting to (ADDRESS=(PROTOCOL=tcp)(HOST=)(PORT=1521))Services Summary...Service &quot;+ASM&quot; has 1 instance(s). Instance &quot;+ASM1&quot;, status READY, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready LOCAL SERVERService &quot;orcl&quot; has 1 instance(s). Instance &quot;orcl1&quot;, status READY, has 1 handler(s) for this service... Handler(s): &quot;DEDICATED&quot; established:0 refused:0 state:ready LOCAL SERVERThe command completed successfully","link":"/upgrade-10gr2-rac-to-11gr2-rac.html"},{"title":"Upgrade and fix pack db2 database","text":"Upgrading to DB2 Version 10.1 is supported from DB2 Version 9.5, DB2 Version 9.7 and DB2 Version 9.8. If you have an earlier version of DB2, you must upgrade to DB2 Version 9.5 before upgrading to DB2 Version 10.1.Upgrade DB2 server there are two methods: one is installing new product binary code to a new path, another is installing new product to the old path,it&#39;s recommended to install to a new path. 1. pre-upgrade tasksFirst of all, we need to check the disk space requirement, recommended space list in the below:On Linux/UNIX,1234/home &gt; 2GB/tmp &gt; 5GB/var &gt; 1GB/install_dir &gt;4G 1.1 upgrade checkBefore upgrading the database, you can run db2ckupgrade to check whether the database is ready for upgrade or not, commonly, the db2ckupgrade is located in &quot;DIRIMG/db2/OS/utilities/db2ckupgrade/bin&quot; directory.Log on as instance owner, issue db2ckupgrade command, as follows:123[db2v97i@db2srv ~]$ db2start[db2v97i@db2srv ~]$ /worktmp/server/db2/linuxamd64/utilities/db2ckupgrade/bin/db2ckupgrade mysample -l ~/db2ckupgrade.log DBT5508I The db2ckupgrade utility completed successfully. The database or databases can be upgraded. The mysample is the database name and the db2ckupgrade.log that includes details on errors and warnings. 1.2 backup database before upgradingPerforming a full offline backup is recommended, check how many databases are under the instance.12345[db2v97i@db2srv ~]$ db2 list db directory[db2v97i@db2srv ~]$ db2 list application[db2v97i@db2srv ~]$ db2 force application all[db2v97i@db2srv ~]$ db2 backup db mysample to /db2/backup/db2v97i/mysample/[db2v97i@db2srv ~]$ db2ckbkp backup_image 1.3 backup database and dbm configurationsdb2support collects the information about the database system catalog, database and database manager configuration parameters, DB2 registry variable settings, diagnostic information etc.1[db2v97i@db2srv ~]$ db2support ./ -d mysample -cl 0 Or you can backup manually:1234567891011--backing up database configurations[db2v97i@db2srv ~]$ db2 connect to mysample[db2v97i@db2srv ~]$ db2 GET DB CFG FOR mysample show detail &gt; mysample.cfg--backing up database manager configurations[db2v97i@db2srv ~]$ db2 get dbm cfg show detail &gt;dbm.cfg--backing up DB2 registry variable settings[db2v97i@db2srv ~]$ db2set -all &gt; reg_db2v97i.cfg--backing up DDL information[db2v97i@db2srv ~]$ db2look -d mysample -e -o mysample_tbs.db2 -l -x--backing up environment variables[db2v97i@db2srv ~]$ set |grep -i db2 &gt; env_db2v97i.txt Backing up the audit configuration (instance level) by the db2audit command if audit is configured:1[db2v97i@db2srv ~]$ db2audit describe &gt; audit_instance-name.cfg 2. upgrading a DB2 server2.1 install DB2 v10.1 productionLog on as root user, install DB2 v10.1 production to a different location (as I have done):12345[db2v97i@db2srv ~]$ db2lsInstall Path Level Fix Pack Special Install Number Install Date Installer UID --------------------------------------------------------------------------------/opt/ibm/db2/V9.7_FP10 9.7.0.10 10 Tue Sep 29 17:07:52 2015 CST 0 /opt/ibm/db2/V10.1 10.1.0.0 0 Wed Sep 30 17:07:00 2015 CST 0 2.2 upgrade the DB2 instanceLog on as instance owner, stop the instance:123[db2v97i@db2srv ~]$ db2 force applications all[db2v97i@db2srv ~]$ db2stop force[db2v97i@db2srv ~]$ db2 terminate Log on as root, run db2iupgrade command from the target DB2 version 10.1 code location, such as:12345678910[root@db2srv ~]# /opt/ibm/db2/V10.1/instance/db2iupgrade -k db2v97i --$DB2DIR/instance/db2iupgrade[root@db2srv ~]# su - db2v97i[db2v97i@db2srv ~]$ db2start10/09/2015 15:45:19 0 0 SQL1063N DB2START processing was successful.SQL1063N DB2START processing was successful.[db2v97i@db2srv ~]$ db2levelDB21085I Instance &quot;db2v97i&quot; uses &quot;64&quot; bits and DB2 code release &quot;SQL10010&quot; with level identifier &quot;0201010E&quot;.Informational tokens are &quot;DB2 v10.1.0.0&quot;, &quot;s120403&quot;, &quot;LINUXAMD64101&quot;, and FixPack &quot;0&quot;.Product is installed at &quot;/opt/ibm/db2/V10.1&quot;. 2.3 upgrading the DB2 databaseLog on as instance owner and using the upgrade database command:12345678[db2v97i@db2srv ~]$ db2 upgrade database mysample[db2v97i@db2srv ~]$ db2 connect to mysample Database Connection Information Database server = DB2/LINUXX8664 10.1.0 SQL authorization ID = DB2V97I Local database alias = MYSAMPLE 3. post-upgrade tasks3.1 rebind packagesAfter upgrading instance and database to new version, all application packages written in C, C++, COBOL, FORTRAN, and REXX are marked as invalid, and will be implicitly rebound the first time an application uses them after upgrading database. To eliminate this overhead, you can rebind invalid packages with REBIND or db2rbind command after the upgrade.12[db2v97i@db2srv ~]$ db2rbind mysample -l ./rbind.log all Rebind done successfully for database &apos;MYSAMPLE&apos;. It&#39;s recommended to bind the following packages while using SQL/MQ replication:1234567891011# db2 connect to &lt;db_name&gt;--Binding SQL Capture packages[db2v97i@db2srv ~]$ db2 bind /opt/ibm/db2/V10.1/bnd/@capture.lst isolation ur blocking all--Binding SQL Apply packages[db2v97i@db2srv ~]$ db2 bind /opt/ibm/db2/V10.1/bnd/@applycs.lst isolation cs blocking all grant public[db2v97i@db2srv ~]$ db2 bind /opt/ibm/db2/V10.1/bnd/@applyur.lst isolation ur blocking all grant public--Binding Q Capture packages[db2v97i@db2srv ~]$ db2 bind /opt/ibm/db2/V10.1/bnd/@qcapture.lst isolation ur blocking all--Binding Q Apply packages[db2v97i@db2srv ~]$ db2 bind /opt/ibm/db2/V10.1/bnd/@qapply.lst isolation ur blocking all grant public# db2 terminate 3.2 apply DB2 license1[db2v97i@db2srv ~]$ db2licm -a /worktmp/db2ese_c.lic 4. Install a fix packCheck the requirements of installation, disk spaces, backup database and configurations, etc.. 4.1 stop DB2 process1234[db2v97i@db2srv ~]$ db2 force applications all[db2v97i@db2srv ~]$ db2 terminate[db2v97i@db2srv ~]$ db2stop [db2v97i@db2srv ~]$ db2licd -end Prevent the instances from auto-starting:1[db2v97i@db2srv ~]$ /opt/ibm/db2/V10.1/instance/db2iauto -off db2v97i 4.2 install fix packThere are 2 methods to install fix pack, using installFixPack to install fix pack to existing location, or install new DB2 product.Go to the fix pack image location, as a root, execute installFixPack command to an existing place:1./installFixPack -b DB2DIR I&#39;d like to install to a new place. The installation steps are omitted, my new fixpack directory is /opt/ibm/db2/V10.1_FP5. 4.3 post-installation tasks for fix packsFirst, run djxlink command.Upgrade each instance using db2iupdt command by root user.123456root@db2srv worktmp]# /opt/ibm/db2/V10.1_FP5/instance/db2iupdt db2v97i[db2v97i@db2srv ~]$ db2levelDB21085I This instance or install (instance name, where applicable: &quot;db2v97i&quot;) uses &quot;64&quot; bits and DB2 code release &quot;SQL10015&quot; with level identifier &quot;0206010E&quot;.Informational tokens are &quot;DB2 v10.1.0.5&quot;, &quot;s150624&quot;, &quot;IP23772&quot;, and Fix Pack &quot;5&quot;.Product is installed at &quot;/opt/ibm/db2/V10.1_FP5&quot;. Update the catalog by using db2updv10 command as instance owner:12345678[root@db2srv worktmp]# find /opt/ibm/db2/V10.1_FP5/ -name &quot;db2updv*&quot;/opt/ibm/db2/V10.1_FP5/bnd/db2updv10.bnd/opt/ibm/db2/V10.1_FP5/bin/db2updv10[db2v97i@db2srv ~]$ /opt/ibm/db2/V10.1_FP5/bin/db2updv10 -d mysample[db2v97i@db2srv ~]$ db2start[db2v97i@db2srv ~]$ db2 connect to mysample--enable autostart[db2v97i@db2srv ~]$ /opt/ibm/db2/V10.1/instance/db2iauto -on db2v97i Final step, binding the packages:1234567891011121314151617181920db2 terminatedb2 CONNECT TO mysampledb2 BIND /opt/ibm/db2/V10.1_FP5/bnd/db2schema.bnd BLOCKING ALL GRANT PUBLIC SQLERROR CONTINUE db2 BIND /opt/ibm/db2/V10.1_FP5/bnd/@db2ubind.lst BLOCKING ALL GRANT PUBLIC ACTION ADD db2 BIND /opt/ibm/db2/V10.1_FP5/bnd/@db2cli.lst BLOCKING ALL GRANT PUBLIC ACTION ADD db2 terminatedb2rbind mysample -l ./rbind.log all[db2v97i@db2srv ~]$ db2levelDB21085I This instance or install (instance name, where applicable: &quot;db2v97i&quot;) uses &quot;64&quot; bits and DB2 code release &quot;SQL10015&quot; with level identifier &quot;0206010E&quot;.Informational tokens are &quot;DB2 v10.1.0.5&quot;, &quot;s150624&quot;, &quot;IP23772&quot;, and Fix Pack &quot;5&quot;.Product is installed at &quot;/opt/ibm/db2/V10.1_FP5&quot;.[db2v97i@db2srv ~]$ db2 connect to mysample Database Connection Information Database server = DB2/LINUXX8664 10.1.5 SQL authorization ID = DB2V97I Local database alias = MYSAMPLE EOF","link":"/upgrade-and-fixpack-db2-database.html"},{"title":"Upgrade single database to 12c","text":"There are two upgrade approaches, one is with GUI tool DBUA, another is upgrade with manually. This post is focus on manualy upgrade method. After upgrade to 12c, the new version database is non-CDB,which is DEPRECATED by Oracle, so I also will show you how to convert the non-CDB to PDB.Regarding the PDB and CDB, you can refer my previous topic CDB Overview.DBUA can automatic backup the database, when upgrade finished, if you&#39;re not satisfied with the result, you can simply restore to previous version if you backup the database with DBUA. 1. Pre-upgrade tasksDatabase version 11.2.0.2 or higher, 10.2.0.5 can be upgraded to 12c directly. Other version should be upgraded to the specific version to meet upgrade requirements.Assume my new 12c binary code has been install into a new directory: /u02/app/oracle/product/12.1.0/db1/. 1.1 Perform an offline full backup before upgradeUpgrade is high risk operations in any softwares, whenever you upgrade a database, you should perform a full backup.123456789SQL&gt; shutdown immediateSQL&gt; startup mountSQL&gt; create pfile from spfile;RMAN&gt; run &#123;allocate channel c1 type disk format &apos;/backup/full_offline_%d_%T_%s&apos;;backup full databaseinclude current controlfile;release channel c1;&#125; 1.2 Pre-request check Gather Statistics This step can reduce the amount of downtime.12SQL&gt; alter database open;SQL&gt; EXEC DBMS_STATS.GATHER_DICTIONARY_STATS; Purge recyclebin 1SQL&gt; purge recyclebin; Check the integrity of the source database 1SQL&gt; @?/rdbms/admin/utlrp.sql 1.3 Run the preupgrade.sql from 12cThese scripts are copied from from 12c $ORACLE_HOME/rdbms/admin.1234567891011[oracle@linora:/home/oracle]$ cp /u02/app/oracle/product/12.1.0/db1/rdbms/admin/preupgrd.sql ~/[oracle@linora:/home/oracle]$ cp /u02/app/oracle/product/12.1.0/db1/rdbms/admin/utluppkg.sql ~/SQL&gt; @preupgrd.sql--sample of outputACTIONS REQUIRED:1. Review results of the pre-upgrade checks: /u01/app/oracle/cfgtoollogs/linora/preupgrade/preupgrade.log2. Execute in the SOURCE environment BEFORE upgrade: /u01/app/oracle/cfgtoollogs/linora/preupgrade/preupgrade_fixups.sql3. Execute in the NEW environment AFTER upgrade: /u01/app/oracle/cfgtoollogs/linora/preupgrade/postupgrade_fixups.sql The Pre-Upgrade Information Tool produces 3 scripts. preupgrade.log: The results of all the checks performed. You need to check this to see if it is safe to continue with the upgrade. preupgrade_fixups.sql: A fixup script that should be run before the upgrade. postupgrade_fixups.sql: A fixup script that should be run after the upgrade. So, let&#39;s run preupgrade fix script.1SQL&gt; @/u01/app/oracle/cfgtoollogs/linora/preupgrade/preupgrade_fixups.sql 1.4 Copy source database configuration files to new 12c ORACLE_HOMECopy the netowrk configuration files, the password files into the new DBHOME. Modify network config files to meet the new database configuration.1234[oracle@linora:/home/oracle]$ export ORACLE_12C_HOME=/u02/app/oracle/product/12.1.0/db1[oracle@linora:/home/oracle]$ cp $ORACLE_HOME/network/admin/*.ora $ORACLE_12C_HOME/network/admin/[oracle@linora:/home/oracle]$ cp $ORACLE_HOME/dbs/orapw* $ORACLE_12C_HOME/dbs[oracle@linora:/home/oracle]$ cp $ORACLE_HOME/dbs/*.ora $ORACLE_12C_HOME/dbs After that, stop the listener, stop the dbconsole and isqlplus.12345678910111213LSNRCTL&gt; stop[oracle@linora:/home/oracle]$ emctl stop dbconsole[oracle@linora:/home/oracle]$ isqlplusctl stop#Remove em when you are using old version EM[oracle@linora:/home/oracle]$ source ~/.bash_profile_11g[oracle@linora:/home/oracle]$ sqlplus &quot;/as sysdba&quot;Connected to:Oracle Database 11g Enterprise Edition Release 11.2.0.4.0 - 64bit ProductionWith the Partitioning, OLAP, Data Mining and Real Application Testing optionsSQL&gt; @/u02/app/oracle/product/12.1.0/db1/rdbms/admin/emremove.sqlold 69: IF (upper(&apos;&amp;LOGGING&apos;) = &apos;VERBOSE&apos;)new 69: IF (upper(&apos;VERBOSE&apos;) = &apos;VERBOSE&apos;)PL/SQL procedure successfully completed. Remove OLAP if you are using in old version, because OALP catalog is desupported in 12c.123[oracle@linora:/home/oracle]$ source ~/.bash_profile_11g[oracle@linora:/home/oracle]$ sqlplus &quot;/as sysdba&quot;SQL&gt; @?/olap/admin/catnoamd.sql Before upgrade, check the dba_registry:1234567891011121314151617181920212223SQL&gt; set line 200col comp_name for a50col version for a15col status for a10select comp_name,version,status from dba_registry;COMP_NAME VERSION STATUS-------------------------------------------------- --------------- ----------OWB 11.2.0.4.0 VALIDOracle Application Express 3.2.1.00.12 VALIDSpatial 11.2.0.4.0 VALIDOracle Multimedia 11.2.0.4.0 VALIDOracle XML Database 11.2.0.4.0 VALIDOracle Text 11.2.0.4.0 VALIDOracle Expression Filter 11.2.0.4.0 VALIDOracle Rules Manager 11.2.0.4.0 VALIDOracle Workspace Manager 11.2.0.4.0 VALIDOracle Database Catalog Views 11.2.0.4.0 VALIDOracle Database Packages and Types 11.2.0.4.0 VALIDJServer JAVA Virtual Machine 11.2.0.4.0 VALIDOracle XDK 11.2.0.4.0 VALIDOracle Database Java Packages 11.2.0.4.0 VALIDOLAP Analytic Workspace 11.2.0.4.0 VALIDOracle OLAP API 11.2.0.4.0 VALID Before upgrade, it&#39;s recommended that change the archive log mode to no-archivelog mode.12345678SQL&gt; shutdown immediateSQL&gt; startup mountSQL&gt; alter database noarchivelog;SQL&gt; archive log list;Database log mode No Archive ModeAutomatic archival DisabledArchive destination /arch/linoraSQL&gt; shutdown immediate 2. Upgrade tasksUpdate the /etc/oratab to new oracle home, and disable the automatic startup.123[oracle@linora:/home/oracle]$ tail -2 /etc/oratab#linora:/u01/app/oracle/product/11gr2:Nlinora:/u02/app/oracle/product/12.1.0/db1:N After modified the oratab file, execute the oraenv to set new environments.123[oracle@linora:/home/oracle]$ . oraenvORACLE_SID = [linora] ?The Oracle base remains unchanged with value /u02/app/oracle Now, we can start upgrade now. Although I keep a copy of old version .bash_profile, but during upgrade, you need to use new 12c profile.Execute upgrade.123456789101112[oracle@linora:/home/oracle]$ source ~/.bash_profile_12cSQL&gt; startup upgradeORACLE instance started.Total System Global Area 591396864 bytesFixed Size 2927096 bytesVariable Size 180356616 bytesDatabase Buffers 402653184 bytesRedo Buffers 5459968 bytesDatabase mounted.Database opened.SQL&gt; exit Execute Upgrade Utilities.1234567891011121314151617[oracle@linora:/home/oracle]$ echo $ORACLE_HOME/u02/app/oracle/product/12.1.0/db1[oracle@linora:/home/oracle]$ cd $ORACLE_HOME/rdbms/admin#the parameter -n, it&apos;s value means the parallelism is 4[oracle@linora:/u02/app/oracle/product/12.1.0/db1/rdbms/admin]$ $ORACLE_HOME/perl/bin/perl catctl.pl -n 4 catupgrd.sql#portion outputAnalyzing file catupgrd.sqlLog files in /u02/app/oracle/product/12.1.0/db1/rdbms/admincatcon: ALL catcon-related output will be written to catupgrd_catcon_2980.lstcatcon: See catupgrd*.log files for output generated by scriptscatcon: See catupgrd_*.lst files for spool files, if any...LOG FILES: (catupgrd*.log)Upgrade Summary Report Located in:/u02/app/oracle/product/12.1.0/db1/cfgtoollogs/linora/upgrade/upg_summary.logGrand Total Upgrade Time: [0d:0h:15m:44s] 3. Post-upgrade tasksRun the post-upgrade scripts when upgrade finished.123456789SQL&gt; startup#Run catcon.pl to invoke utlrp.sql to recompile any remaining stored PL/SQL and Java code.[oracle@linora:/home/oracle]$ cd $ORACLE_HOME/rdbms/admin[oracle@linora:/u02/app/oracle/product/12.1.0/db1/rdbms/admin]$ $ORACLE_HOME/perl/bin/perl \\catcon.pl -n 1 -e -b utlrp -d &apos;&apos;&apos;.&apos;&apos;&apos; utlrp.sqlcatcon: ALL catcon-related output will be written to utlrp_catcon_5779.lstcatcon: See utlrp*.log files for output generated by scriptscatcon: See utlrp_*.lst files for spool files, if any Run postupgrade_fixups.sql.12SQL&gt; startupSQL&gt; @/u01/app/oracle/cfgtoollogs/linora/preupgrade/postupgrade_fixups.sql Run utlu121s.sql to verify that all issues have been fixed.1SQL&gt; @?/rdbms/admin/utlu121s.sql Run catuppst.sql1SQL&gt; @?/rdbms/admin/catuppst.sql Gether statistics1SQL&gt; EXECUTE DBMS_STATS.gather_fixed_objects_stats; Verify and compile invalid objects123SQL&gt; @?/rdbms/admin/utlrp.sqlSQL&gt; @?/rdbms/admin/utluiobj.sqlSQL&gt; @?/rdbms/admin/utlu121s.sql Bring the database back to archive log mode.1234567891011SQL&gt; shutdown immediateSQL&gt; startup mountSQL&gt; alter database archivelog;SQL&gt; alter database open;SQL&gt; archive log list;Database log mode Archive ModeAutomatic archival EnabledArchive destination /arch/linoraOldest online log sequence 54Next log sequence to archive 56Current log sequence 56 Verify the upgrade result.123456789101112131415161718192021SQL&gt; set line 200SQL&gt; col comp_name for a50SQL&gt; col version for a15SQL&gt; col status for a10SQL&gt; select comp_name,version,status from dba_registry;COMP_NAME VERSION STATUS-------------------------------------------------- --------------- ----------Oracle Application Express 4.2.5.00.08 VALIDOWB 11.2.0.4.0 VALIDSpatial 12.1.0.2.0 VALIDOracle Multimedia 12.1.0.2.0 VALIDOracle XML Database 12.1.0.2.0 VALIDOracle Text 12.1.0.2.0 VALIDOracle Workspace Manager 12.1.0.2.0 VALIDOracle Database Catalog Views 12.1.0.2.0 VALIDOracle Database Packages and Types 12.1.0.2.0 VALIDJServer JAVA Virtual Machine 12.1.0.2.0 VALIDOracle XDK 12.1.0.2.0 VALIDOracle Database Java Packages 12.1.0.2.0 VALIDOLAP Analytic Workspace 12.1.0.2.0 VALIDOracle OLAP API 12.1.0.2.0 VALID Backup the database and do rest tasks for post upgrading.1234567RMAN&gt; run&#123;allocate channel c1 type disk format &apos;/backup/full_%d_%T_%s&apos;;backup full databaseinclude current controlfileplus archivelog delete all input;release channel c1;&#125; Modify initial file, adjust parameters to meet new 12 database.123456SQL&gt; shutdown immediate#adjust oracle_base, compatible, diagnostic_dest ,audit_file_dest etc.,#do not forget create necessary directories[oracle@linora:/home/oracle]$ mkdir -p /u02/app/oracle/admin/linora/adumpSQL&gt; startupSQL&gt; create spfile from pfile; Re-create password file by using orapwd tools.12[oracle@linora:/home/oracle]$ orapwd file=$ORACLE_HOME/dbs/orapw$ORACLE_SID \\password=oracle entries=5 force=y ignorecase=y 3.1 Upgrade the Time Zone File Version.123456789101112131415#current timezone file versionSQL&gt; SELECT version FROM v$timezone_file; VERSION---------- 14SQL&gt; SELECT PROPERTY_NAME, SUBSTR(property_value, 1, 30) valueFROM DATABASE_PROPERTIESWHERE PROPERTY_NAME LIKE &apos;DST_%&apos;ORDER BY PROPERTY_NAME;PROPERTY_NAME VALUE------------------------------ ----------------------------------------DST_PRIMARY_TT_VERSION 14DST_SECONDARY_TT_VERSION 0DST_UPGRADE_STATE NONE Prepare update timezone file version Need to put upgrade mode to update the timezone file123456789101112131415161718192021222324252627282930SQL&gt; shutdown immediateSQL&gt; startup upgradeSQL&gt; alter session set &quot;_with_subquery&quot;=materialize;SQL&gt; alter session set &quot;_simple_view_merging&quot;=TRUE;SQL&gt; exec DBMS_DST.BEGIN_PREPARE(18);SQL&gt; SELECT PROPERTY_NAME, SUBSTR(property_value, 1, 30) value FROM DATABASE_PROPERTIES WHERE PROPERTY_NAME LIKE &apos;DST_%&apos; ORDER BY PROPERTY_NAME;PROPERTY_NAME VALUE------------------------------ ----------------------------------------DST_PRIMARY_TT_VERSION 14DST_SECONDARY_TT_VERSION 18DST_UPGRADE_STATE PREPARESQL&gt; TRUNCATE TABLE SYS.DST$TRIGGER_TABLE;SQL&gt; TRUNCATE TABLE sys.dst$affected_tables;SQL&gt; TRUNCATE TABLE sys.dst$error_table;SQL&gt; set serveroutput onSQL&gt; BEGIN DBMS_DST.FIND_AFFECTED_TABLES (affected_tables =&gt; &apos;sys.dst$affected_tables&apos;, log_errors =&gt; TRUE, log_errors_table =&gt; &apos;sys.dst$error_table&apos;); END; /#Below query should not return any rowsSQL&gt; SELECT * FROM sys.dst$affected_tables;SQL&gt; SELECT * FROM sys.dst$error_table;SQL&gt; EXEC DBMS_DST.END_PREPARE;A prepare window has been successfully ended. Begin update the timezone file 1234567891011121314151617181920212223242526272829303132333435SQL&gt; purge dba_recyclebin;SQL&gt; alter session set &quot;_with_subquery&quot;=materialize;SQL&gt; alter session set &quot;_simple_view_merging&quot;=TRUE;SQL&gt; EXEC DBMS_DST.BEGIN_UPGRADE(18);SQL&gt; SELECT PROPERTY_NAME, SUBSTR(property_value, 1, 30) valueFROM DATABASE_PROPERTIES WHERE PROPERTY_NAME LIKE &apos;DST_%&apos; ORDER BY PROPERTY_NAME;PROPERTY_NAME VALUE------------------------------ ----------------------------------------DST_PRIMARY_TT_VERSION 18DST_SECONDARY_TT_VERSION 14DST_UPGRADE_STATE UPGRADE#restart the instanceSQL&gt; shutdown immediateSQL&gt; startupSQL&gt; alter session set &quot;_with_subquery&quot;=materialize;SQL&gt; alter session set &quot;_simple_view_merging&quot;=TRUE;SQL&gt; set serveroutput on VAR numfail number BEGIN DBMS_DST.UPGRADE_DATABASE(:numfail, parallel =&gt; TRUE, log_errors =&gt; TRUE, log_errors_table =&gt; &apos;SYS.DST$ERROR_TABLE&apos;, log_triggers_table =&gt; &apos;SYS.DST$TRIGGER_TABLE&apos;, error_on_overlap_time =&gt; FALSE, error_on_nonexisting_time =&gt; FALSE); DBMS_OUTPUT.PUT_LINE(&apos;Failures:&apos;|| :numfail); END;/SQL&gt; VAR fail number BEGIN DBMS_DST.END_UPGRADE(:fail); DBMS_OUTPUT.PUT_LINE(&apos;Failures:&apos;|| :fail); END;/ Verify the result 123456789101112SQL&gt; SELECT PROPERTY_NAME, SUBSTR(property_value, 1, 30) value FROM DATABASE_PROPERTIES WHERE PROPERTY_NAME LIKE &apos;DST_%&apos; ORDER BY PROPERTY_NAME;PROPERTY_NAME VALUE------------------------------ ----------------------------------------DST_PRIMARY_TT_VERSION 18DST_SECONDARY_TT_VERSION 0DST_UPGRADE_STATE NONESQL&gt; SELECT * FROM v$timezone_file;FILENAME VERSION CON_ID---------------------------------------- ---------- ----------timezlrg_18.dat 18 0 Update the registry 12345678910SQL&gt; select TZ_VERSION from registry$database;TZ_VERSION---------- 14SQL&gt; update registry$database set TZ_VERSION = (select version FROM v$timezone_file);SQL&gt; commit;SQL&gt; select TZ_VERSION from registry$database;TZ_VERSION---------- 18 4. Convert non-CDB to PDBWhen upgrade finished, the database in new 12c should be a non-CDB, which is DEPRECATED by Oracle. If the upgraded database is the only database on the current system, then you need to create a Container Database (CDB) first using dbca. Once the CDB is created you can proceed with the next step.12345SQL&gt; select name,open_mode,database_role,cdb from v$database;NAME OPEN_MODE DATABASE_ROLE CDB------------------------------ ---------- -------------------------------- ------LINORA READ WRITE PRIMARY NO 4.1 Create CDBPlease refer this post Silent Install 12c to build an empty CDB. My testing environment as below:123456SQL&gt; select con_id,dbid,name,open_mode,total_size from v$containers; CON_ID DBID NAME OPEN_MODE TOTAL_SIZE---------- ---------- ---------- ---------- ---------- 1 285246148 CDB$ROOT READ WRITE 0 2 1525007667 PDB$SEED READ ONLY 361758720 My CDB instance is ora12c, my non-CDB instance is linora. 4.2 Convert non-CDB to PDBWhen CDB is ready, there are ways can transfer the non-CDB to PDB: data pump, OGG and DBMS_PDB function. Recommend to use DBMS_PDB. Open non-CDB in read only mode 12345[oracle@linora:/home/oracle]$ export ORACLE_SID=linora[oracle@linora:/home/oracle]$ sqlplus &quot;/as sysdba&quot;SQL&gt; shutdown immediateSQL&gt; startup mount exclusiveSQL&gt; alter database open read only; Generate PDB xml manifest file 12SQL&gt; exec DBMS_PDB.DESCRIBE(pdb_descr_file =&gt; &apos;/home/oracle/ncdb.xml&apos;);SQL&gt; shutdown immediate Connect to CDB, verify xml file 12345678910111213141516[oracle@linora:/home/oracle]$ export ORACLE_SID=ora12c[oracle@linora:/home/oracle]$ sqlplus &quot;/as sysdba&quot;SQL&gt; SET SERVEROUTPUT ONSET SERVEROUTPUT ONDECLAREhold_var boolean;beginhold_var := DBMS_PDB.CHECK_PLUG_COMPATIBILITY(pdb_descr_file=&gt;&apos;/home/oracle/ncdb.xml&apos;);if hold_var thendbms_output.put_line(&apos;YES&apos;);elsedbms_output.put_line(&apos;NO&apos;);end if;end;/YES If the output is NO, please query the following view:123456789101112131415SQL&gt; col cause for a25col message for a85set pagesize 9999select cause,type,message,status from PDB_PLUG_IN_VIOLATIONS where name=&apos;LINORA&apos;;CAUSE TYPE MESSAGE STATUS------------------------- ------------------ ------------------------------------------------------------------------------------------ ------------------Parameter WARNING CDB parameter sga_target mismatch: Previous 564M Current 0 RESOLVEDService Name Conflict WARNING Service name or network name of service linora in the PDB is invalid or conflicts with an RESOLVED existing service name or network name in the CDB.Parameter WARNING CDB parameter open_cursors mismatch: Previous 300 Current 500 RESOLVEDParameter WARNING CDB parameter pga_aggregate_target mismatch: Previous 187M Current 10M RESOLVEDNon-CDB to PDB ERROR PDB plugged in is a non-CDB, requires noncdb_to_pdb.sql be run. RESOLVEDDatabase CHARACTER SET ERROR Character set mismatch: PDB character set WE8MSWIN1252. CDB character set AL32UTF8. PENDINGOPTION ERROR Database option OWM mismatch: PDB installed version 12.1.0.2.0. CDB installed version NULL PENDING Convert the non-CDB to PDB 1234567SQL&gt; CREATE PLUGGABLE DATABASE linoraUSING &apos;/home/oracle/ncdb.xml&apos;COPYFILE_NAME_CONVERT = (&apos;/oradata/linora/linora/&apos;,&apos;/data/PDB/linora/&apos;);#Use NOCOPY, reuse tempfileCREATE PLUGGABLE DATABASE linora USING &apos;/home/oracle/ncdb.xml&apos; NOCOPY TEMPFILE REUSE; Verify the result 12345678910111213SQL&gt; select name, open_mode from v$pdbs;NAME OPEN_MODE---------- --------------------PDB$SEED READ ONLYLINORA MOUNTEDSQL&gt; col pdb_name for a15select pdb_name, status from dba_pdbs;PDB_NAME STATUS--------------- ------------------PDB$SEED NORMALLINORA NEW Access to PDB 1234567SQL&gt; alter session set container=linora;SQL&gt; show con_nameCON_NAME------------------------------LINORA#This script must be run before the new PDB can be opened for the first timeSQL&gt; @?/rdbms/admin/noncdb_to_pdb.sql Access to CDB, verify the convert result 1234567891011121314151617181920212223242526SQL&gt; col cause for a25SQL&gt; col message for a85SQL&gt; set pagesize 9999SQL&gt; select cause,type,message,status from PDB_PLUG_IN_VIOLATIONS;CAUSE TYPE MESSAGE STATUS------------------------- ------------------ ------------------------------------------------------------------------------------- ------------------Parameter WARNING CDB parameter sga_target mismatch: Previous 3616M Current 3600M RESOLVEDService Name Conflict WARNING Service name or network name of service orcl1 in the PDB is invalid or conflicts with RESOLVED an existing service name or network name in the CDB.Parameter WARNING CDB parameter compatible mismatch: Previous &apos;12.1.0&apos; Current &apos;12.1.0.2.0&apos; RESOLVEDParameter WARNING CDB parameter pga_aggregate_target mismatch: Previous 1203M Current 1200M RESOLVEDNon-CDB to PDB ERROR PDB plugged in is a non-CDB, requires noncdb_to_pdb.sql be run. RESOLVEDOPTION WARNING Database option DV mismatch: PDB installed version NULL. CDB installed version 12.1.0 PENDING .2.0.OPTION WARNING Database option OLS mismatch: PDB installed version NULL. CDB installed version 12.1. PENDING 0.2.0.SQL&gt; select con_id, name,open_mode from v$containers; CON_ID NAME OPEN_MODE---------- ------------------------------------------------------------ -------------------- 1 CDB$ROOT READ WRITE 2 PDB$SEED READ ONLY 3 LINORA READ WRITE You also can use v$database view to verify it:1234SQL&gt; select name, decode(cdb, &apos;YES&apos;, &apos;Multitenant Option enabled&apos;, &apos;Regular 12c Database: &apos;) &quot;Multitenant Option&quot; , open_mode, con_id from v$database;NAME Multitenant Option OPEN_MODE CON_ID------------------ ---------------------------------------------------- ---------- ----------ORA12C Multitenant Option enabled READ WRITE 0 EOF","link":"/upgrade-single-database-to-12c.html"},{"title":"使用AUDIT_SYSLOG_LEVEL审计","text":"1.作业系统层面设置 Linux/UNIX系统有syslog来专门记录系统日志，且针对syslog可以自行设置以便满足用户自定义需求，一般配置文件存放在/etc/syslog.conf下。RedHat Linux该文件结构如下： 在Redhat 6中，syslogd配置文件已经改为/etc/rsyslog.conf 123456789101112131415161718192021222324[root@linora ~]# cat /etc/syslog.conf # Log all kernel messages to the console.# Logging much else clutters up the screen.#kern.* /dev/console# Log anything (except mail) of level info or higher.# Don&apos;t log private authentication messages!*.info;mail.none;authpriv.none;cron.none /var/log/messages# The authpriv file has restricted access.authpriv.* /var/log/secure# Log all the mail messages in one place.mail.* -/var/log/maillog# Log cron stuffcron.* /var/log/cron# Everybody gets emergency messages*.emerg *# Save news errors of level crit and higher in a special file.uucp,news.crit /var/log/spooler# Save boot messages also to boot.loglocal7.* /var/log/boot.log--添加关于Oracle的loggedcat &gt;&gt;/etc/syslog.conf&lt;&lt;EOF# About Oracle SysLoguser.notice /var/log/oracle_dbmsEOF 这表示指定一个user.notice的输出位置是/var/log/oracle_dbms文件。重新启动syslogd后台进程，让设置生效，或者直接重启系统。 12345[root@linora ~]# /etc/rc.d/init.d/syslog restartShutting down kernel logger: [ OK ]Shutting down system logger: [ OK ]Starting system logger: [ OK ]Starting kernel logger: [ OK ] 2.数据库层面设置 对audit_syslog_level这个参数进行设置，非动态参数，需要重启实例 12345678--查看默认值SYS@linora&gt;SHOW parameter audit_syslogNAME TYPE VALUE--------------- ---------------------- ------------------------------audit_syslog_level string--修改参数ALTER system SET audit_syslog_level=&apos;user.notice&apos; scope=spfile; 重启实例以便生效。 注意，这种日志记录审计只能审计sys即数据库管理员或者操作员等有限权限的登录登出，但不能记录数据库层面操作，比如DDL，DML语句。 AUDIT_SYSLOG_LEVEL 独立于AUDIT_TRAIL, 当设置了AUDIT_SYSLOG_LEVEL而AUDIT_TRAIL为默认值NONE时，CONNECT,STARTUP,与SHUTDOWN信息始终由SYSLOG记录。 同时设置AUDIT_SYSLOG_LEVEL与AUDIT_SYS_OPERATIONS=TURE 会将SYSDBA 或SYSOPER权限执行的任何操作通过SYSLOG记录，即便AUDIT_TRAIL=NONE。","link":"/using-audit-syslog-level.html"},{"title":"使用udev代替ASMlib","text":"1.Introduction 在Linux平台，从SAN、NAS或者SCSI设备映射过来的LUN一般识别为/dev/sdX。 如： 123456789[root@orcl1 ~]# ll /dev/sd* brw-r----- 1 root disk 8, 0 Sep 6 09:33 /dev/sda brw-r----- 1 root disk 8, 1 Sep 6 09:34 /dev/sda1 brw-r----- 1 root disk 8, 2 Sep 6 09:33 /dev/sda2 brw-r----- 1 root disk 8, 3 Sep 6 09:34 /dev/sda3 brw-r----- 1 root disk 8, 16 Sep 6 09:33 /dev/sdb brw-r----- 1 root disk 8, 32 Sep 6 09:33 /dev/sdc brw-r----- 1 root disk 8, 48 Sep 6 09:33 /dev/sdd brw-r----- 1 root disk 8, 64 Sep 6 09:33 /dev/sde 这样存在一个问题，当一块磁盘因为各种原因从系统移除，就会导致磁盘路径被改变或者修改了磁盘的权限。比如在一个系统中有三块磁盘，sda,sdb,sdc，在下一次重启中sdb损坏了，系统将会只认到两块盘：sda及sdb，但此时的sdb其实是原来的sdc。在RAC或者ASM环境中，LUN mapping过来的名称改变会导致ASM无法识别该磁盘组。 利用ASMLib或者UDEV绑定设备名称可避免这种情况的发生。 本文将示范在RHEL5下如何配置udev，如何利用udev固定设备名称，并且在RAC环境中用udev取代ASMlib。 2.Configuring udev UDEV能够根据系统中的硬件设备的状态，动态的更新设备文件。包括设备文件的创建及删除等。Udev具体的实现过程本文不深入研究，主要会使用就行了。 Udev的配置主要有两个组件：规则配置文件及权限配置文件。在RHEL5以后，权限配置文件已经包含在规则配置文件中，本文不予讨论。 123456[root@orcl1:/etc/udev]# ll total 32 drwxr-xr-x 2 root root 4096 Sep 6 00:17 makedev.d drwxr-xr-x 2 root root 4096 Sep 6 00:40 rules.d drwxr-xr-x 2 root root 4096 Sep 6 00:22 scripts -rw-r--r-- 1 root root 226 Feb 3 2012 udev.conf Udev.conf文档是主要配置文档，它定义了配置文件位置，udev数据库及其他信息。 1234567[root@orcl1:/etc/udev]# cat udev.conf # udev.conf# The initial syslog(3) priority: &quot;err&quot;, &quot;info&quot;, &quot;debug&quot; or its # numerical equivalent. For runtime debugging, the daemons internal # state can be changed with: &quot;udevcontrol log_priority=&amp;lt;value&amp;gt;&quot;. udev_log=&quot;err&quot; 2.1 Setting rules 规则文件基本上决定了磁盘如何被识别，如何在重启或者磁盘替换的时候，分配固定设备名称。规则文件主要包含以下几个栏位： BUS：设备总线类型 KERNEL：内核设备名称 PROGRAM：调用外部命令 RESULT：外部命令PROGRAM返回的结果 NAME：在/dev下产生的设备文件名 OWNER、GROUP及MODE表面此磁盘的权限属主 例如： 1KERNEL==&quot;sd*&quot;, BUS==&quot;scsi&quot;, PROGRAM==&quot;/sbin/scsi_id -g -u -s %p&quot;, RESULT==&quot;SATA_VBOX_HARDDISK_VB96362bad-ec8eda70_&quot;, NAME=&quot;asm-diske&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;asmadmin&quot;, MODE=&quot;0660&quot; 通过scsi_id命令可获取设备UUID（唯一性），通过此UUID固定设备名称。 对于规则文件内容的添加，可用以下脚本产生： 1234for i in b c d e; do echo &quot;KERNEL==\\&quot;sd*\\&quot;, BUS==\\&quot;scsi\\&quot;, PROGRAM==\\&quot;/sbin/scsi_id -g -u -s %p\\&quot;, RESULT==\\&quot;`scsi_id -g -u -s /block/sd$i`\\&quot;, NAME=\\&quot;asm-disk$i\\&quot;, OWNER=\\&quot;grid\\&quot;, GROUP=\\&quot;asmadmin\\&quot;, MODE=\\&quot;0660\\&quot;&quot; done 3．Example 123456789[root@orcl1:/etc/udev]# for i in b c d e; do echo &quot;KERNEL==\\&quot;sd*\\&quot;, BUS==\\&quot;scsi\\&quot;, PROGRAM==\\&quot;/sbin/scsi_id -g -u -s %p\\&quot;, RESULT==\\&quot;`scsi_id -g -u -s /block/sd$i`\\&quot;, NAME=\\&quot;asm-disk$i\\&quot;, OWNER=\\&quot;grid\\&quot;, GROUP=\\&quot;asmadmin\\&quot;, MODE=\\&quot;0660\\&quot;&quot; doneKERNEL==&quot;sd*&quot;, BUS==&quot;scsi&quot;, PROGRAM==&quot;/sbin/scsi_id -g -u -s %p&quot;, RESULT==&quot;SATA_VBOX_HARDDISK_VBb16974be-5341d251_&quot;, NAME=&quot;asm-diskb&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;asmadmin&quot;, MODE=&quot;0660&quot; KERNEL==&quot;sd*&quot;, BUS==&quot;scsi&quot;, PROGRAM==&quot;/sbin/scsi_id -g -u -s %p&quot;, RESULT==&quot;SATA_VBOX_HARDDISK_VB6094ba99-e26492cb_&quot;, NAME=&quot;asm-diskc&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;asmadmin&quot;, MODE=&quot;0660&quot; KERNEL==&quot;sd*&quot;, BUS==&quot;scsi&quot;, PROGRAM==&quot;/sbin/scsi_id -g -u -s %p&quot;, RESULT==&quot;SATA_VBOX_HARDDISK_VB24305be5-421a5edc_&quot;, NAME=&quot;asm-diskd&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;asmadmin&quot;, MODE=&quot;0660&quot; KERNEL==&quot;sd*&quot;, BUS==&quot;scsi&quot;, PROGRAM==&quot;/sbin/scsi_id -g -u -s %p&quot;, RESULT==&quot;SATA_VBOX_HARDDISK_VB96362bad-ec8eda70_&quot;, NAME=&quot;asm-diske&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;asmadmin&quot;, MODE=&quot;0660&quot; 将以上输出添加入/etc/udev/rules.d/99-oracle-asmdevices.rules文件中，并且重启udev服务，以便识别新添加udev设备： 12[root@orcl1:/etc/udev/rules.d]# start_udev Starting udev: [ OK ] 查询udev设备： 12345[root@orcl1:/etc/udev/rules.d]# ll /dev/asm* brw-rw---- 1 grid asmadmin 8, 16 Sep 6 10:47 /dev/asm-diskb brw-rw---- 1 grid asmadmin 8, 32 Sep 6 10:47 /dev/asm-diskc brw-rw---- 1 grid asmadmin 8, 48 Sep 6 10:47 /dev/asm-diskd brw-rw---- 1 grid asmadmin 8, 64 Sep 6 10:47 /dev/asm-diske 脚本原创：http://www.oracledatabase12g.com/archives/utilize-udev-resolve-11gr2-rac-asm-device-name.html 在安装RAC设定ASM磁盘组时，根据当前路径即可完成ASM磁盘组的设定。 在RHEL 6中，上述脚本已经失效，请参照如下设定： 12345678910111213141516171819202122--确认版本[root@linora ~]# cat /etc/redhat-release Red Hat Enterprise Linux Server release 6.5 (Santiago)[root@linora ~]# echo &quot;options=--whitelisted --replace-whitespace&quot; &gt;&gt; /etc/scsi_id.config[root@linora ~]# cat /etc/scsi_id.config options=--whitelisted --replace-whitespace--确认要绑定的设备，这里只有/dev/sdb[root@linora ~]# ll /dev/sd*brw-rw---- 1 root disk 8, 0 Sep 16 12:47 /dev/sdabrw-rw---- 1 root disk 8, 1 Sep 16 12:47 /dev/sda1brw-rw---- 1 root disk 8, 2 Sep 16 12:47 /dev/sda2brw-rw---- 1 root disk 8, 3 Sep 16 12:47 /dev/sda3brw-rw---- 1 root disk 8, 16 Sep 16 12:47 /dev/sdb--执行脚本for i in b c d e f ;doecho &quot;KERNEL==\\&quot;sd*\\&quot;, BUS==\\&quot;scsi\\&quot;, PROGRAM==\\&quot;/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/\\$name\\&quot;, RESULT==\\&quot;`/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$i`\\&quot;, NAME=\\&quot;asm-disk$i\\&quot;, OWNER=\\&quot;grid\\&quot;, GROUP=\\&quot;asmadmin\\&quot;, MODE=\\&quot;0660\\&quot;&quot; done--将以上输出写入/etc/udev/rules.d/99-oracle-asmdevices.rules--启动udev[root@linora ~]# start_udevStarting udev: [ OK ] 4、关于多路径及udev的使用(RHEL6.X) 4.1 EMC PowerPath PowerPath跟linux自带的DM-Multipath是冲突的，如果要使用powerpath必需要关闭掉mpath： 123[root@db01 ~]# powermt display dev=allERROR: Cannot open PowerPath. Initialization error 删除multipath配置文件，关闭后台进程，并且禁止随机启动 1234rm -rf /etc/multipath.com/etc/init.d/multipathd stopchkconfig multipathd off[root@db02 ~]# mpathconf --disable 重启后： 123456789101112131415[root@db02 ~]# powermt display dev=allPseudo name=emcpoweraVNX ID=CKM00144603151 [db_0_1_share]Logical device ID=6006016060703A00851B09E01B0FE511 [db_0_1_share_lun8]state=alive; policy=CLAROpt; queued-IOs=0Owner: default=SP A, current=SP A Array failover mode: 4==============================================================================--------------- Host --------------- - Stor - -- I/O Path -- -- Stats ---### HW Path I/O Paths Interf. Mode State Q-IOs Errors============================================================================== 0 qla2xxx sdi SP A1 active alive 0 0 0 qla2xxx sdr SP B1 active alive 0 0 2 qla2xxx sdaa SP A0 active alive 0 0 2 qla2xxx sdaj SP B0 active alive 0 0... 由于设备名称已经绑定，只需要在udev中赋予相关的授权即可 12345678910111213141516171819202122232425262728293031323334[root@db01 rules.d]# touch 99-oracle-asmdevices.rules[root@db01 rules.d]# ls -l /dev/emc*crw-r--r-- 1 root root 10, 56 6月 10 15:22 /dev/emcpowerbrw-rw---- 1 root disk 120, 0 6月 10 15:22 /dev/emcpowerabrw-rw---- 1 root disk 120, 16 6月 10 15:22 /dev/emcpowerbbrw-rw---- 1 root disk 120, 32 6月 10 15:22 /dev/emcpowercbrw-rw---- 1 root disk 120, 48 6月 10 15:22 /dev/emcpowerdbrw-rw---- 1 root disk 120, 64 6月 10 15:22 /dev/emcpowerebrw-rw---- 1 root disk 120, 80 6月 10 15:22 /dev/emcpowerfbrw-rw---- 1 root disk 120, 96 6月 10 15:22 /dev/emcpowergbrw-rw---- 1 root disk 120, 112 6月 10 15:22 /dev/emcpowerhbrw-rw---- 1 root disk 120, 128 6月 10 15:22 /dev/emcpoweri[root@db01 rules.d]# vi 99-oracle-asmdevices.rules SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowera&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerb&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerc&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerd&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowere&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerf&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerg&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpowerh&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;SUBSYSTEM==&quot;block&quot;, KERNEL==&quot;emcpoweri&quot;, GROUP=&quot;dba&quot;, OWNER=&quot;grid&quot;, MODE=&quot;0660&quot;[root@db01 rules.d]# start_udev 正在启动 udev：[确定]crw-rw---- 1 root root 10, 56 6月 10 15:30 /dev/emcpowerbrw-rw---- 1 grid dba 120, 0 6月 10 15:30 /dev/emcpowerabrw-rw---- 1 grid dba 120, 16 6月 10 15:30 /dev/emcpowerbbrw-rw---- 1 grid dba 120, 32 6月 10 15:30 /dev/emcpowercbrw-rw---- 1 grid dba 120, 48 6月 10 15:30 /dev/emcpowerdbrw-rw---- 1 grid dba 120, 64 6月 10 15:30 /dev/emcpowerebrw-rw---- 1 grid dba 120, 80 6月 10 15:30 /dev/emcpowerfbrw-rw---- 1 grid dba 120, 96 6月 10 15:30 /dev/emcpowergbrw-rw---- 1 grid dba 120, 112 6月 10 15:30 /dev/emcpowerhbrw-rw---- 1 grid dba 120, 128 6月 10 15:30 /dev/emcpoweri 集群安装完成后查看voting disk 1234567[grid@db02:/u01/app/11gr2/grid/log/db02]$ crsctl query css votedisk## STATE File Universal Id File Name Disk group-- ----- ----------------- --------- --------- 1. ONLINE 037f0dd1fc9e4fb5bff478a6d5d448d5 (/dev/emcpowera) [OCR] 2. ONLINE 3b7395481c8b4ff1bfd04007f05e0106 (/dev/emcpowerb) [OCR] 3. ONLINE 3c82301f45724f36bfa2dae4af73338f (/dev/emcpowerc) [OCR]Located 3 voting disk(s). 4.2 dm-multipath with udev 通过脚本查找出设备wwid 1234for i in c d;do /sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/sd$idone 将设备wwid映射到配置文件中，在实际环境中，这一步可以省略，默认的multipath.conf文件会自动聚合出来，同时给出wwid： 1234567891011121314151617[root@db01 ~]# multipath -llmpathe (36006016060703a003b8427f0790ee511) dm-3 DGC,VRAIDsize=304G features=&apos;1 queue_if_no_path&apos; hwhandler=&apos;1 emc&apos; wp=rw|-+- policy=&apos;round-robin 0&apos; prio=1 status=active| |- 0:0:1:3 sdm 8:192 active ready running| `- 2:0:1:3 sdae 65:224 active ready running`-+- policy=&apos;round-robin 0&apos; prio=0 status=enabled |- 0:0:0:3 sdd 8:48 active ready running `- 2:0:0:3 sdv 65:80 active ready runningmpathd (36006016060703a006f80e2e4790ee511) dm-2 DGC,VRAIDsize=303G features=&apos;1 queue_if_no_path&apos; hwhandler=&apos;1 emc&apos; wp=rw|-+- policy=&apos;round-robin 0&apos; prio=1 status=active| |- 0:0:0:2 sdc 8:32 active ready running| `- 2:0:0:2 sdu 65:64 active ready running`-+- policy=&apos;round-robin 0&apos; prio=0 status=enabled |- 0:0:1:2 sdl 8:176 active ready running `- 2:0:1:2 sdad 65:208 active ready running 下面是测试时自己编辑的配置文件： 12345678910111213141516171819202122[root@oel6 rules.d]# cat /etc/multipath.conf | grep -v ^# | grep -v ^$ blacklist &#123; #devnode &quot;^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*&quot; #devnode &quot;^hd[a-z]&quot; devnode &quot;sd[a-b]&quot; #wwid 1ATA_VBOX_HARDDISK_VB2314099c-4ddf514a #wwid 1ATA_VBOX_HARDDISK_VB9b70e1bb-9ea5e71b&#125;defaults &#123; user_friendly_names no getuid_callout &quot;/sbin/scsi_id --whitelisted --replace-whitespace --device=/dev/%n&quot;&#125;multipaths &#123; multipath &#123; wwid 1ATA_VBOX_HARDDISK_VB0d3ee45b-3ed72c0c alias data_mpath1 &#125; multipath &#123; wwid 1ATA_VBOX_HARDDISK_VB3dc9cda2-488673dc alias data_mpath2 &#125;&#125; 重启multipathd进程，并且查看结果 1234567891011121314[root@oel6 ~]# /etc/init.d/multipathd restartokStopping multipathd daemon: [ OK ]Starting multipathd daemon: [ OK ][root@oel6 ~]# multipath -v2[root@oel6 ~]# multipath -lldata_mpath2 (1ATA_VBOX_HARDDISK_VB3dc9cda2-488673dc) dm-3 ATA,VBOX HARDDISKsize=3.0G features=&apos;0&apos; hwhandler=&apos;0&apos; wp=rw`-+- policy=&apos;round-robin 0&apos; prio=1 status=active `- 5:0:0:0 sdd 8:48 active ready runningdata_mpath1 (1ATA_VBOX_HARDDISK_VB0d3ee45b-3ed72c0c) dm-2 ATA,VBOX HARDDISKsize=3.0G features=&apos;0&apos; hwhandler=&apos;0&apos; wp=rw`-+- policy=&apos;round-robin 0&apos; prio=1 status=active `- 4:0:0:0 sdc 8:32 active ready running 用udev进行设备名称绑定 123456789101112[root@oel6 rules.d]# cat 12-dm-permissions.rules ENV&#123;DM_NAME&#125;==&quot;data_mpath1&quot;,NAME=&quot;asmdisk1&quot;, OWNER:=&quot;grid&quot;, GROUP:=&quot;oinstall&quot;, MODE:=&quot;660&quot;ENV&#123;DM_NAME&#125;==&quot;data_mpath2&quot;,NAME=&quot;asmdisk2&quot;, OWNER:=&quot;grid&quot;, GROUP:=&quot;oinstall&quot;, MODE:=&quot;660&quot;[root@oel6 rules.d]# cat 99-oracle-asmdevices.rules KERNEL==&quot;sd*&quot;, SUBSYSTEM==&quot;block&quot;, ENV&#123;DEVTYPE&#125;==&quot;disk&quot;, ENV&#123;ID_SERIAL&#125;==&quot;1ATA_VBOX_HARDDISK_VB0d3ee45b-3ed72c0c&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;oinstall&quot;, MODE=&quot;0660&quot;KERNEL==&quot;sd*&quot;, SUBSYSTEM==&quot;block&quot;, ENV&#123;DEVTYPE&#125;==&quot;disk&quot;, ENV&#123;ID_SERIAL&#125;==&quot;1ATA_VBOX_HARDDISK_VB3dc9cda2-488673dc&quot;, OWNER=&quot;grid&quot;, GROUP=&quot;oinstall&quot;, MODE=&quot;0660&quot;#restart udevudevadm control --reload-rulesstart_udev[root@oel6 rules.d]# ll /dev/asmdisk*brw-rw---- 1 grid oinstall 252, 2 Jun 10 20:50 /dev/asmdisk1brw-rw---- 1 grid oinstall 252, 3 Jun 10 20:50 /dev/asmdisk2 5. RHEL 7 udev 123456#RHEL7.4 ASM udev加盘/usr/bin/scsi-rescanmultipath -llvi /etc/udev/rule.d/99-oracle-asmdevices.rules--restart udev/sbin/udevadm trigger --type=devices --action=change * Udev rule 123456789101112# 获取磁盘UUID[root@cmsdb02l rules.d]# udevadm info --query=all --name=/dev/mapper/ocr-disk01 |grep -i dm_uuidE: DM_UUID=mpath-36005c80058d78000000000001cd# 添加udev规则绑定multipath磁盘，vi 99-oracle-asmdevices.rules# OCR DISKsACTION==\"add|change\", ENV&#123;DM_UUID&#125;==\"mpath-36005c80058d78000000000001cd\",SYMLINK+=\"asmdisk1\", GROUP=\"oinstall\", OWNER=\"grid\", MODE=\"0660\"ACTION==\"add|change\", ENV&#123;DM_UUID&#125;==\"mpath-36005c80058d78000000000001ce\", SYMLINK+=\"asmdisk2\", GROUP=\"oinstall\", OWNER=\"grid\", MODE=\"0660\"ACTION==\"add|change\", ENV&#123;DM_UUID&#125;==\"mpath-36005c80058d78000000000001cf\", SYMLINK+=\"asmdisk3\", GROUP=\"oinstall\", OWNER=\"grid\", MODE=\"0660\"# 重新加载udevudevadm trigger --type=devices --action=change EOF","link":"/using-udev-replace-asmlib.html"},{"title":"Virtual Index虚拟索引的使用","text":"10g以后，可以在表中创建虚拟索引，以用来测试SQL走索引是否能提高性能。虚拟索引不包含数据，因此不会对数据及存储空间造成影响，基本上作为SQL调优的一种手段。测试如下： 123456789101112131415161718SH@linora&gt;SELECT * FROM sh.sales WHERE quantity_sold &gt; 10000; Execution Plan ---------------------------------------------------------- Plan hash value: 1550251865 --------------------------------------------------------------------------------------------- | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | Pstart| Pstop | --------------------------------------------------------------------------------------------- | 0 | SELECT STATEMENT | | 1 | 29 | 4978 (2)| 00:01:00 | | | | 1 | PARTITION RANGE ALL| | 1 | 29 | 4978 (2)| 00:01:00 | 1 | 64 | |* 2 | TABLE ACCESS FULL | SALES | 1 | 29 | 4978 (2)| 00:01:00 | 1 | 64 | --------------------------------------------------------------------------------------------- Predicate Information (identified by operation id): --------------------------------------------------- 2 - filter(&quot;QUANTITY_SOLD&quot;&gt;10000) 全表扫描，cost为4978. 创建虚拟索引： 123SH@linora&gt;ALTER SESSION SET &quot;_use_nosegment_indexes&quot;=TRUE; CREATE INDEX sh.sales_vi1 ON sh.sales(quantity_sold) NOSEGMENT; 再次执行sql，查看执行计划 12345678910111213141516171819SH@linora&gt;SELECT * FROM sh.sales WHERE quantity_sold &gt; 10000; Execution Plan ---------------------------------------------------------- Plan hash value: 3712353291 ---------------------------------------------------------------------------------------------------------------- | Id | Operation | Name | Rows | Bytes | Cost (%CPU)| Time | Pstart| Pstop | ---------------------------------------------------------------------------------------------------------------- | 0 | SELECT STATEMENT | | 1 | 29 | 3 (0)| 00:00:01 | | | | 1 | TABLE ACCESS BY GLOBAL INDEX ROWID| SALES | 1 | 29 | 3 (0)| 00:00:01 | ROWID | ROWID | |* 2 | INDEX RANGE SCAN | SALES_VI1 | 1 | | 2 (0)| 00:00:01 | | | ---------------------------------------------------------------------------------------------------------------- Predicate Information (identified by operation id): --------------------------------------------------- 2 - access(&quot;QUANTITY_SOLD&quot;&gt;10000) 采用了索引扫描，且cost降为3. 查看虚拟索引： 12345SELECT index_owner, index_name FROM dba_ind_columns WHERE index_name NOT LIKE &apos;BIN$%&apos; MINUS SELECT owner, index_name FROM dba_indexes; 删除方法跟正常索引删除一样： 123SH@linora&gt;drop index sales_vi1; Index dropped.","link":"/virtual-index-simple-use.html"},{"title":"Oracle ROWID学习","text":"Reference：http://www.orafaq.com/wiki/ROWID http://www.cnblogs.com/rootq/archive/2008/10/24/1319058.html http://www.oracleonlinux.cn/2011/11/whats-oracle-rowid/ 在Oracle数据库中，每一行记录都会有一个唯一的ROWID指向磁盘中存放此记录的物理地址。 一般ROWID一旦分配就不会改变，但当重组表或者使用exp/imp工具导入一个表时候，ROWID将会改变。 在分区表中，因为update导致数据从一个分区到另一个分区的row Migration也会改变该记录的ROWID。 从8i开始，ROWID大小固定为10bytes，由data_object_id#+rfile#+block#+row#组成，显示为18位字符串，如下所示： BBED@linora> SELECT owner,rowid FROM t WHERE rownum=1; OWNER ROWID ---------- ------------------ SYSTEM AAAO3qAAJAAAAQNAAA 对以上18位字符解释如下： The Oracle 8 format is on 10 bytes: bits 1 to 32 (bytes 1 to 4): data object id (0-4294967295) bits 33 to 44 (byte 5 and half byte 6): file number inside the tablespace (0-4095) bits 45 to 64 (half byte 6 and bytes 7 and 8): block number inside the file (0-1048575) bits 65 to 80 (bytes 9 and 10): row number inside the block (0-65535) 32bit的object number，每个数据库最多有4G个对象 10bit的file number，每个对象最多有1022个文件（2个文件预留） 22bit的block number，每个文件最多有4M个BLOCK 16bit的row number，每个BLOCK最多有64K个ROWS ROWID的格式如下： 数据对象编号 文件编号 块编号 行编号 OOOOOO FFF BBBBBB RRR 根据SQL查找出来的ROWID显示是18字符，这些字符是64位编码，10进制跟64进制转换如下： 由此可得知： A-Z 0 – 25 (26) a-z 26 – 51 (26) 0-9 52 – 61 (10) +/ 62 – 63 (2) 因此10进制跟64进制编码转换公式如下：d*(b^p)，其中b为基数，这里就是64，p就是从右至左，以0开始的位置数，那么上面例子中AAAO3qAAJAAAAQNAAA，文件号AAJ具体计算应该为： 9*(64^0)=9 0*(64^1)=0 0*(64^2)=0 因此该文件号为9。块编号为AAAAQN，具体计算为(A值为0，可以不算了)： N=13*(64^0)=13 Q=16*(64^1)=1024 因此，该块编号为1037，行编号为0，可以使用DBMS_ROWID包验证以上计算结果： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849SELECT DBMS_ROWID.ROWID_OBJECT(rowid) &quot;OBJECT&quot;,DBMS_ROWID.ROWID_RELATIVE_FNO(rowid) &quot;FILE&quot;,DBMS_ROWID.ROWID_BLOCK_NUMBER(rowid) &quot;BLOCK&quot;,DBMS_ROWID.ROWID_ROW_NUMBER(rowid) &quot;ROW&quot;FROM bbed.tWHERE rownum=1/或者：SELECT rowid,dbms_rowid.rowid_object(rowid) object_id,dbms_rowid.rowid_relative_fno(rowid) file_id,dbms_rowid.rowid_block_number(rowid) block_id ,dbms_rowid.rowid_row_number(rowid) num ,rowidtochar(rowid) FROM bbed.t WHERE rownum=1; OBJECT FILE BLOCK ROW---------- ---------- ---------- ---------- 60906 9 1037 0--也可以通过以下方式获取相关rowid信息：CREATE OR REPLACE FUNCTION get_rowid(l_rowid IN varchar2) RETURN varchar2 IS ls_my_rowid varchar2(200); rowid_type NUMBER; object_number NUMBER; relative_fno NUMBER; block_number NUMBER; ROW_NUMBER NUMBER;BEGIN dbms_rowid.rowid_info(l_rowid, rowid_type, object_number, relative_fno, block_number, ROW_NUMBER); ls_my_rowid := &apos;Object# is :&apos; || to_char(object_number) || chr(10) || &apos;Relative_fno is :&apos; || to_char(relative_fno) || chr(10) || &apos;Block number is :&apos; || to_char(block_number) || chr(10) || &apos;Row number is :&apos; || to_char(ROW_NUMBER); RETURN ls_my_rowid;END;/ -- 结果如下所示：BBED@linora&amp;gt;selectget_rowid(rowid), owner FROM t WHERE rownum=1;GET_ROWID(ROWID) OWNER---------------------------- -------------------------------Object# IS :60906 SYSTEMRelative_fno IS :9Block NUMBER IS :1037ROW NUMBER IS :0","link":"/what-is-rowid.html"},{"title":"HPUX Mirror(replace) root disk","text":"一、备份操作系统 make_tape_recovery –A –C –v 二、更换系统镜像根盘的步骤： 1、首先扫描系统disk，找出有问题的disk， 查看磁盘是否有unclaimed或NO_HW #ioscan －fnCdisk 查看磁盘是否有unavliable #vgdisplay -v 查看是否有stale #lvdisplay -v /dev/vg00/lvol* |grep stale 现场情况是ioscan检查硬盘是claimed状态，但vgdisplay –v查看是unavliable状态，lvdisplay –v 查看有stale。 2、确定坏盘（cXtYdZ）的位置 #dd if=/dev/rdsk/c5t5d0 of=/dev/null bs=1024k 坏盘cXtYdZ 的状态灯长亮（其它的disk在正常的情况下，灯都是闪烁的），或者通过磁盘cXtYdZ的SCSI ID号来确认坏盘的位置。 因为坏盘上已经有故障，因此作dd的时候很容易hang住，因此还是选择在好盘上做dd，灯长亮的那块盘为好盘，另一块就是坏盘。 3、去除坏盘镜像 for lvol in lvol1 lvol2 ... lvol8 do lvreduce -m 0 /dev/vg00/$lvol /dev/dsk/c5t5d0 lvreduce -m 0 /dev/vg00/oracle /dev/dsk/c5t5d0 done 11.31可用DSF路径代替： for lvol in lvol1 lvol2 ... lvol8 do lvreduce -m 0 /dev/vg00/$lvol /dev/disk/disk13 lvreduce -m 0 /dev/vg00/oracle /dev/disk/disk13 done 请注意，需要将所有在vg00里面的lv镜像都拆除。 #vgreduce -f /dev/vg00 4、在线热插拔拔出坏盘，插入带来的新硬盘（注意：在正确的机器上拔出正确的盘并且做好防静电措施）。 5、查看系统是否发现新插入的磁盘和状态 #ioscan －fnCdisk 6、安装设备路径 #insf -eCdisk 7、镜像磁盘 #pvcreate -fB /dev/rdsk/c5t5d0 ;为该磁盘创建物理镜像卷组 #pvcreate -fB /dev/rdisk/disk13 ;11.31可使用DSF路径 #vgextend /dev/vg00 /dev/dsk/c5t5d0 ;扩展vg00至镜像磁盘 #mkboot -l /dev/rdsk/c5t5d0 ;创建boot分区 #mkboot -a \"hpux -lq(;0)/stand/vmunix\" /dev/rdsk/c5t5d0 8、将根盘卷中所有lv都镜像到新建立的可启动盘上。（注意：首先镜像lvol1) for lvol in lvol1 lvol2 ... lvol8 do lvextend -m 1 /dev/vg00/$lvol /dev/rdsk/c5t5d0 lvextend -m 1 /dev/vg00/oracle /dev/rdsk/c5t5d0 done or for lvol in lvol1 lvol2 ... lvol8 do lvextend -m 1 /dev/vg00/$lvol /dev/disk/disk13 lvextend -m 1 /dev/vg00/oracle /dev/disk/disk13 done 9、更新BDRA 信息 1234567891011121314#lvlnboot -b /dev/vg00/lvol1#lvlnboot -r /dev/vg00/lvol3#lvlnboot -s /dev/vg00/lvol2#lvlnboot -d /dev/vg00/lvol2#[root@rp7430:/]#ioscan -funCdiskClass I H/W Path Driver S/W State H/W Type Description=======================================================================disk 0 1/0/0/3/0.6.0 sdisk CLAIMED DEVICE HP 146 GST3146707LC /dev/dsk/c0t6d0 /dev/rdsk/c0t6d0disk 1 1/0/0/3/1.2.0 sdisk CLAIMED DEVICE HP DVD-ROM 305 /dev/dsk/c1t2d0 /dev/rdsk/c1t2d0disk 4 1/0/1/1/0/1/1.6.0 sdisk CLAIMED DEVICE HP 146 GST3146707LC /dev/dsk/c3t6d0 /dev/rdsk/c5t5d0 #==mirror disk#[root@rp7430:/]#setboot -a 1/0/1/1/0/1/1.6.0 10、确认镜像情况 #lvlnboot -R /dev/vg00 #lvlnboot -v #setboot -v #lvdisplay -v /dev/vg00/lvoln|more #lifls /dev/disk/disk13 ISL AUTO HPUX PAD LABEL #lifls /dev/disk/disk2 HPUX ISL AUTO PAD LABEL","link":"/hpux-mirrorreplace-root-disk.html"},{"title":"Install DB2 in Linux","text":"Install DB2 server in Linux may not as difficult as Oracle database server installation in Linux, it just need a little change to install DB2 server in Linux, espacially in silent mode. This post just a practice of my homework. And any suggestions will be welcome. I. pre-install tasksMy test environment OS is RHEL6.5 X64, and DB2 version is v10.1. Since v9.7.2, the kernal parameters do not need to modify manually, as the database manager modifies kernal parameters dynamically when it starts. And not like Oracle, DB2 with response file installation no need to create account in OS, as you can specify users in the response file. 1. edit /etc/hosts, add hostname and ip address, and disable selinux12345678[root@hadr01 ~]# cat /etc/hosts127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4::1 localhost localhost.localdomain localhost6 localhost6.localdomain6192.168.56.60 hadr01192.168.56.61 hadr02[root@hadr01 worktmp]# sed -i &apos;/^SELINUX/s/enforcing/disabled/g&apos; /etc/selinux/config 2. extract DB2 binary, and run prerecheck12345678[root@hadr01 worktmp]# ls -ltrtotal 734968drwxr-xr-x. 3 root root 4096 Apr 4 2012 server-rw-r--r--. 1 root root 999 Sep 5 10:24 db2ese_c.lic-rw-r--r--. 1 root root 752588810 Sep 5 10:24 v10.1_linuxx64_server.tar.gz-rw-r--r--. 1 root root 1528 Sep 5 10:59 db2ese.rsp[root@hadr01 worktmp]# cd server/[root@hadr01 server]# ./db2prereqcheck Fix the warnings or errors until all requirements db2prereqcheck matched.12--For TSAMP installation[root@hadr01 server]# yum install libstdc++.i686 perl ksh pam.i686 -y 3. create the response file using the sample responses fileThe sample response file located at server/db2/platform/samples/,12345678910111213141516[root@hadr01 samples]# pwd/worktmp/server/db2/linuxamd64/samples[root@hadr01 samples]# ls -ltrtotal 368-r--r--r--. 1 bin bin 42350 Apr 4 2012 db2pe.rsp-r--r--r--. 1 bin bin 54144 Apr 4 2012 db2ese.rsp-r--r--r--. 1 bin bin 43397 Apr 4 2012 db2consv.rsp-r--r--r--. 1 bin bin 27826 Apr 4 2012 db2client.rsp-r--r--r--. 1 bin bin 54035 Apr 4 2012 db2wse.rsp-r--r--r--. 1 bin bin 54435 Apr 4 2012 db2aese.rsp-r--r--r--. 1 bin bin 9440 Apr 4 2012 db2un.rsp-r--r--r--. 1 bin bin 43713 Apr 4 2012 db2exp.rsp-r--r--r--. 1 bin bin 26381 Apr 4 2012 db2rtcl.rsp[root@hadr01 samples]# mv db2ese.rsp /worktmp/[root@hadr01 samples]# cd /worktmp/ Edit the response file to meet your environment.1234567891011121314151617181920212223242526272829303132333435363738394041424344454647[root@hadr01 worktmp]# cat db2ese.rsp LIC_AGREEMENT = ACCEPTPROD = ENTERPRISE_SERVER_EDITIONFILE = /opt/ibm/db2/V10.1INSTALL_TYPE = CUSTOMCOMP = TSAMPCOMP = APPLICATION_DEVELOPMENT_TOOLSCOMP = COMMUNICATION_SUPPORT_TCPIPCOMP = JDKCOMP = JAVA_SUPPORTCOMP = BASE_DB2_ENGINECOMP = REPL_CLIENTCOMP = LDAP_EXPLOITATIONCOMP = INSTANCE_SETUP_SUPPORTCOMP = DB2_SAMPLE_DATABASECOMP = ACSCOMP = SQL_PROCEDURESCOMP = DB2_DATA_SOURCE_SUPPORTCOMP = BASE_CLIENTCOMP = CONNECT_SUPPORT* ----------------------------------------------* Instance properties * ----------------------------------------------INSTANCE = inst1inst1.TYPE = ese* Instance-owning userinst1.NAME = db2v10iinst1.GROUP_NAME = db2iadm1inst1.HOME_DIRECTORY = /home/db2v10iinst1.PASSWORD = db24everENCRYPTED = inst1.PASSWORDinst1.AUTOSTART = YESinst1.SVCENAME = db2c_db2v10iinst1.PORT_NUMBER = 50000inst1.FCM_PORT_NUMBER = 60000inst1.MAX_LOGICAL_NODES = 4inst1.CONFIGURE_TEXT_SEARCH = NO* Fenced userinst1.FENCED_USERNAME = db2fenc1inst1.FENCED_GROUP_NAME = db2fadm1inst1.FENCED_HOME_DIRECTORY = /home/db2fenc1inst1.FENCED_PASSWORD = db24everENCRYPTED = inst1.FENCED_PASSWORD*-----------------------------------------------* Installed Languages *-----------------------------------------------LANG = EN II. Install DB2 using respons file123456789[root@hadr01 install]# cd /worktmp/server/[root@hadr01 server]# ./db2setup -r /worktmp/db2ese.rsp -l /worktmp/db2setup.log -t /worktmp/db2setup.trcDBI1191I db2setup is installing and configuring DB2 according to the response file provided. Please wait.The execution completed successfully.For more information see the DB2 installation log at &quot;/worktmp/db2setup.log&quot;. III. Post-install tasks1. Configure firewall for DB2 service portYou dont need to manual configure database manager parameter &quot;scvename&quot;, as the response file already did. What we need to do is opening the service port in firewall.12345678910111213141516171819202122232425262728[root@hadr01 ~]# cat /etc/sysconfig/iptables# Firewall configuration written by system-config-firewall# Manual customization of this file is not recommended.*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT#For DB2 services#-A INPUT -p tcp --dport 50000 -j ACCEPT#-A OUTPUT -p tcp --sport 50000 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 50000 -j ACCEPT-A OUTPUT -m state --state NEW -m tcp -p tcp --sport 50000 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibitedCOMMIT[root@hadr01 server]# iptables -L -n |grep 50000ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp dpt:50000 ACCEPT tcp -- 0.0.0.0/0 0.0.0.0/0 tcp spt:50000 [root@hadr01 ~]# cat /etc/services |grep 50000db2c_db2v10i 50000/tcp[db2v10i@hadr01 ~]$ db2 get dbm cfg |grep -i svcename TCP/IP Service name (SVCENAME) = db2c_db2v10i 2. Add license1234567891011121314[db2v10i@hadr01 ~]$ db2licm -a /worktmp/db2ese_c.licLIC1402I License added successfully.LIC1426I This product is now licensed for use as outlined in your License Agreement. USE OF THE PRODUCT CONSTITUTES ACCEPTANCE OF THE TERMS OF THE IBM LICENSE AGREEMENT, LOCATED IN THE FOLLOWING DIRECTORY: &quot;/opt/ibm/db2/V10.1/license/en_US.iso88591&quot;[db2v10i@hadr01 ~]$ db2licm -lProduct name: &quot;DB2 Enterprise Server Edition&quot;License type: &quot;CPU Option&quot;Expiry date: &quot;Permanent&quot;Product identifier: &quot;db2ese&quot;Version information: &quot;10.1&quot;Enforcement policy: &quot;Soft Stop&quot; 3. Create database--Create sample database (optional)1234567[root@hadr01 ~]# mkdir -p /db2/&#123;data,backup,arch,log&#125;[root@hadr01 ~]# chown -R db2v10i:db2iadm1 /db2/[db2v10i@hadr01 ~]$ db2sampl -dbpath /db2/data -name mysample -sql -force -verbose Creating database &quot;mysample&quot; on path &quot;/db2/data&quot;... Connecting to database &quot;mysample&quot;... Creating tables and data in schema &quot;DB2V10I&quot;... &apos;db2sampl&apos; processing complete. --Create user defined database12[db2v10i@hadr01 ~]$ db2 create db testdb automatic storage yes on &apos;/db2/data&apos; DBPATH on &apos;/db2/data&apos; using codeset UTF-8 TERRITORY USDB20000I The CREATE DATABASE command completed successfully. 4. Configure client connectionsOn the clients:First, catalog node on clients:1234567891011121314[db2inst1@db2v10 ~]$ db2 catalog tcpip node hadr01 remote 192.168.56.60 server 50000DB20000I The CATALOG TCPIP NODE command completed successfully.DB21056W Directory changes may not be effective until the directory cache is refreshed.[db2inst1@db2v10 ~]$ db2 list node directory Node Directory Number of entries in the directory = 1Node 1 entry: Node name = HADR01 Comment = Directory entry type = LOCAL Protocol = TCPIP Hostname = 192.168.56.60 Service name = 50000 Second, catalog database on clients:1234567891011121314151617[db2inst1@db2v10 ~]$ db2 catalog database testdb as testdb at node hadr01DB20000I The CATALOG DATABASE command completed successfully.DB21056W Directory changes may not be effective until the directory cache is refreshed.[db2inst1@db2v10 ~]$ db2 list db directory System Database Directory Number of entries in the directory = 1Database 1 entry: Database alias = TESTDB Database name = TESTDB Node name = HADR01 Database release level = 10.00 Comment = Directory entry type = Remote Catalog database partition number = -1 Alternate server hostname = Alternate server port number = In the output, where &quot;Directory entry type&quot; equals &quot;remote&quot;, it means from the database is on a remote server, oppositely, where the &quot;Directory entry type&quot; equals &quot;indirect&quot;, it means a local database.Now, we can connect to the server in the client:1234567[db2inst1@db2v10 ~]$ db2 connect to testdb user db2v10iEnter current password for db2v10i: SQL30081N A communication error has been detected. Communication protocol being used: &quot;TCP/IP&quot;. Communication API being used: &quot;SOCKETS&quot;. Location where the error was detected: &quot;192.168.56.60&quot;. Communication function detecting the error: &quot;connect&quot;. Protocol specific error code(s): &quot;113&quot;, &quot;*&quot;, &quot;*&quot;. SQLSTATE=08001 Something wrong with the client connection. And I found that the issue was firewall configure not correct. In RHEL6, in firewall configuration file /etc/sysconfig/iptables, if you need to open the other port, your configure command need to below 22 port. For example:1234567891011121314151617181920[root@hadr01 ~]# cat /etc/sysconfig/iptables# Firewall configuration written by system-config-firewall# Manual customization of this file is not recommended.*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state --state ESTABLISHED,RELATED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 22 -j ACCEPT#For DB2 services, open other port need to follow the 22 port#-A INPUT -p tcp --dport 50000 -j ACCEPT#-A OUTPUT -p tcp --sport 50000 -j ACCEPT-A INPUT -m state --state NEW -m tcp -p tcp --dport 50000 -j ACCEPT-A OUTPUT -m state --state NEW -m tcp -p tcp --sport 50000 -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited-A FORWARD -j REJECT --reject-with icmp-host-prohibitedCOMMIT Try to reconnect:12345[db2inst1@db2v10 ~]$ db2 connect to testdb user db2v10i using db24ever Database Connection Information Database server = DB2/LINUXX8664 10.1.0 SQL authorization ID = DB2V10I Local database alias = TESTDB 5.Configure archive log using diskDB2 offer 2 methods to manager transaction logs, circular and archive, most of production environment using archive log mode.123456789101112131415161718192021[db2v10i@hadr01 ~]$ mkdir -p /db2/log/db2v10i/mysample[db2v10i@hadr01 ~]$ db2 update db cfg for mysample using NEWLOGPATH /db2/log/db2v10i/mysampleDB20000I The UPDATE DATABASE CONFIGURATION command completed successfully.SQL1363W Database must be deactivated and reactivated before the changes to one or more of the configuration parameters will be effective.[db2v10i@hadr01 ~]$ db2 terminateDB20000I The TERMINATE command completed successfully.[db2v10i@hadr01 ~]$ db2 deactivate database mysampleDB20000I The DEACTIVATE DATABASE command completed successfully.[db2v10i@hadr01 ~]$ db2 activate database mysampleDB20000I The ACTIVATE DATABASE command completed successfully.[db2v10i@hadr01 ~]$ db2 get db cfg for mysample |grep -i log Log retain for recovery status = NO User exit for logging status = NO Catalog cache size (4KB) (CATALOGCACHE_SZ) = (MAXAPPLS*5) Log buffer size (4KB) (LOGBUFSZ) = 256 Log file size (4KB) (LOGFILSIZ) = 1000 Number of primary log files (LOGPRIMARY) = 3 Number of secondary log files (LOGSECOND) = 10 Changed path to log files (NEWLOGPATH) = Path to log files = /db2/log/db2v10i/mysample/NODE0000/LOGSTREAM0000/ Change default circular log mode to archive log123456789101112[db2v10i@hadr01 ~]$ db2 get db cfg for mysample |grep -i LOGARCHMETH1 First log archive method (LOGARCHMETH1) = OFF Archive compression for logarchmeth1 (LOGARCHCOMPR1) = OFF Options for logarchmeth1 (LOGARCHOPT1) = [db2v10i@hadr01 ~]$ db2 update db cfg for mysample using LOGARCHMETH1 disk:db2/arch/mysampleDB20000I The UPDATE DATABASE CONFIGURATION command completed successfully.SQL1363W Database must be deactivated and reactivated before the changes to one or more of the configuration parameters will be effective.[db2v10i@hadr01 ~]$ db2 terminateDB20000I The TERMINATE command completed successfully.[db2v10i@hadr01 ~]$ db2 deactivate database mysampleDB20000I The DEACTIVATE DATABASE command completed successfully. After modifying the LOGARCHMETH1 parameter the database will need an offline full backup:12345678[db2v10i@hadr01 ~]$ db2 backup db mysample to /db2/backup/mysample/Backup successful. The timestamp for this backup image is : 20150906162210[db2v10i@hadr01 ~]$ db2 activate database mysampleDB20000I The ACTIVATE DATABASE command completed successfully.[db2inst1@hadr01 ~]$ db2 connect to testdb[db2v10i@hadr01 ~]$ db2 get db cfg for mysample |grep -i LOGARCHMETH1 First log archive method (LOGARCHMETH1) = DISK:/db2/arch/mysample/ Manual archive a log, and check the archive whether works or not:1234567891011[db2v10i@hadr01 ~]$ ll /db2/arch/mysample/db2v10i/MYSAMPLE/NODE0000/LOGSTREAM0000/C0000000/total 0[db2v10i@hadr01 ~]$ db2 connect resetDB20000I The SQL command completed successfully.[db2v10i@hadr01 ~]$ db2 archive log for database mysampleDB20000I The ARCHIVE LOG command completed successfully.[db2v10i@hadr01 ~]$ ll /db2/arch/mysample/db2v10i/MYSAMPLE/NODE0000/LOGSTREAM0000/C0000000/total 12-rw-r----- 1 db2v10i db2iadm1 12288 Sep 6 16:25 S0000000.LOG 6.Configure incremental tracking modeIf you want to backup the database in the incremental or delta mode, the trackmod configuration parameter must be set to &quot;ON&quot;123[db2v10i@hadr01 ~]$ db2 update db cfg for mysample using trackmod onDB20000I The UPDATE DATABASE CONFIGURATION command completed successfully.SQL1363W Database must be deactivated and reactivated before the changes to one or more of the configuration parameters will be effective. After changing this parameter to &quot;ON&quot; you will also need to take a full backup (online or offline) to establish the baseline for incremental or delta backups.12[db2v10i@hadr01 ~]$ db2 backup database mysample online to /db2/backup/mysample/ include logsBackup successful. The timestamp for this backup image is : 20150906163124 EOF","link":"/install-db2-in-linux.html"},{"title":"Logminer简单用法","text":"1. 安装Logminer 123SQL&gt;@?/rdbms/admin/dbmslm.sql SQL&gt;@?/rdbms/admin/dbmslmd.sql SQL&gt;@?/rdbms/admin/dbmslms.sql 2. 创建数据字典 12345SQL&gt; alter system set utl_file_dir=&apos;/oradata/lgmnr&apos; scope=spfile; --restart the instance -- Create a dictionary file -- (init.ora parameter utl_file_dir must be set) exec dbms_logmnr_d.build(&apos;mydictfile&apos;, &apos;/oradata/lgmnr&apos;); 3. 添加日志 12345-- Register log files, can be from a different db -- (NEWFILE=start new list/ ADDFILE=add next file) exec dbms_logmnr.add_logfile(&apos;/arch/1_141_810359695.dbf&apos;, dbms_logmnr.new); exec dbms_logmnr.add_logfile(&apos;/arch/1_142_810359695.dbf&apos;, dbms_logmnr.addfile); exec dbms_logmnr.add_logfile(&apos;/arch/1_143_810359695.dbf&apos;, dbms_logmnr.addfile); 4. 使用字典分析日志 12-- Start the logminer session exec dbms_logmnr.start_logmnr(DictFileName =&gt; &apos;/oradata/lgmnr/mydictfile&apos;); 5. 查看日志 1234567-- Query v_$logmnr_contents view to extract required info select timestamp, sql_undo from sys.v_$logmnr_contents where seg_name = &apos;T&apos;; select operation,sql_redo,sql_undo from v$logmnr_contents where seg_owner=&apos;BBED&apos; and seg_name=&apos;T&apos; and rownum&lt;=10; 6. 结束日志挖掘 1SQL&gt; execute dbms_logmnr.end_logmnr; EOF","link":"/logminer-simple-use.html"},{"title":"Markdown Syntax","text":"Markdown is a lightweight markup language, the original purpose of markdown is to provide a handy tool for text to html, with easy read and easy write syntax format. Markdown can be defined to: 1. plain-text syntax; 2. a software converting the plain-text to html.When I was using wordpress as my personal blog, I didn&#39;t know which text editor should I use for blogging. After I changed my blog frame to octopress, I begin to use markdown. With handy and simple syntax, it save my a lot of time. Because of its efficiency, I write all of my plain-text documents with markdown. 1. Markdown SyntaxNormally, markdown line breaks are identical like other editors&#39; line break--Enter. But in some situation, There may be different, either by two Enters, or by three spaces in the end of line. 1.1 Headers12345678910# This is H1## This is H2### This is H3#### This is H4##### This is H5###### This is H6Alternative H1===============Alternative H2---------------- In WEB, it will be shown as: This is H1This is H2This is H3This is H4This is H5This is H6Alternative H1Alternative H21.2 Blockquotes123456William Wallace said:&gt; What would you do without freedom,&gt; would you fight?&gt; This is first level&gt; &gt; this is nested blockquotes William Wallace said: What would you do without freedom,would you fight? This is first level this is nested blockquotes Blockquotes also can combine other syntax, such as Header, Lists etc. 123456789&gt; ##This is a Header&gt;&gt; 1. List item one&gt; 2. List item two&gt;&gt; Here's some code block example:&gt; #!/bin/bash&gt; echo \"Hello World\"&gt; exit 0 ##This is a Header List item one List item two Here&#39;s some code block example: #!/bin/bash echo &quot;Hello World&quot; exit 0 1.3 Lists1.3.1 Unordered listsUnordered list use hyphens or asterisks or pluses 1234- Unordered list item 1- Unordered list item 2 + Unorder nested list item 2.1+ Unordered list item 3 Unordered list item 1 Unordered list item 2 Unorder nested list item 2.1 Unordered list item 3 1.3.2 Ordered listsOrdered lists use numbers followed by periods: 1231. Ordered list item 12. Ordered list item 23. Ordered list item 3 Ordered list item 1 Ordered list item 2 Ordered list item 3 1.4 Code Blocks and Syntax HighlightingIndented with four spaces will fenced code block Indented with four spaces #!/bin/bash echo \"hello world\" #!/bin/bash echo &quot;hello world&quot; Sometimes, back ticks are more efficiency. Besides, only back-ticks are supporting syntax highlighting, it&#39;s recommended to use back ticks. Below examples actually no bakslash here, just for escaping. \\`\\`\\`javascript var s = \"JavaScript syntax highlighting\"; alert(s); \\`\\`\\` \\`\\`\\`python s = \"Python syntax highlighting\" print s \\`\\`\\` \\`\\`\\` No language indicated, so no syntax highlighting. \\`\\`\\` Inline code block `syntax highlighting`. 12var s = \"JavaScript syntax highlighting\";alert(s); 12s = \"Python syntax highlighting\"print s 1No language indicated, so no syntax highlighting. Inline code block Inline code highlighting. 1.5 Horizontal rules12345678910111213With three or more asterisks, hyphens, or underscores:Three or more asterisks*******or hyphens---------or underscores___________ With three or more asterisks, hyphens, or underscores: Three or more asterisks or hyphens or underscores 1.6 LinksMarkdown supports two style of line: inline or reference. 123456789This is an **inline** [Link for my blog](http://www.kkdba.com). This is an **reference** [Link for my current post](/markdown-syntax.html).Also reference [Link][markdown syntax] can be used like this way.[markdown syntax]: http://www.kkdba.com/markdown-syntax.html.URLs and URLs in angle brackets will automatically get turned into links. http://www.kkdba.com or &lt;http://www.kkdba.com&gt;. This is an inline Link for my blog. This is an reference Link for my current post. Also reference Link can be used like this way. URLs and URLs in angle brackets will automatically get turned into links: http://www.kkdba.com or http://www.kkdba.com. 1.7 ImagesImages quote just like Link usages: inline or reference. 123This is my image with inline ![Inline](http://www.kkdba.com/images/rss.png).This is my image with reference ![Reference](/images/rss.png). This is my image with inline . This is my image with reference . 1.8 EmphasisThe way emphasize a word is using asterisks or underscores around the word. 1234567Emphasis with one *asterisk*With two __underscores__Or with three ***asterisks***With two ~~tildes~~ add strikethrough to the word Emphasis with one asterisk With two underscores Or with three asterisks With two tildes add strikethrough to the word 1.9 Backslash EscapesMarkdown provides backslash escapes for the following characters: 123456789101112\\ backslash` backtick* asterisk_ underscore&#123;&#125; curly braces[] square brackets() parentheses# hash mark+ plus sign- minus sign (hyphen). dot! exclamation mark 1.10 TablesTables in markdown use pipes and hyphens(Three or more) with colon to align columns, the outer pipes can be optional. 12345| First name(Default Left align) | Last name(Centre align) | Salary(Right align) || ---------- | :---------: | ------------------: || Fung | KK Kong | $3000 || Oracle | Larry | $20 || Larry | Jordan | $300000 | Table 1 -- Colons can be used to align columns First name(Default Left align) Last name(Centre align) Salary(Right align) Fung KK Kong $3000 Oracle Larry $20 Larry Jordan $300000 2. Markdown extension on google chromeGoogle Chrome extension Markdown Preview Plus is for previewing markdown plain-text file via chrome browser, it also can convert the markdown plain-text file to mhtml file or PDF file. Configuration for markdown previewThis extension supports customizing css style, I choose this one zhangjikai/markdown-css. When using export tool by default, the html file is mhtml file format, in my laptop environment, I can&#39;t open it with firefox browser, so I use this tool mht2htmcl (or you can download from my blog) to convert mht file to html file, after converting, it works perfectly for me. EOF","link":"/markdown-syntax.html"},{"title":"管理AWR快照","text":"1.管理快照Oracle默认每小时生成一次快照，11g中，默认保存时间为8天，而在10g中，默认保存时间为7天。Oracle提供了一个DBMS_WORKLOAD_REPOSITORY包用于管理快照，包括创建删除修改快照，但必须要有DBA权限才能进行调用。 查看当前快照设定1234567SYS@linora&gt; col SNAP_INTERVAL for a20SYS@linora&gt; col RETENTION for a20SYS@linora&gt; select * from dba_hist_wr_control; DBID SNAP_INTERVAL RETENTION TOPNSQL---------- -------------------- -------------------- ----------3385851293 +00000 01:00:00.0 +00008 00:00:00.0 DEFAULT 修改快照为15分钟一次，保存10天1234567SYS@linora&gt; BEGIN 2 DBMS_WORKLOAD_REPOSITORY.MODIFY_SNAPSHOT_SETTINGS( 3 interval =&gt; 15, 4 retention =&gt; 10*24*60); 5 END; 6 /PL/SQL procedure successfully completed. 在这个包中，还有其他选项，如：1234567BEGIN DBMS_WORKLOAD_REPOSITORY.MODIFY_SNAPSHOT_SETTINGS(retention =&gt; 43200, interval =&gt; 30, topnsql =&gt; 100, dbid =&gt; 3310949047);END;/ 1.retention表示快照保留时间，以分钟计算，最小值为1天，最大为100年。如果此参数为0，表示永久保留。2.interval表示快照生产间隔时间，以分钟计算，最小10分钟，最大为1年。如果此参数为0，则表示禁用awr。3.topnsql表示抓取符合以下每一项条件的top N sql：12345678910111213141. Elapsed Time (ms)2. CPU Time (ms)3. Executions4. Buffer Gets5. Disk Reads6. Parse Calls7. Rows8. User I/O Wait Time (ms)9 Cluster Wait Time (ms)10. Application Wait Time (ms)11. Concurrency Wait Time (ms)12. Invalidations13. Version Count14. Sharable Mem(KB) 创建快照123456789101112131415SYS@linora&gt; col BEGIN_INTERVAL_TIME for a50 SYS@linora&gt; col FLUSH_ELAPSED for a30SYS@linora&gt; select SNAP_ID,BEGIN_INTERVAL_TIME,FLUSH_ELAPSED from dba_hist_snapshot order by snap_id; SNAP_ID BEGIN_INTERVAL_TIME FLUSH_ELAPSED---------- -------------------------------------------------- ------------------------------ 98 17-JUL-14 02.15.08.645 PM +00000 00:00:00.6 99 17-JUL-14 02.30.11.373 PM +00000 00:00:00.6SYS@linora&gt; exec dbms_workload_repository.create_snapshot();PL/SQL procedure successfully completed.SYS@linora&gt; select SNAP_ID,BEGIN_INTERVAL_TIME,FLUSH_ELAPSED from dba_hist_snapshot order by snap_id; SNAP_ID BEGIN_INTERVAL_TIME FLUSH_ELAPSED---------- -------------------------------------------------- ------------------------------ 98 17-JUL-14 02.15.08.645 PM +00000 00:00:00.6 99 17-JUL-14 02.30.11.373 PM +00000 00:00:00.6 100 17-JUL-14 02.45.14.378 PM +00000 00:00:01.4 删除快照12345678910111213141516171819202122232425SYS@linora&gt; select SNAP_ID,BEGIN_INTERVAL_TIME,FLUSH_ELAPSED from dba_hist_snapshot where snap_id&gt;=75 and snap_id &lt;=80; SNAP_ID BEGIN_INTERVAL_TIME FLUSH_ELAPSED---------- -------------------------------------------------- ------------------------------ 75 16-JUL-14 10.50.34.000 AM +00000 00:00:08.6 76 16-JUL-14 10.55.03.421 AM +00000 00:00:01.7 77 16-JUL-14 11.02.59.311 AM +00000 00:00:02.8 78 16-JUL-14 11.15.32.171 AM +00000 00:00:02.0 79 16-JUL-14 11.30.36.014 AM +00000 00:00:01.2 80 16-JUL-14 11.45.39.828 AM +00000 00:00:01.76 rows selected.SYS@linora&gt; BEGIN 2 DBMS_WORKLOAD_REPOSITORY.DROP_SNAPSHOT_RANGE(low_snap_id =&gt; 77, 3 high_snap_id =&gt; 80, 4 dbid =&gt; 3385851293); 5 END; 6 /PL/SQL procedure successfully completed.SYS@linora&gt; select SNAP_ID,BEGIN_INTERVAL_TIME,FLUSH_ELAPSED from dba_hist_snapshot where snap_id&gt;=75 and snap_id &lt;=80; SNAP_ID BEGIN_INTERVAL_TIME FLUSH_ELAPSED---------- -------------------------------------------------- ------------------------------ 75 16-JUL-14 10.50.34.000 AM +00000 00:00:08.6 76 16-JUL-14 10.55.03.421 AM +00000 00:00:01.7 需要注意的是，调用DROP_SNAPSHOT_RANGE删除snapshot时，在此期间内的ASH也会被删除。 2.管理基线Baseline包含指定时间点的性能数据，一般是在业务峰值性能正常时的数据，因此，当某天性能出现异常时，则可与baseline进行比较。基线有几种类型：单一基线，重复基线，及11G的Moving Window Baseline，这里只涉及最简单的单一基线。 创建baselinebaseline是在两个snapshot之间的，因此，首先从dba_hist_snapshot决定baseline创建在哪两个snapshot之间，然后，使用CREATE_BASELINE进行创建。12345678910SYS@linora&gt; BEGIN 2 DBMS_WORKLOAD_REPOSITORY.CREATE_BASELINE(start_snap_id =&gt; 81, 3 end_snap_id =&gt; 85, 4 baseline_name =&gt; &apos;test baseline&apos;, 5 dbid =&gt; 3385851293, 6 expiration =&gt; 30); 7 END; 8 /PL/SQL procedure successfully completed. 该procedure最后一个参数expiration，在本例中表示30天后该baseline过期，如果不指定此参数，则表示永不过期。 查看baseline1234567SYS@linora&gt; select baseline_name, baseline_type, start_snap_id, end_snap_id, expiration 2 from DBA_HIST_BASELINE;BASELINE_NAME BASELINE_TYPE START_SNAP_ID END_SNAP_ID EXPIRATION---------------------------------------- ------------- ------------- ----------- ----------test baseline STATIC 81 85 30SYSTEM_MOVING_WINDOW MOVING_WINDOW 75 104 这里有个小提示，针对DBA或者其他相关视图，如果忘记此视图叫什么名字，可利用dict数据字典进行模糊查找。1select * from dict where table_name like &apos;DBA_HIST%&apos;; 删除baseline123456SYS@linora&gt; BEGIN DBMS_WORKLOAD_REPOSITORY.DROP_BASELINE(baseline_name =&gt; &apos;test baseline&apos;, cascade =&gt; FALSE, dbid =&gt; 3385851293);END;/ 如果cascade为false，则表示仅仅删除baseline，如果cascade参数为true，则表示相关快照也一起删除。 3.生成AWR报告一般默认执行@?/rdbms/admin/awrrpt.sql，如果需要生成RAC的报告，则执行@?/rdbms/admin/awrgrpt.sql，如果RAC上需要收集其他节点的AWR报告，则执行@?/rdbms/admin/awrrpti.sql。11g同时新增了一个awrddrpt.sql，这个脚本用来比较两个时间段的AWR报告(RAC中使用的是awrgdrpt.sql)。 使用DBMS_WORKLOAD_REPOSITORY手动执行awr报告Function AWR_REPORT_HTML定义如下：1234567DBMS_WORKLOAD_REPOSITORY.AWR_REPORT_HTML( l_dbid IN NUMBER, l_inst_num IN NUMBER, l_bid IN NUMBER, l_eid IN NUMBER, l_options IN NUMBER DEFAULT 0) RETURN awrrpt_text_type_table PIPELINED; 参数解析：l_dbid表示数据库dbid，l_inst_num表示实例号，l_bid表示开始的snapshot id，l_eid表示结束的snapshot id，l_options控制报表的输出，只有一个值：8，则表示输出中带ADDM的建议值。123SYS@linora&gt; spool testawr.htmlSYS@linora&gt; select output from table (DBMS_WORKLOAD_REPOSITORY.AWR_REPORT_HTML(3385851293,1,75,76,8));SYS@linora&gt; spool off Reference:Oracle® Database Performance Tuning Guide 11g Release 2 (11.2)Oracle® Database PL/SQL Packages and Types Reference 11g Release 2 (11.2)","link":"/manage-awr.html"}],"tags":[{"name":"rac","slug":"rac","link":"/tags/rac/"},{"name":"Installation","slug":"Installation","link":"/tags/Installation/"},{"name":"12c","slug":"12c","link":"/tags/12c/"},{"name":"fundamentals","slug":"fundamentals","link":"/tags/fundamentals/"},{"name":"scripts","slug":"scripts","link":"/tags/scripts/"},{"name":"broker","slug":"broker","link":"/tags/broker/"},{"name":"dataguard","slug":"dataguard","link":"/tags/dataguard/"},{"name":"how to","slug":"how-to","link":"/tags/how-to/"},{"name":"multitenant","slug":"multitenant","link":"/tags/multitenant/"},{"name":"tuning","slug":"tuning","link":"/tags/tuning/"},{"name":"concept","slug":"concept","link":"/tags/concept/"},{"name":"patch","slug":"patch","link":"/tags/patch/"},{"name":"db2load","slug":"db2load","link":"/tags/db2load/"},{"name":"partitioning","slug":"partitioning","link":"/tags/partitioning/"},{"name":"aix","slug":"aix","link":"/tags/aix/"},{"name":"tar","slug":"tar","link":"/tags/tar/"},{"name":"asm","slug":"asm","link":"/tags/asm/"},{"name":"shell","slug":"shell","link":"/tags/shell/"},{"name":"bbed","slug":"bbed","link":"/tags/bbed/"},{"name":"nid","slug":"nid","link":"/tags/nid/"},{"name":"backup","slug":"backup","link":"/tags/backup/"},{"name":"new featrure","slug":"new-featrure","link":"/tags/new-featrure/"},{"name":"deinstall","slug":"deinstall","link":"/tags/deinstall/"},{"name":"rman","slug":"rman","link":"/tags/rman/"},{"name":"em","slug":"em","link":"/tags/em/"},{"name":"find","slug":"find","link":"/tags/find/"},{"name":"maintenance","slug":"maintenance","link":"/tags/maintenance/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"sql_id","slug":"sql-id","link":"/tags/sql-id/"},{"name":"redo","slug":"redo","link":"/tags/redo/"},{"name":"hadr","slug":"hadr","link":"/tags/hadr/"},{"name":"installation","slug":"installation","link":"/tags/installation/"},{"name":"vtl","slug":"vtl","link":"/tags/vtl/"},{"name":"database","slug":"database","link":"/tags/database/"},{"name":"udev","slug":"udev","link":"/tags/udev/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"nbu","slug":"nbu","link":"/tags/nbu/"},{"name":"ogg","slug":"ogg","link":"/tags/ogg/"},{"name":"ora-00132","slug":"ora-00132","link":"/tags/ora-00132/"},{"name":"ora-12514","slug":"ora-12514","link":"/tags/ora-12514/"},{"name":"ora-19511","slug":"ora-19511","link":"/tags/ora-19511/"},{"name":"ora01111","slug":"ora01111","link":"/tags/ora01111/"},{"name":"ora01119","slug":"ora01119","link":"/tags/ora01119/"},{"name":"datapump","slug":"datapump","link":"/tags/datapump/"},{"name":"recover","slug":"recover","link":"/tags/recover/"},{"name":"recovery","slug":"recovery","link":"/tags/recovery/"},{"name":"internal","slug":"internal","link":"/tags/internal/"},{"name":"upgrade","slug":"upgrade","link":"/tags/upgrade/"},{"name":"dns","slug":"dns","link":"/tags/dns/"},{"name":"solarized","slug":"solarized","link":"/tags/solarized/"},{"name":"spm","slug":"spm","link":"/tags/spm/"},{"name":"db2","slug":"db2","link":"/tags/db2/"},{"name":"audit","slug":"audit","link":"/tags/audit/"},{"name":"utility","slug":"utility","link":"/tags/utility/"},{"name":"markdown","slug":"markdown","link":"/tags/markdown/"}],"categories":[{"name":"oracle","slug":"oracle","link":"/categories/oracle/"},{"name":"db2","slug":"db2","link":"/categories/db2/"},{"name":"aix","slug":"aix","link":"/categories/aix/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"miscellaneous","slug":"miscellaneous","link":"/categories/miscellaneous/"},{"name":"database","slug":"database","link":"/categories/database/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"nbu","slug":"nbu","link":"/categories/nbu/"},{"name":"hpux","slug":"hpux","link":"/categories/hpux/"}]}